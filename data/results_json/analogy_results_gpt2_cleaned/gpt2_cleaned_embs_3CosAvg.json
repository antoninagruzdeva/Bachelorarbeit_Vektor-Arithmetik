[
  {
    "details": [
      {
        "question verbose": "What is to album ",
        "b": "album",
        "expected answer": [
          "albums"
        ],
        "predictions": [
          {
            "score": 0.9209121465682983,
            "answer": "albums",
            "hit": true
          },
          {
            "score": 0.8159455060958862,
            "answer": "songs",
            "hit": false
          },
          {
            "score": 0.7670267820358276,
            "answer": "lyrics",
            "hit": false
          },
          {
            "score": 0.7656721472740173,
            "answer": "concerts",
            "hit": false
          },
          {
            "score": 0.7610957622528076,
            "answer": "cds",
            "hit": false
          },
          {
            "score": 0.7571103572845459,
            "answer": "recordings",
            "hit": false
          }
        ],
        "set_exclude": [
          "album"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9209121763706207
      },
      {
        "question verbose": "What is to application ",
        "b": "application",
        "expected answer": [
          "applications"
        ],
        "predictions": [
          {
            "score": 0.8073426485061646,
            "answer": "applications",
            "hit": true
          },
          {
            "score": 0.756929874420166,
            "answer": "applicants",
            "hit": false
          },
          {
            "score": 0.7474900484085083,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7341473698616028,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.733917236328125,
            "answer": "apps",
            "hit": false
          },
          {
            "score": 0.7261139750480652,
            "answer": "implementations",
            "hit": false
          }
        ],
        "set_exclude": [
          "application"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8073427379131317
      },
      {
        "question verbose": "What is to area ",
        "b": "area",
        "expected answer": [
          "areas"
        ],
        "predictions": [
          {
            "score": 0.8224930763244629,
            "answer": "areas",
            "hit": true
          },
          {
            "score": 0.7676344513893127,
            "answer": "regions",
            "hit": false
          },
          {
            "score": 0.7541030645370483,
            "answer": "vicinity",
            "hit": false
          },
          {
            "score": 0.7278398871421814,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.7267979979515076,
            "answer": "zones",
            "hit": false
          },
          {
            "score": 0.7174240350723267,
            "answer": "districts",
            "hit": false
          }
        ],
        "set_exclude": [
          "area"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8224930763244629
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "cars"
        ],
        "predictions": [
          {
            "score": 0.7624645829200745,
            "answer": "cars",
            "hit": true
          },
          {
            "score": 0.7480529546737671,
            "answer": "carol",
            "hit": false
          },
          {
            "score": 0.7409834861755371,
            "answer": "carroll",
            "hit": false
          },
          {
            "score": 0.7396333813667297,
            "answer": "carbon",
            "hit": false
          },
          {
            "score": 0.7389096617698669,
            "answer": "caroline",
            "hit": false
          },
          {
            "score": 0.7329840064048767,
            "answer": "carrie",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7624645829200745
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "colleges"
        ],
        "predictions": [
          {
            "score": 0.840587854385376,
            "answer": "colleges",
            "hit": true
          },
          {
            "score": 0.7760392427444458,
            "answer": "universities",
            "hit": false
          },
          {
            "score": 0.760488748550415,
            "answer": "campuses",
            "hit": false
          },
          {
            "score": 0.7548803091049194,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.7482249736785889,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.7460595369338989,
            "answer": "classrooms",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8405878841876984
      },
      {
        "question verbose": "What is to council ",
        "b": "council",
        "expected answer": [
          "councils"
        ],
        "predictions": [
          {
            "score": 0.8308075666427612,
            "answer": "councils",
            "hit": true
          },
          {
            "score": 0.7307940721511841,
            "answer": "commissioners",
            "hit": false
          },
          {
            "score": 0.7299075722694397,
            "answer": "schools",
            "hit": false
          },
          {
            "score": 0.728771984577179,
            "answer": "directors",
            "hit": false
          },
          {
            "score": 0.724745512008667,
            "answer": "officials",
            "hit": false
          },
          {
            "score": 0.7243456840515137,
            "answer": "ministers",
            "hit": false
          }
        ],
        "set_exclude": [
          "council"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8308075666427612
      },
      {
        "question verbose": "What is to customer ",
        "b": "customer",
        "expected answer": [
          "customers"
        ],
        "predictions": [
          {
            "score": 0.8303250074386597,
            "answer": "customers",
            "hit": true
          },
          {
            "score": 0.764258861541748,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.7597819566726685,
            "answer": "custom",
            "hit": false
          },
          {
            "score": 0.7547057867050171,
            "answer": "sales",
            "hit": false
          },
          {
            "score": 0.7543789744377136,
            "answer": "consumer",
            "hit": false
          },
          {
            "score": 0.7529337406158447,
            "answer": "retailers",
            "hit": false
          }
        ],
        "set_exclude": [
          "customer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8303250074386597
      },
      {
        "question verbose": "What is to day ",
        "b": "day",
        "expected answer": [
          "days"
        ],
        "predictions": [
          {
            "score": 0.7812051773071289,
            "answer": "days",
            "hit": true
          },
          {
            "score": 0.7353785634040833,
            "answer": "mornings",
            "hit": false
          },
          {
            "score": 0.7244662046432495,
            "answer": "tuesday",
            "hit": false
          },
          {
            "score": 0.7225257158279419,
            "answer": "friday",
            "hit": false
          },
          {
            "score": 0.7203134894371033,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.7193988561630249,
            "answer": "morning",
            "hit": false
          }
        ],
        "set_exclude": [
          "day"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7812052071094513
      },
      {
        "question verbose": "What is to death ",
        "b": "death",
        "expected answer": [
          "deaths"
        ],
        "predictions": [
          {
            "score": 0.8269845247268677,
            "answer": "deaths",
            "hit": true
          },
          {
            "score": 0.7737691402435303,
            "answer": "died",
            "hit": false
          },
          {
            "score": 0.7652788758277893,
            "answer": "kills",
            "hit": false
          },
          {
            "score": 0.764607310295105,
            "answer": "mortality",
            "hit": false
          },
          {
            "score": 0.7645843029022217,
            "answer": "murders",
            "hit": false
          },
          {
            "score": 0.7611462473869324,
            "answer": "killings",
            "hit": false
          }
        ],
        "set_exclude": [
          "death"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8269844651222229
      },
      {
        "question verbose": "What is to department ",
        "b": "department",
        "expected answer": [
          "departments"
        ],
        "predictions": [
          {
            "score": 0.8373934030532837,
            "answer": "departments",
            "hit": true
          },
          {
            "score": 0.808607280254364,
            "answer": "dept",
            "hit": false
          },
          {
            "score": 0.7700369954109192,
            "answer": "secretary",
            "hit": false
          },
          {
            "score": 0.7682227492332458,
            "answer": "agencies",
            "hit": false
          },
          {
            "score": 0.7679842710494995,
            "answer": "government",
            "hit": false
          },
          {
            "score": 0.762000322341919,
            "answer": "officers",
            "hit": false
          }
        ],
        "set_exclude": [
          "department"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8373934030532837
      },
      {
        "question verbose": "What is to development ",
        "b": "development",
        "expected answer": [
          "developments"
        ],
        "predictions": [
          {
            "score": 0.7789020538330078,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7750396132469177,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7685972452163696,
            "answer": "developments",
            "hit": true
          },
          {
            "score": 0.7587194442749023,
            "answer": "developers",
            "hit": false
          },
          {
            "score": 0.7557041049003601,
            "answer": "developmental",
            "hit": false
          },
          {
            "score": 0.7540957927703857,
            "answer": "building",
            "hit": false
          }
        ],
        "set_exclude": [
          "development"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.768597275018692
      },
      {
        "question verbose": "What is to difference ",
        "b": "difference",
        "expected answer": [
          "differences"
        ],
        "predictions": [
          {
            "score": 0.7888715267181396,
            "answer": "differences",
            "hit": true
          },
          {
            "score": 0.7531702518463135,
            "answer": "distinctions",
            "hit": false
          },
          {
            "score": 0.7484766840934753,
            "answer": "comparison",
            "hit": false
          },
          {
            "score": 0.7410116195678711,
            "answer": "different",
            "hit": false
          },
          {
            "score": 0.7397396564483643,
            "answer": "distinguishes",
            "hit": false
          },
          {
            "score": 0.737085223197937,
            "answer": "contrasts",
            "hit": false
          }
        ],
        "set_exclude": [
          "difference"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7888715267181396
      },
      {
        "question verbose": "What is to director ",
        "b": "director",
        "expected answer": [
          "directors"
        ],
        "predictions": [
          {
            "score": 0.8178017139434814,
            "answer": "directors",
            "hit": true
          },
          {
            "score": 0.7712908387184143,
            "answer": "filmmaker",
            "hit": false
          },
          {
            "score": 0.7684127688407898,
            "answer": "secretary",
            "hit": false
          },
          {
            "score": 0.7659224271774292,
            "answer": "filmmakers",
            "hit": false
          },
          {
            "score": 0.76197350025177,
            "answer": "executive",
            "hit": false
          },
          {
            "score": 0.7539527416229248,
            "answer": "coordinator",
            "hit": false
          }
        ],
        "set_exclude": [
          "director"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8178017437458038
      },
      {
        "question verbose": "What is to event ",
        "b": "event",
        "expected answer": [
          "events"
        ],
        "predictions": [
          {
            "score": 0.835768461227417,
            "answer": "events",
            "hit": true
          },
          {
            "score": 0.7441920042037964,
            "answer": "tournaments",
            "hit": false
          },
          {
            "score": 0.7431221008300781,
            "answer": "incidents",
            "hit": false
          },
          {
            "score": 0.7402109503746033,
            "answer": "fest",
            "hit": false
          },
          {
            "score": 0.7327298521995544,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.732381284236908,
            "answer": "gatherings",
            "hit": false
          }
        ],
        "set_exclude": [
          "event"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.835768461227417
      },
      {
        "question verbose": "What is to example ",
        "b": "example",
        "expected answer": [
          "examples"
        ],
        "predictions": [
          {
            "score": 0.8329944610595703,
            "answer": "examples",
            "hit": true
          },
          {
            "score": 0.7554253339767456,
            "answer": "typical",
            "hit": false
          },
          {
            "score": 0.7383006811141968,
            "answer": "sample",
            "hit": false
          },
          {
            "score": 0.7352052330970764,
            "answer": "instances",
            "hit": false
          },
          {
            "score": 0.7313987612724304,
            "answer": "analogy",
            "hit": false
          },
          {
            "score": 0.7313944101333618,
            "answer": "comparison",
            "hit": false
          }
        ],
        "set_exclude": [
          "example"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8329944610595703
      },
      {
        "question verbose": "What is to fact ",
        "b": "fact",
        "expected answer": [
          "facts"
        ],
        "predictions": [
          {
            "score": 0.7456105947494507,
            "answer": "factors",
            "hit": false
          },
          {
            "score": 0.728218674659729,
            "answer": "facts",
            "hit": true
          },
          {
            "score": 0.7251570820808411,
            "answer": "truths",
            "hit": false
          },
          {
            "score": 0.7239333987236023,
            "answer": "truth",
            "hit": false
          },
          {
            "score": 0.7199370861053467,
            "answer": "factual",
            "hit": false
          },
          {
            "score": 0.7194742560386658,
            "answer": "realities",
            "hit": false
          }
        ],
        "set_exclude": [
          "fact"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7282186597585678
      },
      {
        "question verbose": "What is to friend ",
        "b": "friend",
        "expected answer": [
          "friends"
        ],
        "predictions": [
          {
            "score": 0.7777687907218933,
            "answer": "friends",
            "hit": true
          },
          {
            "score": 0.7672659158706665,
            "answer": "friendships",
            "hit": false
          },
          {
            "score": 0.7499731183052063,
            "answer": "buddy",
            "hit": false
          },
          {
            "score": 0.7451194524765015,
            "answer": "friendship",
            "hit": false
          },
          {
            "score": 0.7257163524627686,
            "answer": "companions",
            "hit": false
          },
          {
            "score": 0.7243528366088867,
            "answer": "comrades",
            "hit": false
          }
        ],
        "set_exclude": [
          "friend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7777687907218933
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "gods"
        ],
        "predictions": [
          {
            "score": 0.7652513980865479,
            "answer": "gods",
            "hit": true
          },
          {
            "score": 0.7440743446350098,
            "answer": "goddess",
            "hit": false
          },
          {
            "score": 0.732922375202179,
            "answer": "holy",
            "hit": false
          },
          {
            "score": 0.7324145436286926,
            "answer": "divine",
            "hit": false
          },
          {
            "score": 0.7318466901779175,
            "answer": "religions",
            "hit": false
          },
          {
            "score": 0.7281012535095215,
            "answer": "righteous",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7652513682842255
      },
      {
        "question verbose": "What is to government ",
        "b": "government",
        "expected answer": [
          "governments"
        ],
        "predictions": [
          {
            "score": 0.8467329740524292,
            "answer": "governments",
            "hit": true
          },
          {
            "score": 0.8364437222480774,
            "answer": "governmental",
            "hit": false
          },
          {
            "score": 0.7786884307861328,
            "answer": "politicians",
            "hit": false
          },
          {
            "score": 0.7753170132637024,
            "answer": "govern",
            "hit": false
          },
          {
            "score": 0.7742924690246582,
            "answer": "liberal",
            "hit": false
          },
          {
            "score": 0.7723643779754639,
            "answer": "ministers",
            "hit": false
          }
        ],
        "set_exclude": [
          "government"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.846733033657074
      },
      {
        "question verbose": "What is to hour ",
        "b": "hour",
        "expected answer": [
          "hours"
        ],
        "predictions": [
          {
            "score": 0.8435088992118835,
            "answer": "hours",
            "hit": true
          },
          {
            "score": 0.8114515542984009,
            "answer": "minute",
            "hit": false
          },
          {
            "score": 0.7514272332191467,
            "answer": "hourly",
            "hit": false
          },
          {
            "score": 0.7393959760665894,
            "answer": "days",
            "hit": false
          },
          {
            "score": 0.7389540672302246,
            "answer": "dozen",
            "hit": false
          },
          {
            "score": 0.7369182109832764,
            "answer": "years",
            "hit": false
          }
        ],
        "set_exclude": [
          "hour"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8435089290142059
      },
      {
        "question verbose": "What is to idea ",
        "b": "idea",
        "expected answer": [
          "ideas"
        ],
        "predictions": [
          {
            "score": 0.808078944683075,
            "answer": "ideas",
            "hit": true
          },
          {
            "score": 0.7582981586456299,
            "answer": "notions",
            "hit": false
          },
          {
            "score": 0.7520338296890259,
            "answer": "concepts",
            "hit": false
          },
          {
            "score": 0.742491602897644,
            "answer": "notion",
            "hit": false
          },
          {
            "score": 0.7390639781951904,
            "answer": "concept",
            "hit": false
          },
          {
            "score": 0.7364413738250732,
            "answer": "think",
            "hit": false
          }
        ],
        "set_exclude": [
          "idea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.808078944683075
      },
      {
        "question verbose": "What is to language ",
        "b": "language",
        "expected answer": [
          "languages"
        ],
        "predictions": [
          {
            "score": 0.806103527545929,
            "answer": "languages",
            "hit": true
          },
          {
            "score": 0.7798565030097961,
            "answer": "speaking",
            "hit": false
          },
          {
            "score": 0.7658372521400452,
            "answer": "linguistic",
            "hit": false
          },
          {
            "score": 0.7513127326965332,
            "answer": "translations",
            "hit": false
          },
          {
            "score": 0.735214352607727,
            "answer": "phrases",
            "hit": false
          },
          {
            "score": 0.7273160815238953,
            "answer": "tongues",
            "hit": false
          }
        ],
        "set_exclude": [
          "language"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.806103527545929
      },
      {
        "question verbose": "What is to law ",
        "b": "law",
        "expected answer": [
          "laws"
        ],
        "predictions": [
          {
            "score": 0.7819291949272156,
            "answer": "laws",
            "hit": true
          },
          {
            "score": 0.7743337154388428,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.7397321462631226,
            "answer": "attorneys",
            "hit": false
          },
          {
            "score": 0.7391893863677979,
            "answer": "statutes",
            "hit": false
          },
          {
            "score": 0.736935555934906,
            "answer": "lawyer",
            "hit": false
          },
          {
            "score": 0.7367926239967346,
            "answer": "lawsuits",
            "hit": false
          }
        ],
        "set_exclude": [
          "law"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.781929224729538
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "members"
        ],
        "predictions": [
          {
            "score": 0.7777349948883057,
            "answer": "members",
            "hit": true
          },
          {
            "score": 0.7510287165641785,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.7401562929153442,
            "answer": "chairman",
            "hit": false
          },
          {
            "score": 0.728050947189331,
            "answer": "countries",
            "hit": false
          },
          {
            "score": 0.7211282849311829,
            "answer": "mps",
            "hit": false
          },
          {
            "score": 0.7209631204605103,
            "answer": "governments",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7777349948883057
      },
      {
        "question verbose": "What is to month ",
        "b": "month",
        "expected answer": [
          "months"
        ],
        "predictions": [
          {
            "score": 0.8177491426467896,
            "answer": "months",
            "hit": true
          },
          {
            "score": 0.7667509317398071,
            "answer": "weeks",
            "hit": false
          },
          {
            "score": 0.7530342936515808,
            "answer": "days",
            "hit": false
          },
          {
            "score": 0.7447579503059387,
            "answer": "year",
            "hit": false
          },
          {
            "score": 0.738597571849823,
            "answer": "monthly",
            "hit": false
          },
          {
            "score": 0.7378600835800171,
            "answer": "seasons",
            "hit": false
          }
        ],
        "set_exclude": [
          "month"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8177491426467896
      },
      {
        "question verbose": "What is to night ",
        "b": "night",
        "expected answer": [
          "nights"
        ],
        "predictions": [
          {
            "score": 0.8733564019203186,
            "answer": "nights",
            "hit": true
          },
          {
            "score": 0.8631589412689209,
            "answer": "evening",
            "hit": false
          },
          {
            "score": 0.8141679763793945,
            "answer": "afternoon",
            "hit": false
          },
          {
            "score": 0.7890299558639526,
            "answer": "evenings",
            "hit": false
          },
          {
            "score": 0.7630971670150757,
            "answer": "weekend",
            "hit": false
          },
          {
            "score": 0.753166675567627,
            "answer": "midnight",
            "hit": false
          }
        ],
        "set_exclude": [
          "night"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.873356431722641
      },
      {
        "question verbose": "What is to office ",
        "b": "office",
        "expected answer": [
          "offices"
        ],
        "predictions": [
          {
            "score": 0.8131841421127319,
            "answer": "offices",
            "hit": true
          },
          {
            "score": 0.7518984079360962,
            "answer": "department",
            "hit": false
          },
          {
            "score": 0.7431555986404419,
            "answer": "departments",
            "hit": false
          },
          {
            "score": 0.7329663038253784,
            "answer": "apartments",
            "hit": false
          },
          {
            "score": 0.7307210564613342,
            "answer": "agencies",
            "hit": false
          },
          {
            "score": 0.7302899956703186,
            "answer": "documents",
            "hit": false
          }
        ],
        "set_exclude": [
          "office"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8131841719150543
      },
      {
        "question verbose": "What is to period ",
        "b": "period",
        "expected answer": [
          "periods"
        ],
        "predictions": [
          {
            "score": 0.8993529081344604,
            "answer": "periods",
            "hit": true
          },
          {
            "score": 0.7467593550682068,
            "answer": "eras",
            "hit": false
          },
          {
            "score": 0.7261381149291992,
            "answer": "phases",
            "hit": false
          },
          {
            "score": 0.7243037223815918,
            "answer": "interval",
            "hit": false
          },
          {
            "score": 0.7213563919067383,
            "answer": "epoch",
            "hit": false
          },
          {
            "score": 0.717436671257019,
            "answer": "decade",
            "hit": false
          }
        ],
        "set_exclude": [
          "period"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8993529677391052
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "players"
        ],
        "predictions": [
          {
            "score": 0.9155260920524597,
            "answer": "players",
            "hit": true
          },
          {
            "score": 0.7363414764404297,
            "answer": "midfielder",
            "hit": false
          },
          {
            "score": 0.7347593307495117,
            "answer": "footballer",
            "hit": false
          },
          {
            "score": 0.7296470403671265,
            "answer": "defender",
            "hit": false
          },
          {
            "score": 0.7249741554260254,
            "answer": "tournaments",
            "hit": false
          },
          {
            "score": 0.7206725478172302,
            "answer": "athlete",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9155260920524597
      },
      {
        "question verbose": "What is to population ",
        "b": "population",
        "expected answer": [
          "populations"
        ],
        "predictions": [
          {
            "score": 0.8232735395431519,
            "answer": "populations",
            "hit": true
          },
          {
            "score": 0.755286693572998,
            "answer": "demographics",
            "hit": false
          },
          {
            "score": 0.7468295097351074,
            "answer": "inhabitants",
            "hit": false
          },
          {
            "score": 0.7448053359985352,
            "answer": "breeding",
            "hit": false
          },
          {
            "score": 0.7382051944732666,
            "answer": "demographic",
            "hit": false
          },
          {
            "score": 0.7351152300834656,
            "answer": "immigration",
            "hit": false
          }
        ],
        "set_exclude": [
          "population"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8232735097408295
      },
      {
        "question verbose": "What is to problem ",
        "b": "problem",
        "expected answer": [
          "problems"
        ],
        "predictions": [
          {
            "score": 0.8224326968193054,
            "answer": "problems",
            "hit": true
          },
          {
            "score": 0.7670185565948486,
            "answer": "issues",
            "hit": false
          },
          {
            "score": 0.7578202486038208,
            "answer": "symptoms",
            "hit": false
          },
          {
            "score": 0.7492354512214661,
            "answer": "question",
            "hit": false
          },
          {
            "score": 0.7483203411102295,
            "answer": "unfortunately",
            "hit": false
          },
          {
            "score": 0.742326021194458,
            "answer": "problematic",
            "hit": false
          }
        ],
        "set_exclude": [
          "problem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8224326968193054
      },
      {
        "question verbose": "What is to product ",
        "b": "product",
        "expected answer": [
          "products"
        ],
        "predictions": [
          {
            "score": 0.8032393455505371,
            "answer": "products",
            "hit": true
          },
          {
            "score": 0.7253363728523254,
            "answer": "retailers",
            "hit": false
          },
          {
            "score": 0.7183755040168762,
            "answer": "suppliers",
            "hit": false
          },
          {
            "score": 0.7180130481719971,
            "answer": "distributors",
            "hit": false
          },
          {
            "score": 0.7160937786102295,
            "answer": "inventions",
            "hit": false
          },
          {
            "score": 0.715368390083313,
            "answer": "manufacturers",
            "hit": false
          }
        ],
        "set_exclude": [
          "product"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8032393753528595
      },
      {
        "question verbose": "What is to resource ",
        "b": "resource",
        "expected answer": [
          "resources"
        ],
        "predictions": [
          {
            "score": 0.7747054100036621,
            "answer": "resources",
            "hit": true
          },
          {
            "score": 0.7274289131164551,
            "answer": "policies",
            "hit": false
          },
          {
            "score": 0.7259714007377625,
            "answer": "organizations",
            "hit": false
          },
          {
            "score": 0.7212756872177124,
            "answer": "strategies",
            "hit": false
          },
          {
            "score": 0.7202962636947632,
            "answer": "policy",
            "hit": false
          },
          {
            "score": 0.7194603681564331,
            "answer": "strategic",
            "hit": false
          }
        ],
        "set_exclude": [
          "resource"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7747054398059845
      },
      {
        "question verbose": "What is to river ",
        "b": "river",
        "expected answer": [
          "rivers"
        ],
        "predictions": [
          {
            "score": 0.7165949940681458,
            "answer": "rivers",
            "hit": true
          },
          {
            "score": 0.7119113206863403,
            "answer": "downstream",
            "hit": false
          },
          {
            "score": 0.7065784335136414,
            "answer": "floods",
            "hit": false
          },
          {
            "score": 0.701503574848175,
            "answer": "inland",
            "hit": false
          },
          {
            "score": 0.701357364654541,
            "answer": "crossings",
            "hit": false
          },
          {
            "score": 0.6998336911201477,
            "answer": "dams",
            "hit": false
          }
        ],
        "set_exclude": [
          "river"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7165950238704681
      },
      {
        "question verbose": "What is to road ",
        "b": "road",
        "expected answer": [
          "roads"
        ],
        "predictions": [
          {
            "score": 0.8752768635749817,
            "answer": "roads",
            "hit": true
          },
          {
            "score": 0.7991186380386353,
            "answer": "roadway",
            "hit": false
          },
          {
            "score": 0.7931171655654907,
            "answer": "highways",
            "hit": false
          },
          {
            "score": 0.7519949674606323,
            "answer": "highway",
            "hit": false
          },
          {
            "score": 0.7409413456916809,
            "answer": "pavement",
            "hit": false
          },
          {
            "score": 0.7294634580612183,
            "answer": "paths",
            "hit": false
          }
        ],
        "set_exclude": [
          "road"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8752768039703369
      },
      {
        "question verbose": "What is to role ",
        "b": "role",
        "expected answer": [
          "roles"
        ],
        "predictions": [
          {
            "score": 0.806969165802002,
            "answer": "roles",
            "hit": true
          },
          {
            "score": 0.7196299433708191,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.7085464596748352,
            "answer": "genres",
            "hit": false
          },
          {
            "score": 0.7080133557319641,
            "answer": "fantasies",
            "hit": false
          },
          {
            "score": 0.7060295343399048,
            "answer": "configurations",
            "hit": false
          },
          {
            "score": 0.7056965827941895,
            "answer": "identities",
            "hit": false
          }
        ],
        "set_exclude": [
          "role"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.806969165802002
      },
      {
        "question verbose": "What is to science ",
        "b": "science",
        "expected answer": [
          "sciences"
        ],
        "predictions": [
          {
            "score": 0.8115023970603943,
            "answer": "scientific",
            "hit": false
          },
          {
            "score": 0.8048290610313416,
            "answer": "scientists",
            "hit": false
          },
          {
            "score": 0.7856083512306213,
            "answer": "sci",
            "hit": false
          },
          {
            "score": 0.7843328714370728,
            "answer": "sciences",
            "hit": true
          },
          {
            "score": 0.7820056676864624,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.764830470085144,
            "answer": "biology",
            "hit": false
          }
        ],
        "set_exclude": [
          "science"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7843329012393951
      },
      {
        "question verbose": "What is to solution ",
        "b": "solution",
        "expected answer": [
          "solutions"
        ],
        "predictions": [
          {
            "score": 0.7979381084442139,
            "answer": "solutions",
            "hit": true
          },
          {
            "score": 0.7966408133506775,
            "answer": "solve",
            "hit": false
          },
          {
            "score": 0.7667298316955566,
            "answer": "remedy",
            "hit": false
          },
          {
            "score": 0.7623899579048157,
            "answer": "solved",
            "hit": false
          },
          {
            "score": 0.7620549201965332,
            "answer": "solving",
            "hit": false
          },
          {
            "score": 0.7357024550437927,
            "answer": "answers",
            "hit": false
          }
        ],
        "set_exclude": [
          "solution"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7979381084442139
      },
      {
        "question verbose": "What is to song ",
        "b": "song",
        "expected answer": [
          "songs"
        ],
        "predictions": [
          {
            "score": 0.8402779698371887,
            "answer": "songs",
            "hit": true
          },
          {
            "score": 0.7653467059135437,
            "answer": "singers",
            "hit": false
          },
          {
            "score": 0.7634099125862122,
            "answer": "sings",
            "hit": false
          },
          {
            "score": 0.7599812746047974,
            "answer": "singing",
            "hit": false
          },
          {
            "score": 0.7553988695144653,
            "answer": "albums",
            "hit": false
          },
          {
            "score": 0.7543278336524963,
            "answer": "musicians",
            "hit": false
          }
        ],
        "set_exclude": [
          "song"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8402779996395111
      },
      {
        "question verbose": "What is to street ",
        "b": "street",
        "expected answer": [
          "streets"
        ],
        "predictions": [
          {
            "score": 0.817656934261322,
            "answer": "streets",
            "hit": true
          },
          {
            "score": 0.8149364590644836,
            "answer": "avenue",
            "hit": false
          },
          {
            "score": 0.7519625425338745,
            "answer": "boulevard",
            "hit": false
          },
          {
            "score": 0.7281946539878845,
            "answer": "drive",
            "hit": false
          },
          {
            "score": 0.7228637933731079,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.7213164567947388,
            "answer": "sidewalk",
            "hit": false
          }
        ],
        "set_exclude": [
          "street"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.817656934261322
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "students"
        ],
        "predictions": [
          {
            "score": 0.8456292748451233,
            "answer": "students",
            "hit": true
          },
          {
            "score": 0.7872215509414673,
            "answer": "classrooms",
            "hit": false
          },
          {
            "score": 0.7828478217124939,
            "answer": "campuses",
            "hit": false
          },
          {
            "score": 0.7826049327850342,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.7769277095794678,
            "answer": "universities",
            "hit": false
          },
          {
            "score": 0.772162139415741,
            "answer": "tuition",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8456292748451233
      },
      {
        "question verbose": "What is to system ",
        "b": "system",
        "expected answer": [
          "systems"
        ],
        "predictions": [
          {
            "score": 0.8362959623336792,
            "answer": "systems",
            "hit": true
          },
          {
            "score": 0.7365484833717346,
            "answer": "ecosystems",
            "hit": false
          },
          {
            "score": 0.7346768379211426,
            "answer": "sciences",
            "hit": false
          },
          {
            "score": 0.7281875610351562,
            "answer": "mechanisms",
            "hit": false
          },
          {
            "score": 0.7274767756462097,
            "answer": "processes",
            "hit": false
          },
          {
            "score": 0.7265239953994751,
            "answer": "technologies",
            "hit": false
          }
        ],
        "set_exclude": [
          "system"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8362959623336792
      },
      {
        "question verbose": "What is to thing ",
        "b": "thing",
        "expected answer": [
          "things"
        ],
        "predictions": [
          {
            "score": 0.7649174928665161,
            "answer": "things",
            "hit": true
          },
          {
            "score": 0.7322896718978882,
            "answer": "inventions",
            "hit": false
          },
          {
            "score": 0.7130876183509827,
            "answer": "ones",
            "hit": false
          },
          {
            "score": 0.7104072570800781,
            "answer": "dude",
            "hit": false
          },
          {
            "score": 0.7037178874015808,
            "answer": "substances",
            "hit": false
          },
          {
            "score": 0.703014612197876,
            "answer": "tangible",
            "hit": false
          }
        ],
        "set_exclude": [
          "thing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7649174928665161
      },
      {
        "question verbose": "What is to town ",
        "b": "town",
        "expected answer": [
          "towns"
        ],
        "predictions": [
          {
            "score": 0.8130232691764832,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.8031307458877563,
            "answer": "village",
            "hit": false
          },
          {
            "score": 0.7937291860580444,
            "answer": "villages",
            "hit": false
          },
          {
            "score": 0.7589698433876038,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.7579885721206665,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.7573373913764954,
            "answer": "hometown",
            "hit": false
          }
        ],
        "set_exclude": [
          "town"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7426073849201202
      },
      {
        "question verbose": "What is to user ",
        "b": "user",
        "expected answer": [
          "users"
        ],
        "predictions": [
          {
            "score": 0.7845890522003174,
            "answer": "users",
            "hit": true
          },
          {
            "score": 0.7244918346405029,
            "answer": "customers",
            "hit": false
          },
          {
            "score": 0.7233085632324219,
            "answer": "player",
            "hit": false
          },
          {
            "score": 0.7229115962982178,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.720344066619873,
            "answer": "developer",
            "hit": false
          },
          {
            "score": 0.7184205651283264,
            "answer": "programmer",
            "hit": false
          }
        ],
        "set_exclude": [
          "user"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7845890522003174
      },
      {
        "question verbose": "What is to version ",
        "b": "version",
        "expected answer": [
          "versions"
        ],
        "predictions": [
          {
            "score": 0.7547961473464966,
            "answer": "implementations",
            "hit": false
          },
          {
            "score": 0.7546176910400391,
            "answer": "versions",
            "hit": true
          },
          {
            "score": 0.7445797920227051,
            "answer": "variants",
            "hit": false
          },
          {
            "score": 0.7433940768241882,
            "answer": "editions",
            "hit": false
          },
          {
            "score": 0.7403117418289185,
            "answer": "features",
            "hit": false
          },
          {
            "score": 0.7380532622337341,
            "answer": "revisions",
            "hit": false
          }
        ],
        "set_exclude": [
          "version"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7546177208423615
      },
      {
        "question verbose": "What is to village ",
        "b": "village",
        "expected answer": [
          "villages"
        ],
        "predictions": [
          {
            "score": 0.9126952886581421,
            "answer": "villages",
            "hit": true
          },
          {
            "score": 0.8436785340309143,
            "answer": "villagers",
            "hit": false
          },
          {
            "score": 0.799146294593811,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.7623496651649475,
            "answer": "tribe",
            "hit": false
          },
          {
            "score": 0.7595282196998596,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.7591533660888672,
            "answer": "city",
            "hit": false
          }
        ],
        "set_exclude": [
          "village"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9126952886581421
      },
      {
        "question verbose": "What is to website ",
        "b": "website",
        "expected answer": [
          "websites"
        ],
        "predictions": [
          {
            "score": 0.9093168377876282,
            "answer": "websites",
            "hit": true
          },
          {
            "score": 0.7683537006378174,
            "answer": "www",
            "hit": false
          },
          {
            "score": 0.7683343887329102,
            "answer": "blogs",
            "hit": false
          },
          {
            "score": 0.7499244809150696,
            "answer": "sites",
            "hit": false
          },
          {
            "score": 0.7452768087387085,
            "answer": "emails",
            "hit": false
          },
          {
            "score": 0.7431672811508179,
            "answer": "facebook",
            "hit": false
          }
        ],
        "set_exclude": [
          "website"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9093168377876282
      },
      {
        "question verbose": "What is to week ",
        "b": "week",
        "expected answer": [
          "weeks"
        ],
        "predictions": [
          {
            "score": 0.7563978433609009,
            "answer": "weeks",
            "hit": true
          },
          {
            "score": 0.7448081970214844,
            "answer": "weekend",
            "hit": false
          },
          {
            "score": 0.7441496849060059,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.7439504265785217,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.7396917343139648,
            "answer": "weekends",
            "hit": false
          },
          {
            "score": 0.7388841509819031,
            "answer": "days",
            "hit": false
          }
        ],
        "set_exclude": [
          "week"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7563978135585785
      },
      {
        "question verbose": "What is to year ",
        "b": "year",
        "expected answer": [
          "years"
        ],
        "predictions": [
          {
            "score": 0.7981586456298828,
            "answer": "years",
            "hit": true
          },
          {
            "score": 0.7822901010513306,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.7715907096862793,
            "answer": "days",
            "hit": false
          },
          {
            "score": 0.7649568319320679,
            "answer": "seasons",
            "hit": false
          },
          {
            "score": 0.761931836605072,
            "answer": "yearly",
            "hit": false
          },
          {
            "score": 0.756100594997406,
            "answer": "month",
            "hit": false
          }
        ],
        "set_exclude": [
          "year"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7981586456298828
      }
    ],
    "result": {
      "cnt_questions_correct": 45,
      "cnt_questions_total": 50,
      "accuracy": 0.9
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I01 [noun - plural_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "5249af75-21df-4906-b35e-41ba53f88c53",
      "timestamp": "2025-05-17T17:12:45.063711"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ability ",
        "b": "ability",
        "expected answer": [
          "abilities"
        ],
        "predictions": [
          {
            "score": 0.8344764113426208,
            "answer": "abilities",
            "hit": true
          },
          {
            "score": 0.8067185282707214,
            "answer": "able",
            "hit": false
          },
          {
            "score": 0.7068329453468323,
            "answer": "capabilities",
            "hit": false
          },
          {
            "score": 0.7016856074333191,
            "answer": "reliability",
            "hit": false
          },
          {
            "score": 0.6972573399543762,
            "answer": "accessibility",
            "hit": false
          },
          {
            "score": 0.6966389417648315,
            "answer": "compatibility",
            "hit": false
          }
        ],
        "set_exclude": [
          "ability"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8344764113426208
      },
      {
        "question verbose": "What is to activity ",
        "b": "activity",
        "expected answer": [
          "activities"
        ],
        "predictions": [
          {
            "score": 0.8523703813552856,
            "answer": "activities",
            "hit": true
          },
          {
            "score": 0.7360212802886963,
            "answer": "behaviors",
            "hit": false
          },
          {
            "score": 0.7318863868713379,
            "answer": "transactions",
            "hit": false
          },
          {
            "score": 0.7248585224151611,
            "answer": "applications",
            "hit": false
          },
          {
            "score": 0.7205660343170166,
            "answer": "functions",
            "hit": false
          },
          {
            "score": 0.7168384790420532,
            "answer": "expenditures",
            "hit": false
          }
        ],
        "set_exclude": [
          "activity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8523704409599304
      },
      {
        "question verbose": "What is to agency ",
        "b": "agency",
        "expected answer": [
          "agencies"
        ],
        "predictions": [
          {
            "score": 0.8433043956756592,
            "answer": "agencies",
            "hit": true
          },
          {
            "score": 0.7764220833778381,
            "answer": "agents",
            "hit": false
          },
          {
            "score": 0.7471819519996643,
            "answer": "departments",
            "hit": false
          },
          {
            "score": 0.7450486421585083,
            "answer": "organizations",
            "hit": false
          },
          {
            "score": 0.7435053586959839,
            "answer": "contractors",
            "hit": false
          },
          {
            "score": 0.7409829497337341,
            "answer": "enforcement",
            "hit": false
          }
        ],
        "set_exclude": [
          "agency"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8433043956756592
      },
      {
        "question verbose": "What is to analysis ",
        "b": "analysis",
        "expected answer": [
          "analyses"
        ],
        "predictions": [
          {
            "score": 0.8102338314056396,
            "answer": "analyses",
            "hit": true
          },
          {
            "score": 0.7676103115081787,
            "answer": "analyze",
            "hit": false
          },
          {
            "score": 0.7629231214523315,
            "answer": "analyzing",
            "hit": false
          },
          {
            "score": 0.7552300691604614,
            "answer": "analytical",
            "hit": false
          },
          {
            "score": 0.7522291541099548,
            "answer": "analyzed",
            "hit": false
          },
          {
            "score": 0.7516821622848511,
            "answer": "analytic",
            "hit": false
          }
        ],
        "set_exclude": [
          "analysis"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8102338314056396
      },
      {
        "question verbose": "What is to army ",
        "b": "army",
        "expected answer": [
          "armies"
        ],
        "predictions": [
          {
            "score": 0.8059713244438171,
            "answer": "armies",
            "hit": true
          },
          {
            "score": 0.8055039644241333,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.7901368737220764,
            "answer": "military",
            "hit": false
          },
          {
            "score": 0.7781081199645996,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.7613826990127563,
            "answer": "infantry",
            "hit": false
          },
          {
            "score": 0.751715362071991,
            "answer": "generals",
            "hit": false
          }
        ],
        "set_exclude": [
          "army"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8059713244438171
      },
      {
        "question verbose": "What is to authority ",
        "b": "authority",
        "expected answer": [
          "authorities"
        ],
        "predictions": [
          {
            "score": 0.7743992805480957,
            "answer": "authorities",
            "hit": true
          },
          {
            "score": 0.7243568301200867,
            "answer": "authoritative",
            "hit": false
          },
          {
            "score": 0.7192173600196838,
            "answer": "officials",
            "hit": false
          },
          {
            "score": 0.718589186668396,
            "answer": "agencies",
            "hit": false
          },
          {
            "score": 0.7182320356369019,
            "answer": "governments",
            "hit": false
          },
          {
            "score": 0.7172399759292603,
            "answer": "appeals",
            "hit": false
          }
        ],
        "set_exclude": [
          "authority"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7743992805480957
      },
      {
        "question verbose": "What is to basis ",
        "b": "basis",
        "expected answer": [
          "bases"
        ],
        "predictions": [
          {
            "score": 0.7382177710533142,
            "answer": "bases",
            "hit": true
          },
          {
            "score": 0.7374413013458252,
            "answer": "foundations",
            "hit": false
          },
          {
            "score": 0.7285358905792236,
            "answer": "premise",
            "hit": false
          },
          {
            "score": 0.7281712293624878,
            "answer": "backbone",
            "hit": false
          },
          {
            "score": 0.7236783504486084,
            "answer": "justification",
            "hit": false
          },
          {
            "score": 0.7167279720306396,
            "answer": "assumption",
            "hit": false
          }
        ],
        "set_exclude": [
          "basis"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7382177412509918
      },
      {
        "question verbose": "What is to business ",
        "b": "business",
        "expected answer": [
          "businesses"
        ],
        "predictions": [
          {
            "score": 0.850550651550293,
            "answer": "businesses",
            "hit": true
          },
          {
            "score": 0.7675905227661133,
            "answer": "entrepreneurs",
            "hit": false
          },
          {
            "score": 0.7658113837242126,
            "answer": "corporate",
            "hit": false
          },
          {
            "score": 0.7559836506843567,
            "answer": "corporations",
            "hit": false
          },
          {
            "score": 0.7440804243087769,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.7339089512825012,
            "answer": "businessman",
            "hit": false
          }
        ],
        "set_exclude": [
          "business"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.850550651550293
      },
      {
        "question verbose": "What is to category ",
        "b": "category",
        "expected answer": [
          "categories"
        ],
        "predictions": [
          {
            "score": 0.7763280868530273,
            "answer": "categories",
            "hit": true
          },
          {
            "score": 0.7569149136543274,
            "answer": "genres",
            "hit": false
          },
          {
            "score": 0.7517377138137817,
            "answer": "categorized",
            "hit": false
          },
          {
            "score": 0.7364193797111511,
            "answer": "listings",
            "hit": false
          },
          {
            "score": 0.7345615029335022,
            "answer": "classify",
            "hit": false
          },
          {
            "score": 0.7323821783065796,
            "answer": "genre",
            "hit": false
          }
        ],
        "set_exclude": [
          "category"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7763281464576721
      },
      {
        "question verbose": "What is to century ",
        "b": "century",
        "expected answer": [
          "centuries"
        ],
        "predictions": [
          {
            "score": 0.809655487537384,
            "answer": "centuries",
            "hit": true
          },
          {
            "score": 0.7799628973007202,
            "answer": "millennium",
            "hit": false
          },
          {
            "score": 0.7775651812553406,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.7684641480445862,
            "answer": "decades",
            "hit": false
          },
          {
            "score": 0.7416996359825134,
            "answer": "dozen",
            "hit": false
          },
          {
            "score": 0.7409530878067017,
            "answer": "historians",
            "hit": false
          }
        ],
        "set_exclude": [
          "century"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8096555173397064
      },
      {
        "question verbose": "What is to child ",
        "b": "child",
        "expected answer": [
          "children"
        ],
        "predictions": [
          {
            "score": 0.7798771858215332,
            "answer": "children",
            "hit": true
          },
          {
            "score": 0.777431070804596,
            "answer": "kids",
            "hit": false
          },
          {
            "score": 0.7391186952590942,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.7383599281311035,
            "answer": "infants",
            "hit": false
          },
          {
            "score": 0.7329010963439941,
            "answer": "childhood",
            "hit": false
          },
          {
            "score": 0.7303990125656128,
            "answer": "parents",
            "hit": false
          }
        ],
        "set_exclude": [
          "child"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7798771858215332
      },
      {
        "question verbose": "What is to city ",
        "b": "city",
        "expected answer": [
          "cities"
        ],
        "predictions": [
          {
            "score": 0.8148713111877441,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.7897095084190369,
            "answer": "cities",
            "hit": true
          },
          {
            "score": 0.7887250781059265,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.7812556624412537,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.7770642638206482,
            "answer": "mayor",
            "hit": false
          },
          {
            "score": 0.7721530199050903,
            "answer": "municipality",
            "hit": false
          }
        ],
        "set_exclude": [
          "city"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7897095382213593
      },
      {
        "question verbose": "What is to community ",
        "b": "community",
        "expected answer": [
          "communities"
        ],
        "predictions": [
          {
            "score": 0.7853526473045349,
            "answer": "communities",
            "hit": true
          },
          {
            "score": 0.7571449279785156,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.7450237274169922,
            "answer": "ecosystem",
            "hit": false
          },
          {
            "score": 0.7357873916625977,
            "answer": "residents",
            "hit": false
          },
          {
            "score": 0.7286276817321777,
            "answer": "families",
            "hit": false
          },
          {
            "score": 0.7285894155502319,
            "answer": "grassroots",
            "hit": false
          }
        ],
        "set_exclude": [
          "community"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7853526771068573
      },
      {
        "question verbose": "What is to country ",
        "b": "country",
        "expected answer": [
          "countries"
        ],
        "predictions": [
          {
            "score": 0.87126225233078,
            "answer": "nation",
            "hit": false
          },
          {
            "score": 0.8640073537826538,
            "answer": "countries",
            "hit": true
          },
          {
            "score": 0.8022763133049011,
            "answer": "nations",
            "hit": false
          },
          {
            "score": 0.7601940631866455,
            "answer": "continent",
            "hit": false
          },
          {
            "score": 0.7453299164772034,
            "answer": "provinces",
            "hit": false
          },
          {
            "score": 0.7423242330551147,
            "answer": "city",
            "hit": false
          }
        ],
        "set_exclude": [
          "country"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8640073537826538
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "counties"
        ],
        "predictions": [
          {
            "score": 0.8522142171859741,
            "answer": "counties",
            "hit": true
          },
          {
            "score": 0.7745211124420166,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.7542035579681396,
            "answer": "sheriff",
            "hit": false
          },
          {
            "score": 0.7483712434768677,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.7319958806037903,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.728515625,
            "answer": "parish",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8522142469882965
      },
      {
        "question verbose": "What is to duty ",
        "b": "duty",
        "expected answer": [
          "duties"
        ],
        "predictions": [
          {
            "score": 0.7891147136688232,
            "answer": "duties",
            "hit": true
          },
          {
            "score": 0.7473400831222534,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.7448702454566956,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.7339263558387756,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.7186339497566223,
            "answer": "responsibility",
            "hit": false
          },
          {
            "score": 0.7153406143188477,
            "answer": "functions",
            "hit": false
          }
        ],
        "set_exclude": [
          "duty"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7891147136688232
      },
      {
        "question verbose": "What is to economy ",
        "b": "economy",
        "expected answer": [
          "economies"
        ],
        "predictions": [
          {
            "score": 0.8150861263275146,
            "answer": "economies",
            "hit": true
          },
          {
            "score": 0.7558409571647644,
            "answer": "economic",
            "hit": false
          },
          {
            "score": 0.7531513571739197,
            "answer": "economists",
            "hit": false
          },
          {
            "score": 0.7435119152069092,
            "answer": "economics",
            "hit": false
          },
          {
            "score": 0.7417434453964233,
            "answer": "economical",
            "hit": false
          },
          {
            "score": 0.7323387861251831,
            "answer": "agriculture",
            "hit": false
          }
        ],
        "set_exclude": [
          "economy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8150861263275146
      },
      {
        "question verbose": "What is to energy ",
        "b": "energy",
        "expected answer": [
          "energies"
        ],
        "predictions": [
          {
            "score": 0.8221879601478577,
            "answer": "energies",
            "hit": true
          },
          {
            "score": 0.7593302726745605,
            "answer": "energetic",
            "hit": false
          },
          {
            "score": 0.754940390586853,
            "answer": "electricity",
            "hit": false
          },
          {
            "score": 0.74310702085495,
            "answer": "intensity",
            "hit": false
          },
          {
            "score": 0.7382100820541382,
            "answer": "fuels",
            "hit": false
          },
          {
            "score": 0.7368467450141907,
            "answer": "emissions",
            "hit": false
          }
        ],
        "set_exclude": [
          "energy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8221880197525024
      },
      {
        "question verbose": "What is to entry ",
        "b": "entry",
        "expected answer": [
          "entries"
        ],
        "predictions": [
          {
            "score": 0.8072308897972107,
            "answer": "entries",
            "hit": true
          },
          {
            "score": 0.7218437790870667,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.721800684928894,
            "answer": "leave",
            "hit": false
          },
          {
            "score": 0.7162541747093201,
            "answer": "establishments",
            "hit": false
          },
          {
            "score": 0.7158688306808472,
            "answer": "aside",
            "hit": false
          },
          {
            "score": 0.7151564359664917,
            "answer": "enters",
            "hit": false
          }
        ],
        "set_exclude": [
          "entry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8072308897972107
      },
      {
        "question verbose": "What is to facility ",
        "b": "facility",
        "expected answer": [
          "facilities"
        ],
        "predictions": [
          {
            "score": 0.8178290128707886,
            "answer": "facilities",
            "hit": true
          },
          {
            "score": 0.7553268671035767,
            "answer": "venues",
            "hit": false
          },
          {
            "score": 0.7504884004592896,
            "answer": "establishments",
            "hit": false
          },
          {
            "score": 0.748438835144043,
            "answer": "amenities",
            "hit": false
          },
          {
            "score": 0.7474859356880188,
            "answer": "capabilities",
            "hit": false
          },
          {
            "score": 0.7405226230621338,
            "answer": "equipment",
            "hit": false
          }
        ],
        "set_exclude": [
          "facility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8178289830684662
      },
      {
        "question verbose": "What is to family ",
        "b": "family",
        "expected answer": [
          "families"
        ],
        "predictions": [
          {
            "score": 0.8198183178901672,
            "answer": "families",
            "hit": true
          },
          {
            "score": 0.7971185445785522,
            "answer": "relatives",
            "hit": false
          },
          {
            "score": 0.7834662795066833,
            "answer": "parents",
            "hit": false
          },
          {
            "score": 0.7572576999664307,
            "answer": "siblings",
            "hit": false
          },
          {
            "score": 0.7571307420730591,
            "answer": "daughters",
            "hit": false
          },
          {
            "score": 0.745945394039154,
            "answer": "marriages",
            "hit": false
          }
        ],
        "set_exclude": [
          "family"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8198182582855225
      },
      {
        "question verbose": "What is to history ",
        "b": "history",
        "expected answer": [
          "histories"
        ],
        "predictions": [
          {
            "score": 0.8364522457122803,
            "answer": "histories",
            "hit": true
          },
          {
            "score": 0.7861911654472351,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.748469889163971,
            "answer": "historical",
            "hit": false
          },
          {
            "score": 0.747856080532074,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.7445732355117798,
            "answer": "events",
            "hit": false
          },
          {
            "score": 0.7398645281791687,
            "answer": "overview",
            "hit": false
          }
        ],
        "set_exclude": [
          "history"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8364522457122803
      },
      {
        "question verbose": "What is to industry ",
        "b": "industry",
        "expected answer": [
          "industries"
        ],
        "predictions": [
          {
            "score": 0.7888004183769226,
            "answer": "industries",
            "hit": true
          },
          {
            "score": 0.7663040161132812,
            "answer": "manufacturers",
            "hit": false
          },
          {
            "score": 0.7592542767524719,
            "answer": "businesses",
            "hit": false
          },
          {
            "score": 0.7551825642585754,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.7505149841308594,
            "answer": "industrial",
            "hit": false
          },
          {
            "score": 0.7503045797348022,
            "answer": "firms",
            "hit": false
          }
        ],
        "set_exclude": [
          "industry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7888004183769226
      },
      {
        "question verbose": "What is to library ",
        "b": "library",
        "expected answer": [
          "libraries"
        ],
        "predictions": [
          {
            "score": 0.812518835067749,
            "answer": "libraries",
            "hit": true
          },
          {
            "score": 0.7464247941970825,
            "answer": "databases",
            "hit": false
          },
          {
            "score": 0.7372033596038818,
            "answer": "manuscripts",
            "hit": false
          },
          {
            "score": 0.7344738245010376,
            "answer": "museums",
            "hit": false
          },
          {
            "score": 0.7305370569229126,
            "answer": "directory",
            "hit": false
          },
          {
            "score": 0.7289650440216064,
            "answer": "churches",
            "hit": false
          }
        ],
        "set_exclude": [
          "library"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8125188946723938
      },
      {
        "question verbose": "What is to life ",
        "b": "life",
        "expected answer": [
          "lives"
        ],
        "predictions": [
          {
            "score": 0.7263481616973877,
            "answer": "lives",
            "hit": true
          },
          {
            "score": 0.7235909104347229,
            "answer": "lifespan",
            "hit": false
          },
          {
            "score": 0.717635989189148,
            "answer": "careers",
            "hit": false
          },
          {
            "score": 0.716964840888977,
            "answer": "choice",
            "hit": false
          },
          {
            "score": 0.713093638420105,
            "answer": "living",
            "hit": false
          },
          {
            "score": 0.7129583358764648,
            "answer": "ecosystems",
            "hit": false
          }
        ],
        "set_exclude": [
          "life"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7263482064008713
      },
      {
        "question verbose": "What is to loss ",
        "b": "loss",
        "expected answer": [
          "losses"
        ],
        "predictions": [
          {
            "score": 0.8848258256912231,
            "answer": "losses",
            "hit": true
          },
          {
            "score": 0.7957249879837036,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7811530828475952,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7413261532783508,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.7307606935501099,
            "answer": "defeats",
            "hit": false
          },
          {
            "score": 0.7300611734390259,
            "answer": "destruction",
            "hit": false
          }
        ],
        "set_exclude": [
          "loss"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8848258852958679
      },
      {
        "question verbose": "What is to memory ",
        "b": "memory",
        "expected answer": [
          "memories"
        ],
        "predictions": [
          {
            "score": 0.8032587766647339,
            "answer": "memories",
            "hit": true
          },
          {
            "score": 0.7543145418167114,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.7461673021316528,
            "answer": "databases",
            "hit": false
          },
          {
            "score": 0.7385551929473877,
            "answer": "cognition",
            "hit": false
          },
          {
            "score": 0.7367569804191589,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.7313101291656494,
            "answer": "libraries",
            "hit": false
          }
        ],
        "set_exclude": [
          "memory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8032588064670563
      },
      {
        "question verbose": "What is to opportunity ",
        "b": "opportunity",
        "expected answer": [
          "opportunities"
        ],
        "predictions": [
          {
            "score": 0.9052647948265076,
            "answer": "opportunities",
            "hit": true
          },
          {
            "score": 0.7447993755340576,
            "answer": "possibilities",
            "hit": false
          },
          {
            "score": 0.7439043521881104,
            "answer": "possibility",
            "hit": false
          },
          {
            "score": 0.7386984825134277,
            "answer": "chances",
            "hit": false
          },
          {
            "score": 0.7301309108734131,
            "answer": "advantages",
            "hit": false
          },
          {
            "score": 0.7244645357131958,
            "answer": "prospects",
            "hit": false
          }
        ],
        "set_exclude": [
          "opportunity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9052647650241852
      },
      {
        "question verbose": "What is to policy ",
        "b": "policy",
        "expected answer": [
          "policies"
        ],
        "predictions": [
          {
            "score": 0.8734863996505737,
            "answer": "policies",
            "hit": true
          },
          {
            "score": 0.7575207948684692,
            "answer": "strategies",
            "hit": false
          },
          {
            "score": 0.7444677352905273,
            "answer": "initiatives",
            "hit": false
          },
          {
            "score": 0.7394939661026001,
            "answer": "issues",
            "hit": false
          },
          {
            "score": 0.7384092807769775,
            "answer": "officials",
            "hit": false
          },
          {
            "score": 0.73764568567276,
            "answer": "guidelines",
            "hit": false
          }
        ],
        "set_exclude": [
          "policy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8734864294528961
      },
      {
        "question verbose": "What is to property ",
        "b": "property",
        "expected answer": [
          "properties"
        ],
        "predictions": [
          {
            "score": 0.7869551181793213,
            "answer": "properties",
            "hit": true
          },
          {
            "score": 0.7460004091262817,
            "answer": "rents",
            "hit": false
          },
          {
            "score": 0.7428798675537109,
            "answer": "estates",
            "hit": false
          },
          {
            "score": 0.7424508333206177,
            "answer": "tenants",
            "hit": false
          },
          {
            "score": 0.7397568225860596,
            "answer": "belongings",
            "hit": false
          },
          {
            "score": 0.7376078367233276,
            "answer": "neighborhoods",
            "hit": false
          }
        ],
        "set_exclude": [
          "property"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7869551181793213
      },
      {
        "question verbose": "What is to responsibility ",
        "b": "responsibility",
        "expected answer": [
          "responsibilities"
        ],
        "predictions": [
          {
            "score": 0.8028014302253723,
            "answer": "responsibilities",
            "hit": true
          },
          {
            "score": 0.7566326856613159,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.7518857717514038,
            "answer": "accountability",
            "hit": false
          },
          {
            "score": 0.7359856367111206,
            "answer": "principles",
            "hit": false
          },
          {
            "score": 0.7346206307411194,
            "answer": "statements",
            "hit": false
          },
          {
            "score": 0.7338006496429443,
            "answer": "policies",
            "hit": false
          }
        ],
        "set_exclude": [
          "responsibility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8028014302253723
      },
      {
        "question verbose": "What is to security ",
        "b": "security",
        "expected answer": [
          "securities"
        ],
        "predictions": [
          {
            "score": 0.7620635032653809,
            "answer": "secure",
            "hit": false
          },
          {
            "score": 0.7552751898765564,
            "answer": "investigators",
            "hit": false
          },
          {
            "score": 0.7501398921012878,
            "answer": "officers",
            "hit": false
          },
          {
            "score": 0.749435544013977,
            "answer": "encryption",
            "hit": false
          },
          {
            "score": 0.7449997663497925,
            "answer": "terrorists",
            "hit": false
          },
          {
            "score": 0.7443583011627197,
            "answer": "terrorism",
            "hit": false
          }
        ],
        "set_exclude": [
          "security"
        ],
        "rank": 189,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.706178829073906
      },
      {
        "question verbose": "What is to series ",
        "b": "series",
        "expected answer": [
          "series"
        ],
        "predictions": [
          {
            "score": 0.7134042978286743,
            "answer": "trilogy",
            "hit": false
          },
          {
            "score": 0.7116161584854126,
            "answer": "episodes",
            "hit": false
          },
          {
            "score": 0.7029331922531128,
            "answer": "season",
            "hit": false
          },
          {
            "score": 0.7016812562942505,
            "answer": "varieties",
            "hit": false
          },
          {
            "score": 0.7007917761802673,
            "answer": "seasons",
            "hit": false
          },
          {
            "score": 0.7004580497741699,
            "answer": "collections",
            "hit": false
          }
        ],
        "set_exclude": [
          "series"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9793744087219238
      },
      {
        "question verbose": "What is to society ",
        "b": "society",
        "expected answer": [
          "societies"
        ],
        "predictions": [
          {
            "score": 0.898961067199707,
            "answer": "societies",
            "hit": true
          },
          {
            "score": 0.8196141719818115,
            "answer": "societal",
            "hit": false
          },
          {
            "score": 0.7815202474594116,
            "answer": "civilization",
            "hit": false
          },
          {
            "score": 0.7662293910980225,
            "answer": "soc",
            "hit": false
          },
          {
            "score": 0.7542431354522705,
            "answer": "institutions",
            "hit": false
          },
          {
            "score": 0.7485347986221313,
            "answer": "cultures",
            "hit": false
          }
        ],
        "set_exclude": [
          "society"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.898961067199707
      },
      {
        "question verbose": "What is to species ",
        "b": "species",
        "expected answer": [
          "species"
        ],
        "predictions": [
          {
            "score": 0.7691657543182373,
            "answer": "varieties",
            "hit": false
          },
          {
            "score": 0.7690688371658325,
            "answer": "habitats",
            "hit": false
          },
          {
            "score": 0.7623932957649231,
            "answer": "breeds",
            "hit": false
          },
          {
            "score": 0.759096622467041,
            "answer": "biodiversity",
            "hit": false
          },
          {
            "score": 0.759059488773346,
            "answer": "genus",
            "hit": false
          },
          {
            "score": 0.758147120475769,
            "answer": "organisms",
            "hit": false
          }
        ],
        "set_exclude": [
          "species"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9803034663200378
      },
      {
        "question verbose": "What is to story ",
        "b": "story",
        "expected answer": [
          "stories"
        ],
        "predictions": [
          {
            "score": 0.8085325956344604,
            "answer": "stories",
            "hit": true
          },
          {
            "score": 0.7866445183753967,
            "answer": "narratives",
            "hit": false
          },
          {
            "score": 0.7690232992172241,
            "answer": "storyline",
            "hit": false
          },
          {
            "score": 0.7687207460403442,
            "answer": "storytelling",
            "hit": false
          },
          {
            "score": 0.7557148933410645,
            "answer": "narrative",
            "hit": false
          },
          {
            "score": 0.7414284944534302,
            "answer": "myths",
            "hit": false
          }
        ],
        "set_exclude": [
          "story"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8085325956344604
      },
      {
        "question verbose": "What is to strategy ",
        "b": "strategy",
        "expected answer": [
          "strategies"
        ],
        "predictions": [
          {
            "score": 0.8368254899978638,
            "answer": "strategies",
            "hit": true
          },
          {
            "score": 0.7888790965080261,
            "answer": "strategic",
            "hit": false
          },
          {
            "score": 0.7833490371704102,
            "answer": "tactics",
            "hit": false
          },
          {
            "score": 0.758635401725769,
            "answer": "tactic",
            "hit": false
          },
          {
            "score": 0.7406482100486755,
            "answer": "investments",
            "hit": false
          },
          {
            "score": 0.7393666505813599,
            "answer": "policies",
            "hit": false
          }
        ],
        "set_exclude": [
          "strategy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8368255198001862
      },
      {
        "question verbose": "What is to success ",
        "b": "success",
        "expected answer": [
          "successes"
        ],
        "predictions": [
          {
            "score": 0.8044346570968628,
            "answer": "successes",
            "hit": true
          },
          {
            "score": 0.7786690592765808,
            "answer": "successful",
            "hit": false
          },
          {
            "score": 0.7605994343757629,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.7550771236419678,
            "answer": "succeeds",
            "hit": false
          },
          {
            "score": 0.7490667104721069,
            "answer": "succeeded",
            "hit": false
          },
          {
            "score": 0.7412712574005127,
            "answer": "victories",
            "hit": false
          }
        ],
        "set_exclude": [
          "success"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.804434597492218
      },
      {
        "question verbose": "What is to technology ",
        "b": "technology",
        "expected answer": [
          "technologies"
        ],
        "predictions": [
          {
            "score": 0.871848464012146,
            "answer": "technologies",
            "hit": true
          },
          {
            "score": 0.8220595717430115,
            "answer": "technological",
            "hit": false
          },
          {
            "score": 0.7921502590179443,
            "answer": "innovations",
            "hit": false
          },
          {
            "score": 0.7894836068153381,
            "answer": "inventions",
            "hit": false
          },
          {
            "score": 0.7696695923805237,
            "answer": "tech",
            "hit": false
          },
          {
            "score": 0.7595047354698181,
            "answer": "science",
            "hit": false
          }
        ],
        "set_exclude": [
          "technology"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8718485236167908
      },
      {
        "question verbose": "What is to theory ",
        "b": "theory",
        "expected answer": [
          "theories"
        ],
        "predictions": [
          {
            "score": 0.8571376800537109,
            "answer": "theories",
            "hit": true
          },
          {
            "score": 0.7691481113433838,
            "answer": "hypothesis",
            "hit": false
          },
          {
            "score": 0.760044276714325,
            "answer": "concepts",
            "hit": false
          },
          {
            "score": 0.7528845071792603,
            "answer": "theoretical",
            "hit": false
          },
          {
            "score": 0.7521082162857056,
            "answer": "doctrines",
            "hit": false
          },
          {
            "score": 0.748345673084259,
            "answer": "interpretations",
            "hit": false
          }
        ],
        "set_exclude": [
          "theory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8571376502513885
      },
      {
        "question verbose": "What is to university ",
        "b": "university",
        "expected answer": [
          "universities"
        ],
        "predictions": [
          {
            "score": 0.844435453414917,
            "answer": "universities",
            "hit": true
          },
          {
            "score": 0.7800866365432739,
            "answer": "colleges",
            "hit": false
          },
          {
            "score": 0.7567939162254333,
            "answer": "harvard",
            "hit": false
          },
          {
            "score": 0.7547622919082642,
            "answer": "professors",
            "hit": false
          },
          {
            "score": 0.7518755197525024,
            "answer": "ucla",
            "hit": false
          },
          {
            "score": 0.750715434551239,
            "answer": "professor",
            "hit": false
          }
        ],
        "set_exclude": [
          "university"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.844435453414917
      },
      {
        "question verbose": "What is to variety ",
        "b": "variety",
        "expected answer": [
          "varieties"
        ],
        "predictions": [
          {
            "score": 0.8299515247344971,
            "answer": "varieties",
            "hit": true
          },
          {
            "score": 0.8061478137969971,
            "answer": "multitude",
            "hit": false
          },
          {
            "score": 0.7826842665672302,
            "answer": "myriad",
            "hit": false
          },
          {
            "score": 0.7689900398254395,
            "answer": "assortment",
            "hit": false
          },
          {
            "score": 0.762570858001709,
            "answer": "varied",
            "hit": false
          },
          {
            "score": 0.7614048719406128,
            "answer": "diversity",
            "hit": false
          }
        ],
        "set_exclude": [
          "variety"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8299515247344971
      },
      {
        "question verbose": "What is to wife ",
        "b": "wife",
        "expected answer": [
          "wives"
        ],
        "predictions": [
          {
            "score": 0.7834106683731079,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.7746753692626953,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.770313560962677,
            "answer": "daughters",
            "hit": false
          },
          {
            "score": 0.7680844068527222,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.7575653791427612,
            "answer": "wives",
            "hit": true
          },
          {
            "score": 0.7565311789512634,
            "answer": "girlfriend",
            "hit": false
          }
        ],
        "set_exclude": [
          "wife"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7575653791427612
      },
      {
        "question verbose": "What is to woman ",
        "b": "woman",
        "expected answer": [
          "women"
        ],
        "predictions": [
          {
            "score": 0.8418959379196167,
            "answer": "women",
            "hit": true
          },
          {
            "score": 0.7685530185699463,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.7592191696166992,
            "answer": "feminist",
            "hit": false
          },
          {
            "score": 0.7568467855453491,
            "answer": "female",
            "hit": false
          },
          {
            "score": 0.7530021667480469,
            "answer": "ladies",
            "hit": false
          },
          {
            "score": 0.7503297328948975,
            "answer": "lady",
            "hit": false
          }
        ],
        "set_exclude": [
          "woman"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8418959379196167
      }
    ],
    "result": {
      "cnt_questions_correct": 38,
      "cnt_questions_total": 44,
      "accuracy": 0.8636363636363636
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I02 [noun - plural_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "4910e4f6-1ec9-4b69-aaef-8e0c95f7cf96",
      "timestamp": "2025-05-17T17:12:45.261729"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to cheap ",
        "b": "cheap",
        "expected answer": [
          "cheaper"
        ],
        "predictions": [
          {
            "score": 0.882105827331543,
            "answer": "cheaper",
            "hit": true
          },
          {
            "score": 0.8228046894073486,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.78106290102005,
            "answer": "expensive",
            "hit": false
          },
          {
            "score": 0.7621415853500366,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.7607864737510681,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.7557587623596191,
            "answer": "simpler",
            "hit": false
          }
        ],
        "set_exclude": [
          "cheap"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.882105827331543
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happier"
        ],
        "predictions": [
          {
            "score": 0.8050521612167358,
            "answer": "happier",
            "hit": true
          },
          {
            "score": 0.7431471347808838,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.7401185035705566,
            "answer": "brighter",
            "hit": false
          },
          {
            "score": 0.7384667992591858,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.7368252873420715,
            "answer": "prosperous",
            "hit": false
          },
          {
            "score": 0.7274282574653625,
            "answer": "bigger",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8050521612167358
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "stronger"
        ],
        "predictions": [
          {
            "score": 0.8373273611068726,
            "answer": "stronger",
            "hit": true
          },
          {
            "score": 0.8068992495536804,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.7662810683250427,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.7455411553382874,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.7305435538291931,
            "answer": "softer",
            "hit": false
          },
          {
            "score": 0.7279099822044373,
            "answer": "clearer",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8373274505138397
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weaker"
        ],
        "predictions": [
          {
            "score": 0.8343197107315063,
            "answer": "weaker",
            "hit": true
          },
          {
            "score": 0.8106366395950317,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.755596935749054,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.7542935013771057,
            "answer": "weaken",
            "hit": false
          },
          {
            "score": 0.749870240688324,
            "answer": "weakened",
            "hit": false
          },
          {
            "score": 0.7482497096061707,
            "answer": "softer",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8343197107315063
      }
    ],
    "result": {
      "cnt_questions_correct": 4,
      "cnt_questions_total": 4,
      "accuracy": 1.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I03 [adj - comparative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "ee008d86-0731-4f4d-9ec9-d01e759b0971",
      "timestamp": "2025-05-17T17:12:45.439085"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to hot ",
        "b": "hot",
        "expected answer": [
          "hottest"
        ],
        "predictions": [
          {
            "score": 0.7437618374824524,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.7370359897613525,
            "answer": "hottest",
            "hit": true
          },
          {
            "score": 0.7233213782310486,
            "answer": "biggest",
            "hit": false
          },
          {
            "score": 0.6909874677658081,
            "answer": "closest",
            "hit": false
          },
          {
            "score": 0.6902544498443604,
            "answer": "deepest",
            "hit": false
          },
          {
            "score": 0.6856129169464111,
            "answer": "lowest",
            "hit": false
          }
        ],
        "set_exclude": [
          "hot"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7370360195636749
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongest"
        ],
        "predictions": [
          {
            "score": 0.774980902671814,
            "answer": "hottest",
            "hit": false
          },
          {
            "score": 0.7686882019042969,
            "answer": "strongest",
            "hit": true
          },
          {
            "score": 0.7226107716560364,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.7022738456726074,
            "answer": "fastest",
            "hit": false
          },
          {
            "score": 0.6962748765945435,
            "answer": "brightest",
            "hit": false
          },
          {
            "score": 0.6910865306854248,
            "answer": "weaker",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7686882019042969
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 2,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I04 [adj - superlative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "fcbc3779-bd50-45b0-b45d-c3c0326ef065",
      "timestamp": "2025-05-17T17:12:45.452158"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepts"
        ],
        "predictions": [
          {
            "score": 0.9359727501869202,
            "answer": "accepts",
            "hit": true
          },
          {
            "score": 0.8530135154724121,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.8453404903411865,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.805214524269104,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.7970830202102661,
            "answer": "rejects",
            "hit": false
          },
          {
            "score": 0.7914783954620361,
            "answer": "acknowledges",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9359727799892426
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.7495858669281006,
            "answer": "brings",
            "hit": false
          },
          {
            "score": 0.7453678846359253,
            "answer": "contributes",
            "hit": false
          },
          {
            "score": 0.7441790699958801,
            "answer": "expands",
            "hit": false
          },
          {
            "score": 0.7412091493606567,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.7402926683425903,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7396457195281982,
            "answer": "encourages",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7376550734043121
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agrees"
        ],
        "predictions": [
          {
            "score": 0.9245318174362183,
            "answer": "agrees",
            "hit": true
          },
          {
            "score": 0.8439640998840332,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.8259856700897217,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7927874326705933,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7873131036758423,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7857402563095093,
            "answer": "acknowledges",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.924531877040863
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.9544636011123657,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.8648908138275146,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8468525409698486,
            "answer": "lets",
            "hit": false
          },
          {
            "score": 0.8439418077468872,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.836389422416687,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.8252301216125488,
            "answer": "provides",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9544635713100433
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.8908507823944092,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8350303769111633,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8168220520019531,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.799241840839386,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7830657958984375,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7829879522323608,
            "answer": "resembles",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7485455721616745
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.8480756282806396,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.7990257740020752,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7908197641372681,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.780670166015625,
            "answer": "removes",
            "hit": false
          },
          {
            "score": 0.7741760015487671,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.7735921144485474,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.848075658082962
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.7802624702453613,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.7759438753128052,
            "answer": "refuses",
            "hit": false
          },
          {
            "score": 0.7731980681419373,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.7690904140472412,
            "answer": "insists",
            "hit": false
          },
          {
            "score": 0.7674083709716797,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7671217918395996,
            "answer": "tells",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 285,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7104842215776443
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoids"
        ],
        "predictions": [
          {
            "score": 0.8673228025436401,
            "answer": "avoids",
            "hit": true
          },
          {
            "score": 0.8224823474884033,
            "answer": "avoiding",
            "hit": false
          },
          {
            "score": 0.8158937692642212,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.8054369688034058,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.7940725088119507,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.7865493893623352,
            "answer": "reduces",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8673228323459625
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.7950214743614197,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.7633717060089111,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7517693042755127,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.7506691217422485,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7492282390594482,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7471174001693726,
            "answer": "encourages",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7950214743614197
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.8465374708175659,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.7798245549201965,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.7750744819641113,
            "answer": "insists",
            "hit": false
          },
          {
            "score": 0.7710335850715637,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7706111669540405,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7668503522872925,
            "answer": "honestly",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8465375304222107
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.8111105561256409,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.7884349822998047,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7741422057151794,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.7618322372436523,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.7598072290420532,
            "answer": "suggests",
            "hit": false
          },
          {
            "score": 0.7591343522071838,
            "answer": "examines",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8111105561256409
      },
      {
        "question verbose": "What is to consist ",
        "b": "consist",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.9460827112197876,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.8949518203735352,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.8486583828926086,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.8436771035194397,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.8127423524856567,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8117529153823853,
            "answer": "comprised",
            "hit": false
          }
        ],
        "set_exclude": [
          "consist"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.94608274102211
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.9383792281150818,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.8415527939796448,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.8322256803512573,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.8041935563087463,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.7938070297241211,
            "answer": "possesses",
            "hit": false
          },
          {
            "score": 0.7925689816474915,
            "answer": "provides",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.938379168510437
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.8207540512084961,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.761574387550354,
            "answer": "progresses",
            "hit": false
          },
          {
            "score": 0.7517051100730896,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.7504440546035767,
            "answer": "keeps",
            "hit": false
          },
          {
            "score": 0.7484198212623596,
            "answer": "completes",
            "hit": false
          },
          {
            "score": 0.7472648620605469,
            "answer": "continued",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8207540512084961
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.8791168928146362,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.8045685291290283,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.8016831874847412,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.7814557552337646,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.7799683213233948,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7767170667648315,
            "answer": "produces",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8791168928146362
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.940332293510437,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.8453940749168396,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.821139931678772,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.813065767288208,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.8117995262145996,
            "answer": "defines",
            "hit": false
          },
          {
            "score": 0.8092951774597168,
            "answer": "discusses",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.940332293510437
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.9400985836982727,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.8542937636375427,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.8516762852668762,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.808478057384491,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.795637845993042,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7863975167274475,
            "answer": "establishes",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9400985836982727
      },
      {
        "question verbose": "What is to enable ",
        "b": "enable",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.8447706699371338,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.788704514503479,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.7827719449996948,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7801223993301392,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7784141302108765,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.776645302772522,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "enable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8447706997394562
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoys"
        ],
        "predictions": [
          {
            "score": 0.8351812362670898,
            "answer": "enjoys",
            "hit": true
          },
          {
            "score": 0.7993795275688171,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7907788753509521,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.7642319202423096,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.7636140584945679,
            "answer": "celebrates",
            "hit": false
          },
          {
            "score": 0.7616294622421265,
            "answer": "explores",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8351812362670898
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensures"
        ],
        "predictions": [
          {
            "score": 0.8558495044708252,
            "answer": "ensures",
            "hit": true
          },
          {
            "score": 0.8071122169494629,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.8025555610656738,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7945961952209473,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7919415831565857,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7913528680801392,
            "answer": "prevents",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8558495044708252
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.8073698282241821,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.8010222315788269,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.7826400399208069,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7814574837684631,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.7714551687240601,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.7706283926963806,
            "answer": "survives",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8073698282241821
      },
      {
        "question verbose": "What is to explain ",
        "b": "explain",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.8272603750228882,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8008014559745789,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.800632894039154,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.782686710357666,
            "answer": "argues",
            "hit": false
          },
          {
            "score": 0.7811563014984131,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.7780781984329224,
            "answer": "emphasizes",
            "hit": false
          }
        ],
        "set_exclude": [
          "explain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8272603452205658
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.8660032153129578,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.8108150362968445,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.7496674060821533,
            "answer": "comes",
            "hit": false
          },
          {
            "score": 0.7312353849411011,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7309160828590393,
            "answer": "goes",
            "hit": false
          },
          {
            "score": 0.7288956642150879,
            "answer": "continues",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8660032153129578
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.9228306412696838,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.8841418027877808,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8395119905471802,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.8356720209121704,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.8247808218002319,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7964258193969727,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9228306710720062
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.8733245134353638,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.8069574236869812,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.7937216758728027,
            "answer": "sees",
            "hit": false
          },
          {
            "score": 0.7655799984931946,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.764340341091156,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.759646475315094,
            "answer": "heard",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8733245134353638
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifies"
        ],
        "predictions": [
          {
            "score": 0.942946195602417,
            "answer": "identifies",
            "hit": true
          },
          {
            "score": 0.8597046136856079,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8052344918251038,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7920071482658386,
            "answer": "recognizes",
            "hit": false
          },
          {
            "score": 0.784820556640625,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.7847920656204224,
            "answer": "distinguishes",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.942946195602417
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.8595868349075317,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.8376526236534119,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.824454665184021,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.7960484027862549,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.7931619882583618,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7895200252532959,
            "answer": "reduces",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8595868349075317
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.8469274044036865,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.8111678957939148,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8081651926040649,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.8053601384162903,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.7985690832138062,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.7961657643318176,
            "answer": "consists",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7819273471832275
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.9496472477912903,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.8347007036209106,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.8155947327613831,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.808549165725708,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.8050535321235657,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.8023746013641357,
            "answer": "relies",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9496472477912903
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.8487696647644043,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.8364300727844238,
            "answer": "learning",
            "hit": false
          },
          {
            "score": 0.8124523162841797,
            "answer": "discovers",
            "hit": false
          },
          {
            "score": 0.8053836822509766,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8003283739089966,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.7848957180976868,
            "answer": "knows",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 26,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7563516795635223
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintains"
        ],
        "predictions": [
          {
            "score": 0.9205462336540222,
            "answer": "maintains",
            "hit": true
          },
          {
            "score": 0.8629247546195984,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.8508022427558899,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.8128534555435181,
            "answer": "keeps",
            "hit": false
          },
          {
            "score": 0.8037832379341125,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.7874035239219666,
            "answer": "ensures",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.920546293258667
      },
      {
        "question verbose": "What is to occur ",
        "b": "occur",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.9555169939994812,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.8875735402107239,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.8514394760131836,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.845355749130249,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.8242737054824829,
            "answer": "arises",
            "hit": false
          },
          {
            "score": 0.8231773972511292,
            "answer": "happen",
            "hit": false
          }
        ],
        "set_exclude": [
          "occur"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9555168747901917
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.9544512033462524,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.8028944134712219,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.7988824844360352,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.792793333530426,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.7899571657180786,
            "answer": "regulates",
            "hit": false
          },
          {
            "score": 0.7889310717582703,
            "answer": "provides",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9544512033462524
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "prevents"
        ],
        "predictions": [
          {
            "score": 0.9221212863922119,
            "answer": "prevents",
            "hit": true
          },
          {
            "score": 0.8570718765258789,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.8527956008911133,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.8188067674636841,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.8129653930664062,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.8128067255020142,
            "answer": "prohibits",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9221212267875671
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.9480124711990356,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8645275235176086,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.8445221781730652,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8357268571853638,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.819446861743927,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.798313319683075,
            "answer": "encourage",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9480124413967133
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protects"
        ],
        "predictions": [
          {
            "score": 0.8617837429046631,
            "answer": "protects",
            "hit": true
          },
          {
            "score": 0.8055221438407898,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.7963402271270752,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.78834468126297,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.7747206091880798,
            "answer": "protections",
            "hit": false
          },
          {
            "score": 0.7713904976844788,
            "answer": "removes",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8617837727069855
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.962509274482727,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.8649654388427734,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.8564700484275818,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8413575887680054,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8290931582450867,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8243498802185059,
            "answer": "offers",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9625093638896942
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.9402068853378296,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.8382685780525208,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.8105717897415161,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.797066330909729,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.7862464189529419,
            "answer": "delivers",
            "hit": false
          },
          {
            "score": 0.7816377878189087,
            "answer": "provides",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9402068853378296
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.9439674615859985,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.8670171499252319,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.8338844776153564,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.8334065079689026,
            "answer": "lowers",
            "hit": false
          },
          {
            "score": 0.8303342461585999,
            "answer": "decreases",
            "hit": false
          },
          {
            "score": 0.8287488222122192,
            "answer": "improves",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9439675211906433
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.811383068561554,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.7781316041946411,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7759734392166138,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7746527791023254,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.7707101106643677,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.77033531665802,
            "answer": "considers",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.811383068561554
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.8973151445388794,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.8963258266448975,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.8323755264282227,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8250730037689209,
            "answer": "stays",
            "hit": false
          },
          {
            "score": 0.8187615871429443,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.8066045045852661,
            "answer": "stayed",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8973151445388794
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembers"
        ],
        "predictions": [
          {
            "score": 0.9011838436126709,
            "answer": "remembers",
            "hit": true
          },
          {
            "score": 0.8136001825332642,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.8129726648330688,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.8004113435745239,
            "answer": "recalls",
            "hit": false
          },
          {
            "score": 0.7868536710739136,
            "answer": "recall",
            "hit": false
          },
          {
            "score": 0.7845377326011658,
            "answer": "knows",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9011838734149933
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.8291547298431396,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.8138920664787292,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.7985001802444458,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.7858310341835022,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.7695863842964172,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.7656169533729553,
            "answer": "depicts",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8138920664787292
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.8295899629592896,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.8244359493255615,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.81571364402771,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8108224272727966,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.8000589609146118,
            "answer": "prohibits",
            "hit": false
          },
          {
            "score": 0.7989869117736816,
            "answer": "provides",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7844664454460144
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.8881839513778687,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8147492408752441,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.8120708465576172,
            "answer": "tends",
            "hit": false
          },
          {
            "score": 0.7912728786468506,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.7869839668273926,
            "answer": "doesn",
            "hit": false
          },
          {
            "score": 0.7852638959884644,
            "answer": "suggests",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7912728786468506
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sends"
        ],
        "predictions": [
          {
            "score": 0.8389657735824585,
            "answer": "sends",
            "hit": true
          },
          {
            "score": 0.772455632686615,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7631956934928894,
            "answer": "delivers",
            "hit": false
          },
          {
            "score": 0.7583799362182617,
            "answer": "responds",
            "hit": false
          },
          {
            "score": 0.7538226246833801,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7528784871101379,
            "answer": "brings",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8389658331871033
      },
      {
        "question verbose": "What is to suggest ",
        "b": "suggest",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.8181465864181519,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.7944054007530212,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.7929098606109619,
            "answer": "suggested",
            "hit": false
          },
          {
            "score": 0.7887687683105469,
            "answer": "recommends",
            "hit": false
          },
          {
            "score": 0.7861257791519165,
            "answer": "suggestions",
            "hit": false
          },
          {
            "score": 0.7720358967781067,
            "answer": "indicates",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8181465566158295
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.8374030590057373,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.7682024240493774,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.7575907707214355,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7557809352874756,
            "answer": "reveals",
            "hit": false
          },
          {
            "score": 0.7544682025909424,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.7531932592391968,
            "answer": "speaks",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8374030590057373
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.8422119617462158,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.7944107055664062,
            "answer": "realizes",
            "hit": false
          },
          {
            "score": 0.7844830751419067,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.7835850715637207,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7833766937255859,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.7819329500198364,
            "answer": "identifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8422120213508606
      }
    ],
    "result": {
      "cnt_questions_correct": 41,
      "cnt_questions_total": 49,
      "accuracy": 0.8367346938775511
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I05 [verb_inf - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "07845f8b-6213-41af-9bb7-f51225891c72",
      "timestamp": "2025-05-17T17:12:45.460017"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieving"
        ],
        "predictions": [
          {
            "score": 0.8494521975517273,
            "answer": "achieving",
            "hit": true
          },
          {
            "score": 0.7782297730445862,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.7663378119468689,
            "answer": "overcoming",
            "hit": false
          },
          {
            "score": 0.7654156684875488,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7614825963973999,
            "answer": "eliminating",
            "hit": false
          },
          {
            "score": 0.7587918639183044,
            "answer": "defeating",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8494522273540497
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adding"
        ],
        "predictions": [
          {
            "score": 0.7293934226036072,
            "answer": "bringing",
            "hit": false
          },
          {
            "score": 0.7236338257789612,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.7214543223381042,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7210210561752319,
            "answer": "adding",
            "hit": true
          },
          {
            "score": 0.7198057174682617,
            "answer": "noting",
            "hit": false
          },
          {
            "score": 0.7193772792816162,
            "answer": "modifying",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7210210859775543
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowing"
        ],
        "predictions": [
          {
            "score": 0.9145216941833496,
            "answer": "allowing",
            "hit": true
          },
          {
            "score": 0.8780513405799866,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8344375491142273,
            "answer": "letting",
            "hit": false
          },
          {
            "score": 0.7977573275566101,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.7925777435302734,
            "answer": "permit",
            "hit": false
          },
          {
            "score": 0.7907141447067261,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9145217537879944
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appearing"
        ],
        "predictions": [
          {
            "score": 0.881566047668457,
            "answer": "appearing",
            "hit": true
          },
          {
            "score": 0.8682368993759155,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8222327828407288,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7871304750442505,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7668819427490234,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7543928027153015,
            "answer": "resembling",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.881566047668457
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applying"
        ],
        "predictions": [
          {
            "score": 0.8657979369163513,
            "answer": "applying",
            "hit": true
          },
          {
            "score": 0.7820466160774231,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.7782875895500183,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.755940318107605,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.7530190348625183,
            "answer": "transferring",
            "hit": false
          },
          {
            "score": 0.7526130676269531,
            "answer": "assessing",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8657979369163513
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asking"
        ],
        "predictions": [
          {
            "score": 0.8089406490325928,
            "answer": "asking",
            "hit": true
          },
          {
            "score": 0.7700278759002686,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.7603388428688049,
            "answer": "reminding",
            "hit": false
          },
          {
            "score": 0.7599645256996155,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.7573257088661194,
            "answer": "acknowledging",
            "hit": false
          },
          {
            "score": 0.7568354606628418,
            "answer": "giving",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8089406490325928
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attending"
        ],
        "predictions": [
          {
            "score": 0.9158209562301636,
            "answer": "attending",
            "hit": true
          },
          {
            "score": 0.8560211658477783,
            "answer": "attended",
            "hit": false
          },
          {
            "score": 0.8182869553565979,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.7946391105651855,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.7684850692749023,
            "answer": "visiting",
            "hit": false
          },
          {
            "score": 0.7643617391586304,
            "answer": "participating",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9158209562301636
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoiding"
        ],
        "predictions": [
          {
            "score": 0.8763745427131653,
            "answer": "avoiding",
            "hit": true
          },
          {
            "score": 0.8147139549255371,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.8000234365463257,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.7885767221450806,
            "answer": "avoids",
            "hit": false
          },
          {
            "score": 0.7832512259483337,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.7790975570678711,
            "answer": "reducing",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8763745427131653
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becoming"
        ],
        "predictions": [
          {
            "score": 0.7925712466239929,
            "answer": "becoming",
            "hit": true
          },
          {
            "score": 0.7367516160011292,
            "answer": "going",
            "hit": false
          },
          {
            "score": 0.7326870560646057,
            "answer": "acquiring",
            "hit": false
          },
          {
            "score": 0.7319821119308472,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.7230048179626465,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.721662700176239,
            "answer": "adopting",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7925712168216705
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believing"
        ],
        "predictions": [
          {
            "score": 0.8221545815467834,
            "answer": "believing",
            "hit": true
          },
          {
            "score": 0.7793073654174805,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.7651088237762451,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7586967349052429,
            "answer": "insisting",
            "hit": false
          },
          {
            "score": 0.7494259476661682,
            "answer": "honestly",
            "hit": false
          },
          {
            "score": 0.7469012141227722,
            "answer": "considering",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8221545517444611
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considering"
        ],
        "predictions": [
          {
            "score": 0.7852035760879517,
            "answer": "considering",
            "hit": true
          },
          {
            "score": 0.7700506448745728,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.7669193148612976,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.7665549516677856,
            "answer": "increasing",
            "hit": false
          },
          {
            "score": 0.7580634355545044,
            "answer": "noting",
            "hit": false
          },
          {
            "score": 0.7570651769638062,
            "answer": "adopting",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7852035760879517
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "containing"
        ],
        "predictions": [
          {
            "score": 0.8828094601631165,
            "answer": "containing",
            "hit": true
          },
          {
            "score": 0.8764315843582153,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.8416633009910583,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.7557309865951538,
            "answer": "possessing",
            "hit": false
          },
          {
            "score": 0.748354434967041,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.7480257749557495,
            "answer": "incorporating",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8828094899654388
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuing"
        ],
        "predictions": [
          {
            "score": 0.7592427134513855,
            "answer": "continuing",
            "hit": true
          },
          {
            "score": 0.7464959025382996,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.7440279722213745,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.739125669002533,
            "answer": "progressing",
            "hit": false
          },
          {
            "score": 0.7375986576080322,
            "answer": "pursuing",
            "hit": false
          },
          {
            "score": 0.7338083386421204,
            "answer": "completing",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7592427134513855
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creating"
        ],
        "predictions": [
          {
            "score": 0.8725642561912537,
            "answer": "creating",
            "hit": true
          },
          {
            "score": 0.7919337153434753,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7720401287078857,
            "answer": "generating",
            "hit": false
          },
          {
            "score": 0.7640189528465271,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.7639563083648682,
            "answer": "designing",
            "hit": false
          },
          {
            "score": 0.754938542842865,
            "answer": "establishing",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8725642263889313
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developing"
        ],
        "predictions": [
          {
            "score": 0.9164913892745972,
            "answer": "developing",
            "hit": true
          },
          {
            "score": 0.8727877736091614,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.8577024340629578,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7856425046920776,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.784011960029602,
            "answer": "producing",
            "hit": false
          },
          {
            "score": 0.7779366970062256,
            "answer": "improving",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9164913296699524
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouraging"
        ],
        "predictions": [
          {
            "score": 0.8787307143211365,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8650686144828796,
            "answer": "encouraging",
            "hit": true
          },
          {
            "score": 0.8566850423812866,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.8479846715927124,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.8080556392669678,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.7999629974365234,
            "answer": "urging",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.865068644285202
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoying"
        ],
        "predictions": [
          {
            "score": 0.8468155860900879,
            "answer": "enjoying",
            "hit": true
          },
          {
            "score": 0.7684914469718933,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.766478419303894,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.7638168931007385,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7509981393814087,
            "answer": "celebrating",
            "hit": false
          },
          {
            "score": 0.7494946718215942,
            "answer": "experiencing",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8468155860900879
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensuring"
        ],
        "predictions": [
          {
            "score": 0.8617775440216064,
            "answer": "ensuring",
            "hit": true
          },
          {
            "score": 0.7874860167503357,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.7815696001052856,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.767493724822998,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.7673048377037048,
            "answer": "preserving",
            "hit": false
          },
          {
            "score": 0.7663740515708923,
            "answer": "facilitating",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8617776036262512
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishing"
        ],
        "predictions": [
          {
            "score": 0.8824976086616516,
            "answer": "establishing",
            "hit": true
          },
          {
            "score": 0.798913836479187,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7954363822937012,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7861668467521667,
            "answer": "restoring",
            "hit": false
          },
          {
            "score": 0.7853065729141235,
            "answer": "initiating",
            "hit": false
          },
          {
            "score": 0.7774136066436768,
            "answer": "asserting",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8824976086616516
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "existing"
        ],
        "predictions": [
          {
            "score": 0.8155304193496704,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.7446235418319702,
            "answer": "confronting",
            "hit": false
          },
          {
            "score": 0.7444636821746826,
            "answer": "existent",
            "hit": false
          },
          {
            "score": 0.7442224025726318,
            "answer": "exists",
            "hit": false
          },
          {
            "score": 0.7414674758911133,
            "answer": "embracing",
            "hit": false
          },
          {
            "score": 0.7345591187477112,
            "answer": "asserting",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 641,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6839160323143005
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expecting"
        ],
        "predictions": [
          {
            "score": 0.800579309463501,
            "answer": "expecting",
            "hit": true
          },
          {
            "score": 0.7954193949699402,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.7643238306045532,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.7608147859573364,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7451905012130737,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.74310302734375,
            "answer": "expected",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8005793690681458
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "following"
        ],
        "predictions": [
          {
            "score": 0.8077348470687866,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.7976759076118469,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.771077573299408,
            "answer": "following",
            "hit": true
          },
          {
            "score": 0.7136098146438599,
            "answer": "pursuing",
            "hit": false
          },
          {
            "score": 0.712888240814209,
            "answer": "subsequent",
            "hit": false
          },
          {
            "score": 0.7120869159698486,
            "answer": "sequel",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.771077573299408
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happening"
        ],
        "predictions": [
          {
            "score": 0.882529616355896,
            "answer": "happening",
            "hit": true
          },
          {
            "score": 0.8537206053733826,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8523962497711182,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.8132020831108093,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8069436550140381,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7695468664169312,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8825297057628632
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifying"
        ],
        "predictions": [
          {
            "score": 0.9261555075645447,
            "answer": "identifying",
            "hit": true
          },
          {
            "score": 0.8778971433639526,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7809116244316101,
            "answer": "recognizing",
            "hit": false
          },
          {
            "score": 0.7763683199882507,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.7730147838592529,
            "answer": "locating",
            "hit": false
          },
          {
            "score": 0.770904004573822,
            "answer": "acknowledging",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9261555373668671
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improving"
        ],
        "predictions": [
          {
            "score": 0.8527916073799133,
            "answer": "improving",
            "hit": true
          },
          {
            "score": 0.8286340236663818,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.8268638253211975,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.8098021745681763,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.7935565710067749,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.7834072709083557,
            "answer": "improves",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8527916073799133
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "including"
        ],
        "predictions": [
          {
            "score": 0.8485264778137207,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.7636955380439758,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7635200023651123,
            "answer": "including",
            "hit": true
          },
          {
            "score": 0.7603098154067993,
            "answer": "incorporating",
            "hit": false
          },
          {
            "score": 0.755713164806366,
            "answer": "incorporate",
            "hit": false
          },
          {
            "score": 0.7549441456794739,
            "answer": "involve",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7635200023651123
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involving"
        ],
        "predictions": [
          {
            "score": 0.8856175541877747,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8718045949935913,
            "answer": "involving",
            "hit": true
          },
          {
            "score": 0.7735838890075684,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.7715333104133606,
            "answer": "incorporating",
            "hit": false
          },
          {
            "score": 0.7658511400222778,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.7622736692428589,
            "answer": "employing",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8718046247959137
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learning"
        ],
        "predictions": [
          {
            "score": 0.8850008845329285,
            "answer": "learning",
            "hit": true
          },
          {
            "score": 0.844701886177063,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.8016610741615295,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.7947210073471069,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.765019416809082,
            "answer": "figuring",
            "hit": false
          },
          {
            "score": 0.7584490776062012,
            "answer": "studying",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8850008845329285
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "losing"
        ],
        "predictions": [
          {
            "score": 0.8230440616607666,
            "answer": "losing",
            "hit": true
          },
          {
            "score": 0.787575364112854,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7737290859222412,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.7522854804992676,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.7428238987922668,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.7422099113464355,
            "answer": "losses",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.823044091463089
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintaining"
        ],
        "predictions": [
          {
            "score": 0.9194855093955994,
            "answer": "maintaining",
            "hit": true
          },
          {
            "score": 0.8562003374099731,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.8460983633995056,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.8048038482666016,
            "answer": "keeping",
            "hit": false
          },
          {
            "score": 0.7893696427345276,
            "answer": "preserving",
            "hit": false
          },
          {
            "score": 0.7760375142097473,
            "answer": "sustaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.919485479593277
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managing"
        ],
        "predictions": [
          {
            "score": 0.8581526279449463,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7981442213058472,
            "answer": "managing",
            "hit": true
          },
          {
            "score": 0.7808802723884583,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7748676538467407,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.757605254650116,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7548680305480957,
            "answer": "administering",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7981441617012024
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operating"
        ],
        "predictions": [
          {
            "score": 0.8891450762748718,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7935794591903687,
            "answer": "operating",
            "hit": true
          },
          {
            "score": 0.790549635887146,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.7807257175445557,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7708796262741089,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.769992470741272,
            "answer": "conducting",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7935794591903687
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performing"
        ],
        "predictions": [
          {
            "score": 0.8873380422592163,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.8607641458511353,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.7880417704582214,
            "answer": "performing",
            "hit": true
          },
          {
            "score": 0.7743546366691589,
            "answer": "conducting",
            "hit": false
          },
          {
            "score": 0.7727104425430298,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7714987993240356,
            "answer": "executing",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7880417704582214
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "preventing"
        ],
        "predictions": [
          {
            "score": 0.915160059928894,
            "answer": "preventing",
            "hit": true
          },
          {
            "score": 0.845204770565033,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.8399313688278198,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.8043718338012695,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.7960874438285828,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7924666404724121,
            "answer": "reducing",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.915160059928894
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoting"
        ],
        "predictions": [
          {
            "score": 0.9381662607192993,
            "answer": "promoting",
            "hit": true
          },
          {
            "score": 0.8827589750289917,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.833098292350769,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7976909875869751,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.7932990789413452,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.7929993867874146,
            "answer": "facilitating",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9381662607192993
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protecting"
        ],
        "predictions": [
          {
            "score": 0.8600496649742126,
            "answer": "protecting",
            "hit": true
          },
          {
            "score": 0.7846643924713135,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7834649085998535,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.7823667526245117,
            "answer": "preserving",
            "hit": false
          },
          {
            "score": 0.7819791436195374,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.7715173959732056,
            "answer": "restoring",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8600496351718903
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "providing"
        ],
        "predictions": [
          {
            "score": 0.9400144815444946,
            "answer": "providing",
            "hit": true
          },
          {
            "score": 0.8849299550056458,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8109195232391357,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.8051977157592773,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.80023193359375,
            "answer": "offering",
            "hit": false
          },
          {
            "score": 0.796330451965332,
            "answer": "ensuring",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.940014511346817
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiving"
        ],
        "predictions": [
          {
            "score": 0.904908299446106,
            "answer": "receiving",
            "hit": true
          },
          {
            "score": 0.8717153072357178,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7797532081604004,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.7735222578048706,
            "answer": "obtaining",
            "hit": false
          },
          {
            "score": 0.7733928561210632,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7697973251342773,
            "answer": "getting",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.904908299446106
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reducing"
        ],
        "predictions": [
          {
            "score": 0.939630389213562,
            "answer": "reducing",
            "hit": true
          },
          {
            "score": 0.8694669008255005,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8390849828720093,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.8390121459960938,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.8296476006507874,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.8263626098632812,
            "answer": "decreasing",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.939630389213562
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referring"
        ],
        "predictions": [
          {
            "score": 0.814586341381073,
            "answer": "referring",
            "hit": true
          },
          {
            "score": 0.76988685131073,
            "answer": "mentioning",
            "hit": false
          },
          {
            "score": 0.7665185928344727,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.7626563906669617,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.7625089883804321,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.7583921551704407,
            "answer": "noting",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8145863115787506
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remaining"
        ],
        "predictions": [
          {
            "score": 0.8770270943641663,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.8497784733772278,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.805280864238739,
            "answer": "remaining",
            "hit": true
          },
          {
            "score": 0.7997369170188904,
            "answer": "staying",
            "hit": false
          },
          {
            "score": 0.785714864730835,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7789788246154785,
            "answer": "stayed",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8052808940410614
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembering"
        ],
        "predictions": [
          {
            "score": 0.862855076789856,
            "answer": "remembering",
            "hit": true
          },
          {
            "score": 0.8425596952438354,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.8111906051635742,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.7935535907745361,
            "answer": "recall",
            "hit": false
          },
          {
            "score": 0.77406907081604,
            "answer": "recalling",
            "hit": false
          },
          {
            "score": 0.7676014304161072,
            "answer": "forgetting",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.862855076789856
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "representing"
        ],
        "predictions": [
          {
            "score": 0.8291487693786621,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.823401153087616,
            "answer": "representing",
            "hit": true
          },
          {
            "score": 0.7915571331977844,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.7654129862785339,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.7525897026062012,
            "answer": "presenting",
            "hit": false
          },
          {
            "score": 0.7464388012886047,
            "answer": "advocating",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.823401153087616
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requiring"
        ],
        "predictions": [
          {
            "score": 0.8931061029434204,
            "answer": "requiring",
            "hit": true
          },
          {
            "score": 0.8096895813941956,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.7848469018936157,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.783788800239563,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.763046383857727,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7619284391403198,
            "answer": "relying",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8931061327457428
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seeming"
        ],
        "predictions": [
          {
            "score": 0.8658987283706665,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.832287073135376,
            "answer": "seeming",
            "hit": true
          },
          {
            "score": 0.812473714351654,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7848403453826904,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.7709707021713257,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7704907059669495,
            "answer": "seems",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8322871327400208
      },
      {
        "question verbose": "What is to sit ",
        "b": "sit",
        "expected answer": [
          "sitting"
        ],
        "predictions": [
          {
            "score": 0.8654541969299316,
            "answer": "sitting",
            "hit": true
          },
          {
            "score": 0.826751172542572,
            "answer": "sits",
            "hit": false
          },
          {
            "score": 0.7482610940933228,
            "answer": "staring",
            "hit": false
          },
          {
            "score": 0.736648440361023,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.7293744087219238,
            "answer": "holding",
            "hit": false
          },
          {
            "score": 0.7265205383300781,
            "answer": "hanging",
            "hit": false
          }
        ],
        "set_exclude": [
          "sit"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8654541969299316
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spending"
        ],
        "predictions": [
          {
            "score": 0.8951194286346436,
            "answer": "spending",
            "hit": true
          },
          {
            "score": 0.8788262009620667,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8549087643623352,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.7698856592178345,
            "answer": "investing",
            "hit": false
          },
          {
            "score": 0.7694040536880493,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7689526081085205,
            "answer": "expenditure",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8951194286346436
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teaching"
        ],
        "predictions": [
          {
            "score": 0.880132794380188,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8708081841468811,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.8460072875022888,
            "answer": "teaching",
            "hit": true
          },
          {
            "score": 0.7817347049713135,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.7788823246955872,
            "answer": "classroom",
            "hit": false
          },
          {
            "score": 0.7770390510559082,
            "answer": "preaching",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8460072576999664
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "telling"
        ],
        "predictions": [
          {
            "score": 0.8023884296417236,
            "answer": "telling",
            "hit": true
          },
          {
            "score": 0.7645759582519531,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.7445530891418457,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.7354239225387573,
            "answer": "reminding",
            "hit": false
          },
          {
            "score": 0.7335165143013,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.7320212721824646,
            "answer": "talking",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.802388459444046
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understanding"
        ],
        "predictions": [
          {
            "score": 0.8050718903541565,
            "answer": "understanding",
            "hit": true
          },
          {
            "score": 0.7872936129570007,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7751038074493408,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7727106213569641,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.772024393081665,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7632098197937012,
            "answer": "realizing",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8050718903541565
      }
    ],
    "result": {
      "cnt_questions_correct": 37,
      "cnt_questions_total": 50,
      "accuracy": 0.74
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I06 [verb_inf - Ving].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "7b67a68b-956a-4e1b-841e-a2ccf415f9ed",
      "timestamp": "2025-05-17T17:12:45.648140"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepted"
        ],
        "predictions": [
          {
            "score": 0.8916603326797485,
            "answer": "accepted",
            "hit": true
          },
          {
            "score": 0.8812675476074219,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.8571990132331848,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.81401127576828,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.7739278078079224,
            "answer": "rejected",
            "hit": false
          },
          {
            "score": 0.7680131793022156,
            "answer": "acknowledged",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8916602730751038
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieved"
        ],
        "predictions": [
          {
            "score": 0.8217934370040894,
            "answer": "achieved",
            "hit": true
          },
          {
            "score": 0.791495144367218,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.789311945438385,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7629196643829346,
            "answer": "accomplished",
            "hit": false
          },
          {
            "score": 0.7536123991012573,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7496882081031799,
            "answer": "conquered",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8217934668064117
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.7426040172576904,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.7097728252410889,
            "answer": "elaborated",
            "hit": false
          },
          {
            "score": 0.706565260887146,
            "answer": "reiterated",
            "hit": false
          },
          {
            "score": 0.704553484916687,
            "answer": "incurred",
            "hit": false
          },
          {
            "score": 0.7035270929336548,
            "answer": "additive",
            "hit": false
          },
          {
            "score": 0.702072262763977,
            "answer": "noted",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7426040023565292
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.885299026966095,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8777180910110474,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8346239328384399,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8116694688796997,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7981528639793396,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7518768906593323,
            "answer": "disagreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.885299026966095
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.8895950317382812,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8507778644561768,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.817430853843689,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.7987329959869385,
            "answer": "let",
            "hit": false
          },
          {
            "score": 0.796130895614624,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.795677661895752,
            "answer": "permit",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7703381776809692
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8216664791107178,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.809962272644043,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.772155225276947,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.7602170705795288,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.7527654767036438,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.7448635101318359,
            "answer": "unveiled",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7527654767036438
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.906007707118988,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.83259516954422,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.832228422164917,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8026444911956787,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7546527981758118,
            "answer": "showed",
            "hit": false
          },
          {
            "score": 0.7469817996025085,
            "answer": "resembled",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9060076773166656
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8082521557807922,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.8047404289245605,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7891549468040466,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.7491613030433655,
            "answer": "evaluated",
            "hit": false
          },
          {
            "score": 0.7478384971618652,
            "answer": "rubbed",
            "hit": false
          },
          {
            "score": 0.7439271807670593,
            "answer": "formulated",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8082521855831146
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.7712331414222717,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.769199788570404,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.7668372392654419,
            "answer": "begged",
            "hit": false
          },
          {
            "score": 0.751011073589325,
            "answer": "questions",
            "hit": false
          },
          {
            "score": 0.7484734654426575,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.7454653978347778,
            "answer": "prayed",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7691998183727264
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.897323727607727,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.8751755356788635,
            "answer": "attending",
            "hit": false
          },
          {
            "score": 0.8089991807937622,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.7979378700256348,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.7777464389801025,
            "answer": "participated",
            "hit": false
          },
          {
            "score": 0.7661663293838501,
            "answer": "participate",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.897323727607727
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.7501577734947205,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.7383997440338135,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.7331404089927673,
            "answer": "surpassed",
            "hit": false
          },
          {
            "score": 0.728219747543335,
            "answer": "reached",
            "hit": false
          },
          {
            "score": 0.7258498668670654,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.7203904986381531,
            "answer": "becomes",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7501577138900757
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.7982395887374878,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.790804922580719,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.7693722248077393,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7544205188751221,
            "answer": "honestly",
            "hit": false
          },
          {
            "score": 0.7496355772018433,
            "answer": "didn",
            "hit": false
          },
          {
            "score": 0.7439099550247192,
            "answer": "doubted",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7982395887374878
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.779918372631073,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7555572986602783,
            "answer": "increasing",
            "hit": false
          },
          {
            "score": 0.7500758171081543,
            "answer": "reasonable",
            "hit": false
          },
          {
            "score": 0.7475306391716003,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7462372779846191,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7425473928451538,
            "answer": "given",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7367515861988068
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.7697017192840576,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.7608269453048706,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.742393970489502,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7329850196838379,
            "answer": "resumed",
            "hit": false
          },
          {
            "score": 0.7296037673950195,
            "answer": "proceeded",
            "hit": false
          },
          {
            "score": 0.7271596193313599,
            "answer": "progressed",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7697017788887024
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.8041478395462036,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8036980628967285,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.7823244333267212,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.750285267829895,
            "answer": "generated",
            "hit": false
          },
          {
            "score": 0.7432622909545898,
            "answer": "crafted",
            "hit": false
          },
          {
            "score": 0.7425330281257629,
            "answer": "creation",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7823244333267212
      },
      {
        "question verbose": "What is to decide ",
        "b": "decide",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8930690884590149,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8929570317268372,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8228476643562317,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.8170729279518127,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7958553433418274,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.7924486398696899,
            "answer": "choose",
            "hit": false
          }
        ],
        "set_exclude": [
          "decide"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8929570913314819
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8921878933906555,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8564366102218628,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.7949280738830566,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.7838210463523865,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.7765912413597107,
            "answer": "characterized",
            "hit": false
          },
          {
            "score": 0.7664198279380798,
            "answer": "depict",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7838210463523865
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.9009494781494141,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.8911281824111938,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.8742949962615967,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7888387441635132,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7640097141265869,
            "answer": "evolve",
            "hit": false
          },
          {
            "score": 0.7630096673965454,
            "answer": "developmental",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9009494781494141
      },
      {
        "question verbose": "What is to discover ",
        "b": "discover",
        "expected answer": [
          "discovered"
        ],
        "predictions": [
          {
            "score": 0.7570902705192566,
            "answer": "discovers",
            "hit": false
          },
          {
            "score": 0.7544848918914795,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.7541189789772034,
            "answer": "discovered",
            "hit": true
          },
          {
            "score": 0.7505534887313843,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.7430405616760254,
            "answer": "finding",
            "hit": false
          },
          {
            "score": 0.737285315990448,
            "answer": "created",
            "hit": false
          }
        ],
        "set_exclude": [
          "discover"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7541189789772034
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyed"
        ],
        "predictions": [
          {
            "score": 0.8098876476287842,
            "answer": "enjoyed",
            "hit": true
          },
          {
            "score": 0.80149245262146,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7814127206802368,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.7574975490570068,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7402478456497192,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7273726463317871,
            "answer": "thanks",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8098876178264618
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensured"
        ],
        "predictions": [
          {
            "score": 0.8216516375541687,
            "answer": "ensured",
            "hit": true
          },
          {
            "score": 0.7959935665130615,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7855711579322815,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7629846334457397,
            "answer": "verify",
            "hit": false
          },
          {
            "score": 0.7531948089599609,
            "answer": "ideally",
            "hit": false
          },
          {
            "score": 0.7511804103851318,
            "answer": "emphasized",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8216516375541687
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8405922055244446,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8172031044960022,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7897443175315857,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.7599468231201172,
            "answer": "instituted",
            "hit": false
          },
          {
            "score": 0.752301037311554,
            "answer": "regained",
            "hit": false
          },
          {
            "score": 0.7468072175979614,
            "answer": "restoring",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7897443175315857
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.7903567552566528,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.7768141031265259,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.7695382237434387,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.7674034833908081,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.7554225921630859,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7304137945175171,
            "answer": "considering",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7674035131931305
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.8264140486717224,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.8183009624481201,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.742825984954834,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7181500196456909,
            "answer": "preceded",
            "hit": false
          },
          {
            "score": 0.7112731337547302,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.710990309715271,
            "answer": "sequel",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8264140486717224
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8485457301139832,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.8163508772850037,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.7921110391616821,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.7826398015022278,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7470638751983643,
            "answer": "seen",
            "hit": false
          },
          {
            "score": 0.7447235584259033,
            "answer": "listening",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7921110987663269
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identified"
        ],
        "predictions": [
          {
            "score": 0.8957786560058594,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8760771155357361,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7874816060066223,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.7781838178634644,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.7647069096565247,
            "answer": "identified",
            "hit": true
          },
          {
            "score": 0.7536085844039917,
            "answer": "locate",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7647069096565247
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.8460256457328796,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.83641517162323,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7987502813339233,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.794340968132019,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7924416661262512,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7620022296905518,
            "answer": "increased",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.846025675535202
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.8890951871871948,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.7678190469741821,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7654045224189758,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.7595424652099609,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7554171085357666,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.7532631158828735,
            "answer": "involve",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8890951871871948
      },
      {
        "question verbose": "What is to introduce ",
        "b": "introduce",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.917149543762207,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8949956893920898,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.8931311964988708,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.8207677006721497,
            "answer": "introduction",
            "hit": false
          },
          {
            "score": 0.765461266040802,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.7610197067260742,
            "answer": "brought",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9171496033668518
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8962402939796448,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8509017825126648,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7846004962921143,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.7790998220443726,
            "answer": "resulted",
            "hit": false
          },
          {
            "score": 0.7733771204948425,
            "answer": "involved",
            "hit": true
          },
          {
            "score": 0.7712361216545105,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7733771204948425
      },
      {
        "question verbose": "What is to locate ",
        "b": "locate",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8775397539138794,
            "answer": "locating",
            "hit": false
          },
          {
            "score": 0.8271147012710571,
            "answer": "located",
            "hit": true
          },
          {
            "score": 0.7849483489990234,
            "answer": "relocated",
            "hit": false
          },
          {
            "score": 0.7658864259719849,
            "answer": "situated",
            "hit": false
          },
          {
            "score": 0.7603467702865601,
            "answer": "retrieve",
            "hit": false
          },
          {
            "score": 0.7601017951965332,
            "answer": "searched",
            "hit": false
          }
        ],
        "set_exclude": [
          "locate"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8271147012710571
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.7972589731216431,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7827218770980835,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.7752496004104614,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7473721504211426,
            "answer": "regained",
            "hit": false
          },
          {
            "score": 0.7425300478935242,
            "answer": "gained",
            "hit": false
          },
          {
            "score": 0.7393044233322144,
            "answer": "losses",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7827218770980835
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8708694577217102,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.8005390167236328,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.7793203592300415,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7437819838523865,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.7437034845352173,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.7434223294258118,
            "answer": "maintained",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8005390167236328
      },
      {
        "question verbose": "What is to marry ",
        "b": "marry",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.8905774354934692,
            "answer": "marrying",
            "hit": false
          },
          {
            "score": 0.8603885769844055,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.8111882209777832,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.8012133836746216,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.7919905185699463,
            "answer": "kissed",
            "hit": false
          },
          {
            "score": 0.7785177230834961,
            "answer": "marital",
            "hit": false
          }
        ],
        "set_exclude": [
          "marry"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8603885769844055
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.9119455814361572,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.9032017588615417,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7746298909187317,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7693226933479309,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.7649948596954346,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.762554407119751,
            "answer": "conducted",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9119455814361572
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8998963832855225,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8689117431640625,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8085629343986511,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.8061126470565796,
            "answer": "gave",
            "hit": false
          },
          {
            "score": 0.8006048798561096,
            "answer": "offered",
            "hit": false
          },
          {
            "score": 0.7909907102584839,
            "answer": "gives",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 49,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7362730801105499
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.8666988611221313,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.8227095603942871,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.8201141357421875,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.7937954664230347,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.7916508316993713,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.7608087062835693,
            "answer": "unpublished",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8201140761375427
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8840999007225037,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.856673002243042,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.8144364953041077,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.7500821948051453,
            "answer": "obtain",
            "hit": false
          },
          {
            "score": 0.7481443285942078,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.7449493408203125,
            "answer": "participated",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8144364953041077
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.8837583065032959,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8804657459259033,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.8721504807472229,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.8437284231185913,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.8334712386131287,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.8253461122512817,
            "answer": "reductions",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8721504509449005
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.7781119346618652,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.773330807685852,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.7609490752220154,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.7564400434494019,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.7545933723449707,
            "answer": "although",
            "hit": false
          },
          {
            "score": 0.7532415390014648,
            "answer": "remarked",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7609491348266602
      },
      {
        "question verbose": "What is to relate ",
        "b": "relate",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8845056295394897,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.8168465495109558,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7521464824676514,
            "answer": "correlated",
            "hit": false
          },
          {
            "score": 0.7502740621566772,
            "answer": "attributed",
            "hit": false
          },
          {
            "score": 0.7483901977539062,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.7448570728302002,
            "answer": "arose",
            "hit": false
          }
        ],
        "set_exclude": [
          "relate"
        ],
        "rank": 166,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7045832574367523
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.9128047227859497,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.8594202995300293,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.8221631050109863,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.7815625667572021,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.7732514142990112,
            "answer": "kept",
            "hit": false
          },
          {
            "score": 0.7728936672210693,
            "answer": "stays",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9128047227859497
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.780040442943573,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.7701752185821533,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.7564212679862976,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.7459521293640137,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7458792328834534,
            "answer": "split",
            "hit": false
          },
          {
            "score": 0.7332285642623901,
            "answer": "substituted",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.780040442943573
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.8421962857246399,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.7846934199333191,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7823404669761658,
            "answer": "demanded",
            "hit": false
          },
          {
            "score": 0.7806774377822876,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7686583995819092,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.7658311724662781,
            "answer": "needed",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7686583995819092
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.900740921497345,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.8265938758850098,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7976710796356201,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.7938361167907715,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7758515477180481,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.7709550261497498,
            "answer": "seems",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.900740921497345
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.7788350582122803,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7782665491104126,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.7549516558647156,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.74033522605896,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.7256178855895996,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.7229856252670288,
            "answer": "sentenced",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.754951685667038
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8961742520332336,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.889461100101471,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8603293895721436,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.7709328532218933,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7654763460159302,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7632229328155518,
            "answer": "invested",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8961742520332336
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.7757099270820618,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.7503576278686523,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.7473065257072449,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.7375757694244385,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.7255258560180664,
            "answer": "said",
            "hit": false
          },
          {
            "score": 0.7193720936775208,
            "answer": "didn",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7503575682640076
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8126365542411804,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.8010456562042236,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7758855819702148,
            "answer": "grasped",
            "hit": false
          },
          {
            "score": 0.7709555625915527,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7672200202941895,
            "answer": "understanding",
            "hit": false
          },
          {
            "score": 0.7618079781532288,
            "answer": "obviously",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8126366138458252
      },
      {
        "question verbose": "What is to unite ",
        "b": "unite",
        "expected answer": [
          "united"
        ],
        "predictions": [
          {
            "score": 0.7897998690605164,
            "answer": "unified",
            "hit": false
          },
          {
            "score": 0.7841503024101257,
            "answer": "unity",
            "hit": false
          },
          {
            "score": 0.7598236203193665,
            "answer": "fused",
            "hit": false
          },
          {
            "score": 0.747244119644165,
            "answer": "denounced",
            "hit": false
          },
          {
            "score": 0.7391708493232727,
            "answer": "converge",
            "hit": false
          },
          {
            "score": 0.7389639616012573,
            "answer": "embraced",
            "hit": false
          }
        ],
        "set_exclude": [
          "unite"
        ],
        "rank": 169,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.702189713716507
      }
    ],
    "result": {
      "cnt_questions_correct": 23,
      "cnt_questions_total": 50,
      "accuracy": 0.46
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I07 [verb_inf - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "8422eb3f-3142-422d-aec3-a179b8aa098a",
      "timestamp": "2025-05-17T17:12:45.841221"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.8290901184082031,
            "answer": "adds",
            "hit": true
          },
          {
            "score": 0.7993554472923279,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7935607433319092,
            "answer": "contributes",
            "hit": false
          },
          {
            "score": 0.7871910333633423,
            "answer": "removes",
            "hit": false
          },
          {
            "score": 0.7802976369857788,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.779809296131134,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8290901184082031
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.9271736145019531,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.8639450669288635,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8575705289840698,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.828132152557373,
            "answer": "lets",
            "hit": false
          },
          {
            "score": 0.8237060308456421,
            "answer": "letting",
            "hit": false
          },
          {
            "score": 0.8220919370651245,
            "answer": "gives",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9271736741065979
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.856445848941803,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8371091485023499,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7848441004753113,
            "answer": "disappears",
            "hit": false
          },
          {
            "score": 0.7834069132804871,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7760184407234192,
            "answer": "arises",
            "hit": false
          },
          {
            "score": 0.7748680710792542,
            "answer": "resembles",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7510160207748413
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.8944472074508667,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.853055477142334,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.8328295946121216,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.7786815166473389,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.7781521677970886,
            "answer": "removes",
            "hit": false
          },
          {
            "score": 0.7766780853271484,
            "answer": "operates",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8944472074508667
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.8020276427268982,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.7924286127090454,
            "answer": "seeks",
            "hit": false
          },
          {
            "score": 0.7882221341133118,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.7841979265213013,
            "answer": "wants",
            "hit": false
          },
          {
            "score": 0.778560996055603,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7765669822692871,
            "answer": "suggests",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 455,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6907934546470642
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.8856245279312134,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.7950485944747925,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.7788892984390259,
            "answer": "grows",
            "hit": false
          },
          {
            "score": 0.7703075408935547,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.76663738489151,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.765489935874939,
            "answer": "loses",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8856245875358582
      },
      {
        "question verbose": "What is to believing ",
        "b": "believing",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.8860680460929871,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.8233428001403809,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.8049251437187195,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.8022056818008423,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7932214736938477,
            "answer": "insists",
            "hit": false
          },
          {
            "score": 0.7908135652542114,
            "answer": "convinced",
            "hit": false
          }
        ],
        "set_exclude": [
          "believing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8860681056976318
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.8336700201034546,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.8142909407615662,
            "answer": "honestly",
            "hit": false
          },
          {
            "score": 0.811458170413971,
            "answer": "implies",
            "hit": false
          },
          {
            "score": 0.8090827465057373,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8048615455627441,
            "answer": "depending",
            "hit": false
          },
          {
            "score": 0.8044584393501282,
            "answer": "compared",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8336700797080994
      },
      {
        "question verbose": "What is to consisting ",
        "b": "consisting",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.9167097806930542,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.8677340149879456,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.8590617775917053,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.8467739224433899,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.8439904451370239,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.8371261358261108,
            "answer": "consist",
            "hit": false
          }
        ],
        "set_exclude": [
          "consisting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9167097508907318
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.9049479961395264,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.8515145182609558,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.7984551191329956,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.7939119935035706,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.7906721830368042,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.7850285172462463,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9049479365348816
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.8134123086929321,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.7612195014953613,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.7528436183929443,
            "answer": "expands",
            "hit": false
          },
          {
            "score": 0.7487450838088989,
            "answer": "engages",
            "hit": false
          },
          {
            "score": 0.7466317415237427,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7463192939758301,
            "answer": "explores",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8134123086929321
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.9302080869674683,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.8240833878517151,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.8220386505126953,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.8090349435806274,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.8080413341522217,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8018919825553894,
            "answer": "allows",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9302080571651459
      },
      {
        "question verbose": "What is to depending ",
        "b": "depending",
        "expected answer": [
          "depends"
        ],
        "predictions": [
          {
            "score": 0.8233542442321777,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.8129392862319946,
            "answer": "generally",
            "hit": false
          },
          {
            "score": 0.8123247623443604,
            "answer": "ideally",
            "hit": false
          },
          {
            "score": 0.8104129433631897,
            "answer": "depends",
            "hit": true
          },
          {
            "score": 0.8029544353485107,
            "answer": "alternatively",
            "hit": false
          },
          {
            "score": 0.8008049726486206,
            "answer": "determines",
            "hit": false
          }
        ],
        "set_exclude": [
          "depending"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8104129433631897
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.9187861680984497,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.8699966073036194,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.8218994140625,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.82149338722229,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.8198680877685547,
            "answer": "depicts",
            "hit": false
          },
          {
            "score": 0.8109049797058105,
            "answer": "identifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9187861680984497
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.8940116167068481,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.8734662532806396,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.8324400186538696,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7774235010147095,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.7638909816741943,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7543996572494507,
            "answer": "development",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8940117061138153
      },
      {
        "question verbose": "What is to discovering ",
        "b": "discovering",
        "expected answer": [
          "discovers"
        ],
        "predictions": [
          {
            "score": 0.9119799733161926,
            "answer": "discovers",
            "hit": true
          },
          {
            "score": 0.8303431272506714,
            "answer": "discovered",
            "hit": false
          },
          {
            "score": 0.8293271064758301,
            "answer": "finds",
            "hit": false
          },
          {
            "score": 0.8244261145591736,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.8130541443824768,
            "answer": "realizes",
            "hit": false
          },
          {
            "score": 0.8125250339508057,
            "answer": "explores",
            "hit": false
          }
        ],
        "set_exclude": [
          "discovering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.911980003118515
      },
      {
        "question verbose": "What is to enabling ",
        "b": "enabling",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.918470025062561,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.8371773958206177,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8290385007858276,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.8152633905410767,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8131976127624512,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7912641763687134,
            "answer": "creates",
            "hit": false
          }
        ],
        "set_exclude": [
          "enabling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9184700846672058
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.7719016075134277,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.7434728145599365,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7353574633598328,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7325654625892639,
            "answer": "extant",
            "hit": false
          },
          {
            "score": 0.7301630973815918,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.7266995906829834,
            "answer": "occurs",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7719016075134277
      },
      {
        "question verbose": "What is to explaining ",
        "b": "explaining",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.8867689967155457,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8227348327636719,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8222095370292664,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.8209882974624634,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.8064984083175659,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.8057480454444885,
            "answer": "explanation",
            "hit": false
          }
        ],
        "set_exclude": [
          "explaining"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.886769026517868
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.8177106380462646,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.7371480464935303,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.7251602411270142,
            "answer": "after",
            "hit": false
          },
          {
            "score": 0.7205207943916321,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.7172322273254395,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7146909236907959,
            "answer": "preceding",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8177106976509094
      },
      {
        "question verbose": "What is to happening ",
        "b": "happening",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.8829367160797119,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.8574540615081787,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8451274633407593,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.834884762763977,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.8292683362960815,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7935521602630615,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happening"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8829367458820343
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.8118136525154114,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.8101966977119446,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7984611392021179,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.7488058805465698,
            "answer": "sees",
            "hit": false
          },
          {
            "score": 0.7439519762992859,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.736998438835144,
            "answer": "speaks",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7984611392021179
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.9182627201080322,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.8226763010025024,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8127410411834717,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.8083805441856384,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.805745005607605,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.7998138666152954,
            "answer": "improvements",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9182627201080322
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.8065818548202515,
            "answer": "excluding",
            "hit": false
          },
          {
            "score": 0.8057095408439636,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.7922518253326416,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.7856979370117188,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.784469723701477,
            "answer": "particularly",
            "hit": false
          },
          {
            "score": 0.7829595804214478,
            "answer": "incorporates",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8057095408439636
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.8882718086242676,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.8375681638717651,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7962779402732849,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7872937917709351,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.7828418016433716,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.781145453453064,
            "answer": "consists",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8882717788219452
      },
      {
        "question verbose": "What is to learning ",
        "b": "learning",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.8448747396469116,
            "answer": "learn",
            "hit": false
          },
          {
            "score": 0.7926927804946899,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.7879520654678345,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7731558084487915,
            "answer": "learners",
            "hit": false
          },
          {
            "score": 0.7639294862747192,
            "answer": "discovers",
            "hit": false
          },
          {
            "score": 0.7512685060501099,
            "answer": "learnt",
            "hit": false
          }
        ],
        "set_exclude": [
          "learning"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7334299087524414
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "loses"
        ],
        "predictions": [
          {
            "score": 0.9039231538772583,
            "answer": "loses",
            "hit": true
          },
          {
            "score": 0.808955192565918,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.795529305934906,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7873077392578125,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.7809443473815918,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.7761013507843018,
            "answer": "receives",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9039231538772583
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "manages"
        ],
        "predictions": [
          {
            "score": 0.808236300945282,
            "answer": "manages",
            "hit": true
          },
          {
            "score": 0.7762395739555359,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.7682029008865356,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7653969526290894,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.761522114276886,
            "answer": "owns",
            "hit": false
          },
          {
            "score": 0.7613925933837891,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.808236300945282
      },
      {
        "question verbose": "What is to occurring ",
        "b": "occurring",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.904112696647644,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.8596845865249634,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8435784578323364,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.8305163383483887,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.8241976499557495,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.8000661134719849,
            "answer": "arises",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.904112696647644
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.8310229778289795,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.7798876762390137,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7616565227508545,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.753818690776825,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.7456748485565186,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7445911169052124,
            "answer": "performs",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8310230076313019
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performs"
        ],
        "predictions": [
          {
            "score": 0.8296914100646973,
            "answer": "performs",
            "hit": true
          },
          {
            "score": 0.7950299978256226,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.7649558782577515,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7641783356666565,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7624082565307617,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.7619146108627319,
            "answer": "generates",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8296913802623749
      },
      {
        "question verbose": "What is to promoting ",
        "b": "promoting",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.9330065250396729,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8946000337600708,
            "answer": "promote",
            "hit": false
          },
          {
            "score": 0.8297290802001953,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8155376315116882,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.8127046823501587,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7956249117851257,
            "answer": "advocating",
            "hit": false
          }
        ],
        "set_exclude": [
          "promoting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9330066442489624
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.9334108233451843,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.8879632353782654,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8350653052330017,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.8260416984558105,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8259547352790833,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.824260413646698,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9334108829498291
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.8979842662811279,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.8581293821334839,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.7713466882705688,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.7622562646865845,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.7536212205886841,
            "answer": "participates",
            "hit": false
          },
          {
            "score": 0.7527092695236206,
            "answer": "delivers",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8979842066764832
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.9346799254417419,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.8884365558624268,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.845415472984314,
            "answer": "decreases",
            "hit": false
          },
          {
            "score": 0.8357474207878113,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.8338884711265564,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8331542015075684,
            "answer": "lowers",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9346799850463867
      },
      {
        "question verbose": "What is to referring ",
        "b": "referring",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.8844090700149536,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.8250044584274292,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.8001127243041992,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7907028794288635,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7825016975402832,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.78249192237854,
            "answer": "implies",
            "hit": false
          }
        ],
        "set_exclude": [
          "referring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8844090700149536
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "relates"
        ],
        "predictions": [
          {
            "score": 0.871084451675415,
            "answer": "relates",
            "hit": true
          },
          {
            "score": 0.8391104936599731,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.8251593708992004,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7932230234146118,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.7922197580337524,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7914354801177979,
            "answer": "involves",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.871084451675415
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.814255952835083,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.7890897989273071,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.7860600352287292,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7759184837341309,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7594330310821533,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.755754828453064,
            "answer": "continues",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7890897691249847
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.9025594592094421,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.7926408052444458,
            "answer": "depicts",
            "hit": false
          },
          {
            "score": 0.785941481590271,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.7832539081573486,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.7821515202522278,
            "answer": "reflects",
            "hit": false
          },
          {
            "score": 0.780612587928772,
            "answer": "serves",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9025594592094421
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.8550676107406616,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.813355565071106,
            "answer": "prohibits",
            "hit": false
          },
          {
            "score": 0.8116017580032349,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.803158164024353,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.802301824092865,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.8012374043464661,
            "answer": "requires",
            "hit": true
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8012374043464661
      },
      {
        "question verbose": "What is to seeming ",
        "b": "seeming",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.834976315498352,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8145524859428406,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.8088378310203552,
            "answer": "tends",
            "hit": false
          },
          {
            "score": 0.8043795824050903,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7953817248344421,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.789488673210144,
            "answer": "resembles",
            "hit": false
          }
        ],
        "set_exclude": [
          "seeming"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7953816652297974
      },
      {
        "question verbose": "What is to sitting ",
        "b": "sitting",
        "expected answer": [
          "sits"
        ],
        "predictions": [
          {
            "score": 0.8710182905197144,
            "answer": "sits",
            "hit": true
          },
          {
            "score": 0.8271462321281433,
            "answer": "sit",
            "hit": false
          },
          {
            "score": 0.7752190828323364,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.7665489315986633,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.7629373073577881,
            "answer": "leans",
            "hit": false
          },
          {
            "score": 0.7557731866836548,
            "answer": "stood",
            "hit": false
          }
        ],
        "set_exclude": [
          "sitting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8710182905197144
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spends"
        ],
        "predictions": [
          {
            "score": 0.8719890713691711,
            "answer": "spends",
            "hit": true
          },
          {
            "score": 0.8536230325698853,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8226392865180969,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.8037388324737549,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7755616903305054,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.763187050819397,
            "answer": "budgets",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8719891011714935
      },
      {
        "question verbose": "What is to suggesting ",
        "b": "suggesting",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.9107046127319336,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.8599937558174133,
            "answer": "implying",
            "hit": false
          },
          {
            "score": 0.8372012972831726,
            "answer": "indicating",
            "hit": false
          },
          {
            "score": 0.8371000289916992,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.8365510702133179,
            "answer": "implies",
            "hit": false
          },
          {
            "score": 0.817808210849762,
            "answer": "proposes",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggesting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9107046723365784
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "teaches"
        ],
        "predictions": [
          {
            "score": 0.8601431846618652,
            "answer": "teaches",
            "hit": true
          },
          {
            "score": 0.8172390460968018,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.8088729977607727,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.7945507168769836,
            "answer": "teachers",
            "hit": false
          },
          {
            "score": 0.7912856936454773,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7712495923042297,
            "answer": "encourages",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8601431250572205
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.8887068033218384,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.7991390824317932,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.788799524307251,
            "answer": "says",
            "hit": false
          },
          {
            "score": 0.7871055603027344,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7868793606758118,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.7825725674629211,
            "answer": "saying",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8887068033218384
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.8242138624191284,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.7857954502105713,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7719216346740723,
            "answer": "knows",
            "hit": false
          },
          {
            "score": 0.7699899673461914,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.7675347328186035,
            "answer": "realizes",
            "hit": false
          },
          {
            "score": 0.7616108059883118,
            "answer": "explains",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8242138922214508
      }
    ],
    "result": {
      "cnt_questions_correct": 38,
      "cnt_questions_total": 47,
      "accuracy": 0.8085106382978723
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I08 [verb_Ving - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "e042297c-d1ef-48df-9098-77d63709033c",
      "timestamp": "2025-05-17T17:12:46.036459"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.796468198299408,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.7726149559020996,
            "answer": "additionally",
            "hit": false
          },
          {
            "score": 0.7619137763977051,
            "answer": "increased",
            "hit": false
          },
          {
            "score": 0.7616105079650879,
            "answer": "putting",
            "hit": false
          },
          {
            "score": 0.7588014006614685,
            "answer": "could",
            "hit": false
          },
          {
            "score": 0.755290687084198,
            "answer": "initially",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7545050978660583
      },
      {
        "question verbose": "What is to agreeing ",
        "b": "agreeing",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8810778856277466,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8486567139625549,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.8412929773330688,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8040573596954346,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7783219218254089,
            "answer": "persuaded",
            "hit": false
          },
          {
            "score": 0.7754173278808594,
            "answer": "agreements",
            "hit": false
          }
        ],
        "set_exclude": [
          "agreeing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8810778856277466
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.8634078502655029,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8612210750579834,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8305138349533081,
            "answer": "letting",
            "hit": false
          },
          {
            "score": 0.8037115335464478,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.7963428497314453,
            "answer": "permitting",
            "hit": false
          },
          {
            "score": 0.7926319241523743,
            "answer": "granting",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7631040811538696
      },
      {
        "question verbose": "What is to announcing ",
        "b": "announcing",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8595685958862305,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.8312425017356873,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.8193434476852417,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8050464391708374,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.7907419204711914,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.7806491851806641,
            "answer": "announce",
            "hit": false
          }
        ],
        "set_exclude": [
          "announcing"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7907419800758362
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.867213249206543,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8380465507507324,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7681393623352051,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7590034008026123,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.757970929145813,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7536399364471436,
            "answer": "displayed",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.867213249206543
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8979028463363647,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.8400170207023621,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.8351904153823853,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.7581865191459656,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.7549921870231628,
            "answer": "applicants",
            "hit": false
          },
          {
            "score": 0.7534811496734619,
            "answer": "subjected",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8979029059410095
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.8020728230476379,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.791785717010498,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.7827187776565552,
            "answer": "begged",
            "hit": false
          },
          {
            "score": 0.7803319096565247,
            "answer": "demanded",
            "hit": false
          },
          {
            "score": 0.7757881879806519,
            "answer": "wondered",
            "hit": false
          },
          {
            "score": 0.7755354642868042,
            "answer": "begging",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7618057131767273
      },
      {
        "question verbose": "What is to attending ",
        "b": "attending",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.8766708970069885,
            "answer": "attend",
            "hit": false
          },
          {
            "score": 0.872410237789154,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.7975043058395386,
            "answer": "participated",
            "hit": false
          },
          {
            "score": 0.7850867509841919,
            "answer": "participating",
            "hit": false
          },
          {
            "score": 0.7849067449569702,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.7796152830123901,
            "answer": "attendance",
            "hit": false
          }
        ],
        "set_exclude": [
          "attending"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8724102675914764
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8162261843681335,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.7620161771774292,
            "answer": "become",
            "hit": false
          },
          {
            "score": 0.759020984172821,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.7545007467269897,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.7478200197219849,
            "answer": "getting",
            "hit": false
          },
          {
            "score": 0.7445659041404724,
            "answer": "surpassed",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7545007467269897
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8187209367752075,
            "answer": "compared",
            "hit": false
          },
          {
            "score": 0.814558207988739,
            "answer": "honestly",
            "hit": false
          },
          {
            "score": 0.8091605305671692,
            "answer": "clearly",
            "hit": false
          },
          {
            "score": 0.8087196946144104,
            "answer": "granted",
            "hit": false
          },
          {
            "score": 0.80743008852005,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.800788164138794,
            "answer": "besides",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 66,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.754533052444458
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.8466758728027344,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.8447421193122864,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.8280824422836304,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.798608660697937,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.7669349312782288,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.7599230408668518,
            "answer": "comprised",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8280825018882751
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.7578139901161194,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7509053349494934,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.742040753364563,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7416812777519226,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.735731303691864,
            "answer": "persisted",
            "hit": false
          },
          {
            "score": 0.7330113649368286,
            "answer": "resumed",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7509053647518158
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.8648566007614136,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8261430859565735,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.7977364659309387,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.7921954393386841,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.7912747263908386,
            "answer": "generating",
            "hit": false
          },
          {
            "score": 0.7860133647918701,
            "answer": "designing",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7977364659309387
      },
      {
        "question verbose": "What is to deciding ",
        "b": "deciding",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8401638269424438,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.839896559715271,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8367563486099243,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8353638648986816,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.7820976376533508,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7766921520233154,
            "answer": "determines",
            "hit": false
          }
        ],
        "set_exclude": [
          "deciding"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8367563784122467
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8678191900253296,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.8641388416290283,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8112345933914185,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.8054088354110718,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.7882876396179199,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7825878262519836,
            "answer": "depicting",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7807283997535706
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8717986345291138,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.8682763576507568,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.8350929021835327,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7570086717605591,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7479231953620911,
            "answer": "emerging",
            "hit": false
          },
          {
            "score": 0.7367796301841736,
            "answer": "developmental",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.871798574924469
      },
      {
        "question verbose": "What is to establishing ",
        "b": "establishing",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8753914833068848,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8491607308387756,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.8418017625808716,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.7741861939430237,
            "answer": "initiating",
            "hit": false
          },
          {
            "score": 0.7654672861099243,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.7622057199478149,
            "answer": "instituted",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8418018221855164
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "existed"
        ],
        "predictions": [
          {
            "score": 0.7491422891616821,
            "answer": "extant",
            "hit": false
          },
          {
            "score": 0.7472989559173584,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.73165363073349,
            "answer": "proposed",
            "hit": false
          },
          {
            "score": 0.7297515869140625,
            "answer": "old",
            "hit": false
          },
          {
            "score": 0.7250065803527832,
            "answer": "existed",
            "hit": true
          },
          {
            "score": 0.7203892469406128,
            "answer": "previously",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.725006639957428
      },
      {
        "question verbose": "What is to expecting ",
        "b": "expecting",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8154902458190918,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.7991160154342651,
            "answer": "hoping",
            "hit": false
          },
          {
            "score": 0.7756498456001282,
            "answer": "intending",
            "hit": false
          },
          {
            "score": 0.7736008167266846,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.7706087827682495,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.7570466995239258,
            "answer": "waited",
            "hit": false
          }
        ],
        "set_exclude": [
          "expecting"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7736007869243622
      },
      {
        "question verbose": "What is to failing ",
        "b": "failing",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.8248834609985352,
            "answer": "fails",
            "hit": false
          },
          {
            "score": 0.808350682258606,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.8017212748527527,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.7896665334701538,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.7864691019058228,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.7624924182891846,
            "answer": "faulty",
            "hit": false
          }
        ],
        "set_exclude": [
          "failing"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7864691019058228
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.7667304277420044,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.735031247138977,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.7316455841064453,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.7266285419464111,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.721603274345398,
            "answer": "after",
            "hit": false
          },
          {
            "score": 0.6895807981491089,
            "answer": "returned",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7316455543041229
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8134602308273315,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.8133826851844788,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.7710652947425842,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.7635812759399414,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.7449748516082764,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7368528842926025,
            "answer": "auditory",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7635813057422638
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.8619222640991211,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8334502577781677,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.8329464793205261,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8212682008743286,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.8016245365142822,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.799103856086731,
            "answer": "enhancing",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8334502577781677
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.8081917762756348,
            "answer": "excluding",
            "hit": false
          },
          {
            "score": 0.7933813333511353,
            "answer": "particularly",
            "hit": false
          },
          {
            "score": 0.7789663076400757,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7687079906463623,
            "answer": "mostly",
            "hit": false
          },
          {
            "score": 0.7621281147003174,
            "answer": "even",
            "hit": false
          },
          {
            "score": 0.7620811462402344,
            "answer": "also",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.739029198884964
      },
      {
        "question verbose": "What is to introducing ",
        "b": "introducing",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.9077541828155518,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.8959059715270996,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8836663961410522,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.829611599445343,
            "answer": "introduction",
            "hit": false
          },
          {
            "score": 0.7686529159545898,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.7637580037117004,
            "answer": "debuted",
            "hit": false
          }
        ],
        "set_exclude": [
          "introducing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8959059715270996
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8267039060592651,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8224568367004395,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7784056067466736,
            "answer": "undertaken",
            "hit": false
          },
          {
            "score": 0.765854001045227,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7624585032463074,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.7619957327842712,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7414389699697495
      },
      {
        "question verbose": "What is to locating ",
        "b": "locating",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8858884572982788,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7927919626235962,
            "answer": "located",
            "hit": true
          },
          {
            "score": 0.7723016738891602,
            "answer": "relocated",
            "hit": false
          },
          {
            "score": 0.7660064697265625,
            "answer": "finding",
            "hit": false
          },
          {
            "score": 0.7594395875930786,
            "answer": "resided",
            "hit": false
          },
          {
            "score": 0.7587000727653503,
            "answer": "retrieved",
            "hit": false
          }
        ],
        "set_exclude": [
          "locating"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7927919924259186
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8471134901046753,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.805070698261261,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7995831966400146,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7880120277404785,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.7812083959579468,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.7630786895751953,
            "answer": "loser",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7880120873451233
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.7704655528068542,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.7539845108985901,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.7514778971672058,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7425540089607239,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.7333754897117615,
            "answer": "executive",
            "hit": false
          },
          {
            "score": 0.7303391695022583,
            "answer": "ceo",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7539845108985901
      },
      {
        "question verbose": "What is to marrying ",
        "b": "marrying",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.9031170606613159,
            "answer": "marry",
            "hit": false
          },
          {
            "score": 0.8537341356277466,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.8208928108215332,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.7994465231895447,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.7936766147613525,
            "answer": "divorced",
            "hit": false
          },
          {
            "score": 0.7916166186332703,
            "answer": "kissed",
            "hit": false
          }
        ],
        "set_exclude": [
          "marrying"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.853734165430069
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.7723830938339233,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.772315502166748,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7460435628890991,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7198212146759033,
            "answer": "operated",
            "hit": true
          },
          {
            "score": 0.717120885848999,
            "answer": "integrated",
            "hit": false
          },
          {
            "score": 0.7147629857063293,
            "answer": "operator",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7198212146759033
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.7895932793617249,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.7689924240112305,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.7672542333602905,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7595919966697693,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7534536123275757,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.753235936164856,
            "answer": "funded",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7689924240112305
      },
      {
        "question verbose": "What is to proposing ",
        "b": "proposing",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8879615664482117,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.8819124102592468,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8502306342124939,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.8337678909301758,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.8216301202774048,
            "answer": "proposals",
            "hit": false
          },
          {
            "score": 0.8104251027107239,
            "answer": "advocated",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8502306640148163
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8865225911140442,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8655571341514587,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8322671055793762,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.8076862096786499,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.7987031936645508,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.794526219367981,
            "answer": "assisting",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.758700966835022
      },
      {
        "question verbose": "What is to publishing ",
        "b": "publishing",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.8755700588226318,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.8277807235717773,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.8272041082382202,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.825612485408783,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7961207628250122,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.7619422674179077,
            "answer": "publications",
            "hit": false
          }
        ],
        "set_exclude": [
          "publishing"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7961207628250122
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8560649156570435,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.8346379399299622,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7813433408737183,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.7570319175720215,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.7467058897018433,
            "answer": "recipient",
            "hit": false
          },
          {
            "score": 0.7373554706573486,
            "answer": "recipients",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7813432812690735
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.8920536041259766,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.8737226724624634,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8609055876731873,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.8473587036132812,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.8366869688034058,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.8319577574729919,
            "answer": "decreasing",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8609055876731873
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8512312173843384,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.8212059140205383,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.8185749053955078,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7913134098052979,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.7785068154335022,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7747794389724731,
            "answer": "arising",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 149,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7055162489414215
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8142154216766357,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.791579008102417,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.7714095115661621,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7468562126159668,
            "answer": "surviving",
            "hit": false
          },
          {
            "score": 0.7376506328582764,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.7300779819488525,
            "answer": "retained",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7915789484977722
      },
      {
        "question verbose": "What is to replacing ",
        "b": "replacing",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8906554579734802,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8721508383750916,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.8221112489700317,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.8082991242408752,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7951148748397827,
            "answer": "substituted",
            "hit": false
          },
          {
            "score": 0.790838360786438,
            "answer": "replace",
            "hit": false
          }
        ],
        "set_exclude": [
          "replacing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.890655517578125
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.845717191696167,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.7914285063743591,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.7815013527870178,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7810919880867004,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.7565385103225708,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.7560167908668518,
            "answer": "comprising",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7810919880867004
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.8501734733581543,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.798548698425293,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.7857215404510498,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7816674709320068,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.7779983878135681,
            "answer": "demanded",
            "hit": false
          },
          {
            "score": 0.7752472162246704,
            "answer": "requires",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7539256811141968
      },
      {
        "question verbose": "What is to sending ",
        "b": "sending",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8738179206848145,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.8006171584129333,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.7527152299880981,
            "answer": "transmitted",
            "hit": false
          },
          {
            "score": 0.7521765232086182,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.749539315700531,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.7479017972946167,
            "answer": "communicated",
            "hit": false
          }
        ],
        "set_exclude": [
          "sending"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7521765530109406
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8617335557937622,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8274587392807007,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8249735832214355,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.8096826076507568,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.8063785433769226,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.759602427482605,
            "answer": "expenses",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8063785135746002
      },
      {
        "question verbose": "What is to suffering ",
        "b": "suffering",
        "expected answer": [
          "suffered"
        ],
        "predictions": [
          {
            "score": 0.8388471007347107,
            "answer": "suffered",
            "hit": true
          },
          {
            "score": 0.8325270414352417,
            "answer": "suffer",
            "hit": false
          },
          {
            "score": 0.7948747277259827,
            "answer": "suffers",
            "hit": false
          },
          {
            "score": 0.7944212555885315,
            "answer": "misery",
            "hit": false
          },
          {
            "score": 0.7823209166526794,
            "answer": "anguish",
            "hit": false
          },
          {
            "score": 0.7802333831787109,
            "answer": "agony",
            "hit": false
          }
        ],
        "set_exclude": [
          "suffering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8388471603393555
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "taught"
        ],
        "predictions": [
          {
            "score": 0.8315316438674927,
            "answer": "taught",
            "hit": true
          },
          {
            "score": 0.815974235534668,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.8060723543167114,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8041735291481018,
            "answer": "teachers",
            "hit": false
          },
          {
            "score": 0.7969726920127869,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.7676651477813721,
            "answer": "education",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8315316140651703
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.8319149017333984,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.7878040671348572,
            "answer": "saying",
            "hit": false
          },
          {
            "score": 0.7800933718681335,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.772547721862793,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.7706329822540283,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.7522348165512085,
            "answer": "explaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7800933122634888
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8031980991363525,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.7800458669662476,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.779580295085907,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7642458081245422,
            "answer": "comprehension",
            "hit": false
          },
          {
            "score": 0.7603600025177002,
            "answer": "insight",
            "hit": false
          },
          {
            "score": 0.7563250064849854,
            "answer": "comprehend",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8031981289386749
      }
    ],
    "result": {
      "cnt_questions_correct": 8,
      "cnt_questions_total": 48,
      "accuracy": 0.16666666666666666
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I09 [verb_Ving - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "fc633873-d76d-404b-a7ca-87646da28ce0",
      "timestamp": "2025-05-17T17:12:46.219843"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adds ",
        "b": "adds",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.7892665266990662,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.7632769346237183,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.754456639289856,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.7536224126815796,
            "answer": "increased",
            "hit": false
          },
          {
            "score": 0.744701623916626,
            "answer": "noticed",
            "hit": false
          },
          {
            "score": 0.7405288815498352,
            "answer": "removed",
            "hit": false
          }
        ],
        "set_exclude": [
          "adds"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7544566094875336
      },
      {
        "question verbose": "What is to agrees ",
        "b": "agrees",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8963669538497925,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8781169652938843,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.8331056237220764,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8211137056350708,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7686153650283813,
            "answer": "acknowledged",
            "hit": false
          },
          {
            "score": 0.7681568264961243,
            "answer": "nodded",
            "hit": false
          }
        ],
        "set_exclude": [
          "agrees"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8963669538497925
      },
      {
        "question verbose": "What is to allows ",
        "b": "allows",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.9026906490325928,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8576929569244385,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.854974627494812,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8245081305503845,
            "answer": "lets",
            "hit": false
          },
          {
            "score": 0.8188206553459167,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.8120971918106079,
            "answer": "gives",
            "hit": false
          }
        ],
        "set_exclude": [
          "allows"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7763321697711945
      },
      {
        "question verbose": "What is to announces ",
        "b": "announces",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8520585894584656,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.8109555244445801,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.80897057056427,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8057315945625305,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.7965466976165771,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.7942684888839722,
            "answer": "announce",
            "hit": false
          }
        ],
        "set_exclude": [
          "announces"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8109555542469025
      },
      {
        "question verbose": "What is to appears ",
        "b": "appears",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.7386074066162109,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.7229671478271484,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.7212117910385132,
            "answer": "reached",
            "hit": false
          },
          {
            "score": 0.7173827290534973,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7119738459587097,
            "answer": "apparently",
            "hit": false
          },
          {
            "score": 0.7102670669555664,
            "answer": "became",
            "hit": false
          }
        ],
        "set_exclude": [
          "appears"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7386073768138885
      },
      {
        "question verbose": "What is to applies ",
        "b": "applies",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.860375702381134,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.8232466578483582,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7919726371765137,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.7894686460494995,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.7400602698326111,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7371238470077515,
            "answer": "prohibits",
            "hit": false
          }
        ],
        "set_exclude": [
          "applies"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8603757619857788
      },
      {
        "question verbose": "What is to asks ",
        "b": "asks",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.7076027989387512,
            "answer": "task",
            "hit": false
          },
          {
            "score": 0.7073796987533569,
            "answer": "tasks",
            "hit": false
          },
          {
            "score": 0.7000421285629272,
            "answer": "demanded",
            "hit": false
          },
          {
            "score": 0.6870366334915161,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.6831995844841003,
            "answer": "agitated",
            "hit": false
          },
          {
            "score": 0.6822208166122437,
            "answer": "ask",
            "hit": false
          }
        ],
        "set_exclude": [
          "asks"
        ],
        "rank": 31,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.666048139333725
      },
      {
        "question verbose": "What is to becomes ",
        "b": "becomes",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8227803707122803,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.7783368229866028,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.772295355796814,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.7705923318862915,
            "answer": "disappears",
            "hit": false
          },
          {
            "score": 0.7686392664909363,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7606759071350098,
            "answer": "remained",
            "hit": false
          }
        ],
        "set_exclude": [
          "becomes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7722953259944916
      },
      {
        "question verbose": "What is to believes ",
        "b": "believes",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.881342887878418,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.8303960561752319,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.8260278701782227,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.8131230473518372,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.7973127365112305,
            "answer": "insisted",
            "hit": false
          },
          {
            "score": 0.796694278717041,
            "answer": "believe",
            "hit": false
          }
        ],
        "set_exclude": [
          "believes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8813428282737732
      },
      {
        "question verbose": "What is to considers ",
        "b": "considers",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8753033876419067,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.8150665163993835,
            "answer": "regarded",
            "hit": false
          },
          {
            "score": 0.8051360845565796,
            "answer": "deemed",
            "hit": false
          },
          {
            "score": 0.7950229048728943,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.7860063910484314,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7818350791931152,
            "answer": "believes",
            "hit": false
          }
        ],
        "set_exclude": [
          "considers"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8753033876419067
      },
      {
        "question verbose": "What is to consists ",
        "b": "consists",
        "expected answer": [
          "consisted"
        ],
        "predictions": [
          {
            "score": 0.9393254518508911,
            "answer": "consisted",
            "hit": true
          },
          {
            "score": 0.907667875289917,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.872199296951294,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.8481429815292358,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.8370193243026733,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7922871112823486,
            "answer": "comprise",
            "hit": false
          }
        ],
        "set_exclude": [
          "consists"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9393255114555359
      },
      {
        "question verbose": "What is to contains ",
        "b": "contains",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.8948916792869568,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.8686267137527466,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.8502935171127319,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.7819268703460693,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.7755252718925476,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.7652044892311096,
            "answer": "comprised",
            "hit": false
          }
        ],
        "set_exclude": [
          "contains"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8686267733573914
      },
      {
        "question verbose": "What is to continues ",
        "b": "continues",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.8086630702018738,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7805377244949341,
            "answer": "persisted",
            "hit": false
          },
          {
            "score": 0.7793622612953186,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.7785511612892151,
            "answer": "resumed",
            "hit": false
          },
          {
            "score": 0.7735930681228638,
            "answer": "kept",
            "hit": false
          },
          {
            "score": 0.7719748020172119,
            "answer": "remains",
            "hit": false
          }
        ],
        "set_exclude": [
          "continues"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.779362291097641
      },
      {
        "question verbose": "What is to creates ",
        "b": "creates",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.8536543250083923,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.8262155652046204,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.8226617574691772,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.8002179861068726,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.7974568605422974,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.7896534204483032,
            "answer": "destroys",
            "hit": false
          }
        ],
        "set_exclude": [
          "creates"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7974568605422974
      },
      {
        "question verbose": "What is to decides ",
        "b": "decides",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.9112197756767273,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8991640210151672,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8379532694816589,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.8366394639015198,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.8114992380142212,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.8060756325721741,
            "answer": "opted",
            "hit": false
          }
        ],
        "set_exclude": [
          "decides"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9112198054790497
      },
      {
        "question verbose": "What is to describes ",
        "b": "describes",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8872533440589905,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.849304735660553,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8177734613418579,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.7976922988891602,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.7956018447875977,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.7893315553665161,
            "answer": "characterized",
            "hit": false
          }
        ],
        "set_exclude": [
          "describes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8177734613418579
      },
      {
        "question verbose": "What is to develops ",
        "b": "develops",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8890404105186462,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.8694822788238525,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.8382527232170105,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7861281633377075,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7768074870109558,
            "answer": "progressed",
            "hit": false
          },
          {
            "score": 0.7767695188522339,
            "answer": "progresses",
            "hit": false
          }
        ],
        "set_exclude": [
          "develops"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8694823384284973
      },
      {
        "question verbose": "What is to establishes ",
        "b": "establishes",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8652012348175049,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8539625406265259,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.8394044041633606,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.7772946357727051,
            "answer": "instituted",
            "hit": false
          },
          {
            "score": 0.7745013236999512,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.7736735939979553,
            "answer": "upheld",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishes"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8539624810218811
      },
      {
        "question verbose": "What is to expects ",
        "b": "expects",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8350380063056946,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.8234264850616455,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.7984063625335693,
            "answer": "intends",
            "hit": false
          },
          {
            "score": 0.7938928008079529,
            "answer": "hoped",
            "hit": false
          },
          {
            "score": 0.7888802289962769,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.7856765389442444,
            "answer": "believes",
            "hit": false
          }
        ],
        "set_exclude": [
          "expects"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8350380063056946
      },
      {
        "question verbose": "What is to fails ",
        "b": "fails",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.8895450234413147,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.8362753987312317,
            "answer": "failing",
            "hit": false
          },
          {
            "score": 0.8159698247909546,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.805797278881073,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.7984442114830017,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.7827679514884949,
            "answer": "refused",
            "hit": false
          }
        ],
        "set_exclude": [
          "fails"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.805797278881073
      },
      {
        "question verbose": "What is to follows ",
        "b": "follows",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.8150010108947754,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.8080250024795532,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.7752848863601685,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7312043905258179,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.726460874080658,
            "answer": "preceded",
            "hit": false
          },
          {
            "score": 0.7051331996917725,
            "answer": "prompted",
            "hit": false
          }
        ],
        "set_exclude": [
          "follows"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8080250024795532
      },
      {
        "question verbose": "What is to happens ",
        "b": "happens",
        "expected answer": [
          "happened"
        ],
        "predictions": [
          {
            "score": 0.9136648178100586,
            "answer": "happened",
            "hit": true
          },
          {
            "score": 0.8774757385253906,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8383768796920776,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.8220259547233582,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.8115740418434143,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.7912949919700623,
            "answer": "occur",
            "hit": false
          }
        ],
        "set_exclude": [
          "happens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9136647582054138
      },
      {
        "question verbose": "What is to hears ",
        "b": "hears",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8315930366516113,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7944638133049011,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.7635687589645386,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.7446681261062622,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7331482172012329,
            "answer": "whispered",
            "hit": false
          },
          {
            "score": 0.7291665077209473,
            "answer": "witnessed",
            "hit": false
          }
        ],
        "set_exclude": [
          "hears"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7944638431072235
      },
      {
        "question verbose": "What is to includes ",
        "b": "includes",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.7772992849349976,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.7578561305999756,
            "answer": "excluding",
            "hit": false
          },
          {
            "score": 0.7481490969657898,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.7298691868782043,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.7225058078765869,
            "answer": "specified",
            "hit": false
          },
          {
            "score": 0.7214725613594055,
            "answer": "received",
            "hit": false
          }
        ],
        "set_exclude": [
          "includes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7481490820646286
      },
      {
        "question verbose": "What is to intends ",
        "b": "intends",
        "expected answer": [
          "intended"
        ],
        "predictions": [
          {
            "score": 0.8415808081626892,
            "answer": "intending",
            "hit": false
          },
          {
            "score": 0.8218809962272644,
            "answer": "intended",
            "hit": true
          },
          {
            "score": 0.8013209104537964,
            "answer": "vowed",
            "hit": false
          },
          {
            "score": 0.7993395328521729,
            "answer": "hoped",
            "hit": false
          },
          {
            "score": 0.7962794899940491,
            "answer": "planned",
            "hit": false
          },
          {
            "score": 0.7909145355224609,
            "answer": "expects",
            "hit": false
          }
        ],
        "set_exclude": [
          "intends"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8218809962272644
      },
      {
        "question verbose": "What is to introduces ",
        "b": "introduces",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.897384762763977,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.8963497877120972,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8716928958892822,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.8074824810028076,
            "answer": "introduction",
            "hit": false
          },
          {
            "score": 0.774785578250885,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.7726916074752808,
            "answer": "debuted",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduces"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8963497877120972
      },
      {
        "question verbose": "What is to involves ",
        "b": "involves",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.9007946252822876,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8454010486602783,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.808927059173584,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.7969416975975037,
            "answer": "resulted",
            "hit": false
          },
          {
            "score": 0.7930249571800232,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.7882150411605835,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "involves"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7681178450584412
      },
      {
        "question verbose": "What is to loses ",
        "b": "loses",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8517516851425171,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.8312646746635437,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.8152502775192261,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.7995781302452087,
            "answer": "lose",
            "hit": false
          },
          {
            "score": 0.7945655584335327,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7826987504959106,
            "answer": "regained",
            "hit": false
          }
        ],
        "set_exclude": [
          "loses"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8152502775192261
      },
      {
        "question verbose": "What is to manages ",
        "b": "manages",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8715664744377136,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.8080397248268127,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.7622431516647339,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7579559087753296,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.755715012550354,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.750219464302063,
            "answer": "succeeded",
            "hit": false
          }
        ],
        "set_exclude": [
          "manages"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8080397248268127
      },
      {
        "question verbose": "What is to occurs ",
        "b": "occurs",
        "expected answer": [
          "occurred"
        ],
        "predictions": [
          {
            "score": 0.9116459488868713,
            "answer": "occurred",
            "hit": true
          },
          {
            "score": 0.9081839323043823,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8624828457832336,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.831081748008728,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.8284057974815369,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.7877860069274902,
            "answer": "arises",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurs"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9116459488868713
      },
      {
        "question verbose": "What is to operates ",
        "b": "operates",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.9088773131370544,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7917177677154541,
            "answer": "operated",
            "hit": true
          },
          {
            "score": 0.783245325088501,
            "answer": "operating",
            "hit": false
          },
          {
            "score": 0.7824559211730957,
            "answer": "conducted",
            "hit": false
          },
          {
            "score": 0.7721712589263916,
            "answer": "regulates",
            "hit": false
          },
          {
            "score": 0.7697816491127014,
            "answer": "operational",
            "hit": false
          }
        ],
        "set_exclude": [
          "operates"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7917177677154541
      },
      {
        "question verbose": "What is to performs ",
        "b": "performs",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.9063259363174438,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.9053712487220764,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.7930513620376587,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7902024984359741,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.7729138135910034,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7725003361701965,
            "answer": "undertook",
            "hit": false
          }
        ],
        "set_exclude": [
          "performs"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9053712785243988
      },
      {
        "question verbose": "What is to proposes ",
        "b": "proposes",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8929975032806396,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8786554336547852,
            "answer": "proposing",
            "hit": false
          },
          {
            "score": 0.8731505870819092,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.8319137096405029,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.8261192440986633,
            "answer": "proposals",
            "hit": false
          },
          {
            "score": 0.8175813555717468,
            "answer": "advocated",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.873150646686554
      },
      {
        "question verbose": "What is to provides ",
        "b": "provides",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.9064308404922485,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8534833192825317,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8300654888153076,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.8212606906890869,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8203332424163818,
            "answer": "gave",
            "hit": false
          },
          {
            "score": 0.8134200572967529,
            "answer": "offers",
            "hit": false
          }
        ],
        "set_exclude": [
          "provides"
        ],
        "rank": 76,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.740662083029747
      },
      {
        "question verbose": "What is to receives ",
        "b": "receives",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8905173540115356,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.8430438041687012,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.8261306285858154,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.7818953394889832,
            "answer": "underwent",
            "hit": false
          },
          {
            "score": 0.7724990844726562,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.7701787948608398,
            "answer": "participated",
            "hit": false
          }
        ],
        "set_exclude": [
          "receives"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.826130598783493
      },
      {
        "question verbose": "What is to refers ",
        "b": "refers",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.825066089630127,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7860955595970154,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7819419503211975,
            "answer": "referenced",
            "hit": false
          },
          {
            "score": 0.7744359970092773,
            "answer": "denotes",
            "hit": false
          },
          {
            "score": 0.7605165243148804,
            "answer": "refer",
            "hit": false
          },
          {
            "score": 0.7592191696166992,
            "answer": "implies",
            "hit": false
          }
        ],
        "set_exclude": [
          "refers"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.749332994222641
      },
      {
        "question verbose": "What is to relates ",
        "b": "relates",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.876236617565155,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.8175187706947327,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7686155438423157,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.763546347618103,
            "answer": "correlated",
            "hit": false
          },
          {
            "score": 0.7562050223350525,
            "answer": "arose",
            "hit": false
          },
          {
            "score": 0.7531483173370361,
            "answer": "attributed",
            "hit": false
          }
        ],
        "set_exclude": [
          "relates"
        ],
        "rank": 140,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7114704847335815
      },
      {
        "question verbose": "What is to remains ",
        "b": "remains",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.863086998462677,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.8488383889198303,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7476157546043396,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.7471612095832825,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.7415223717689514,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7382825613021851,
            "answer": "remnants",
            "hit": false
          }
        ],
        "set_exclude": [
          "remains"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.863086998462677
      },
      {
        "question verbose": "What is to replaces ",
        "b": "replaces",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8800514936447144,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8566851615905762,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.796619713306427,
            "answer": "substituted",
            "hit": false
          },
          {
            "score": 0.7919543981552124,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.783376932144165,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7646796703338623,
            "answer": "replace",
            "hit": false
          }
        ],
        "set_exclude": [
          "replaces"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8800515234470367
      },
      {
        "question verbose": "What is to represents ",
        "b": "represents",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.8410221934318542,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.7805417776107788,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.7686688303947449,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.7686361074447632,
            "answer": "constitutes",
            "hit": false
          },
          {
            "score": 0.7680796384811401,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.7612701058387756,
            "answer": "reflects",
            "hit": false
          }
        ],
        "set_exclude": [
          "represents"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7805417776107788
      },
      {
        "question verbose": "What is to requires ",
        "b": "requires",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.7513867020606995,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.7495173215866089,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.7455448508262634,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.7351899147033691,
            "answer": "mandated",
            "hit": false
          },
          {
            "score": 0.7297440767288208,
            "answer": "noticed",
            "hit": false
          },
          {
            "score": 0.728118896484375,
            "answer": "ensure",
            "hit": false
          }
        ],
        "set_exclude": [
          "requires"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7495173215866089
      },
      {
        "question verbose": "What is to seems ",
        "b": "seems",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.8077037930488586,
            "answer": "didn",
            "hit": false
          },
          {
            "score": 0.8042607307434082,
            "answer": "apparently",
            "hit": false
          },
          {
            "score": 0.7914865016937256,
            "answer": "looks",
            "hit": false
          },
          {
            "score": 0.7862247228622437,
            "answer": "hmm",
            "hit": false
          },
          {
            "score": 0.7854042053222656,
            "answer": "somehow",
            "hit": false
          },
          {
            "score": 0.7778562307357788,
            "answer": "seemed",
            "hit": true
          }
        ],
        "set_exclude": [
          "seems"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7778562605381012
      },
      {
        "question verbose": "What is to sends ",
        "b": "sends",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8664124011993408,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7919989228248596,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.7627198696136475,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.7620043158531189,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.7595347762107849,
            "answer": "communicated",
            "hit": false
          },
          {
            "score": 0.7586307525634766,
            "answer": "gave",
            "hit": false
          }
        ],
        "set_exclude": [
          "sends"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7627198696136475
      },
      {
        "question verbose": "What is to spends ",
        "b": "spends",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8956165909767151,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8853356838226318,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8283690810203552,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.7863496541976929,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7698749303817749,
            "answer": "invested",
            "hit": false
          },
          {
            "score": 0.7674188613891602,
            "answer": "wasted",
            "hit": false
          }
        ],
        "set_exclude": [
          "spends"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8853357434272766
      },
      {
        "question verbose": "What is to suggests ",
        "b": "suggests",
        "expected answer": [
          "suggested"
        ],
        "predictions": [
          {
            "score": 0.8886974453926086,
            "answer": "suggested",
            "hit": true
          },
          {
            "score": 0.8517262935638428,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.8338125944137573,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.8167610168457031,
            "answer": "implies",
            "hit": false
          },
          {
            "score": 0.8062744140625,
            "answer": "indicated",
            "hit": false
          },
          {
            "score": 0.8050277829170227,
            "answer": "indicate",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggests"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8886974155902863
      },
      {
        "question verbose": "What is to tells ",
        "b": "tells",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.8241231441497803,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.8079918622970581,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.7963124513626099,
            "answer": "says",
            "hit": false
          },
          {
            "score": 0.7919461727142334,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.784694254398346,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.7839195728302002,
            "answer": "explained",
            "hit": false
          }
        ],
        "set_exclude": [
          "tells"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8079918026924133
      }
    ],
    "result": {
      "cnt_questions_correct": 13,
      "cnt_questions_total": 46,
      "accuracy": 0.2826086956521739
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I10 [verb_3pSg - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "2adccd1a-0540-446b-a58c-fe0a77818a55",
      "timestamp": "2025-05-17T17:12:46.407704"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to home ",
        "b": "home",
        "expected answer": [
          "homeless"
        ],
        "predictions": [
          {
            "score": 0.7189476490020752,
            "answer": "ruthless",
            "hit": false
          },
          {
            "score": 0.7088533639907837,
            "answer": "homes",
            "hit": false
          },
          {
            "score": 0.7041786909103394,
            "answer": "hometown",
            "hit": false
          },
          {
            "score": 0.6833445429801941,
            "answer": "fearful",
            "hit": false
          },
          {
            "score": 0.6798582673072815,
            "answer": "house",
            "hit": false
          },
          {
            "score": 0.6777639389038086,
            "answer": "backyard",
            "hit": false
          }
        ],
        "set_exclude": [
          "home"
        ],
        "rank": 109,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6576284170150757
      },
      {
        "question verbose": "What is to ruth ",
        "b": "ruth",
        "expected answer": [
          "ruthless"
        ],
        "predictions": [
          {
            "score": 0.804472804069519,
            "answer": "homeless",
            "hit": false
          },
          {
            "score": 0.7537654042243958,
            "answer": "ruthless",
            "hit": true
          },
          {
            "score": 0.7199631929397583,
            "answer": "unemployed",
            "hit": false
          },
          {
            "score": 0.7072340846061707,
            "answer": "vicious",
            "hit": false
          },
          {
            "score": 0.7052534818649292,
            "answer": "cynical",
            "hit": false
          },
          {
            "score": 0.6995627284049988,
            "answer": "smug",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruth"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7537654638290405
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 2,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D01 [noun+less_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "8a3ea431-c6d0-415e-ac5d-04216898e2d4",
      "timestamp": "2025-05-17T17:12:46.581371"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to able ",
        "b": "able",
        "expected answer": [
          "unable"
        ],
        "predictions": [
          {
            "score": 0.8071517944335938,
            "answer": "ability",
            "hit": false
          },
          {
            "score": 0.7031209468841553,
            "answer": "abilities",
            "hit": false
          },
          {
            "score": 0.6803181171417236,
            "answer": "inaccessible",
            "hit": false
          },
          {
            "score": 0.6758211851119995,
            "answer": "unacceptable",
            "hit": false
          },
          {
            "score": 0.6735420823097229,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.6714228391647339,
            "answer": "incompatible",
            "hit": false
          }
        ],
        "set_exclude": [
          "able"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6605264842510223
      },
      {
        "question verbose": "What is to acceptable ",
        "b": "acceptable",
        "expected answer": [
          "unacceptable"
        ],
        "predictions": [
          {
            "score": 0.8720666170120239,
            "answer": "unacceptable",
            "hit": true
          },
          {
            "score": 0.7748945951461792,
            "answer": "inappropriate",
            "hit": false
          },
          {
            "score": 0.7626566886901855,
            "answer": "unpleasant",
            "hit": false
          },
          {
            "score": 0.759507954120636,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.7577394247055054,
            "answer": "inadequate",
            "hit": false
          },
          {
            "score": 0.7571418285369873,
            "answer": "uncomfortable",
            "hit": false
          }
        ],
        "set_exclude": [
          "acceptable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8720666468143463
      },
      {
        "question verbose": "What is to affected ",
        "b": "affected",
        "expected answer": [
          "unaffected"
        ],
        "predictions": [
          {
            "score": 0.8778040409088135,
            "answer": "impacted",
            "hit": false
          },
          {
            "score": 0.8123440742492676,
            "answer": "unaffected",
            "hit": true
          },
          {
            "score": 0.7923334836959839,
            "answer": "affects",
            "hit": false
          },
          {
            "score": 0.7897480130195618,
            "answer": "affect",
            "hit": false
          },
          {
            "score": 0.7729665637016296,
            "answer": "damaged",
            "hit": false
          },
          {
            "score": 0.7669848799705505,
            "answer": "affecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "affected"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8123440146446228
      },
      {
        "question verbose": "What is to available ",
        "b": "available",
        "expected answer": [
          "unavailable"
        ],
        "predictions": [
          {
            "score": 0.8316258192062378,
            "answer": "unavailable",
            "hit": true
          },
          {
            "score": 0.7383696436882019,
            "answer": "inaccessible",
            "hit": false
          },
          {
            "score": 0.7335538864135742,
            "answer": "possible",
            "hit": false
          },
          {
            "score": 0.7171764969825745,
            "answer": "offered",
            "hit": false
          },
          {
            "score": 0.7169173359870911,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.7139719128608704,
            "answer": "inadequate",
            "hit": false
          }
        ],
        "set_exclude": [
          "available"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8316258490085602
      },
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "unaware"
        ],
        "predictions": [
          {
            "score": 0.7739158272743225,
            "answer": "unaware",
            "hit": true
          },
          {
            "score": 0.744090735912323,
            "answer": "ignorant",
            "hit": false
          },
          {
            "score": 0.7234383225440979,
            "answer": "unsure",
            "hit": false
          },
          {
            "score": 0.7189592123031616,
            "answer": "ashamed",
            "hit": false
          },
          {
            "score": 0.7188676595687866,
            "answer": "unwilling",
            "hit": false
          },
          {
            "score": 0.7150692939758301,
            "answer": "wary",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7739157676696777
      },
      {
        "question verbose": "What is to certain ",
        "b": "certain",
        "expected answer": [
          "uncertain"
        ],
        "predictions": [
          {
            "score": 0.7583423852920532,
            "answer": "generally",
            "hit": false
          },
          {
            "score": 0.7556780576705933,
            "answer": "various",
            "hit": false
          },
          {
            "score": 0.7554113864898682,
            "answer": "some",
            "hit": false
          },
          {
            "score": 0.7501471638679504,
            "answer": "several",
            "hit": false
          },
          {
            "score": 0.740939736366272,
            "answer": "depending",
            "hit": false
          },
          {
            "score": 0.7406606674194336,
            "answer": "occasionally",
            "hit": false
          }
        ],
        "set_exclude": [
          "certain"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.730359360575676
      },
      {
        "question verbose": "What is to changed ",
        "b": "changed",
        "expected answer": [
          "unchanged"
        ],
        "predictions": [
          {
            "score": 0.7881041765213013,
            "answer": "removed",
            "hit": false
          },
          {
            "score": 0.7805686593055725,
            "answer": "altered",
            "hit": false
          },
          {
            "score": 0.7736936211585999,
            "answer": "changing",
            "hit": false
          },
          {
            "score": 0.7507755160331726,
            "answer": "overturned",
            "hit": false
          },
          {
            "score": 0.7449162006378174,
            "answer": "change",
            "hit": false
          },
          {
            "score": 0.7446516752243042,
            "answer": "increased",
            "hit": false
          }
        ],
        "set_exclude": [
          "changed"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7406301647424698
      },
      {
        "question verbose": "What is to comfortable ",
        "b": "comfortable",
        "expected answer": [
          "uncomfortable"
        ],
        "predictions": [
          {
            "score": 0.8654260635375977,
            "answer": "uncomfortable",
            "hit": true
          },
          {
            "score": 0.8006229400634766,
            "answer": "uneasy",
            "hit": false
          },
          {
            "score": 0.7966930866241455,
            "answer": "comfortably",
            "hit": false
          },
          {
            "score": 0.7805713415145874,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.779273271560669,
            "answer": "confident",
            "hit": false
          },
          {
            "score": 0.7681311368942261,
            "answer": "cozy",
            "hit": false
          }
        ],
        "set_exclude": [
          "comfortable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8654260635375977
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "unconscious"
        ],
        "predictions": [
          {
            "score": 0.8153232336044312,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.8045395016670227,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.8039963245391846,
            "answer": "unconscious",
            "hit": true
          },
          {
            "score": 0.7686382532119751,
            "answer": "unaware",
            "hit": false
          },
          {
            "score": 0.7651530504226685,
            "answer": "ignorant",
            "hit": false
          },
          {
            "score": 0.7612375020980835,
            "answer": "deliberate",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8039963245391846
      },
      {
        "question verbose": "What is to employed ",
        "b": "employed",
        "expected answer": [
          "unemployed"
        ],
        "predictions": [
          {
            "score": 0.8308409452438354,
            "answer": "unemployed",
            "hit": true
          },
          {
            "score": 0.765681266784668,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.75577712059021,
            "answer": "employment",
            "hit": false
          },
          {
            "score": 0.7549635171890259,
            "answer": "unemployment",
            "hit": false
          },
          {
            "score": 0.7514837980270386,
            "answer": "incarcerated",
            "hit": false
          },
          {
            "score": 0.7466112971305847,
            "answer": "elderly",
            "hit": false
          }
        ],
        "set_exclude": [
          "employed"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8308409452438354
      },
      {
        "question verbose": "What is to expected ",
        "b": "expected",
        "expected answer": [
          "unexpected"
        ],
        "predictions": [
          {
            "score": 0.7766363024711609,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.7708855867385864,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.7579777240753174,
            "answer": "hoped",
            "hit": false
          },
          {
            "score": 0.7566560506820679,
            "answer": "unexpected",
            "hit": true
          },
          {
            "score": 0.7548926472663879,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.7534978985786438,
            "answer": "projected",
            "hit": false
          }
        ],
        "set_exclude": [
          "expected"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7566560506820679
      },
      {
        "question verbose": "What is to finished ",
        "b": "finished",
        "expected answer": [
          "unfinished"
        ],
        "predictions": [
          {
            "score": 0.8343052268028259,
            "answer": "unfinished",
            "hit": true
          },
          {
            "score": 0.7436362504959106,
            "answer": "finishing",
            "hit": false
          },
          {
            "score": 0.7425143718719482,
            "answer": "incomplete",
            "hit": false
          },
          {
            "score": 0.7356845140457153,
            "answer": "unpublished",
            "hit": false
          },
          {
            "score": 0.729373574256897,
            "answer": "assembled",
            "hit": false
          },
          {
            "score": 0.7290278077125549,
            "answer": "completed",
            "hit": false
          }
        ],
        "set_exclude": [
          "finished"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8343052268028259
      },
      {
        "question verbose": "What is to fortunate ",
        "b": "fortunate",
        "expected answer": [
          "unfortunate"
        ],
        "predictions": [
          {
            "score": 0.8332123160362244,
            "answer": "unfortunate",
            "hit": true
          },
          {
            "score": 0.7709609270095825,
            "answer": "thankful",
            "hit": false
          },
          {
            "score": 0.7650730609893799,
            "answer": "privileged",
            "hit": false
          },
          {
            "score": 0.7583678364753723,
            "answer": "foolish",
            "hit": false
          },
          {
            "score": 0.7557961940765381,
            "answer": "unsuccessful",
            "hit": false
          },
          {
            "score": 0.7508974671363831,
            "answer": "luckily",
            "hit": false
          }
        ],
        "set_exclude": [
          "fortunate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8332123160362244
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "unhappy"
        ],
        "predictions": [
          {
            "score": 0.7940187454223633,
            "answer": "unhappy",
            "hit": true
          },
          {
            "score": 0.7627190947532654,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.7485902905464172,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.747509241104126,
            "answer": "cheerful",
            "hit": false
          },
          {
            "score": 0.7395069599151611,
            "answer": "lucky",
            "hit": false
          },
          {
            "score": 0.7370730042457581,
            "answer": "angry",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7940187454223633
      },
      {
        "question verbose": "What is to identified ",
        "b": "identified",
        "expected answer": [
          "unidentified"
        ],
        "predictions": [
          {
            "score": 0.7681998014450073,
            "answer": "reached",
            "hit": false
          },
          {
            "score": 0.7501894235610962,
            "answer": "unidentified",
            "hit": true
          },
          {
            "score": 0.7492346167564392,
            "answer": "noticed",
            "hit": false
          },
          {
            "score": 0.7390751242637634,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.7329329252243042,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7320749759674072,
            "answer": "identifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "identified"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7501894235610962
      },
      {
        "question verbose": "What is to known ",
        "b": "known",
        "expected answer": [
          "unknown"
        ],
        "predictions": [
          {
            "score": 0.7621201276779175,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.7333471775054932,
            "answer": "commonly",
            "hit": false
          },
          {
            "score": 0.7330354452133179,
            "answer": "renowned",
            "hit": false
          },
          {
            "score": 0.7310338020324707,
            "answer": "infamous",
            "hit": false
          },
          {
            "score": 0.7215046882629395,
            "answer": "dubbed",
            "hit": false
          },
          {
            "score": 0.7187508940696716,
            "answer": "seen",
            "hit": false
          }
        ],
        "set_exclude": [
          "known"
        ],
        "rank": 29,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.690907895565033
      },
      {
        "question verbose": "What is to lawful ",
        "b": "lawful",
        "expected answer": [
          "unlawful"
        ],
        "predictions": [
          {
            "score": 0.8653684854507446,
            "answer": "unlawful",
            "hit": true
          },
          {
            "score": 0.771742045879364,
            "answer": "illegal",
            "hit": false
          },
          {
            "score": 0.7707495093345642,
            "answer": "unconstitutional",
            "hit": false
          },
          {
            "score": 0.7609274387359619,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.7598264217376709,
            "answer": "improper",
            "hit": false
          },
          {
            "score": 0.7598055601119995,
            "answer": "unauthorized",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8653685748577118
      },
      {
        "question verbose": "What is to paid ",
        "b": "paid",
        "expected answer": [
          "unpaid"
        ],
        "predictions": [
          {
            "score": 0.8137166500091553,
            "answer": "unpaid",
            "hit": true
          },
          {
            "score": 0.8040528297424316,
            "answer": "pays",
            "hit": false
          },
          {
            "score": 0.7568433880805969,
            "answer": "compensated",
            "hit": false
          },
          {
            "score": 0.7439428567886353,
            "answer": "financed",
            "hit": false
          },
          {
            "score": 0.7380379438400269,
            "answer": "paying",
            "hit": false
          },
          {
            "score": 0.7358745336532593,
            "answer": "hired",
            "hit": false
          }
        ],
        "set_exclude": [
          "paid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8137167394161224
      },
      {
        "question verbose": "What is to pleasant ",
        "b": "pleasant",
        "expected answer": [
          "unpleasant"
        ],
        "predictions": [
          {
            "score": 0.877185583114624,
            "answer": "unpleasant",
            "hit": true
          },
          {
            "score": 0.8418859839439392,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.8337047100067139,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7923243641853333,
            "answer": "charming",
            "hit": false
          },
          {
            "score": 0.7901861071586609,
            "answer": "cheerful",
            "hit": false
          },
          {
            "score": 0.7806882858276367,
            "answer": "pleasing",
            "hit": false
          }
        ],
        "set_exclude": [
          "pleasant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8771856129169464
      },
      {
        "question verbose": "What is to popular ",
        "b": "popular",
        "expected answer": [
          "unpopular"
        ],
        "predictions": [
          {
            "score": 0.8150378465652466,
            "answer": "unpopular",
            "hit": true
          },
          {
            "score": 0.7620767951011658,
            "answer": "popularity",
            "hit": false
          },
          {
            "score": 0.7605078220367432,
            "answer": "influential",
            "hit": false
          },
          {
            "score": 0.7567751407623291,
            "answer": "fashionable",
            "hit": false
          },
          {
            "score": 0.7500098943710327,
            "answer": "beloved",
            "hit": false
          },
          {
            "score": 0.748427152633667,
            "answer": "commonplace",
            "hit": false
          }
        ],
        "set_exclude": [
          "popular"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.815037876367569
      },
      {
        "question verbose": "What is to predictable ",
        "b": "predictable",
        "expected answer": [
          "unpredictable"
        ],
        "predictions": [
          {
            "score": 0.8347486853599548,
            "answer": "unpredictable",
            "hit": true
          },
          {
            "score": 0.7834481596946716,
            "answer": "unexpected",
            "hit": false
          },
          {
            "score": 0.7689921855926514,
            "answer": "inevitable",
            "hit": false
          },
          {
            "score": 0.7644709348678589,
            "answer": "unpleasant",
            "hit": false
          },
          {
            "score": 0.7601611018180847,
            "answer": "disappointing",
            "hit": false
          },
          {
            "score": 0.7556712627410889,
            "answer": "unreliable",
            "hit": false
          }
        ],
        "set_exclude": [
          "predictable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8347486853599548
      },
      {
        "question verbose": "What is to published ",
        "b": "published",
        "expected answer": [
          "unpublished"
        ],
        "predictions": [
          {
            "score": 0.8124439120292664,
            "answer": "unpublished",
            "hit": true
          },
          {
            "score": 0.7943308353424072,
            "answer": "authored",
            "hit": false
          },
          {
            "score": 0.7739025950431824,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.7710435390472412,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7621734738349915,
            "answer": "reprinted",
            "hit": false
          },
          {
            "score": 0.748405396938324,
            "answer": "publishing",
            "hit": false
          }
        ],
        "set_exclude": [
          "published"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8124439716339111
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "unreasonable"
        ],
        "predictions": [
          {
            "score": 0.8516039848327637,
            "answer": "unreasonable",
            "hit": true
          },
          {
            "score": 0.7793101668357849,
            "answer": "unacceptable",
            "hit": false
          },
          {
            "score": 0.7714396119117737,
            "answer": "irrational",
            "hit": false
          },
          {
            "score": 0.7702090740203857,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.7693156003952026,
            "answer": "reason",
            "hit": false
          },
          {
            "score": 0.7690555453300476,
            "answer": "plausible",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8516040444374084
      },
      {
        "question verbose": "What is to related ",
        "b": "related",
        "expected answer": [
          "unrelated"
        ],
        "predictions": [
          {
            "score": 0.7492563724517822,
            "answer": "further",
            "hit": false
          },
          {
            "score": 0.7482618093490601,
            "answer": "unrelated",
            "hit": true
          },
          {
            "score": 0.7453415393829346,
            "answer": "specific",
            "hit": false
          },
          {
            "score": 0.7439477443695068,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.7389273047447205,
            "answer": "aside",
            "hit": false
          },
          {
            "score": 0.7383714318275452,
            "answer": "additional",
            "hit": false
          }
        ],
        "set_exclude": [
          "related"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7482618391513824
      },
      {
        "question verbose": "What is to reliable ",
        "b": "reliable",
        "expected answer": [
          "unreliable"
        ],
        "predictions": [
          {
            "score": 0.8775506615638733,
            "answer": "unreliable",
            "hit": true
          },
          {
            "score": 0.8007030487060547,
            "answer": "reliability",
            "hit": false
          },
          {
            "score": 0.7873328924179077,
            "answer": "accurate",
            "hit": false
          },
          {
            "score": 0.786727786064148,
            "answer": "credible",
            "hit": false
          },
          {
            "score": 0.7690119743347168,
            "answer": "unpredictable",
            "hit": false
          },
          {
            "score": 0.7687376737594604,
            "answer": "inaccurate",
            "hit": false
          }
        ],
        "set_exclude": [
          "reliable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8775506317615509
      },
      {
        "question verbose": "What is to specified ",
        "b": "specified",
        "expected answer": [
          "unspecified"
        ],
        "predictions": [
          {
            "score": 0.7985782623291016,
            "answer": "unspecified",
            "hit": true
          },
          {
            "score": 0.7619546055793762,
            "answer": "specify",
            "hit": false
          },
          {
            "score": 0.7612237930297852,
            "answer": "defined",
            "hit": false
          },
          {
            "score": 0.7528039813041687,
            "answer": "unclear",
            "hit": false
          },
          {
            "score": 0.7525104284286499,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.7444705963134766,
            "answer": "unknown",
            "hit": false
          }
        ],
        "set_exclude": [
          "specified"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7985782623291016
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "unsuccessful"
        ],
        "predictions": [
          {
            "score": 0.8844285011291504,
            "answer": "unsuccessful",
            "hit": true
          },
          {
            "score": 0.7851764559745789,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.7666362524032593,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.763149619102478,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.7617025971412659,
            "answer": "success",
            "hit": false
          },
          {
            "score": 0.7495434284210205,
            "answer": "prosperous",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8844285309314728
      },
      {
        "question verbose": "What is to used ",
        "b": "used",
        "expected answer": [
          "unused"
        ],
        "predictions": [
          {
            "score": 0.7934602499008179,
            "answer": "uses",
            "hit": false
          },
          {
            "score": 0.7438744902610779,
            "answer": "usable",
            "hit": false
          },
          {
            "score": 0.736882209777832,
            "answer": "unused",
            "hit": true
          },
          {
            "score": 0.722294807434082,
            "answer": "abused",
            "hit": false
          },
          {
            "score": 0.7176023721694946,
            "answer": "discarded",
            "hit": false
          },
          {
            "score": 0.7124745845794678,
            "answer": "ineffective",
            "hit": false
          }
        ],
        "set_exclude": [
          "used"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.736882209777832
      },
      {
        "question verbose": "What is to usual ",
        "b": "usual",
        "expected answer": [
          "unusual"
        ],
        "predictions": [
          {
            "score": 0.7870076894760132,
            "answer": "unusual",
            "hit": true
          },
          {
            "score": 0.766326904296875,
            "answer": "unusually",
            "hit": false
          },
          {
            "score": 0.7634285688400269,
            "answer": "abnormal",
            "hit": false
          },
          {
            "score": 0.7534456849098206,
            "answer": "usually",
            "hit": false
          },
          {
            "score": 0.7483537793159485,
            "answer": "unexpected",
            "hit": false
          },
          {
            "score": 0.746957540512085,
            "answer": "customary",
            "hit": false
          }
        ],
        "set_exclude": [
          "usual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.787007749080658
      },
      {
        "question verbose": "What is to wanted ",
        "b": "wanted",
        "expected answer": [
          "unwanted"
        ],
        "predictions": [
          {
            "score": 0.8470042943954468,
            "answer": "wants",
            "hit": false
          },
          {
            "score": 0.8028770089149475,
            "answer": "wished",
            "hit": false
          },
          {
            "score": 0.7904853224754333,
            "answer": "wanting",
            "hit": false
          },
          {
            "score": 0.7853906750679016,
            "answer": "want",
            "hit": false
          },
          {
            "score": 0.7785758376121521,
            "answer": "hated",
            "hit": false
          },
          {
            "score": 0.7729389071464539,
            "answer": "liked",
            "hit": false
          }
        ],
        "set_exclude": [
          "wanted"
        ],
        "rank": 37,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7309438437223434
      }
    ],
    "result": {
      "cnt_questions_correct": 19,
      "cnt_questions_total": 30,
      "accuracy": 0.6333333333333333
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D02 [un+adj_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "63b15504-8f7e-4f9f-8db3-83f11f9caa7a",
      "timestamp": "2025-05-17T17:12:46.588420"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to according ",
        "b": "according",
        "expected answer": [
          "accordingly"
        ],
        "predictions": [
          {
            "score": 0.7561009526252747,
            "answer": "reportedly",
            "hit": false
          },
          {
            "score": 0.7258288860321045,
            "answer": "essentially",
            "hit": false
          },
          {
            "score": 0.7235782742500305,
            "answer": "says",
            "hit": false
          },
          {
            "score": 0.7219712734222412,
            "answer": "roughly",
            "hit": false
          },
          {
            "score": 0.721956193447113,
            "answer": "evidently",
            "hit": false
          },
          {
            "score": 0.7212823033332825,
            "answer": "accordance",
            "hit": false
          }
        ],
        "set_exclude": [
          "according"
        ],
        "rank": 155,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.675912469625473
      },
      {
        "question verbose": "What is to actual ",
        "b": "actual",
        "expected answer": [
          "actually"
        ],
        "predictions": [
          {
            "score": 0.7758699655532837,
            "answer": "real",
            "hit": false
          },
          {
            "score": 0.7422542572021484,
            "answer": "actually",
            "hit": true
          },
          {
            "score": 0.7394442558288574,
            "answer": "genuine",
            "hit": false
          },
          {
            "score": 0.7390959858894348,
            "answer": "entire",
            "hit": false
          },
          {
            "score": 0.735663890838623,
            "answer": "genuinely",
            "hit": false
          },
          {
            "score": 0.7327371835708618,
            "answer": "exact",
            "hit": false
          }
        ],
        "set_exclude": [
          "actual"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7422542572021484
      },
      {
        "question verbose": "What is to additional ",
        "b": "additional",
        "expected answer": [
          "additionally"
        ],
        "predictions": [
          {
            "score": 0.7874211072921753,
            "answer": "further",
            "hit": false
          },
          {
            "score": 0.7864601612091064,
            "answer": "additionally",
            "hit": true
          },
          {
            "score": 0.7682605981826782,
            "answer": "furthermore",
            "hit": false
          },
          {
            "score": 0.7564374208450317,
            "answer": "although",
            "hit": false
          },
          {
            "score": 0.7549471855163574,
            "answer": "consequently",
            "hit": false
          },
          {
            "score": 0.7501678466796875,
            "answer": "alternatively",
            "hit": false
          }
        ],
        "set_exclude": [
          "additional"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7864601314067841
      },
      {
        "question verbose": "What is to apparent ",
        "b": "apparent",
        "expected answer": [
          "apparently"
        ],
        "predictions": [
          {
            "score": 0.8191332817077637,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.8023523688316345,
            "answer": "obvious",
            "hit": false
          },
          {
            "score": 0.7705858945846558,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7689803838729858,
            "answer": "evidently",
            "hit": false
          },
          {
            "score": 0.7665387392044067,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.7632107138633728,
            "answer": "noticeable",
            "hit": false
          }
        ],
        "set_exclude": [
          "apparent"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7369847744703293
      },
      {
        "question verbose": "What is to beautiful ",
        "b": "beautiful",
        "expected answer": [
          "beautifully"
        ],
        "predictions": [
          {
            "score": 0.9009683132171631,
            "answer": "gorgeous",
            "hit": false
          },
          {
            "score": 0.8665233850479126,
            "answer": "beautifully",
            "hit": true
          },
          {
            "score": 0.856164813041687,
            "answer": "magnificent",
            "hit": false
          },
          {
            "score": 0.8505967855453491,
            "answer": "wonderful",
            "hit": false
          },
          {
            "score": 0.8215721249580383,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.8104737401008606,
            "answer": "glorious",
            "hit": false
          }
        ],
        "set_exclude": [
          "beautiful"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.866523414850235
      },
      {
        "question verbose": "What is to critical ",
        "b": "critical",
        "expected answer": [
          "critically"
        ],
        "predictions": [
          {
            "score": 0.7829387784004211,
            "answer": "critically",
            "hit": true
          },
          {
            "score": 0.7445433735847473,
            "answer": "critics",
            "hit": false
          },
          {
            "score": 0.7381942272186279,
            "answer": "pivotal",
            "hit": false
          },
          {
            "score": 0.7378545999526978,
            "answer": "fundamentally",
            "hit": false
          },
          {
            "score": 0.7348461747169495,
            "answer": "profoundly",
            "hit": false
          },
          {
            "score": 0.7321301698684692,
            "answer": "ultimately",
            "hit": false
          }
        ],
        "set_exclude": [
          "critical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7829388082027435
      },
      {
        "question verbose": "What is to cultural ",
        "b": "cultural",
        "expected answer": [
          "culturally"
        ],
        "predictions": [
          {
            "score": 0.825021505355835,
            "answer": "culturally",
            "hit": true
          },
          {
            "score": 0.7531051635742188,
            "answer": "socio",
            "hit": false
          },
          {
            "score": 0.7444568872451782,
            "answer": "socially",
            "hit": false
          },
          {
            "score": 0.7428308725357056,
            "answer": "societal",
            "hit": false
          },
          {
            "score": 0.7391986846923828,
            "answer": "archaeological",
            "hit": false
          },
          {
            "score": 0.7384134531021118,
            "answer": "politically",
            "hit": false
          }
        ],
        "set_exclude": [
          "cultural"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.825021505355835
      },
      {
        "question verbose": "What is to decided ",
        "b": "decided",
        "expected answer": [
          "decidedly"
        ],
        "predictions": [
          {
            "score": 0.8592193126678467,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8325644135475159,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8118304014205933,
            "answer": "opted",
            "hit": false
          },
          {
            "score": 0.8064867258071899,
            "answer": "chose",
            "hit": false
          },
          {
            "score": 0.7745070457458496,
            "answer": "determined",
            "hit": false
          },
          {
            "score": 0.7731581330299377,
            "answer": "figured",
            "hit": false
          }
        ],
        "set_exclude": [
          "decided"
        ],
        "rank": 103,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7168290913105011
      },
      {
        "question verbose": "What is to different ",
        "b": "different",
        "expected answer": [
          "differently"
        ],
        "predictions": [
          {
            "score": 0.810215175151825,
            "answer": "differently",
            "hit": true
          },
          {
            "score": 0.7936533689498901,
            "answer": "depending",
            "hit": false
          },
          {
            "score": 0.7901497483253479,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.7895495891571045,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.7845028638839722,
            "answer": "differs",
            "hit": false
          },
          {
            "score": 0.7825024127960205,
            "answer": "differed",
            "hit": false
          }
        ],
        "set_exclude": [
          "different"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.810215175151825
      },
      {
        "question verbose": "What is to digital ",
        "b": "digital",
        "expected answer": [
          "digitally"
        ],
        "predictions": [
          {
            "score": 0.8624526858329773,
            "answer": "digitally",
            "hit": true
          },
          {
            "score": 0.7699303030967712,
            "answer": "electronic",
            "hit": false
          },
          {
            "score": 0.7581781148910522,
            "answer": "electronically",
            "hit": false
          },
          {
            "score": 0.7569369077682495,
            "answer": "virtual",
            "hit": false
          },
          {
            "score": 0.7454512119293213,
            "answer": "technological",
            "hit": false
          },
          {
            "score": 0.7383764982223511,
            "answer": "smartphone",
            "hit": false
          }
        ],
        "set_exclude": [
          "digital"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8624526858329773
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectively"
        ],
        "predictions": [
          {
            "score": 0.75830078125,
            "answer": "effectively",
            "hit": true
          },
          {
            "score": 0.757898211479187,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.740114688873291,
            "answer": "efficiently",
            "hit": false
          },
          {
            "score": 0.7384312748908997,
            "answer": "accordingly",
            "hit": false
          },
          {
            "score": 0.734652042388916,
            "answer": "efficient",
            "hit": false
          },
          {
            "score": 0.7337688207626343,
            "answer": "whenever",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.75830078125
      },
      {
        "question verbose": "What is to environmental ",
        "b": "environmental",
        "expected answer": [
          "environmentally"
        ],
        "predictions": [
          {
            "score": 0.8138086795806885,
            "answer": "environmentally",
            "hit": true
          },
          {
            "score": 0.7983381748199463,
            "answer": "environment",
            "hit": false
          },
          {
            "score": 0.78529953956604,
            "answer": "epa",
            "hit": false
          },
          {
            "score": 0.7797511219978333,
            "answer": "ecological",
            "hit": false
          },
          {
            "score": 0.7732828855514526,
            "answer": "climate",
            "hit": false
          },
          {
            "score": 0.752503514289856,
            "answer": "ecology",
            "hit": false
          }
        ],
        "set_exclude": [
          "environmental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8138087391853333
      },
      {
        "question verbose": "What is to extensive ",
        "b": "extensive",
        "expected answer": [
          "extensively"
        ],
        "predictions": [
          {
            "score": 0.8268352150917053,
            "answer": "extensively",
            "hit": true
          },
          {
            "score": 0.814163327217102,
            "answer": "lengthy",
            "hit": false
          },
          {
            "score": 0.8104053139686584,
            "answer": "expansive",
            "hit": false
          },
          {
            "score": 0.8096694946289062,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.7982016801834106,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.7908886671066284,
            "answer": "numerous",
            "hit": false
          }
        ],
        "set_exclude": [
          "extensive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8268352150917053
      },
      {
        "question verbose": "What is to famous ",
        "b": "famous",
        "expected answer": [
          "famously"
        ],
        "predictions": [
          {
            "score": 0.7794787287712097,
            "answer": "famed",
            "hit": false
          },
          {
            "score": 0.770727813243866,
            "answer": "famously",
            "hit": true
          },
          {
            "score": 0.7652673721313477,
            "answer": "renowned",
            "hit": false
          },
          {
            "score": 0.7630414962768555,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.7606644630432129,
            "answer": "infamous",
            "hit": false
          },
          {
            "score": 0.7569250464439392,
            "answer": "iconic",
            "hit": false
          }
        ],
        "set_exclude": [
          "famous"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.770727813243866
      },
      {
        "question verbose": "What is to financial ",
        "b": "financial",
        "expected answer": [
          "financially"
        ],
        "predictions": [
          {
            "score": 0.7895659804344177,
            "answer": "financially",
            "hit": true
          },
          {
            "score": 0.7539693117141724,
            "answer": "securities",
            "hit": false
          },
          {
            "score": 0.7525444626808167,
            "answer": "banking",
            "hit": false
          },
          {
            "score": 0.7495948076248169,
            "answer": "finances",
            "hit": false
          },
          {
            "score": 0.7484802007675171,
            "answer": "finance",
            "hit": false
          },
          {
            "score": 0.7457643151283264,
            "answer": "loans",
            "hit": false
          }
        ],
        "set_exclude": [
          "financial"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7895659804344177
      },
      {
        "question verbose": "What is to global ",
        "b": "global",
        "expected answer": [
          "globally"
        ],
        "predictions": [
          {
            "score": 0.8391363024711609,
            "answer": "globally",
            "hit": true
          },
          {
            "score": 0.7720916867256165,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.7454556822776794,
            "answer": "internationally",
            "hit": false
          },
          {
            "score": 0.7454100847244263,
            "answer": "globe",
            "hit": false
          },
          {
            "score": 0.7414097785949707,
            "answer": "international",
            "hit": false
          },
          {
            "score": 0.7273209095001221,
            "answer": "europe",
            "hit": false
          }
        ],
        "set_exclude": [
          "global"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8391363024711609
      },
      {
        "question verbose": "What is to historical ",
        "b": "historical",
        "expected answer": [
          "historically"
        ],
        "predictions": [
          {
            "score": 0.8435319066047668,
            "answer": "historically",
            "hit": true
          },
          {
            "score": 0.7836883664131165,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.7710744142532349,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.769962728023529,
            "answer": "archaeological",
            "hit": false
          },
          {
            "score": 0.7571728229522705,
            "answer": "historic",
            "hit": false
          },
          {
            "score": 0.7550251483917236,
            "answer": "medieval",
            "hit": false
          }
        ],
        "set_exclude": [
          "historical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8435319066047668
      },
      {
        "question verbose": "What is to huge ",
        "b": "huge",
        "expected answer": [
          "hugely"
        ],
        "predictions": [
          {
            "score": 0.7994462251663208,
            "answer": "gigantic",
            "hit": false
          },
          {
            "score": 0.7768052220344543,
            "answer": "hugely",
            "hit": true
          },
          {
            "score": 0.7747297286987305,
            "answer": "enormous",
            "hit": false
          },
          {
            "score": 0.7711327075958252,
            "answer": "massive",
            "hit": false
          },
          {
            "score": 0.7520740032196045,
            "answer": "incredibly",
            "hit": false
          },
          {
            "score": 0.7500537633895874,
            "answer": "immense",
            "hit": false
          }
        ],
        "set_exclude": [
          "huge"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7768052220344543
      },
      {
        "question verbose": "What is to immediate ",
        "b": "immediate",
        "expected answer": [
          "immediately"
        ],
        "predictions": [
          {
            "score": 0.8282003402709961,
            "answer": "immediately",
            "hit": true
          },
          {
            "score": 0.7738778591156006,
            "answer": "instantly",
            "hit": false
          },
          {
            "score": 0.7475547790527344,
            "answer": "imminent",
            "hit": false
          },
          {
            "score": 0.7429577112197876,
            "answer": "urgent",
            "hit": false
          },
          {
            "score": 0.7344577312469482,
            "answer": "quickly",
            "hit": false
          },
          {
            "score": 0.7323206067085266,
            "answer": "swiftly",
            "hit": false
          }
        ],
        "set_exclude": [
          "immediate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8282002806663513
      },
      {
        "question verbose": "What is to important ",
        "b": "important",
        "expected answer": [
          "importantly"
        ],
        "predictions": [
          {
            "score": 0.8577053546905518,
            "answer": "crucial",
            "hit": false
          },
          {
            "score": 0.8132210373878479,
            "answer": "vital",
            "hit": false
          },
          {
            "score": 0.7961544394493103,
            "answer": "valuable",
            "hit": false
          },
          {
            "score": 0.787343442440033,
            "answer": "importantly",
            "hit": true
          },
          {
            "score": 0.7773109674453735,
            "answer": "pivotal",
            "hit": false
          },
          {
            "score": 0.772057056427002,
            "answer": "noteworthy",
            "hit": false
          }
        ],
        "set_exclude": [
          "important"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.787343442440033
      },
      {
        "question verbose": "What is to increasing ",
        "b": "increasing",
        "expected answer": [
          "increasingly"
        ],
        "predictions": [
          {
            "score": 0.8182038068771362,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.8110864162445068,
            "answer": "increasingly",
            "hit": true
          },
          {
            "score": 0.7823196649551392,
            "answer": "steadily",
            "hit": false
          },
          {
            "score": 0.77459716796875,
            "answer": "progressively",
            "hit": false
          },
          {
            "score": 0.7730324268341064,
            "answer": "accelerating",
            "hit": false
          },
          {
            "score": 0.7718634009361267,
            "answer": "decreases",
            "hit": false
          }
        ],
        "set_exclude": [
          "increasing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8110864758491516
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "internally"
        ],
        "predictions": [
          {
            "score": 0.7869167923927307,
            "answer": "internally",
            "hit": true
          },
          {
            "score": 0.772457480430603,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.7323115468025208,
            "answer": "external",
            "hit": false
          },
          {
            "score": 0.7263833284378052,
            "answer": "intra",
            "hit": false
          },
          {
            "score": 0.7149986028671265,
            "answer": "efficiently",
            "hit": false
          },
          {
            "score": 0.7136069536209106,
            "answer": "fundamentally",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7869167923927307
      },
      {
        "question verbose": "What is to international ",
        "b": "international",
        "expected answer": [
          "internationally"
        ],
        "predictions": [
          {
            "score": 0.833034873008728,
            "answer": "internationally",
            "hit": true
          },
          {
            "score": 0.7841292023658752,
            "answer": "globally",
            "hit": false
          },
          {
            "score": 0.7611286640167236,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.7552177906036377,
            "answer": "overseas",
            "hit": false
          },
          {
            "score": 0.7508937120437622,
            "answer": "abroad",
            "hit": false
          },
          {
            "score": 0.7480753660202026,
            "answer": "national",
            "hit": false
          }
        ],
        "set_exclude": [
          "international"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.833034873008728
      },
      {
        "question verbose": "What is to legal ",
        "b": "legal",
        "expected answer": [
          "legally"
        ],
        "predictions": [
          {
            "score": 0.8005818128585815,
            "answer": "legally",
            "hit": true
          },
          {
            "score": 0.7763041257858276,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.7632704973220825,
            "answer": "litigation",
            "hit": false
          },
          {
            "score": 0.7570674419403076,
            "answer": "lawyer",
            "hit": false
          },
          {
            "score": 0.752334475517273,
            "answer": "attorneys",
            "hit": false
          },
          {
            "score": 0.7458133697509766,
            "answer": "lawsuit",
            "hit": false
          }
        ],
        "set_exclude": [
          "legal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8005818128585815
      },
      {
        "question verbose": "What is to mental ",
        "b": "mental",
        "expected answer": [
          "mentally"
        ],
        "predictions": [
          {
            "score": 0.846582293510437,
            "answer": "mentally",
            "hit": true
          },
          {
            "score": 0.7852309942245483,
            "answer": "cognitive",
            "hit": false
          },
          {
            "score": 0.7684903144836426,
            "answer": "neurological",
            "hit": false
          },
          {
            "score": 0.7644990682601929,
            "answer": "emotionally",
            "hit": false
          },
          {
            "score": 0.7567980289459229,
            "answer": "psychiatrist",
            "hit": false
          },
          {
            "score": 0.755393922328949,
            "answer": "psychotic",
            "hit": false
          }
        ],
        "set_exclude": [
          "mental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8465823531150818
      },
      {
        "question verbose": "What is to nice ",
        "b": "nice",
        "expected answer": [
          "nicely"
        ],
        "predictions": [
          {
            "score": 0.7472239136695862,
            "answer": "nicely",
            "hit": true
          },
          {
            "score": 0.7312251329421997,
            "answer": "beautifully",
            "hit": false
          },
          {
            "score": 0.7235997915267944,
            "answer": "neat",
            "hit": false
          },
          {
            "score": 0.7230319976806641,
            "answer": "thank",
            "hit": false
          },
          {
            "score": 0.7224665880203247,
            "answer": "mostly",
            "hit": false
          },
          {
            "score": 0.7200585007667542,
            "answer": "politely",
            "hit": false
          }
        ],
        "set_exclude": [
          "nice"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7472239434719086
      },
      {
        "question verbose": "What is to obvious ",
        "b": "obvious",
        "expected answer": [
          "obviously"
        ],
        "predictions": [
          {
            "score": 0.8031283617019653,
            "answer": "apparent",
            "hit": false
          },
          {
            "score": 0.788493812084198,
            "answer": "plainly",
            "hit": false
          },
          {
            "score": 0.7845125198364258,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.781478226184845,
            "answer": "glaring",
            "hit": false
          },
          {
            "score": 0.7618141174316406,
            "answer": "straightforward",
            "hit": false
          },
          {
            "score": 0.7587235569953918,
            "answer": "obviously",
            "hit": true
          }
        ],
        "set_exclude": [
          "obvious"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7587235569953918
      },
      {
        "question verbose": "What is to physical ",
        "b": "physical",
        "expected answer": [
          "physically"
        ],
        "predictions": [
          {
            "score": 0.819948136806488,
            "answer": "physically",
            "hit": true
          },
          {
            "score": 0.734107494354248,
            "answer": "ideally",
            "hit": false
          },
          {
            "score": 0.7338670492172241,
            "answer": "personally",
            "hit": false
          },
          {
            "score": 0.733694314956665,
            "answer": "mechanically",
            "hit": false
          },
          {
            "score": 0.7335987687110901,
            "answer": "violently",
            "hit": false
          },
          {
            "score": 0.7314338088035583,
            "answer": "physiological",
            "hit": false
          }
        ],
        "set_exclude": [
          "physical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8199481666088104
      },
      {
        "question verbose": "What is to political ",
        "b": "political",
        "expected answer": [
          "politically"
        ],
        "predictions": [
          {
            "score": 0.835207998752594,
            "answer": "politically",
            "hit": true
          },
          {
            "score": 0.7783647179603577,
            "answer": "politics",
            "hit": false
          },
          {
            "score": 0.7687561511993408,
            "answer": "ideological",
            "hit": false
          },
          {
            "score": 0.7589547634124756,
            "answer": "politicians",
            "hit": false
          },
          {
            "score": 0.7559459805488586,
            "answer": "parliamentary",
            "hit": false
          },
          {
            "score": 0.7554098963737488,
            "answer": "politician",
            "hit": false
          }
        ],
        "set_exclude": [
          "political"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.835207998752594
      },
      {
        "question verbose": "What is to practical ",
        "b": "practical",
        "expected answer": [
          "practically"
        ],
        "predictions": [
          {
            "score": 0.7713878154754639,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.7604860663414001,
            "answer": "realistic",
            "hit": false
          },
          {
            "score": 0.7540262937545776,
            "answer": "economical",
            "hit": false
          },
          {
            "score": 0.7519204020500183,
            "answer": "theoretical",
            "hit": false
          },
          {
            "score": 0.7510452270507812,
            "answer": "practically",
            "hit": true
          },
          {
            "score": 0.7490526437759399,
            "answer": "theoretically",
            "hit": false
          }
        ],
        "set_exclude": [
          "practical"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7510452270507812
      },
      {
        "question verbose": "What is to previous ",
        "b": "previous",
        "expected answer": [
          "previously"
        ],
        "predictions": [
          {
            "score": 0.7576490640640259,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.7436774969100952,
            "answer": "current",
            "hit": false
          },
          {
            "score": 0.7425568699836731,
            "answer": "although",
            "hit": false
          },
          {
            "score": 0.7422863245010376,
            "answer": "previously",
            "hit": true
          },
          {
            "score": 0.7398160099983215,
            "answer": "clearly",
            "hit": false
          },
          {
            "score": 0.7375918626785278,
            "answer": "unlike",
            "hit": false
          }
        ],
        "set_exclude": [
          "previous"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7422863095998764
      },
      {
        "question verbose": "What is to rare ",
        "b": "rare",
        "expected answer": [
          "rarely"
        ],
        "predictions": [
          {
            "score": 0.7855048179626465,
            "answer": "rarely",
            "hit": true
          },
          {
            "score": 0.7843408584594727,
            "answer": "legendary",
            "hit": false
          },
          {
            "score": 0.7792671918869019,
            "answer": "common",
            "hit": false
          },
          {
            "score": 0.77671879529953,
            "answer": "uncommon",
            "hit": false
          },
          {
            "score": 0.7640352845191956,
            "answer": "occasionally",
            "hit": false
          },
          {
            "score": 0.763656497001648,
            "answer": "very",
            "hit": false
          }
        ],
        "set_exclude": [
          "rare"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7855048775672913
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriously"
        ],
        "predictions": [
          {
            "score": 0.7722629904747009,
            "answer": "seriously",
            "hit": true
          },
          {
            "score": 0.7398557662963867,
            "answer": "profoundly",
            "hit": false
          },
          {
            "score": 0.7351498007774353,
            "answer": "seriousness",
            "hit": false
          },
          {
            "score": 0.735081672668457,
            "answer": "hugely",
            "hit": false
          },
          {
            "score": 0.733715295791626,
            "answer": "moderately",
            "hit": false
          },
          {
            "score": 0.7328829765319824,
            "answer": "decidedly",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7722629606723785
      },
      {
        "question verbose": "What is to sexual ",
        "b": "sexual",
        "expected answer": [
          "sexually"
        ],
        "predictions": [
          {
            "score": 0.8576816320419312,
            "answer": "sexually",
            "hit": true
          },
          {
            "score": 0.8073540925979614,
            "answer": "sexuality",
            "hit": false
          },
          {
            "score": 0.7908910512924194,
            "answer": "raped",
            "hit": false
          },
          {
            "score": 0.7887754440307617,
            "answer": "homosexual",
            "hit": false
          },
          {
            "score": 0.7809170484542847,
            "answer": "homosexuality",
            "hit": false
          },
          {
            "score": 0.777959942817688,
            "answer": "rape",
            "hit": false
          }
        ],
        "set_exclude": [
          "sexual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8576816618442535
      },
      {
        "question verbose": "What is to significant ",
        "b": "significant",
        "expected answer": [
          "significantly"
        ],
        "predictions": [
          {
            "score": 0.8131439089775085,
            "answer": "significantly",
            "hit": true
          },
          {
            "score": 0.787525475025177,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.7834054827690125,
            "answer": "substantially",
            "hit": false
          },
          {
            "score": 0.7775529623031616,
            "answer": "noteworthy",
            "hit": false
          },
          {
            "score": 0.7757200002670288,
            "answer": "markedly",
            "hit": false
          },
          {
            "score": 0.7674734592437744,
            "answer": "profoundly",
            "hit": false
          }
        ],
        "set_exclude": [
          "significant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8131438493728638
      },
      {
        "question verbose": "What is to similar ",
        "b": "similar",
        "expected answer": [
          "similarly"
        ],
        "predictions": [
          {
            "score": 0.7948852181434631,
            "answer": "similarly",
            "hit": true
          },
          {
            "score": 0.7858868837356567,
            "answer": "analogous",
            "hit": false
          },
          {
            "score": 0.7763169407844543,
            "answer": "reminiscent",
            "hit": false
          },
          {
            "score": 0.7719615697860718,
            "answer": "comparable",
            "hit": false
          },
          {
            "score": 0.7634811401367188,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.7543396949768066,
            "answer": "essentially",
            "hit": false
          }
        ],
        "set_exclude": [
          "similar"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7948852181434631
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongly"
        ],
        "predictions": [
          {
            "score": 0.7675505876541138,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.7569494247436523,
            "answer": "strongly",
            "hit": true
          },
          {
            "score": 0.7565769553184509,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.7331230640411377,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.7255035042762756,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.7117620706558228,
            "answer": "strength",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7569493651390076
      },
      {
        "question verbose": "What is to subsequent ",
        "b": "subsequent",
        "expected answer": [
          "subsequently"
        ],
        "predictions": [
          {
            "score": 0.8648747205734253,
            "answer": "subsequently",
            "hit": true
          },
          {
            "score": 0.8319833874702454,
            "answer": "ensuing",
            "hit": false
          },
          {
            "score": 0.7934277057647705,
            "answer": "thereafter",
            "hit": false
          },
          {
            "score": 0.7871639728546143,
            "answer": "successive",
            "hit": false
          },
          {
            "score": 0.778472900390625,
            "answer": "resultant",
            "hit": false
          },
          {
            "score": 0.7687454223632812,
            "answer": "afterward",
            "hit": false
          }
        ],
        "set_exclude": [
          "subsequent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8648747205734253
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "successfully"
        ],
        "predictions": [
          {
            "score": 0.8299764394760132,
            "answer": "unsuccessful",
            "hit": false
          },
          {
            "score": 0.7779724597930908,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.7773851156234741,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.7648873925209045,
            "answer": "successfully",
            "hit": true
          },
          {
            "score": 0.764330267906189,
            "answer": "success",
            "hit": false
          },
          {
            "score": 0.7606997489929199,
            "answer": "succeeds",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7648874223232269
      },
      {
        "question verbose": "What is to traditional ",
        "b": "traditional",
        "expected answer": [
          "traditionally"
        ],
        "predictions": [
          {
            "score": 0.8104062676429749,
            "answer": "traditionally",
            "hit": true
          },
          {
            "score": 0.7729812860488892,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.770851731300354,
            "answer": "modern",
            "hit": false
          },
          {
            "score": 0.761651873588562,
            "answer": "conventional",
            "hit": false
          },
          {
            "score": 0.7553557753562927,
            "answer": "ideally",
            "hit": false
          },
          {
            "score": 0.7533174753189087,
            "answer": "personally",
            "hit": false
          }
        ],
        "set_exclude": [
          "traditional"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8104063272476196
      },
      {
        "question verbose": "What is to typical ",
        "b": "typical",
        "expected answer": [
          "typically"
        ],
        "predictions": [
          {
            "score": 0.8037611246109009,
            "answer": "generally",
            "hit": false
          },
          {
            "score": 0.7930518984794617,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.7771100997924805,
            "answer": "usually",
            "hit": false
          },
          {
            "score": 0.7771097421646118,
            "answer": "clearly",
            "hit": false
          },
          {
            "score": 0.775375485420227,
            "answer": "typically",
            "hit": true
          },
          {
            "score": 0.7745926380157471,
            "answer": "presumably",
            "hit": false
          }
        ],
        "set_exclude": [
          "typical"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.775375485420227
      },
      {
        "question verbose": "What is to unique ",
        "b": "unique",
        "expected answer": [
          "uniquely"
        ],
        "predictions": [
          {
            "score": 0.8024618625640869,
            "answer": "uniquely",
            "hit": true
          },
          {
            "score": 0.7736747860908508,
            "answer": "distinctive",
            "hit": false
          },
          {
            "score": 0.7582358121871948,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.749025285243988,
            "answer": "beautifully",
            "hit": false
          },
          {
            "score": 0.74881511926651,
            "answer": "exceptionally",
            "hit": false
          },
          {
            "score": 0.7464230060577393,
            "answer": "rare",
            "hit": false
          }
        ],
        "set_exclude": [
          "unique"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8024618625640869
      },
      {
        "question verbose": "What is to virtual ",
        "b": "virtual",
        "expected answer": [
          "virtually"
        ],
        "predictions": [
          {
            "score": 0.7564754486083984,
            "answer": "digital",
            "hit": false
          },
          {
            "score": 0.7383170127868652,
            "answer": "digitally",
            "hit": false
          },
          {
            "score": 0.7331965565681458,
            "answer": "simulated",
            "hit": false
          },
          {
            "score": 0.7298154830932617,
            "answer": "augmented",
            "hit": false
          },
          {
            "score": 0.7206653356552124,
            "answer": "virtually",
            "hit": true
          },
          {
            "score": 0.7123935222625732,
            "answer": "globally",
            "hit": false
          }
        ],
        "set_exclude": [
          "virtual"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.72066530585289
      },
      {
        "question verbose": "What is to visual ",
        "b": "visual",
        "expected answer": [
          "visually"
        ],
        "predictions": [
          {
            "score": 0.8095582127571106,
            "answer": "visually",
            "hit": true
          },
          {
            "score": 0.730141818523407,
            "answer": "horizontally",
            "hit": false
          },
          {
            "score": 0.7255473136901855,
            "answer": "vertically",
            "hit": false
          },
          {
            "score": 0.7252928614616394,
            "answer": "sensory",
            "hit": false
          },
          {
            "score": 0.7239431738853455,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.7232764363288879,
            "answer": "depicts",
            "hit": false
          }
        ],
        "set_exclude": [
          "visual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8095582127571106
      }
    ],
    "result": {
      "cnt_questions_correct": 27,
      "cnt_questions_total": 44,
      "accuracy": 0.6136363636363636
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D03 [adj+ly_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "f7d9f8e7-a960-4244-aeb5-d293f451eb2c",
      "timestamp": "2025-05-17T17:12:46.694960"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "awareness"
        ],
        "predictions": [
          {
            "score": 0.7365074157714844,
            "answer": "awareness",
            "hit": true
          },
          {
            "score": 0.7306933403015137,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.7292309999465942,
            "answer": "seriousness",
            "hit": false
          },
          {
            "score": 0.7143799066543579,
            "answer": "sadness",
            "hit": false
          },
          {
            "score": 0.7139387130737305,
            "answer": "ignorance",
            "hit": false
          },
          {
            "score": 0.7138013243675232,
            "answer": "unaware",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7365074306726456
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "consciousness"
        ],
        "predictions": [
          {
            "score": 0.8516135215759277,
            "answer": "consciousness",
            "hit": true
          },
          {
            "score": 0.7974186539649963,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.7964650988578796,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.7577095031738281,
            "answer": "unconscious",
            "hit": false
          },
          {
            "score": 0.7421290874481201,
            "answer": "deliberate",
            "hit": false
          },
          {
            "score": 0.7330838441848755,
            "answer": "perception",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8516135215759277
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectiveness"
        ],
        "predictions": [
          {
            "score": 0.7594093680381775,
            "answer": "effectiveness",
            "hit": true
          },
          {
            "score": 0.7386966943740845,
            "answer": "efficacy",
            "hit": false
          },
          {
            "score": 0.7316766977310181,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.7268443703651428,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.7252076268196106,
            "answer": "efficiency",
            "hit": false
          },
          {
            "score": 0.7230044603347778,
            "answer": "whenever",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7594093680381775
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happiness"
        ],
        "predictions": [
          {
            "score": 0.762742280960083,
            "answer": "happiness",
            "hit": true
          },
          {
            "score": 0.7543705701828003,
            "answer": "sadness",
            "hit": false
          },
          {
            "score": 0.7531659007072449,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.7469857335090637,
            "answer": "excitement",
            "hit": false
          },
          {
            "score": 0.7426109910011292,
            "answer": "gratitude",
            "hit": false
          },
          {
            "score": 0.7393473386764526,
            "answer": "cheerful",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7627422213554382
      },
      {
        "question verbose": "What is to mad ",
        "b": "mad",
        "expected answer": [
          "madness"
        ],
        "predictions": [
          {
            "score": 0.7336170673370361,
            "answer": "madness",
            "hit": true
          },
          {
            "score": 0.7218700051307678,
            "answer": "seriousness",
            "hit": false
          },
          {
            "score": 0.7124575972557068,
            "answer": "sadness",
            "hit": false
          },
          {
            "score": 0.7120403051376343,
            "answer": "insanity",
            "hit": false
          },
          {
            "score": 0.7103753685951233,
            "answer": "melancholy",
            "hit": false
          },
          {
            "score": 0.7069617509841919,
            "answer": "madrid",
            "hit": false
          }
        ],
        "set_exclude": [
          "mad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7336170375347137
      },
      {
        "question verbose": "What is to sad ",
        "b": "sad",
        "expected answer": [
          "sadness"
        ],
        "predictions": [
          {
            "score": 0.7830411195755005,
            "answer": "sadness",
            "hit": true
          },
          {
            "score": 0.7437270879745483,
            "answer": "anguish",
            "hit": false
          },
          {
            "score": 0.7304282188415527,
            "answer": "misery",
            "hit": false
          },
          {
            "score": 0.7266381978988647,
            "answer": "sorrow",
            "hit": false
          },
          {
            "score": 0.7266116738319397,
            "answer": "madness",
            "hit": false
          },
          {
            "score": 0.7261940240859985,
            "answer": "agony",
            "hit": false
          }
        ],
        "set_exclude": [
          "sad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7830410897731781
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriousness"
        ],
        "predictions": [
          {
            "score": 0.7779862880706787,
            "answer": "seriousness",
            "hit": true
          },
          {
            "score": 0.7254884243011475,
            "answer": "seriously",
            "hit": false
          },
          {
            "score": 0.718755841255188,
            "answer": "severity",
            "hit": false
          },
          {
            "score": 0.7177256345748901,
            "answer": "efficacy",
            "hit": false
          },
          {
            "score": 0.7153382301330566,
            "answer": "effectiveness",
            "hit": false
          },
          {
            "score": 0.7150183916091919,
            "answer": "skepticism",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7779863476753235
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weakness"
        ],
        "predictions": [
          {
            "score": 0.7954932451248169,
            "answer": "weakness",
            "hit": true
          },
          {
            "score": 0.7626185417175293,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.7560466527938843,
            "answer": "weaknesses",
            "hit": false
          },
          {
            "score": 0.7529260516166687,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.7521060705184937,
            "answer": "weaken",
            "hit": false
          },
          {
            "score": 0.7351387143135071,
            "answer": "strengths",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7954932153224945
      }
    ],
    "result": {
      "cnt_questions_correct": 8,
      "cnt_questions_total": 8,
      "accuracy": 1.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D05 [adj+ness_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "944dbe9f-7670-40b8-b5a0-f1bed0ba9330",
      "timestamp": "2025-05-17T17:12:46.859136"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "acceptable"
        ],
        "predictions": [
          {
            "score": 0.8598856925964355,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.8548789024353027,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.8476579785346985,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.7960621118545532,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.7523410320281982,
            "answer": "reject",
            "hit": false
          },
          {
            "score": 0.7453351020812988,
            "answer": "unacceptable",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7382657378911972
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustable"
        ],
        "predictions": [
          {
            "score": 0.8273996114730835,
            "answer": "adjustable",
            "hit": true
          },
          {
            "score": 0.8144268989562988,
            "answer": "adjustment",
            "hit": false
          },
          {
            "score": 0.8095104098320007,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.7957640886306763,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.756571888923645,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.7362973093986511,
            "answer": "variable",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8273996114730835
      },
      {
        "question verbose": "What is to afford ",
        "b": "afford",
        "expected answer": [
          "affordable"
        ],
        "predictions": [
          {
            "score": 0.7907914519309998,
            "answer": "afforded",
            "hit": false
          },
          {
            "score": 0.7786521911621094,
            "answer": "affordable",
            "hit": true
          },
          {
            "score": 0.7557608485221863,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.7372834086418152,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.7370452880859375,
            "answer": "adequate",
            "hit": false
          },
          {
            "score": 0.7362514138221741,
            "answer": "expensive",
            "hit": false
          }
        ],
        "set_exclude": [
          "afford"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7786521911621094
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considerable"
        ],
        "predictions": [
          {
            "score": 0.7793271541595459,
            "answer": "reasonable",
            "hit": false
          },
          {
            "score": 0.7695175409317017,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7555065155029297,
            "answer": "increasing",
            "hit": false
          },
          {
            "score": 0.7543131113052368,
            "answer": "acceptable",
            "hit": false
          },
          {
            "score": 0.7502275705337524,
            "answer": "considerable",
            "hit": true
          },
          {
            "score": 0.7415931224822998,
            "answer": "consideration",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7502275705337524
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyable"
        ],
        "predictions": [
          {
            "score": 0.784674882888794,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.776386022567749,
            "answer": "enjoyable",
            "hit": true
          },
          {
            "score": 0.7696886658668518,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.7617508769035339,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.7518246173858643,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7428094744682312,
            "answer": "happy",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7763860523700714
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifiable"
        ],
        "predictions": [
          {
            "score": 0.869620144367218,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8644164204597473,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8042443990707397,
            "answer": "identifiable",
            "hit": true
          },
          {
            "score": 0.769750714302063,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.7637746334075928,
            "answer": "recognizable",
            "hit": false
          },
          {
            "score": 0.7596758604049683,
            "answer": "locate",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8042443692684174
      },
      {
        "question verbose": "What is to predict ",
        "b": "predict",
        "expected answer": [
          "predictable"
        ],
        "predictions": [
          {
            "score": 0.8435349464416504,
            "answer": "predicting",
            "hit": false
          },
          {
            "score": 0.8295853734016418,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.7928391695022583,
            "answer": "predictions",
            "hit": false
          },
          {
            "score": 0.7869327068328857,
            "answer": "predictable",
            "hit": true
          },
          {
            "score": 0.7556527853012085,
            "answer": "forecast",
            "hit": false
          },
          {
            "score": 0.741851806640625,
            "answer": "correlated",
            "hit": false
          }
        ],
        "set_exclude": [
          "predict"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7869327366352081
      },
      {
        "question verbose": "What is to rely ",
        "b": "rely",
        "expected answer": [
          "reliable"
        ],
        "predictions": [
          {
            "score": 0.8782168626785278,
            "answer": "relied",
            "hit": false
          },
          {
            "score": 0.871056854724884,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.8568787574768066,
            "answer": "relying",
            "hit": false
          },
          {
            "score": 0.8035261631011963,
            "answer": "depended",
            "hit": false
          },
          {
            "score": 0.8015716671943665,
            "answer": "reliance",
            "hit": false
          },
          {
            "score": 0.770602822303772,
            "answer": "unreliable",
            "hit": false
          }
        ],
        "set_exclude": [
          "rely"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7670770883560181
      },
      {
        "question verbose": "What is to renew ",
        "b": "renew",
        "expected answer": [
          "renewable"
        ],
        "predictions": [
          {
            "score": 0.8523344397544861,
            "answer": "renewal",
            "hit": false
          },
          {
            "score": 0.8325259685516357,
            "answer": "renewed",
            "hit": false
          },
          {
            "score": 0.7555583715438843,
            "answer": "renewable",
            "hit": true
          },
          {
            "score": 0.7163769006729126,
            "answer": "restoring",
            "hit": false
          },
          {
            "score": 0.715794563293457,
            "answer": "strengthening",
            "hit": false
          },
          {
            "score": 0.7138014435768127,
            "answer": "repairing",
            "hit": false
          }
        ],
        "set_exclude": [
          "renew"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7555583715438843
      },
      {
        "question verbose": "What is to sustain ",
        "b": "sustain",
        "expected answer": [
          "sustainable"
        ],
        "predictions": [
          {
            "score": 0.8405232429504395,
            "answer": "sustaining",
            "hit": false
          },
          {
            "score": 0.7984373569488525,
            "answer": "sustained",
            "hit": false
          },
          {
            "score": 0.7527819275856018,
            "answer": "sustainability",
            "hit": false
          },
          {
            "score": 0.7523938417434692,
            "answer": "affordable",
            "hit": false
          },
          {
            "score": 0.7373834848403931,
            "answer": "reliable",
            "hit": false
          },
          {
            "score": 0.7343215942382812,
            "answer": "credible",
            "hit": false
          }
        ],
        "set_exclude": [
          "sustain"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7168978303670883
      },
      {
        "question verbose": "What is to vary ",
        "b": "vary",
        "expected answer": [
          "variable"
        ],
        "predictions": [
          {
            "score": 0.8769657611846924,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.8369432687759399,
            "answer": "varied",
            "hit": false
          },
          {
            "score": 0.8242416381835938,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.7980303168296814,
            "answer": "varying",
            "hit": false
          },
          {
            "score": 0.7929739952087402,
            "answer": "differed",
            "hit": false
          },
          {
            "score": 0.7801833748817444,
            "answer": "differs",
            "hit": false
          }
        ],
        "set_exclude": [
          "vary"
        ],
        "rank": 48,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.711098700761795
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 11,
      "accuracy": 0.09090909090909091
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D07 [verb+able_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "8bbdb4e4-6cb4-4922-a24c-8a25fc5657ac",
      "timestamp": "2025-05-17T17:12:46.885275"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believer"
        ],
        "predictions": [
          {
            "score": 0.7683058381080627,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7628718614578247,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.7542761564254761,
            "answer": "believer",
            "hit": true
          },
          {
            "score": 0.7509573698043823,
            "answer": "honestly",
            "hit": false
          },
          {
            "score": 0.7412497401237488,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7361832857131958,
            "answer": "bel",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7542761564254761
      },
      {
        "question verbose": "What is to compose ",
        "b": "compose",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.8619308471679688,
            "answer": "composing",
            "hit": false
          },
          {
            "score": 0.7951390147209167,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.7798711061477661,
            "answer": "composer",
            "hit": true
          },
          {
            "score": 0.7556540369987488,
            "answer": "composition",
            "hit": false
          },
          {
            "score": 0.7328765392303467,
            "answer": "conductor",
            "hit": false
          },
          {
            "score": 0.7322227954864502,
            "answer": "compositions",
            "hit": false
          }
        ],
        "set_exclude": [
          "compose"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7798711359500885
      },
      {
        "question verbose": "What is to consume ",
        "b": "consume",
        "expected answer": [
          "consumer"
        ],
        "predictions": [
          {
            "score": 0.856980562210083,
            "answer": "consumed",
            "hit": false
          },
          {
            "score": 0.797804594039917,
            "answer": "consumption",
            "hit": false
          },
          {
            "score": 0.7755599617958069,
            "answer": "eats",
            "hit": false
          },
          {
            "score": 0.7635166645050049,
            "answer": "eat",
            "hit": false
          },
          {
            "score": 0.7620029449462891,
            "answer": "consuming",
            "hit": false
          },
          {
            "score": 0.7529172897338867,
            "answer": "eaten",
            "hit": false
          }
        ],
        "set_exclude": [
          "consume"
        ],
        "rank": 132,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6936963796615601
      },
      {
        "question verbose": "What is to contend ",
        "b": "contend",
        "expected answer": [
          "contender"
        ],
        "predictions": [
          {
            "score": 0.7631680965423584,
            "answer": "contention",
            "hit": false
          },
          {
            "score": 0.7547287344932556,
            "answer": "contender",
            "hit": true
          },
          {
            "score": 0.7503246665000916,
            "answer": "asserts",
            "hit": false
          },
          {
            "score": 0.7413398623466492,
            "answer": "argues",
            "hit": false
          },
          {
            "score": 0.7377498745918274,
            "answer": "argue",
            "hit": false
          },
          {
            "score": 0.7336240410804749,
            "answer": "alleging",
            "hit": false
          }
        ],
        "set_exclude": [
          "contend"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7547287344932556
      },
      {
        "question verbose": "What is to defend ",
        "b": "defend",
        "expected answer": [
          "defender"
        ],
        "predictions": [
          {
            "score": 0.8607352375984192,
            "answer": "defending",
            "hit": false
          },
          {
            "score": 0.8546391725540161,
            "answer": "defended",
            "hit": false
          },
          {
            "score": 0.8170076608657837,
            "answer": "defender",
            "hit": true
          },
          {
            "score": 0.7928304672241211,
            "answer": "defenders",
            "hit": false
          },
          {
            "score": 0.7783152461051941,
            "answer": "defence",
            "hit": false
          },
          {
            "score": 0.7640319466590881,
            "answer": "defenses",
            "hit": false
          }
        ],
        "set_exclude": [
          "defend"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8170076310634613
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developer"
        ],
        "predictions": [
          {
            "score": 0.8710134029388428,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.8640409708023071,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8482757806777954,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7908357381820679,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7743532657623291,
            "answer": "developer",
            "hit": true
          },
          {
            "score": 0.7663429379463196,
            "answer": "developmental",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7743533253669739
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examiner"
        ],
        "predictions": [
          {
            "score": 0.8707981109619141,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.8474582433700562,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.8398571014404297,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.7838901281356812,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.7798143029212952,
            "answer": "assess",
            "hit": false
          },
          {
            "score": 0.7798089981079102,
            "answer": "examinations",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7677536010742188
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.8819774389266968,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.8673837184906006,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.8524213433265686,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.7741241455078125,
            "answer": "exploration",
            "hit": false
          },
          {
            "score": 0.7682142853736877,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.7643909454345703,
            "answer": "examine",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 50,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7198289930820465
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follower"
        ],
        "predictions": [
          {
            "score": 0.7972524762153625,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.7783628106117249,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.7366152405738831,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7283852696418762,
            "answer": "follower",
            "hit": true
          },
          {
            "score": 0.7193187475204468,
            "answer": "sequel",
            "hit": false
          },
          {
            "score": 0.7027851343154907,
            "answer": "continuation",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7283852845430374
      },
      {
        "question verbose": "What is to interpret ",
        "b": "interpret",
        "expected answer": [
          "interpreter"
        ],
        "predictions": [
          {
            "score": 0.7761951088905334,
            "answer": "interpretations",
            "hit": false
          },
          {
            "score": 0.7711440324783325,
            "answer": "interpretation",
            "hit": false
          },
          {
            "score": 0.7681666612625122,
            "answer": "interpreting",
            "hit": false
          },
          {
            "score": 0.7487993240356445,
            "answer": "interpreted",
            "hit": false
          },
          {
            "score": 0.7260441184043884,
            "answer": "interpreter",
            "hit": true
          },
          {
            "score": 0.7090479731559753,
            "answer": "believer",
            "hit": false
          }
        ],
        "set_exclude": [
          "interpret"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7260441780090332
      },
      {
        "question verbose": "What is to listen ",
        "b": "listen",
        "expected answer": [
          "listener"
        ],
        "predictions": [
          {
            "score": 0.7777072191238403,
            "answer": "listener",
            "hit": true
          },
          {
            "score": 0.776613712310791,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7708804607391357,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.7605522871017456,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7220653295516968,
            "answer": "guitarist",
            "hit": false
          },
          {
            "score": 0.7205430865287781,
            "answer": "musician",
            "hit": false
          }
        ],
        "set_exclude": [
          "listen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7777072489261627
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "loser"
        ],
        "predictions": [
          {
            "score": 0.7782333493232727,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7616264820098877,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7570474147796631,
            "answer": "loser",
            "hit": true
          },
          {
            "score": 0.7403014898300171,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.7271313667297363,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7181777954101562,
            "answer": "achieve",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7570474147796631
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "manager"
        ],
        "predictions": [
          {
            "score": 0.8478353023529053,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7859198451042175,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7645916938781738,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.7501416206359863,
            "answer": "manager",
            "hit": true
          },
          {
            "score": 0.749885082244873,
            "answer": "administrator",
            "hit": false
          },
          {
            "score": 0.7409460544586182,
            "answer": "management",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7501416206359863
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observer"
        ],
        "predictions": [
          {
            "score": 0.8755594491958618,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.8612200617790222,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.8218793869018555,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.8161376118659973,
            "answer": "observer",
            "hit": true
          },
          {
            "score": 0.7757957577705383,
            "answer": "observation",
            "hit": false
          },
          {
            "score": 0.7754700183868408,
            "answer": "observers",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8161375820636749
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organizer"
        ],
        "predictions": [
          {
            "score": 0.8709713220596313,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.8589105606079102,
            "answer": "organizer",
            "hit": true
          },
          {
            "score": 0.8400923013687134,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.8219285011291504,
            "answer": "organizers",
            "hit": false
          },
          {
            "score": 0.7844980955123901,
            "answer": "organizational",
            "hit": false
          },
          {
            "score": 0.776720404624939,
            "answer": "organization",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8589105606079102
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performer"
        ],
        "predictions": [
          {
            "score": 0.8879745006561279,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.8538939356803894,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.8291974067687988,
            "answer": "performer",
            "hit": true
          },
          {
            "score": 0.7850627899169922,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7649052143096924,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.7584481239318848,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8291974663734436
      },
      {
        "question verbose": "What is to preach ",
        "b": "preach",
        "expected answer": [
          "preacher"
        ],
        "predictions": [
          {
            "score": 0.870740532875061,
            "answer": "preaching",
            "hit": false
          },
          {
            "score": 0.8246365785598755,
            "answer": "preacher",
            "hit": true
          },
          {
            "score": 0.7955530881881714,
            "answer": "sermon",
            "hit": false
          },
          {
            "score": 0.7688093781471252,
            "answer": "pastor",
            "hit": false
          },
          {
            "score": 0.7605546712875366,
            "answer": "theological",
            "hit": false
          },
          {
            "score": 0.7530116438865662,
            "answer": "theology",
            "hit": false
          }
        ],
        "set_exclude": [
          "preach"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8246366381645203
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoter"
        ],
        "predictions": [
          {
            "score": 0.8756605386734009,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.874316930770874,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.8303009867668152,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7982701659202576,
            "answer": "promoter",
            "hit": true
          },
          {
            "score": 0.792853832244873,
            "answer": "promotion",
            "hit": false
          },
          {
            "score": 0.78627610206604,
            "answer": "encourage",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7982701361179352
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provider"
        ],
        "predictions": [
          {
            "score": 0.877747118473053,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8667390942573547,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.7930908203125,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.7747917175292969,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7680696845054626,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.7625333070755005,
            "answer": "supplying",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7355228662490845
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "publisher"
        ],
        "predictions": [
          {
            "score": 0.8678121566772461,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.8382948637008667,
            "answer": "publisher",
            "hit": true
          },
          {
            "score": 0.8318223357200623,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.8076622486114502,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.7804359793663025,
            "answer": "published",
            "hit": false
          },
          {
            "score": 0.768324613571167,
            "answer": "journalist",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8382948637008667
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiver"
        ],
        "predictions": [
          {
            "score": 0.8706688284873962,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.851024866104126,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.7853712439537048,
            "answer": "recipient",
            "hit": false
          },
          {
            "score": 0.7795103788375854,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.7484986186027527,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.7469453811645508,
            "answer": "receiver",
            "hit": true
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7469454109668732
      },
      {
        "question verbose": "What is to speak ",
        "b": "speak",
        "expected answer": [
          "speaker"
        ],
        "predictions": [
          {
            "score": 0.7294071912765503,
            "answer": "terminology",
            "hit": false
          },
          {
            "score": 0.7223842144012451,
            "answer": "speaking",
            "hit": false
          },
          {
            "score": 0.7088806629180908,
            "answer": "vocabulary",
            "hit": false
          },
          {
            "score": 0.7070626020431519,
            "answer": "speaks",
            "hit": false
          },
          {
            "score": 0.7033263444900513,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.702963650226593,
            "answer": "interpreter",
            "hit": false
          }
        ],
        "set_exclude": [
          "speak"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6986539661884308
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teacher"
        ],
        "predictions": [
          {
            "score": 0.8733389377593994,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8651821613311768,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.8310858011245728,
            "answer": "teaching",
            "hit": false
          },
          {
            "score": 0.8093733787536621,
            "answer": "instructor",
            "hit": false
          },
          {
            "score": 0.8036403059959412,
            "answer": "teacher",
            "hit": true
          },
          {
            "score": 0.794096827507019,
            "answer": "instructors",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8036403059959412
      },
      {
        "question verbose": "What is to write ",
        "b": "write",
        "expected answer": [
          "writer"
        ],
        "predictions": [
          {
            "score": 0.8330737352371216,
            "answer": "wrote",
            "hit": false
          },
          {
            "score": 0.8297973275184631,
            "answer": "writes",
            "hit": false
          },
          {
            "score": 0.7805641293525696,
            "answer": "writing",
            "hit": false
          },
          {
            "score": 0.7512364983558655,
            "answer": "written",
            "hit": false
          },
          {
            "score": 0.7431102991104126,
            "answer": "writ",
            "hit": false
          },
          {
            "score": 0.7424564361572266,
            "answer": "columnist",
            "hit": false
          }
        ],
        "set_exclude": [
          "write"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7353247404098511
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 24,
      "accuracy": 0.041666666666666664
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D08 [verb+er_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "e40ff6e8-1bf6-45c8-9bac-52255be641d6",
      "timestamp": "2025-05-17T17:12:46.921374"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accuse ",
        "b": "accuse",
        "expected answer": [
          "accusation"
        ],
        "predictions": [
          {
            "score": 0.8795475959777832,
            "answer": "accusing",
            "hit": false
          },
          {
            "score": 0.8621565103530884,
            "answer": "accusation",
            "hit": true
          },
          {
            "score": 0.8416913747787476,
            "answer": "accused",
            "hit": false
          },
          {
            "score": 0.8379392623901367,
            "answer": "accusations",
            "hit": false
          },
          {
            "score": 0.7907768487930298,
            "answer": "alleging",
            "hit": false
          },
          {
            "score": 0.777945876121521,
            "answer": "blaming",
            "hit": false
          }
        ],
        "set_exclude": [
          "accuse"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8621564507484436
      },
      {
        "question verbose": "What is to admire ",
        "b": "admire",
        "expected answer": [
          "admiration"
        ],
        "predictions": [
          {
            "score": 0.8320683240890503,
            "answer": "admiration",
            "hit": true
          },
          {
            "score": 0.8181464076042175,
            "answer": "admired",
            "hit": false
          },
          {
            "score": 0.7420299053192139,
            "answer": "appreciation",
            "hit": false
          },
          {
            "score": 0.731757402420044,
            "answer": "praise",
            "hit": false
          },
          {
            "score": 0.7280995845794678,
            "answer": "enthusiasts",
            "hit": false
          },
          {
            "score": 0.7277582883834839,
            "answer": "encouragement",
            "hit": false
          }
        ],
        "set_exclude": [
          "admire"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8320682644844055
      },
      {
        "question verbose": "What is to compute ",
        "b": "compute",
        "expected answer": [
          "computation"
        ],
        "predictions": [
          {
            "score": 0.8336495161056519,
            "answer": "computation",
            "hit": true
          },
          {
            "score": 0.7968431711196899,
            "answer": "computational",
            "hit": false
          },
          {
            "score": 0.7806007266044617,
            "answer": "computed",
            "hit": false
          },
          {
            "score": 0.7665607929229736,
            "answer": "computing",
            "hit": false
          },
          {
            "score": 0.7547475099563599,
            "answer": "calculation",
            "hit": false
          },
          {
            "score": 0.7349764704704285,
            "answer": "calculating",
            "hit": false
          }
        ],
        "set_exclude": [
          "compute"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8336495161056519
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuation"
        ],
        "predictions": [
          {
            "score": 0.758594274520874,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.7515976428985596,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7432528734207153,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.728262186050415,
            "answer": "continuation",
            "hit": true
          },
          {
            "score": 0.7168548107147217,
            "answer": "proceed",
            "hit": false
          },
          {
            "score": 0.7051956057548523,
            "answer": "increase",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7282622158527374
      },
      {
        "question verbose": "What is to declare ",
        "b": "declare",
        "expected answer": [
          "declaration"
        ],
        "predictions": [
          {
            "score": 0.8751207590103149,
            "answer": "declaring",
            "hit": false
          },
          {
            "score": 0.8692253232002258,
            "answer": "declared",
            "hit": false
          },
          {
            "score": 0.8623628616333008,
            "answer": "declares",
            "hit": false
          },
          {
            "score": 0.77618408203125,
            "answer": "declaration",
            "hit": true
          },
          {
            "score": 0.7538942694664001,
            "answer": "assertion",
            "hit": false
          },
          {
            "score": 0.739629328250885,
            "answer": "asserted",
            "hit": false
          }
        ],
        "set_exclude": [
          "declare"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.77618408203125
      },
      {
        "question verbose": "What is to determine ",
        "b": "determine",
        "expected answer": [
          "determination"
        ],
        "predictions": [
          {
            "score": 0.8719136714935303,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.8643753528594971,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.815986692905426,
            "answer": "determined",
            "hit": false
          },
          {
            "score": 0.8076760172843933,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.783217191696167,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.7824708223342896,
            "answer": "decides",
            "hit": false
          }
        ],
        "set_exclude": [
          "determine"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7613312005996704
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examination"
        ],
        "predictions": [
          {
            "score": 0.8815279006958008,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.8627752065658569,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.8408373594284058,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.8110476136207581,
            "answer": "examinations",
            "hit": false
          },
          {
            "score": 0.8064064979553223,
            "answer": "examination",
            "hit": true
          },
          {
            "score": 0.7874671220779419,
            "answer": "analyze",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8064064979553223
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "exploration"
        ],
        "predictions": [
          {
            "score": 0.8887442350387573,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.8696520328521729,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.8499473333358765,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.7956273555755615,
            "answer": "exploration",
            "hit": true
          },
          {
            "score": 0.7644314765930176,
            "answer": "examine",
            "hit": false
          },
          {
            "score": 0.7643840312957764,
            "answer": "investigate",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7956274151802063
      },
      {
        "question verbose": "What is to imagine ",
        "b": "imagine",
        "expected answer": [
          "imagination"
        ],
        "predictions": [
          {
            "score": 0.7736425399780273,
            "answer": "imagining",
            "hit": false
          },
          {
            "score": 0.7609192728996277,
            "answer": "imagined",
            "hit": false
          },
          {
            "score": 0.7550299167633057,
            "answer": "maybe",
            "hit": false
          },
          {
            "score": 0.7460138201713562,
            "answer": "why",
            "hit": false
          },
          {
            "score": 0.7452970743179321,
            "answer": "almost",
            "hit": false
          },
          {
            "score": 0.7448878288269043,
            "answer": "someone",
            "hit": false
          }
        ],
        "set_exclude": [
          "imagine"
        ],
        "rank": 79,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.705778494477272
      },
      {
        "question verbose": "What is to inspire ",
        "b": "inspire",
        "expected answer": [
          "inspiration"
        ],
        "predictions": [
          {
            "score": 0.8478266596794128,
            "answer": "inspiring",
            "hit": false
          },
          {
            "score": 0.8059988021850586,
            "answer": "inspiration",
            "hit": true
          },
          {
            "score": 0.7670041918754578,
            "answer": "inspired",
            "hit": false
          },
          {
            "score": 0.7668758034706116,
            "answer": "encouragement",
            "hit": false
          },
          {
            "score": 0.7585245370864868,
            "answer": "admiration",
            "hit": false
          },
          {
            "score": 0.7475478649139404,
            "answer": "motivation",
            "hit": false
          }
        ],
        "set_exclude": [
          "inspire"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8059988021850586
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observation"
        ],
        "predictions": [
          {
            "score": 0.8835732936859131,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.8582920432090759,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.843241810798645,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.8198767304420471,
            "answer": "observation",
            "hit": true
          },
          {
            "score": 0.8058632612228394,
            "answer": "observations",
            "hit": false
          },
          {
            "score": 0.7800310850143433,
            "answer": "observer",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8198767304420471
      },
      {
        "question verbose": "What is to occupy ",
        "b": "occupy",
        "expected answer": [
          "occupation"
        ],
        "predictions": [
          {
            "score": 0.8842899799346924,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.8606693148612976,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.8044095635414124,
            "answer": "occupation",
            "hit": true
          },
          {
            "score": 0.7764022350311279,
            "answer": "occupied",
            "hit": false
          },
          {
            "score": 0.7581914663314819,
            "answer": "inhabit",
            "hit": false
          },
          {
            "score": 0.7375500202178955,
            "answer": "vacated",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupy"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8044095933437347
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organization"
        ],
        "predictions": [
          {
            "score": 0.8905175924301147,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.8477810621261597,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.8106024265289307,
            "answer": "organizer",
            "hit": false
          },
          {
            "score": 0.7957056760787964,
            "answer": "organizers",
            "hit": false
          },
          {
            "score": 0.7932761907577515,
            "answer": "organizational",
            "hit": false
          },
          {
            "score": 0.7839279174804688,
            "answer": "organization",
            "hit": true
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7839279472827911
      },
      {
        "question verbose": "What is to prepare ",
        "b": "prepare",
        "expected answer": [
          "preparation"
        ],
        "predictions": [
          {
            "score": 0.8669732213020325,
            "answer": "preparation",
            "hit": true
          },
          {
            "score": 0.8587767481803894,
            "answer": "preparing",
            "hit": false
          },
          {
            "score": 0.8554937839508057,
            "answer": "prepares",
            "hit": false
          },
          {
            "score": 0.8364023566246033,
            "answer": "prepared",
            "hit": false
          },
          {
            "score": 0.802883505821228,
            "answer": "preparations",
            "hit": false
          },
          {
            "score": 0.7392163276672363,
            "answer": "readiness",
            "hit": false
          }
        ],
        "set_exclude": [
          "prepare"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8669732809066772
      },
      {
        "question verbose": "What is to restore ",
        "b": "restore",
        "expected answer": [
          "restoration"
        ],
        "predictions": [
          {
            "score": 0.8978085517883301,
            "answer": "restoring",
            "hit": false
          },
          {
            "score": 0.8541104793548584,
            "answer": "restored",
            "hit": false
          },
          {
            "score": 0.8020623326301575,
            "answer": "restoration",
            "hit": true
          },
          {
            "score": 0.7602367401123047,
            "answer": "repair",
            "hit": false
          },
          {
            "score": 0.7505667209625244,
            "answer": "rebuilding",
            "hit": false
          },
          {
            "score": 0.750497579574585,
            "answer": "rebuild",
            "hit": false
          }
        ],
        "set_exclude": [
          "restore"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8020623326301575
      },
      {
        "question verbose": "What is to stabilize ",
        "b": "stabilize",
        "expected answer": [
          "stabilization"
        ],
        "predictions": [
          {
            "score": 0.8807778358459473,
            "answer": "stabilized",
            "hit": false
          },
          {
            "score": 0.8736793994903564,
            "answer": "stabilization",
            "hit": true
          },
          {
            "score": 0.8046376705169678,
            "answer": "stability",
            "hit": false
          },
          {
            "score": 0.7750492095947266,
            "answer": "instability",
            "hit": false
          },
          {
            "score": 0.7733481526374817,
            "answer": "stable",
            "hit": false
          },
          {
            "score": 0.748989999294281,
            "answer": "unstable",
            "hit": false
          }
        ],
        "set_exclude": [
          "stabilize"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8736794590950012
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 16,
      "accuracy": 0.1875
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D09 [verb+tion_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "15a5d24a-61a4-4a13-8509-33df9f334b78",
      "timestamp": "2025-05-17T17:12:47.002586"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accomplish ",
        "b": "accomplish",
        "expected answer": [
          "accomplishment"
        ],
        "predictions": [
          {
            "score": 0.8462343811988831,
            "answer": "accomplished",
            "hit": false
          },
          {
            "score": 0.8307593464851379,
            "answer": "accomplishment",
            "hit": true
          },
          {
            "score": 0.8000879287719727,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7944625616073608,
            "answer": "accomplishments",
            "hit": false
          },
          {
            "score": 0.7915952205657959,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.7633311748504639,
            "answer": "achievement",
            "hit": false
          }
        ],
        "set_exclude": [
          "accomplish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8307593166828156
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achievement"
        ],
        "predictions": [
          {
            "score": 0.7923529148101807,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7786147594451904,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.7673858404159546,
            "answer": "achievement",
            "hit": true
          },
          {
            "score": 0.7663909196853638,
            "answer": "accomplishment",
            "hit": false
          },
          {
            "score": 0.7539423108100891,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.7429413199424744,
            "answer": "accomplishments",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7673857808113098
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustment"
        ],
        "predictions": [
          {
            "score": 0.8636733293533325,
            "answer": "adjustment",
            "hit": true
          },
          {
            "score": 0.838577151298523,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.8177896738052368,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.793088436126709,
            "answer": "adjustable",
            "hit": false
          },
          {
            "score": 0.7424479722976685,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.7311067581176758,
            "answer": "adapting",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8636733591556549
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreement"
        ],
        "predictions": [
          {
            "score": 0.8647619485855103,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8424831628799438,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.832003116607666,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7809257507324219,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7771178483963013,
            "answer": "disagreement",
            "hit": false
          },
          {
            "score": 0.7709370851516724,
            "answer": "disagreed",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7613095641136169
      },
      {
        "question verbose": "What is to align ",
        "b": "align",
        "expected answer": [
          "alignment"
        ],
        "predictions": [
          {
            "score": 0.7901099920272827,
            "answer": "alignment",
            "hit": true
          },
          {
            "score": 0.7736644148826599,
            "answer": "aligned",
            "hit": false
          },
          {
            "score": 0.7164109945297241,
            "answer": "adjust",
            "hit": false
          },
          {
            "score": 0.7143625020980835,
            "answer": "convergence",
            "hit": false
          },
          {
            "score": 0.713707447052002,
            "answer": "positioning",
            "hit": false
          },
          {
            "score": 0.7125567197799683,
            "answer": "adjustments",
            "hit": false
          }
        ],
        "set_exclude": [
          "align"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7901099920272827
      },
      {
        "question verbose": "What is to amend ",
        "b": "amend",
        "expected answer": [
          "amendment"
        ],
        "predictions": [
          {
            "score": 0.819654107093811,
            "answer": "amended",
            "hit": false
          },
          {
            "score": 0.8117605447769165,
            "answer": "amendments",
            "hit": false
          },
          {
            "score": 0.7705913782119751,
            "answer": "amendment",
            "hit": true
          },
          {
            "score": 0.7578097581863403,
            "answer": "alteration",
            "hit": false
          },
          {
            "score": 0.7469204664230347,
            "answer": "revisions",
            "hit": false
          },
          {
            "score": 0.7426180839538574,
            "answer": "alterations",
            "hit": false
          }
        ],
        "set_exclude": [
          "amend"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7705913782119751
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announcement"
        ],
        "predictions": [
          {
            "score": 0.8400577306747437,
            "answer": "announcement",
            "hit": true
          },
          {
            "score": 0.835702657699585,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.7571465969085693,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.7543554306030273,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.7396222352981567,
            "answer": "notification",
            "hit": false
          },
          {
            "score": 0.7357245683670044,
            "answer": "decision",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8400577902793884
      },
      {
        "question verbose": "What is to appoint ",
        "b": "appoint",
        "expected answer": [
          "appointment"
        ],
        "predictions": [
          {
            "score": 0.8300145864486694,
            "answer": "appointed",
            "hit": false
          },
          {
            "score": 0.8156152963638306,
            "answer": "appointment",
            "hit": true
          },
          {
            "score": 0.7948650121688843,
            "answer": "appointments",
            "hit": false
          },
          {
            "score": 0.7481716871261597,
            "answer": "nominee",
            "hit": false
          },
          {
            "score": 0.7420393228530884,
            "answer": "nomination",
            "hit": false
          },
          {
            "score": 0.739673376083374,
            "answer": "nominations",
            "hit": false
          }
        ],
        "set_exclude": [
          "appoint"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8156152963638306
      },
      {
        "question verbose": "What is to arrange ",
        "b": "arrange",
        "expected answer": [
          "arrangement"
        ],
        "predictions": [
          {
            "score": 0.8864690065383911,
            "answer": "arranging",
            "hit": false
          },
          {
            "score": 0.8553641438484192,
            "answer": "arranged",
            "hit": false
          },
          {
            "score": 0.8256028890609741,
            "answer": "arrangement",
            "hit": true
          },
          {
            "score": 0.8076684474945068,
            "answer": "arrangements",
            "hit": false
          },
          {
            "score": 0.7734721899032593,
            "answer": "organize",
            "hit": false
          },
          {
            "score": 0.7395728826522827,
            "answer": "organised",
            "hit": false
          }
        ],
        "set_exclude": [
          "arrange"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8256028890609741
      },
      {
        "question verbose": "What is to assess ",
        "b": "assess",
        "expected answer": [
          "assessment"
        ],
        "predictions": [
          {
            "score": 0.8665452599525452,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.8512784242630005,
            "answer": "assessed",
            "hit": false
          },
          {
            "score": 0.8482668399810791,
            "answer": "assessments",
            "hit": false
          },
          {
            "score": 0.8171214461326599,
            "answer": "assessment",
            "hit": true
          },
          {
            "score": 0.8083990812301636,
            "answer": "evaluate",
            "hit": false
          },
          {
            "score": 0.7965104579925537,
            "answer": "evaluation",
            "hit": false
          }
        ],
        "set_exclude": [
          "assess"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8171214461326599
      },
      {
        "question verbose": "What is to assign ",
        "b": "assign",
        "expected answer": [
          "assignment"
        ],
        "predictions": [
          {
            "score": 0.865446150302887,
            "answer": "assigns",
            "hit": false
          },
          {
            "score": 0.8400553464889526,
            "answer": "assigned",
            "hit": false
          },
          {
            "score": 0.7981789708137512,
            "answer": "assignments",
            "hit": false
          },
          {
            "score": 0.794380247592926,
            "answer": "assignment",
            "hit": true
          },
          {
            "score": 0.7592910528182983,
            "answer": "allocation",
            "hit": false
          },
          {
            "score": 0.7473371624946594,
            "answer": "allocated",
            "hit": false
          }
        ],
        "set_exclude": [
          "assign"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7943802773952484
      },
      {
        "question verbose": "What is to commit ",
        "b": "commit",
        "expected answer": [
          "commitment"
        ],
        "predictions": [
          {
            "score": 0.8160936832427979,
            "answer": "commitment",
            "hit": true
          },
          {
            "score": 0.773181676864624,
            "answer": "committing",
            "hit": false
          },
          {
            "score": 0.7597321271896362,
            "answer": "commitments",
            "hit": false
          },
          {
            "score": 0.7508748173713684,
            "answer": "commits",
            "hit": false
          },
          {
            "score": 0.7415781021118164,
            "answer": "dedication",
            "hit": false
          },
          {
            "score": 0.7356486320495605,
            "answer": "committed",
            "hit": false
          }
        ],
        "set_exclude": [
          "commit"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8160936832427979
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "development"
        ],
        "predictions": [
          {
            "score": 0.8734439611434937,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.8696037530899048,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8565280437469482,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7996277809143066,
            "answer": "development",
            "hit": true
          },
          {
            "score": 0.7722582817077637,
            "answer": "developmental",
            "hit": false
          },
          {
            "score": 0.7652369737625122,
            "answer": "evolve",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7996277809143066
      },
      {
        "question verbose": "What is to disagree ",
        "b": "disagree",
        "expected answer": [
          "disagreement"
        ],
        "predictions": [
          {
            "score": 0.8635081052780151,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.8290852308273315,
            "answer": "disagreement",
            "hit": true
          },
          {
            "score": 0.7677644491195679,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.7591288089752197,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7527538537979126,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.7485899925231934,
            "answer": "differing",
            "hit": false
          }
        ],
        "set_exclude": [
          "disagree"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8290852308273315
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouragement"
        ],
        "predictions": [
          {
            "score": 0.8734748363494873,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8619473576545715,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.8442238569259644,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.8221703171730042,
            "answer": "encouraging",
            "hit": false
          },
          {
            "score": 0.8175528645515442,
            "answer": "encouragement",
            "hit": true
          },
          {
            "score": 0.7927364110946655,
            "answer": "promote",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8175528943538666
      },
      {
        "question verbose": "What is to enforce ",
        "b": "enforce",
        "expected answer": [
          "enforcement"
        ],
        "predictions": [
          {
            "score": 0.8649171590805054,
            "answer": "enforcing",
            "hit": false
          },
          {
            "score": 0.8429187536239624,
            "answer": "enforced",
            "hit": false
          },
          {
            "score": 0.780823826789856,
            "answer": "enforcement",
            "hit": true
          },
          {
            "score": 0.7444363832473755,
            "answer": "policing",
            "hit": false
          },
          {
            "score": 0.742588996887207,
            "answer": "implementation",
            "hit": false
          },
          {
            "score": 0.7316101789474487,
            "answer": "upheld",
            "hit": false
          }
        ],
        "set_exclude": [
          "enforce"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7808237671852112
      },
      {
        "question verbose": "What is to engage ",
        "b": "engage",
        "expected answer": [
          "engagement"
        ],
        "predictions": [
          {
            "score": 0.8888563513755798,
            "answer": "engages",
            "hit": false
          },
          {
            "score": 0.8813952207565308,
            "answer": "engaging",
            "hit": false
          },
          {
            "score": 0.8571341633796692,
            "answer": "engaged",
            "hit": false
          },
          {
            "score": 0.8401250839233398,
            "answer": "engagement",
            "hit": true
          },
          {
            "score": 0.7638846635818481,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.7600753903388977,
            "answer": "participate",
            "hit": false
          }
        ],
        "set_exclude": [
          "engage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8401251137256622
      },
      {
        "question verbose": "What is to enhance ",
        "b": "enhance",
        "expected answer": [
          "enhancement"
        ],
        "predictions": [
          {
            "score": 0.8051161766052246,
            "answer": "enhancement",
            "hit": true
          },
          {
            "score": 0.7736940979957581,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.7606086730957031,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7480038404464722,
            "answer": "enhanced",
            "hit": false
          },
          {
            "score": 0.7408857345581055,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.735327422618866,
            "answer": "improved",
            "hit": false
          }
        ],
        "set_exclude": [
          "enhance"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.805116206407547
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyment"
        ],
        "predictions": [
          {
            "score": 0.7948635220527649,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7846167683601379,
            "answer": "enjoyment",
            "hit": true
          },
          {
            "score": 0.7671454548835754,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.7615529894828796,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.733302116394043,
            "answer": "thanks",
            "hit": false
          },
          {
            "score": 0.732464611530304,
            "answer": "happy",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7846167683601379
      },
      {
        "question verbose": "What is to entertain ",
        "b": "entertain",
        "expected answer": [
          "entertainment"
        ],
        "predictions": [
          {
            "score": 0.8156788349151611,
            "answer": "entertainment",
            "hit": true
          },
          {
            "score": 0.8110126256942749,
            "answer": "entertained",
            "hit": false
          },
          {
            "score": 0.7967932820320129,
            "answer": "entertaining",
            "hit": false
          },
          {
            "score": 0.7549670338630676,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.7416321039199829,
            "answer": "musician",
            "hit": false
          },
          {
            "score": 0.7379981875419617,
            "answer": "performer",
            "hit": false
          }
        ],
        "set_exclude": [
          "entertain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8156788945198059
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishment"
        ],
        "predictions": [
          {
            "score": 0.8508747816085815,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8024958372116089,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7561473250389099,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.7549492120742798,
            "answer": "restoring",
            "hit": false
          },
          {
            "score": 0.7529021501541138,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7519479990005493,
            "answer": "initiating",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7328655123710632
      },
      {
        "question verbose": "What is to fulfill ",
        "b": "fulfill",
        "expected answer": [
          "fulfillment"
        ],
        "predictions": [
          {
            "score": 0.853670597076416,
            "answer": "fulfilling",
            "hit": false
          },
          {
            "score": 0.8529388308525085,
            "answer": "fulfilled",
            "hit": false
          },
          {
            "score": 0.8518036007881165,
            "answer": "fulfillment",
            "hit": true
          },
          {
            "score": 0.8017079830169678,
            "answer": "satisfy",
            "hit": false
          },
          {
            "score": 0.7673695087432861,
            "answer": "accomplishment",
            "hit": false
          },
          {
            "score": 0.7554757595062256,
            "answer": "accomplish",
            "hit": false
          }
        ],
        "set_exclude": [
          "fulfill"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8518036007881165
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improvement"
        ],
        "predictions": [
          {
            "score": 0.8413808345794678,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.8338475823402405,
            "answer": "improvement",
            "hit": true
          },
          {
            "score": 0.8268714547157288,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.7968224883079529,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7745327353477478,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7632273435592651,
            "answer": "deterioration",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8338476419448853
      },
      {
        "question verbose": "What is to invest ",
        "b": "invest",
        "expected answer": [
          "investment"
        ],
        "predictions": [
          {
            "score": 0.7972167134284973,
            "answer": "investment",
            "hit": true
          },
          {
            "score": 0.7774790525436401,
            "answer": "investigation",
            "hit": false
          },
          {
            "score": 0.7747839689254761,
            "answer": "investor",
            "hit": false
          },
          {
            "score": 0.7728387117385864,
            "answer": "investing",
            "hit": false
          },
          {
            "score": 0.7681039571762085,
            "answer": "investments",
            "hit": false
          },
          {
            "score": 0.7457931637763977,
            "answer": "invested",
            "hit": false
          }
        ],
        "set_exclude": [
          "invest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7972167134284973
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involvement"
        ],
        "predictions": [
          {
            "score": 0.8832204341888428,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8376859426498413,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7864084839820862,
            "answer": "involvement",
            "hit": true
          },
          {
            "score": 0.7618794441223145,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.7559671401977539,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.7557520866394043,
            "answer": "consist",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7864084839820862
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "management"
        ],
        "predictions": [
          {
            "score": 0.8516522645950317,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7746542096138,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7701809406280518,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.7659935355186462,
            "answer": "management",
            "hit": true
          },
          {
            "score": 0.7342726588249207,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.7276077270507812,
            "answer": "managers",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7659935653209686
      },
      {
        "question verbose": "What is to punish ",
        "b": "punish",
        "expected answer": [
          "punishment"
        ],
        "predictions": [
          {
            "score": 0.8722695112228394,
            "answer": "punished",
            "hit": false
          },
          {
            "score": 0.8662757873535156,
            "answer": "punishment",
            "hit": true
          },
          {
            "score": 0.7828922867774963,
            "answer": "retaliation",
            "hit": false
          },
          {
            "score": 0.7607660293579102,
            "answer": "revenge",
            "hit": false
          },
          {
            "score": 0.7571361064910889,
            "answer": "penalties",
            "hit": false
          },
          {
            "score": 0.7556312084197998,
            "answer": "reward",
            "hit": false
          }
        ],
        "set_exclude": [
          "punish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8662757873535156
      },
      {
        "question verbose": "What is to reinforce ",
        "b": "reinforce",
        "expected answer": [
          "reinforcement"
        ],
        "predictions": [
          {
            "score": 0.865029513835907,
            "answer": "reinforced",
            "hit": false
          },
          {
            "score": 0.8538729548454285,
            "answer": "reinforcement",
            "hit": true
          },
          {
            "score": 0.7989678382873535,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.7930275201797485,
            "answer": "strengthening",
            "hit": false
          },
          {
            "score": 0.7788227796554565,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.7717081308364868,
            "answer": "undermine",
            "hit": false
          }
        ],
        "set_exclude": [
          "reinforce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8538729846477509
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replacement"
        ],
        "predictions": [
          {
            "score": 0.7698407769203186,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.7611008882522583,
            "answer": "replacement",
            "hit": true
          },
          {
            "score": 0.7510538697242737,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.749043881893158,
            "answer": "replaced",
            "hit": false
          },
          {
            "score": 0.7400006651878357,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.736717939376831,
            "answer": "split",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7611009478569031
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requirement"
        ],
        "predictions": [
          {
            "score": 0.8356817960739136,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.8137661814689636,
            "answer": "requirement",
            "hit": true
          },
          {
            "score": 0.7991660237312317,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7619165182113647,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.755681037902832,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.754328191280365,
            "answer": "needing",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8137661814689636
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 30,
      "accuracy": 0.23333333333333334
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D10 [verb+ment_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "2c363e5a-9329-4946-b679-96df0d70a208",
      "timestamp": "2025-05-17T17:12:47.055029"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to athens ",
        "b": "athens",
        "expected answer": [
          "greece"
        ],
        "predictions": [
          {
            "score": 0.9077639579772949,
            "answer": "greece",
            "hit": true
          },
          {
            "score": 0.8105074167251587,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.8081942796707153,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.793848991394043,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.793304443359375,
            "answer": "bulgaria",
            "hit": false
          },
          {
            "score": 0.7908053994178772,
            "answer": "spain",
            "hit": false
          }
        ],
        "set_exclude": [
          "athens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9077639579772949
      },
      {
        "question verbose": "What is to baghdad ",
        "b": "baghdad",
        "expected answer": [
          "iraq"
        ],
        "predictions": [
          {
            "score": 0.8781589865684509,
            "answer": "iraq",
            "hit": true
          },
          {
            "score": 0.859298586845398,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.8116952180862427,
            "answer": "saddam",
            "hit": false
          },
          {
            "score": 0.810798704624176,
            "answer": "afghanistan",
            "hit": false
          },
          {
            "score": 0.8096757531166077,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.8044987916946411,
            "answer": "kuwait",
            "hit": false
          }
        ],
        "set_exclude": [
          "baghdad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8781590461730957
      },
      {
        "question verbose": "What is to bangkok ",
        "b": "bangkok",
        "expected answer": [
          "thailand"
        ],
        "predictions": [
          {
            "score": 0.9274064302444458,
            "answer": "thailand",
            "hit": true
          },
          {
            "score": 0.8444205522537231,
            "answer": "thai",
            "hit": false
          },
          {
            "score": 0.8352857828140259,
            "answer": "cambodia",
            "hit": false
          },
          {
            "score": 0.8197316527366638,
            "answer": "myanmar",
            "hit": false
          },
          {
            "score": 0.815630316734314,
            "answer": "indonesia",
            "hit": false
          },
          {
            "score": 0.8052082657814026,
            "answer": "bangladesh",
            "hit": false
          }
        ],
        "set_exclude": [
          "bangkok"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9274064302444458
      },
      {
        "question verbose": "What is to beijing ",
        "b": "beijing",
        "expected answer": [
          "china"
        ],
        "predictions": [
          {
            "score": 0.9019529223442078,
            "answer": "china",
            "hit": true
          },
          {
            "score": 0.8351541757583618,
            "answer": "chinese",
            "hit": false
          },
          {
            "score": 0.8154529333114624,
            "answer": "japan",
            "hit": false
          },
          {
            "score": 0.813431978225708,
            "answer": "taiwan",
            "hit": false
          },
          {
            "score": 0.8111417293548584,
            "answer": "shanghai",
            "hit": false
          },
          {
            "score": 0.8095340728759766,
            "answer": "thailand",
            "hit": false
          }
        ],
        "set_exclude": [
          "beijing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9019529223442078
      },
      {
        "question verbose": "What is to berlin ",
        "b": "berlin",
        "expected answer": [
          "germany"
        ],
        "predictions": [
          {
            "score": 0.8743624687194824,
            "answer": "germany",
            "hit": true
          },
          {
            "score": 0.8168216347694397,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.8114515542984009,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.8067497611045837,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.8047364354133606,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.8010091781616211,
            "answer": "belgium",
            "hit": false
          }
        ],
        "set_exclude": [
          "berlin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8743624985218048
      },
      {
        "question verbose": "What is to bern ",
        "b": "bern",
        "expected answer": [
          "switzerland"
        ],
        "predictions": [
          {
            "score": 0.7257328629493713,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7049379348754883,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7029134035110474,
            "answer": "bernie",
            "hit": false
          },
          {
            "score": 0.7017520666122437,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7000230550765991,
            "answer": "england",
            "hit": false
          },
          {
            "score": 0.6973297595977783,
            "answer": "austria",
            "hit": false
          }
        ],
        "set_exclude": [
          "bern"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6856890171766281
      },
      {
        "question verbose": "What is to brussels ",
        "b": "brussels",
        "expected answer": [
          "belgium"
        ],
        "predictions": [
          {
            "score": 0.8736187815666199,
            "answer": "belgium",
            "hit": true
          },
          {
            "score": 0.8208920955657959,
            "answer": "belgian",
            "hit": false
          },
          {
            "score": 0.8151055574417114,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7993183732032776,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.7946611642837524,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7932493686676025,
            "answer": "europe",
            "hit": false
          }
        ],
        "set_exclude": [
          "brussels"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8736187815666199
      },
      {
        "question verbose": "What is to budapest ",
        "b": "budapest",
        "expected answer": [
          "hungary"
        ],
        "predictions": [
          {
            "score": 0.9255082607269287,
            "answer": "hungary",
            "hit": true
          },
          {
            "score": 0.872313380241394,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.8316558599472046,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.8187873959541321,
            "answer": "bulgaria",
            "hit": false
          },
          {
            "score": 0.8154183626174927,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.8118495345115662,
            "answer": "romania",
            "hit": false
          }
        ],
        "set_exclude": [
          "budapest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9255083203315735
      },
      {
        "question verbose": "What is to cairo ",
        "b": "cairo",
        "expected answer": [
          "egypt"
        ],
        "predictions": [
          {
            "score": 0.9014220237731934,
            "answer": "egypt",
            "hit": true
          },
          {
            "score": 0.8428131341934204,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.8107251524925232,
            "answer": "libya",
            "hit": false
          },
          {
            "score": 0.7931675314903259,
            "answer": "morocco",
            "hit": false
          },
          {
            "score": 0.7840766310691833,
            "answer": "ethiopia",
            "hit": false
          },
          {
            "score": 0.7805174589157104,
            "answer": "syria",
            "hit": false
          }
        ],
        "set_exclude": [
          "cairo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9014220237731934
      },
      {
        "question verbose": "What is to copenhagen ",
        "b": "copenhagen",
        "expected answer": [
          "denmark"
        ],
        "predictions": [
          {
            "score": 0.8969820141792297,
            "answer": "denmark",
            "hit": true
          },
          {
            "score": 0.8499299883842468,
            "answer": "danish",
            "hit": false
          },
          {
            "score": 0.8285685777664185,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.8267630934715271,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.8095290660858154,
            "answer": "iceland",
            "hit": false
          },
          {
            "score": 0.8001984357833862,
            "answer": "finland",
            "hit": false
          }
        ],
        "set_exclude": [
          "copenhagen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.896981954574585
      },
      {
        "question verbose": "What is to damascus ",
        "b": "damascus",
        "expected answer": [
          "syria"
        ],
        "predictions": [
          {
            "score": 0.8592860698699951,
            "answer": "syria",
            "hit": true
          },
          {
            "score": 0.8193907141685486,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.8039906024932861,
            "answer": "lebanon",
            "hit": false
          },
          {
            "score": 0.7951115369796753,
            "answer": "egypt",
            "hit": false
          },
          {
            "score": 0.7897121906280518,
            "answer": "russia",
            "hit": false
          },
          {
            "score": 0.7818768620491028,
            "answer": "libya",
            "hit": false
          }
        ],
        "set_exclude": [
          "damascus"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8592860698699951
      },
      {
        "question verbose": "What is to dublin ",
        "b": "dublin",
        "expected answer": [
          "ireland"
        ],
        "predictions": [
          {
            "score": 0.8775683641433716,
            "answer": "ireland",
            "hit": true
          },
          {
            "score": 0.8163975477218628,
            "answer": "irish",
            "hit": false
          },
          {
            "score": 0.7890627980232239,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.7847721576690674,
            "answer": "cork",
            "hit": false
          },
          {
            "score": 0.7846333384513855,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.7812917232513428,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "dublin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8775683343410492
      },
      {
        "question verbose": "What is to helsinki ",
        "b": "helsinki",
        "expected answer": [
          "finland"
        ],
        "predictions": [
          {
            "score": 0.8861494064331055,
            "answer": "finland",
            "hit": true
          },
          {
            "score": 0.8414173722267151,
            "answer": "finnish",
            "hit": false
          },
          {
            "score": 0.8130389451980591,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.7990135550498962,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.7929864525794983,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.7926578521728516,
            "answer": "denmark",
            "hit": false
          }
        ],
        "set_exclude": [
          "helsinki"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8861494660377502
      },
      {
        "question verbose": "What is to kingston ",
        "b": "kingston",
        "expected answer": [
          "jamaica"
        ],
        "predictions": [
          {
            "score": 0.795415997505188,
            "answer": "jamaica",
            "hit": true
          },
          {
            "score": 0.7516813278198242,
            "answer": "canada",
            "hit": false
          },
          {
            "score": 0.7487090826034546,
            "answer": "ontario",
            "hit": false
          },
          {
            "score": 0.7424799203872681,
            "answer": "ghana",
            "hit": false
          },
          {
            "score": 0.7361354231834412,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.7320232391357422,
            "answer": "sweden",
            "hit": false
          }
        ],
        "set_exclude": [
          "kingston"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7954159677028656
      },
      {
        "question verbose": "What is to lisbon ",
        "b": "lisbon",
        "expected answer": [
          "portugal"
        ],
        "predictions": [
          {
            "score": 0.8878821730613708,
            "answer": "portugal",
            "hit": true
          },
          {
            "score": 0.8145461678504944,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.8050962686538696,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7955697178840637,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7950885891914368,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.7884801626205444,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "lisbon"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8878822028636932
      },
      {
        "question verbose": "What is to madrid ",
        "b": "madrid",
        "expected answer": [
          "spain"
        ],
        "predictions": [
          {
            "score": 0.8974961042404175,
            "answer": "spain",
            "hit": true
          },
          {
            "score": 0.83050936460495,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.815632700920105,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.813262403011322,
            "answer": "barcelona",
            "hit": false
          },
          {
            "score": 0.8105587363243103,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.8092758059501648,
            "answer": "argentina",
            "hit": false
          }
        ],
        "set_exclude": [
          "madrid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8974961042404175
      },
      {
        "question verbose": "What is to manila ",
        "b": "manila",
        "expected answer": [
          "philippines"
        ],
        "predictions": [
          {
            "score": 0.8676948547363281,
            "answer": "philippine",
            "hit": false
          },
          {
            "score": 0.8643026947975159,
            "answer": "philippines",
            "hit": true
          },
          {
            "score": 0.7991850972175598,
            "answer": "china",
            "hit": false
          },
          {
            "score": 0.799008309841156,
            "answer": "indonesia",
            "hit": false
          },
          {
            "score": 0.7975001335144043,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.7942520976066589,
            "answer": "malaysia",
            "hit": false
          }
        ],
        "set_exclude": [
          "manila"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8643026947975159
      },
      {
        "question verbose": "What is to moscow ",
        "b": "moscow",
        "expected answer": [
          "russia"
        ],
        "predictions": [
          {
            "score": 0.9187270998954773,
            "answer": "russia",
            "hit": true
          },
          {
            "score": 0.8296887874603271,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.8260442018508911,
            "answer": "russians",
            "hit": false
          },
          {
            "score": 0.8219175338745117,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.8214799761772156,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.8169894814491272,
            "answer": "syria",
            "hit": false
          }
        ],
        "set_exclude": [
          "moscow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9187270998954773
      },
      {
        "question verbose": "What is to oslo ",
        "b": "oslo",
        "expected answer": [
          "norway"
        ],
        "predictions": [
          {
            "score": 0.8914593458175659,
            "answer": "norway",
            "hit": true
          },
          {
            "score": 0.8346050381660461,
            "answer": "norwegian",
            "hit": false
          },
          {
            "score": 0.8141228556632996,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.8035876154899597,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.7981883883476257,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.7890993356704712,
            "answer": "iceland",
            "hit": false
          }
        ],
        "set_exclude": [
          "oslo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8914592862129211
      },
      {
        "question verbose": "What is to ottawa ",
        "b": "ottawa",
        "expected answer": [
          "canada"
        ],
        "predictions": [
          {
            "score": 0.856654942035675,
            "answer": "canada",
            "hit": true
          },
          {
            "score": 0.8410199284553528,
            "answer": "ontario",
            "hit": false
          },
          {
            "score": 0.829531192779541,
            "answer": "canadians",
            "hit": false
          },
          {
            "score": 0.8260749578475952,
            "answer": "saskatchewan",
            "hit": false
          },
          {
            "score": 0.8212130665779114,
            "answer": "alberta",
            "hit": false
          },
          {
            "score": 0.8207641839981079,
            "answer": "quebec",
            "hit": false
          }
        ],
        "set_exclude": [
          "ottawa"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.856654942035675
      },
      {
        "question verbose": "What is to paris ",
        "b": "paris",
        "expected answer": [
          "france"
        ],
        "predictions": [
          {
            "score": 0.8426557183265686,
            "answer": "france",
            "hit": true
          },
          {
            "score": 0.8095316886901855,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7828323841094971,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7812848091125488,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.7794694900512695,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7751835584640503,
            "answer": "switzerland",
            "hit": false
          }
        ],
        "set_exclude": [
          "paris"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8426557779312134
      },
      {
        "question verbose": "What is to rome ",
        "b": "rome",
        "expected answer": [
          "italy"
        ],
        "predictions": [
          {
            "score": 0.7083834409713745,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7083463668823242,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7061767578125,
            "answer": "italy",
            "hit": true
          },
          {
            "score": 0.7037826180458069,
            "answer": "roma",
            "hit": false
          },
          {
            "score": 0.7023380994796753,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.6981452703475952,
            "answer": "croatia",
            "hit": false
          }
        ],
        "set_exclude": [
          "rome"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7061767280101776
      },
      {
        "question verbose": "What is to santiago ",
        "b": "santiago",
        "expected answer": [
          "chile"
        ],
        "predictions": [
          {
            "score": 0.8290266990661621,
            "answer": "chile",
            "hit": true
          },
          {
            "score": 0.7916460037231445,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7885999083518982,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.7713462114334106,
            "answer": "peru",
            "hit": false
          },
          {
            "score": 0.7691948413848877,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.7611676454544067,
            "answer": "cuba",
            "hit": false
          }
        ],
        "set_exclude": [
          "santiago"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8290267288684845
      },
      {
        "question verbose": "What is to stockholm ",
        "b": "stockholm",
        "expected answer": [
          "sweden"
        ],
        "predictions": [
          {
            "score": 0.8993379473686218,
            "answer": "sweden",
            "hit": true
          },
          {
            "score": 0.8404062986373901,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.8336789011955261,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.8292612433433533,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.8240911960601807,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.7997324466705322,
            "answer": "germany",
            "hit": false
          }
        ],
        "set_exclude": [
          "stockholm"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8993379771709442
      },
      {
        "question verbose": "What is to tehran ",
        "b": "tehran",
        "expected answer": [
          "iran"
        ],
        "predictions": [
          {
            "score": 0.9300276041030884,
            "answer": "iran",
            "hit": true
          },
          {
            "score": 0.8792644143104553,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.8103131651878357,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.8032540082931519,
            "answer": "russia",
            "hit": false
          },
          {
            "score": 0.8025121092796326,
            "answer": "pakistan",
            "hit": false
          },
          {
            "score": 0.80078125,
            "answer": "saudi",
            "hit": false
          }
        ],
        "set_exclude": [
          "tehran"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9300276041030884
      },
      {
        "question verbose": "What is to tokyo ",
        "b": "tokyo",
        "expected answer": [
          "japan"
        ],
        "predictions": [
          {
            "score": 0.9114636182785034,
            "answer": "japan",
            "hit": true
          },
          {
            "score": 0.8095215559005737,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.7996083498001099,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.7957659363746643,
            "answer": "china",
            "hit": false
          },
          {
            "score": 0.787756085395813,
            "answer": "seoul",
            "hit": false
          },
          {
            "score": 0.7828401327133179,
            "answer": "italy",
            "hit": false
          }
        ],
        "set_exclude": [
          "tokyo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9114636182785034
      },
      {
        "question verbose": "What is to vienna ",
        "b": "vienna",
        "expected answer": [
          "austria"
        ],
        "predictions": [
          {
            "score": 0.8836138248443604,
            "answer": "austria",
            "hit": true
          },
          {
            "score": 0.8178408145904541,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.8165457248687744,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.8137584924697876,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.7998232841491699,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7968626618385315,
            "answer": "italy",
            "hit": false
          }
        ],
        "set_exclude": [
          "vienna"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8836137652397156
      },
      {
        "question verbose": "What is to warsaw ",
        "b": "warsaw",
        "expected answer": [
          "poland"
        ],
        "predictions": [
          {
            "score": 0.8938691020011902,
            "answer": "poland",
            "hit": true
          },
          {
            "score": 0.8216029405593872,
            "answer": "polish",
            "hit": false
          },
          {
            "score": 0.8093708753585815,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.8034408092498779,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.7952440977096558,
            "answer": "romania",
            "hit": false
          },
          {
            "score": 0.7872655391693115,
            "answer": "poles",
            "hit": false
          }
        ],
        "set_exclude": [
          "warsaw"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8938691020011902
      }
    ],
    "result": {
      "cnt_questions_correct": 25,
      "cnt_questions_total": 28,
      "accuracy": 0.8928571428571429
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E01 [country - capital].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "d53ab62c-7f8c-4530-b6db-8d6bb854e8b1",
      "timestamp": "2025-05-17T17:12:47.164090"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to argentina ",
        "b": "argentina",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8775171041488647,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.8602592349052429,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.8220713138580322,
            "answer": "buenos",
            "hit": false
          },
          {
            "score": 0.8035972118377686,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.8027850389480591,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7871735095977783,
            "answer": "argent",
            "hit": false
          }
        ],
        "set_exclude": [
          "argentina"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8602592945098877
      },
      {
        "question verbose": "What is to australia ",
        "b": "australia",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.8354206085205078,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.829757571220398,
            "answer": "australians",
            "hit": false
          },
          {
            "score": 0.8002159595489502,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.7916924357414246,
            "answer": "sydney",
            "hit": false
          },
          {
            "score": 0.7894738912582397,
            "answer": "melbourne",
            "hit": false
          },
          {
            "score": 0.7850231528282166,
            "answer": "spanish",
            "hit": false
          }
        ],
        "set_exclude": [
          "australia"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8002159595489502
      },
      {
        "question verbose": "What is to austria ",
        "b": "austria",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.8604996204376221,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.8178000450134277,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.800078272819519,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7987233400344849,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.7901551723480225,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7858695983886719,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "austria"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7901551723480225
      },
      {
        "question verbose": "What is to brazil ",
        "b": "brazil",
        "expected answer": [
          "portuguese"
        ],
        "predictions": [
          {
            "score": 0.8797561526298523,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.8538485765457153,
            "answer": "portuguese",
            "hit": true
          },
          {
            "score": 0.8476322293281555,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.8086903691291809,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.794931948184967,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7919673919677734,
            "answer": "arabic",
            "hit": false
          }
        ],
        "set_exclude": [
          "brazil"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8538485467433929
      },
      {
        "question verbose": "What is to canada ",
        "b": "canada",
        "expected answer": [
          "english",
          "french"
        ],
        "predictions": [
          {
            "score": 0.8554848432540894,
            "answer": "canadian",
            "hit": false
          },
          {
            "score": 0.8094249963760376,
            "answer": "canadians",
            "hit": false
          },
          {
            "score": 0.7950523495674133,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7883012890815735,
            "answer": "french",
            "hit": true
          },
          {
            "score": 0.7870489358901978,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7852610945701599,
            "answer": "english",
            "hit": true
          }
        ],
        "set_exclude": [
          "canada"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7852610945701599
      },
      {
        "question verbose": "What is to chile ",
        "b": "chile",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.86720871925354,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.781638503074646,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7777920961380005,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7773959636688232,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7750370502471924,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.774300217628479,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "chile"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8672087788581848
      },
      {
        "question verbose": "What is to colombia ",
        "b": "colombia",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8567774891853333,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.8096456527709961,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7954924702644348,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7728176712989807,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7724618911743164,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7717031240463257,
            "answer": "mexican",
            "hit": false
          }
        ],
        "set_exclude": [
          "colombia"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8567774891853333
      },
      {
        "question verbose": "What is to cuba ",
        "b": "cuba",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8691778779029846,
            "answer": "cuban",
            "hit": false
          },
          {
            "score": 0.8514376878738403,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7931315302848816,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7795464396476746,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7690742611885071,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7647148370742798,
            "answer": "spain",
            "hit": false
          }
        ],
        "set_exclude": [
          "cuba"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8514376878738403
      },
      {
        "question verbose": "What is to cyprus ",
        "b": "cyprus",
        "expected answer": [
          "greek",
          "turkish"
        ],
        "predictions": [
          {
            "score": 0.8187383413314819,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.8027321100234985,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.8025026321411133,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7899389863014221,
            "answer": "turkish",
            "hit": true
          },
          {
            "score": 0.7683956027030945,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7658199071884155,
            "answer": "hebrew",
            "hit": false
          }
        ],
        "set_exclude": [
          "cyprus"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8027321100234985
      },
      {
        "question verbose": "What is to egypt ",
        "b": "egypt",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.9083148241043091,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.841096043586731,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.8089418411254883,
            "answer": "cairo",
            "hit": false
          },
          {
            "score": 0.8059482574462891,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7906636595726013,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.783710241317749,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "egypt"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8410960733890533
      },
      {
        "question verbose": "What is to guatemala ",
        "b": "guatemala",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8399635553359985,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.8027160167694092,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7984945774078369,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7872388362884521,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7698423266410828,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.758135199546814,
            "answer": "hungarian",
            "hit": false
          }
        ],
        "set_exclude": [
          "guatemala"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8399636149406433
      },
      {
        "question verbose": "What is to iran ",
        "b": "iran",
        "expected answer": [
          "persian"
        ],
        "predictions": [
          {
            "score": 0.8952235579490662,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.830136239528656,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.8299948573112488,
            "answer": "persian",
            "hit": true
          },
          {
            "score": 0.8289982080459595,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.7801284790039062,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7771170139312744,
            "answer": "turkish",
            "hit": false
          }
        ],
        "set_exclude": [
          "iran"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8299948573112488
      },
      {
        "question verbose": "What is to iraq ",
        "b": "iraq",
        "expected answer": [
          "arabic",
          "kurdish"
        ],
        "predictions": [
          {
            "score": 0.8674479722976685,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.8383007645606995,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7987476587295532,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.7912893295288086,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7852551937103271,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7766425609588623,
            "answer": "persian",
            "hit": false
          }
        ],
        "set_exclude": [
          "iraq"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8383007645606995
      },
      {
        "question verbose": "What is to israel ",
        "b": "israel",
        "expected answer": [
          "hebrew",
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.853869616985321,
            "answer": "hebrew",
            "hit": true
          },
          {
            "score": 0.8291276693344116,
            "answer": "israeli",
            "hit": false
          },
          {
            "score": 0.8203696608543396,
            "answer": "jewish",
            "hit": false
          },
          {
            "score": 0.8063900470733643,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7972074151039124,
            "answer": "israelis",
            "hit": false
          },
          {
            "score": 0.7944495677947998,
            "answer": "english",
            "hit": false
          }
        ],
        "set_exclude": [
          "israel"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8538695871829987
      },
      {
        "question verbose": "What is to jordan ",
        "b": "jordan",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8000209331512451,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7602795362472534,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7478230595588684,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.7386539578437805,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.7340800762176514,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.733879804611206,
            "answer": "german",
            "hit": false
          }
        ],
        "set_exclude": [
          "jordan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8000208735466003
      },
      {
        "question verbose": "What is to kuwait ",
        "b": "kuwait",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8324152231216431,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.8023127913475037,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7968372702598572,
            "answer": "persian",
            "hit": false
          },
          {
            "score": 0.7744658589363098,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.7706835269927979,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.7699851393699646,
            "answer": "lebanese",
            "hit": false
          }
        ],
        "set_exclude": [
          "kuwait"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8324151933193207
      },
      {
        "question verbose": "What is to palestine ",
        "b": "palestine",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8420295715332031,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.8224573135375977,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.8031841516494751,
            "answer": "palestinian",
            "hit": false
          },
          {
            "score": 0.8004697561264038,
            "answer": "palestinians",
            "hit": false
          },
          {
            "score": 0.7983777523040771,
            "answer": "jewish",
            "hit": false
          },
          {
            "score": 0.7784706354141235,
            "answer": "spanish",
            "hit": false
          }
        ],
        "set_exclude": [
          "palestine"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8420295715332031
      },
      {
        "question verbose": "What is to peru ",
        "b": "peru",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8574153184890747,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.8156472444534302,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7795963287353516,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7712193131446838,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.770961582660675,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7684286236763,
            "answer": "arabic",
            "hit": false
          }
        ],
        "set_exclude": [
          "peru"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8574153780937195
      },
      {
        "question verbose": "What is to switzerland ",
        "b": "switzerland",
        "expected answer": [
          "german",
          "french",
          "italian"
        ],
        "predictions": [
          {
            "score": 0.8675833940505981,
            "answer": "swiss",
            "hit": false
          },
          {
            "score": 0.8181110620498657,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.8021268844604492,
            "answer": "french",
            "hit": true
          },
          {
            "score": 0.7922067046165466,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7881866097450256,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.7773555517196655,
            "answer": "english",
            "hit": false
          }
        ],
        "set_exclude": [
          "switzerland"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7754192650318146
      },
      {
        "question verbose": "What is to syria ",
        "b": "syria",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8625984191894531,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.8450207114219666,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.8070971965789795,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.7964605093002319,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.788141131401062,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7797008156776428,
            "answer": "damascus",
            "hit": false
          }
        ],
        "set_exclude": [
          "syria"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8450207412242889
      },
      {
        "question verbose": "What is to taiwan ",
        "b": "taiwan",
        "expected answer": [
          "chinese"
        ],
        "predictions": [
          {
            "score": 0.8153958916664124,
            "answer": "tai",
            "hit": false
          },
          {
            "score": 0.8072264194488525,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.8061779737472534,
            "answer": "chinese",
            "hit": true
          },
          {
            "score": 0.7963303327560425,
            "answer": "korean",
            "hit": false
          },
          {
            "score": 0.7762548327445984,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.7741612195968628,
            "answer": "arabic",
            "hit": false
          }
        ],
        "set_exclude": [
          "taiwan"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8061780035495758
      },
      {
        "question verbose": "What is to usa ",
        "b": "usa",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.7422153949737549,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7346930503845215,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.7163000106811523,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7162251472473145,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7129828333854675,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7026728391647339,
            "answer": "greek",
            "hit": false
          }
        ],
        "set_exclude": [
          "usa"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7346930652856827
      },
      {
        "question verbose": "What is to venezuela ",
        "b": "venezuela",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8619922399520874,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7964248061180115,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7874531745910645,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7871179580688477,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7834873199462891,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.77939772605896,
            "answer": "mexican",
            "hit": false
          }
        ],
        "set_exclude": [
          "venezuela"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8619922399520874
      }
    ],
    "result": {
      "cnt_questions_correct": 9,
      "cnt_questions_total": 23,
      "accuracy": 0.391304347826087
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E02 [country - language].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "23b29bfa-8929-4645-93a4-9fe65bf781ae",
      "timestamp": "2025-05-17T17:12:47.262759"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bath ",
        "b": "bath",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.8178755044937134,
            "answer": "baths",
            "hit": false
          },
          {
            "score": 0.7914259433746338,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.7569653987884521,
            "answer": "bathing",
            "hit": false
          },
          {
            "score": 0.747687816619873,
            "answer": "bathroom",
            "hit": false
          },
          {
            "score": 0.7386590242385864,
            "answer": "shower",
            "hit": false
          },
          {
            "score": 0.7250858545303345,
            "answer": "toilet",
            "hit": false
          }
        ],
        "set_exclude": [
          "bath"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7157419919967651
      },
      {
        "question verbose": "What is to bradford ",
        "b": "bradford",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8508095741271973,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7763381004333496,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7654881477355957,
            "answer": "brad",
            "hit": false
          },
          {
            "score": 0.759161114692688,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.7583374977111816,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7487624287605286,
            "answer": "essex",
            "hit": false
          }
        ],
        "set_exclude": [
          "bradford"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8508095741271973
      },
      {
        "question verbose": "What is to brighton ",
        "b": "brighton",
        "expected answer": [
          "sussex"
        ],
        "predictions": [
          {
            "score": 0.8558011054992676,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.8104603290557861,
            "answer": "sussex",
            "hit": true
          },
          {
            "score": 0.8044633865356445,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7693407535552979,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.7680612802505493,
            "answer": "essex",
            "hit": false
          },
          {
            "score": 0.7599596977233887,
            "answer": "hampshire",
            "hit": false
          }
        ],
        "set_exclude": [
          "brighton"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8104603290557861
      },
      {
        "question verbose": "What is to hull ",
        "b": "hull",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.7826321125030518,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.730049192905426,
            "answer": "chassis",
            "hit": false
          },
          {
            "score": 0.7202998995780945,
            "answer": "maritime",
            "hit": false
          },
          {
            "score": 0.7165243625640869,
            "answer": "vessel",
            "hit": false
          },
          {
            "score": 0.7101877927780151,
            "answer": "naval",
            "hit": false
          },
          {
            "score": 0.7089296579360962,
            "answer": "torso",
            "hit": false
          }
        ],
        "set_exclude": [
          "hull"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7826321125030518
      },
      {
        "question verbose": "What is to leeds ",
        "b": "leeds",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.896943211555481,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7937317490577698,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7878484129905701,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.7798593044281006,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7776636481285095,
            "answer": "newcastle",
            "hit": false
          },
          {
            "score": 0.7750968933105469,
            "answer": "sheffield",
            "hit": false
          }
        ],
        "set_exclude": [
          "leeds"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.896943211555481
      },
      {
        "question verbose": "What is to plymouth ",
        "b": "plymouth",
        "expected answer": [
          "devon"
        ],
        "predictions": [
          {
            "score": 0.8474372625350952,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.8120420575141907,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7702336311340332,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7672432065010071,
            "answer": "devon",
            "hit": true
          },
          {
            "score": 0.7618458867073059,
            "answer": "cornwall",
            "hit": false
          },
          {
            "score": 0.754213809967041,
            "answer": "hampshire",
            "hit": false
          }
        ],
        "set_exclude": [
          "plymouth"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7672432661056519
      },
      {
        "question verbose": "What is to sheffield ",
        "b": "sheffield",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8711501359939575,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.8082818984985352,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.7889364957809448,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7861995697021484,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.7800950407981873,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.757632851600647,
            "answer": "birmingham",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheffield"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8711501955986023
      },
      {
        "question verbose": "What is to wells ",
        "b": "wells",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.7671005725860596,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.7430893182754517,
            "answer": "groundwater",
            "hit": false
          },
          {
            "score": 0.7399047017097473,
            "answer": "reservoirs",
            "hit": false
          },
          {
            "score": 0.7306695580482483,
            "answer": "somerset",
            "hit": true
          },
          {
            "score": 0.7228968143463135,
            "answer": "earthquakes",
            "hit": false
          },
          {
            "score": 0.722545862197876,
            "answer": "drilling",
            "hit": false
          }
        ],
        "set_exclude": [
          "wells"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7306696027517319
      },
      {
        "question verbose": "What is to york ",
        "b": "york",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8091515302658081,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7734315395355225,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7615355849266052,
            "answer": "yorker",
            "hit": false
          },
          {
            "score": 0.7596617937088013,
            "answer": "washington",
            "hit": false
          },
          {
            "score": 0.7489050626754761,
            "answer": "hampshire",
            "hit": false
          },
          {
            "score": 0.7459035515785217,
            "answer": "sussex",
            "hit": false
          }
        ],
        "set_exclude": [
          "york"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8091515004634857
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 9,
      "accuracy": 0.5555555555555556
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E03 [UK_city - county].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "fc051eb7-1b4d-44a5-a3b0-1f00fcc454b7",
      "timestamp": "2025-05-17T17:12:47.341535"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.8256929516792297,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.802881121635437,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.7951923608779907,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7949076890945435,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7846032381057739,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.7716934084892273,
            "answer": "spanish",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8256929516792297
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "roman"
        ],
        "predictions": [
          {
            "score": 0.7762564420700073,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7750427722930908,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7701060175895691,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7529240846633911,
            "answer": "roman",
            "hit": true
          },
          {
            "score": 0.7442614436149597,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.7396231889724731,
            "answer": "egyptian",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7529240548610687
      },
      {
        "question verbose": "What is to darwin ",
        "b": "darwin",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7749434113502502,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.764611005783081,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.7494993209838867,
            "answer": "dar",
            "hit": false
          },
          {
            "score": 0.7392417192459106,
            "answer": "evolutionary",
            "hit": false
          },
          {
            "score": 0.7382603883743286,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.7374880909919739,
            "answer": "austrian",
            "hit": false
          }
        ],
        "set_exclude": [
          "darwin"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7136448323726654
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7594203948974609,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7489450573921204,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7454776167869568,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7449978590011597,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.7399916648864746,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7372524738311768,
            "answer": "spanish",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7449979037046432
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "jewish",
          "german",
          "american"
        ],
        "predictions": [
          {
            "score": 0.8187321424484253,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.765011727809906,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7600665092468262,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.7544727325439453,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.75421541929245,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7539194822311401,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7470738887786865
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "german",
          "austrian"
        ],
        "predictions": [
          {
            "score": 0.8633883595466614,
            "answer": "nazi",
            "hit": false
          },
          {
            "score": 0.8450451493263245,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.8102789521217346,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.7865368127822876,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.773834764957428,
            "answer": "jewish",
            "hit": false
          },
          {
            "score": 0.770747184753418,
            "answer": "polish",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8450451493263245
      },
      {
        "question verbose": "What is to homer ",
        "b": "homer",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.810789942741394,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7869905233383179,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.7519484758377075,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.7457404732704163,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7451634407043457,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.742622971534729,
            "answer": "turkish",
            "hit": false
          }
        ],
        "set_exclude": [
          "homer"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7869905531406403
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7704253792762756,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7676892280578613,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7617447972297668,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.75194251537323,
            "answer": "irish",
            "hit": false
          },
          {
            "score": 0.751166045665741,
            "answer": "scottish",
            "hit": true
          },
          {
            "score": 0.7492580413818359,
            "answer": "french",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7511660754680634
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7857593894004822,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7667770981788635,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7469587922096252,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7446479797363281,
            "answer": "european",
            "hit": false
          },
          {
            "score": 0.7435858249664307,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.743331789970398,
            "answer": "belgian",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.785759449005127
      },
      {
        "question verbose": "What is to kepler ",
        "b": "kepler",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.764900267124176,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7605468034744263,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.739261269569397,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7388701438903809,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7335361838340759,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.7269991636276245,
            "answer": "european",
            "hit": false
          }
        ],
        "set_exclude": [
          "kepler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.764900267124176
      },
      {
        "question verbose": "What is to lenin ",
        "b": "lenin",
        "expected answer": [
          "soviet",
          "russian"
        ],
        "predictions": [
          {
            "score": 0.8190043568611145,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7944705486297607,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7908920049667358,
            "answer": "russian",
            "hit": true
          },
          {
            "score": 0.779159665107727,
            "answer": "ukrainian",
            "hit": false
          },
          {
            "score": 0.779062032699585,
            "answer": "russia",
            "hit": false
          },
          {
            "score": 0.7760133147239685,
            "answer": "soviet",
            "hit": true
          }
        ],
        "set_exclude": [
          "lenin"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7760133445262909
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7706114053726196,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7521787881851196,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7520895600318909,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.7477647662162781,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.7451539039611816,
            "answer": "nebraska",
            "hit": false
          },
          {
            "score": 0.7342309355735779,
            "answer": "mexican",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7520896196365356
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7494801878929138,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.748170793056488,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7453800439834595,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.74024498462677,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7381824254989624,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.7377910614013672,
            "answer": "swedish",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.730977863073349
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.8343959450721741,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.817801296710968,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7720808982849121,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.7665600776672363,
            "answer": "bourgeois",
            "hit": false
          },
          {
            "score": 0.7660290002822876,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7639463543891907,
            "answer": "british",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8178013563156128
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.752827525138855,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7422451972961426,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7237678170204163,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.7233224511146545,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.7074326276779175,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7069298624992371,
            "answer": "swedish",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6898025721311569
      },
      {
        "question verbose": "What is to newton ",
        "b": "newton",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.766231894493103,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7375116348266602,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.735395610332489,
            "answer": "english",
            "hit": true
          },
          {
            "score": 0.73292475938797,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.7278085947036743,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.7261406779289246,
            "answer": "scottish",
            "hit": false
          }
        ],
        "set_exclude": [
          "newton"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7353955805301666
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.8182252645492554,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.8038695454597473,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7893142700195312,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.7749524712562561,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7696452736854553,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.7672284245491028,
            "answer": "socrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8182252645492554
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7686686515808105,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7555645108222961,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.7413597702980042,
            "answer": "soviet",
            "hit": false
          },
          {
            "score": 0.7413069605827332,
            "answer": "korean",
            "hit": false
          },
          {
            "score": 0.735579252243042,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.7332735657691956,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7555645108222961
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7840647101402283,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7459127902984619,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.7366984486579895,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7364519834518433,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.7361695170402527,
            "answer": "welsh",
            "hit": false
          },
          {
            "score": 0.7350913286209106,
            "answer": "polish",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7840647399425507
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 19,
      "accuracy": 0.3684210526315789
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E04 [name - nationality].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "6de99bfe-b56c-49ea-877b-8d8593dbe839",
      "timestamp": "2025-05-17T17:12:47.370745"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8665320873260498,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.8210748434066772,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.8068364858627319,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.8057167530059814,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7853513360023499,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.7850404977798462,
            "answer": "poet",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8665320873260498
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "emperor",
          "commander",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.7884924411773682,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7634857892990112,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.7368558645248413,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7356411814689636,
            "answer": "ruler",
            "hit": false
          },
          {
            "score": 0.7333997488021851,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7263786792755127,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7247400879859924
      },
      {
        "question verbose": "What is to columbus ",
        "b": "columbus",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.7700731754302979,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7399817109107971,
            "answer": "indianapolis",
            "hit": false
          },
          {
            "score": 0.738294780254364,
            "answer": "cincinnati",
            "hit": false
          },
          {
            "score": 0.7328343391418457,
            "answer": "cleveland",
            "hit": false
          },
          {
            "score": 0.7308428287506104,
            "answer": "founder",
            "hit": false
          },
          {
            "score": 0.7306479215621948,
            "answer": "philadelphia",
            "hit": false
          }
        ],
        "set_exclude": [
          "columbus"
        ],
        "rank": 1984,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6428651809692383
      },
      {
        "question verbose": "What is to dante ",
        "b": "dante",
        "expected answer": [
          "poet"
        ],
        "predictions": [
          {
            "score": 0.7929753661155701,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7778363227844238,
            "answer": "poet",
            "hit": true
          },
          {
            "score": 0.7550428509712219,
            "answer": "composer",
            "hit": false
          },
          {
            "score": 0.7541408538818359,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.7520768046379089,
            "answer": "rapper",
            "hit": false
          },
          {
            "score": 0.751969039440155,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "dante"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7778363823890686
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "inventor",
          "businessman"
        ],
        "predictions": [
          {
            "score": 0.7719939351081848,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7682577967643738,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7529764175415039,
            "answer": "inventor",
            "hit": true
          },
          {
            "score": 0.7413967847824097,
            "answer": "entrepreneur",
            "hit": false
          },
          {
            "score": 0.7388959527015686,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7330406308174133,
            "answer": "scientist",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7529764175415039
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.8466675877571106,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.8268433213233948,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7941677570343018,
            "answer": "scientist",
            "hit": true
          },
          {
            "score": 0.77231365442276,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7701753377914429,
            "answer": "inventor",
            "hit": false
          },
          {
            "score": 0.7583413124084473,
            "answer": "psychologist",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.846667617559433
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "dictator",
          "politician",
          "nazi"
        ],
        "predictions": [
          {
            "score": 0.8509098887443542,
            "answer": "nazi",
            "hit": true
          },
          {
            "score": 0.8010262250900269,
            "answer": "dictator",
            "hit": true
          },
          {
            "score": 0.7926256656646729,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.773931622505188,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.7704596519470215,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7699140310287476,
            "answer": "stalin",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8010262846946716
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "philosopher",
          "politician"
        ],
        "predictions": [
          {
            "score": 0.8203235864639282,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7715998291969299,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7690609097480774,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7555421590805054,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.7499270439147949,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.7473694682121277,
            "answer": "journalist",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8203235268592834
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8104021549224854,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7714942693710327,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7669413685798645,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7541868090629578,
            "answer": "psychologist",
            "hit": false
          },
          {
            "score": 0.7519068717956543,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7469519972801208,
            "answer": "scientist",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8104021847248077
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.7801211476325989,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7493415474891663,
            "answer": "nebraska",
            "hit": false
          },
          {
            "score": 0.7475854754447937,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7456928491592407,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.7389048933982849,
            "answer": "president",
            "hit": true
          },
          {
            "score": 0.7301852703094482,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7389048933982849
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7891325950622559,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7571307420730591,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7420397996902466,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7418513298034668,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.730626106262207,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7304168939590454,
            "answer": "novelist",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7891325652599335
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "philosopher",
          "communist"
        ],
        "predictions": [
          {
            "score": 0.8536830544471741,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.8042170405387878,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7802759408950806,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.779132604598999,
            "answer": "lenin",
            "hit": false
          },
          {
            "score": 0.7770174741744995,
            "answer": "communist",
            "hit": true
          },
          {
            "score": 0.7722364664077759,
            "answer": "socialist",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8042170405387878
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.7685247659683228,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7479619979858398,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.7153339385986328,
            "answer": "kepler",
            "hit": false
          },
          {
            "score": 0.7116062045097351,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.709284782409668,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7081176042556763,
            "answer": "inventor",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7479619979858398
      },
      {
        "question verbose": "What is to moses ",
        "b": "moses",
        "expected answer": [
          "prophet",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.7883367538452148,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.773036003112793,
            "answer": "prophet",
            "hit": true
          },
          {
            "score": 0.7648065090179443,
            "answer": "rabbi",
            "hit": false
          },
          {
            "score": 0.7591561079025269,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7554522752761841,
            "answer": "prophets",
            "hit": false
          },
          {
            "score": 0.7488327026367188,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "moses"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.773036003112793
      },
      {
        "question verbose": "What is to napoleon ",
        "b": "napoleon",
        "expected answer": [
          "emperor",
          "leader",
          "politician",
          "commander"
        ],
        "predictions": [
          {
            "score": 0.8079593181610107,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7699885964393616,
            "answer": "emperor",
            "hit": true
          },
          {
            "score": 0.7675303220748901,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.7595330476760864,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7593995332717896,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.7511390447616577,
            "answer": "poet",
            "hit": false
          }
        ],
        "set_exclude": [
          "napoleon"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7699885666370392
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8680109977722168,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.8227594494819641,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.8163143396377563,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.7873905301094055,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7828761339187622,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7767043709754944,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8680109977722168
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.7890372276306152,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7619668245315552,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.7587510347366333,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.7568756341934204,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7477174997329712,
            "answer": "president",
            "hit": true
          },
          {
            "score": 0.7443755269050598,
            "answer": "prophet",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7477174699306488
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.7746239900588989,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7586262822151184,
            "answer": "composer",
            "hit": true
          },
          {
            "score": 0.7496626973152161,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7448152303695679,
            "answer": "musician",
            "hit": false
          },
          {
            "score": 0.7339698076248169,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.7297755479812622,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7586262822151184
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 18,
      "accuracy": 0.3888888888888889
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E05 [name - occupation].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "f0ba836b-98f0-4457-887c-4c712da839c8",
      "timestamp": "2025-05-17T17:12:47.433939"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "baby",
          "infant"
        ],
        "predictions": [
          {
            "score": 0.7630387544631958,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7318981885910034,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.708266019821167,
            "answer": "negro",
            "hit": false
          },
          {
            "score": 0.703079104423523,
            "answer": "infant",
            "hit": true
          },
          {
            "score": 0.7025679349899292,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.7005001306533813,
            "answer": "cuban",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6536329090595245
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.7306506037712097,
            "answer": "borne",
            "hit": false
          },
          {
            "score": 0.7281836271286011,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.7074540257453918,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.7049511075019836,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7014613151550293,
            "answer": "endure",
            "hit": false
          },
          {
            "score": 0.6892075538635254,
            "answer": "baby",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7281835824251175
      },
      {
        "question verbose": "What is to buffalo ",
        "b": "buffalo",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7614275813102722,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7477420568466187,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.7288378477096558,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.7163769006729126,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7149502038955688,
            "answer": "cubs",
            "hit": false
          },
          {
            "score": 0.7098334431648254,
            "answer": "turkey",
            "hit": false
          }
        ],
        "set_exclude": [
          "buffalo"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.747742086648941
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.8333064317703247,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7604357004165649,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.7544339895248413,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7517635822296143,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.7287671566009521,
            "answer": "infants",
            "hit": false
          },
          {
            "score": 0.7112764716148376,
            "answer": "calves",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7517635822296143
      },
      {
        "question verbose": "What is to goat ",
        "b": "goat",
        "expected answer": [
          "kid"
        ],
        "predictions": [
          {
            "score": 0.7735598087310791,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7584724426269531,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7326514720916748,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7084598541259766,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.6960957050323486,
            "answer": "pumpkin",
            "hit": false
          },
          {
            "score": 0.6934731602668762,
            "answer": "rabbit",
            "hit": false
          }
        ],
        "set_exclude": [
          "goat"
        ],
        "rank": 197,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6588956713676453
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.7564773559570312,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7203546762466431,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.7147282958030701,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.7118528485298157,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.708231508731842,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.7039880752563477,
            "answer": "newborn",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7203546762466431
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "infant"
        ],
        "predictions": [
          {
            "score": 0.8336573243141174,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7464253902435303,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.7415062785148621,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7194953560829163,
            "answer": "babies",
            "hit": false
          },
          {
            "score": 0.7078104019165039,
            "answer": "cuban",
            "hit": false
          },
          {
            "score": 0.7056933045387268,
            "answer": "puppy",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 89,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6703997105360031
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "pup"
        ],
        "predictions": [
          {
            "score": 0.7520011067390442,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6980577707290649,
            "answer": "detainees",
            "hit": false
          },
          {
            "score": 0.6970201730728149,
            "answer": "sailors",
            "hit": false
          },
          {
            "score": 0.6935960650444031,
            "answer": "sealing",
            "hit": false
          },
          {
            "score": 0.6921077370643616,
            "answer": "pentagon",
            "hit": false
          },
          {
            "score": 0.6902225613594055,
            "answer": "cuban",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 330,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6560455411672592
      },
      {
        "question verbose": "What is to shark ",
        "b": "shark",
        "expected answer": [
          "cub",
          "pup"
        ],
        "predictions": [
          {
            "score": 0.770811915397644,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.7545978426933289,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.7382519245147705,
            "answer": "seafood",
            "hit": false
          },
          {
            "score": 0.7343062162399292,
            "answer": "fins",
            "hit": false
          },
          {
            "score": 0.7281500697135925,
            "answer": "swimming",
            "hit": false
          },
          {
            "score": 0.726759135723114,
            "answer": "shrimp",
            "hit": false
          }
        ],
        "set_exclude": [
          "shark"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7200273722410202
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.8436083793640137,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.7714085578918457,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.755042552947998,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.7310131788253784,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.7300864458084106,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.7298807501792908,
            "answer": "bengal",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7550425231456757
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7726846933364868,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7548457384109497,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6994866132736206,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.6957951784133911,
            "answer": "wave",
            "hit": false
          },
          {
            "score": 0.6955715417861938,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.6946668028831482,
            "answer": "sperm",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6994865834712982
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 11,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E06 [animal - young].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "e0910bcd-6abd-4c89-a0b2-28d246dc5f73",
      "timestamp": "2025-05-17T17:12:47.496924"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bee ",
        "b": "bee",
        "expected answer": [
          "buzz",
          "hum"
        ],
        "predictions": [
          {
            "score": 0.7313653230667114,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.7288593053817749,
            "answer": "buzz",
            "hit": true
          },
          {
            "score": 0.7120000123977661,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.7060438990592957,
            "answer": "bees",
            "hit": false
          },
          {
            "score": 0.6813876628875732,
            "answer": "sings",
            "hit": false
          },
          {
            "score": 0.6783691644668579,
            "answer": "singing",
            "hit": false
          }
        ],
        "set_exclude": [
          "bee"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7288592755794525
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "buzz"
        ],
        "predictions": [
          {
            "score": 0.7372168302536011,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.7356005311012268,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.7175541520118713,
            "answer": "buzz",
            "hit": true
          },
          {
            "score": 0.7027120590209961,
            "answer": "flying",
            "hit": false
          },
          {
            "score": 0.6993410587310791,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.6979120969772339,
            "answer": "danced",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7175541818141937
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "bark"
        ],
        "predictions": [
          {
            "score": 0.7636264562606812,
            "answer": "buzz",
            "hit": false
          },
          {
            "score": 0.6954741477966309,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.6815661191940308,
            "answer": "generals",
            "hit": false
          },
          {
            "score": 0.6815567016601562,
            "answer": "infantry",
            "hit": false
          },
          {
            "score": 0.6795201897621155,
            "answer": "sailors",
            "hit": false
          },
          {
            "score": 0.6783102750778198,
            "answer": "rolling",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 4868,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6141583323478699
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sing"
        ],
        "predictions": [
          {
            "score": 0.801950991153717,
            "answer": "buzz",
            "hit": false
          },
          {
            "score": 0.7609026432037354,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.6916160583496094,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.6827328205108643,
            "answer": "beast",
            "hit": false
          },
          {
            "score": 0.6803799867630005,
            "answer": "harbour",
            "hit": false
          },
          {
            "score": 0.6786564588546753,
            "answer": "shark",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 13349,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5752970427274704
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E07 [animal - sound].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "229a6e40-5cba-4078-832f-2bfbba8e071a",
      "timestamp": "2025-05-17T17:12:47.532457"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "grove",
          "tree",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7510926127433777,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.726980447769165,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7167942523956299,
            "answer": "cave",
            "hit": false
          },
          {
            "score": 0.707690954208374,
            "answer": "ancient",
            "hit": false
          },
          {
            "score": 0.7038542032241821,
            "answer": "evolutionary",
            "hit": false
          },
          {
            "score": 0.7020112872123718,
            "answer": "pagan",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 55,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6762919872999191
      },
      {
        "question verbose": "What is to bat ",
        "b": "bat",
        "expected answer": [
          "cave",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7750328183174133,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7299517393112183,
            "answer": "bed",
            "hit": false
          },
          {
            "score": 0.7203642129898071,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7063620090484619,
            "answer": "batman",
            "hit": false
          },
          {
            "score": 0.7042914032936096,
            "answer": "hen",
            "hit": false
          },
          {
            "score": 0.7030117511749268,
            "answer": "bathing",
            "hit": false
          }
        ],
        "set_exclude": [
          "bat"
        ],
        "rank": 1555,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6351992636919022
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7357227802276611,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7232822179794312,
            "answer": "borne",
            "hit": false
          },
          {
            "score": 0.6994946002960205,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.6924147605895996,
            "answer": "endure",
            "hit": false
          },
          {
            "score": 0.6903925538063049,
            "answer": "den",
            "hit": true
          },
          {
            "score": 0.6765748262405396,
            "answer": "suffer",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6903925240039825
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "barn",
          "coral"
        ],
        "predictions": [
          {
            "score": 0.8456034660339355,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.8061153888702393,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7817583680152893,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7778337001800537,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7479304671287537,
            "answer": "dairy",
            "hit": false
          },
          {
            "score": 0.7460287809371948,
            "answer": "grazing",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 1836,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.64438596367836
      },
      {
        "question verbose": "What is to cricket ",
        "b": "cricket",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.775519609451294,
            "answer": "rugby",
            "hit": false
          },
          {
            "score": 0.7615700960159302,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7470489740371704,
            "answer": "soccer",
            "hit": false
          },
          {
            "score": 0.7459404468536377,
            "answer": "bowling",
            "hit": false
          },
          {
            "score": 0.7420772314071655,
            "answer": "football",
            "hit": false
          },
          {
            "score": 0.733439564704895,
            "answer": "hockey",
            "hit": false
          }
        ],
        "set_exclude": [
          "cricket"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7615701258182526
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7567326426506042,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7127228379249573,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7037196159362793,
            "answer": "exclaimed",
            "hit": false
          },
          {
            "score": 0.6889441609382629,
            "answer": "sighed",
            "hit": false
          },
          {
            "score": 0.6882065534591675,
            "answer": "chuckled",
            "hit": false
          },
          {
            "score": 0.6872905492782593,
            "answer": "nests",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7567325830459595
      },
      {
        "question verbose": "What is to duck ",
        "b": "duck",
        "expected answer": [
          "pond",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.8216736316680908,
            "answer": "ducks",
            "hit": false
          },
          {
            "score": 0.76693195104599,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7258625030517578,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7069860100746155,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.6938803791999817,
            "answer": "nesting",
            "hit": false
          },
          {
            "score": 0.6906182169914246,
            "answer": "egg",
            "hit": false
          }
        ],
        "set_exclude": [
          "duck"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6741233468055725
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7438935041427612,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.733250617980957,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7223653197288513,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.7142054438591003,
            "answer": "flies",
            "hit": false
          },
          {
            "score": 0.7124959826469421,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.7018928527832031,
            "answer": "stay",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7332506030797958
      },
      {
        "question verbose": "What is to fox ",
        "b": "fox",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7619652152061462,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7545058727264404,
            "answer": "cbs",
            "hit": false
          },
          {
            "score": 0.754004955291748,
            "answer": "nbc",
            "hit": false
          },
          {
            "score": 0.7128172516822815,
            "answer": "espn",
            "hit": false
          },
          {
            "score": 0.7040509581565857,
            "answer": "abc",
            "hit": false
          },
          {
            "score": 0.6977806091308594,
            "answer": "nike",
            "hit": false
          }
        ],
        "set_exclude": [
          "fox"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6946673095226288
      },
      {
        "question verbose": "What is to insect ",
        "b": "insect",
        "expected answer": [
          "nest",
          "cage",
          "box"
        ],
        "predictions": [
          {
            "score": 0.7920113205909729,
            "answer": "insects",
            "hit": false
          },
          {
            "score": 0.7911529541015625,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7121015191078186,
            "answer": "larvae",
            "hit": false
          },
          {
            "score": 0.709644079208374,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7091749906539917,
            "answer": "nests",
            "hit": false
          },
          {
            "score": 0.7086741924285889,
            "answer": "birds",
            "hit": false
          }
        ],
        "set_exclude": [
          "insect"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7911530137062073
      },
      {
        "question verbose": "What is to mole ",
        "b": "mole",
        "expected answer": [
          "hole",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7729960680007935,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6991132497787476,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6972466707229614,
            "answer": "hole",
            "hit": true
          },
          {
            "score": 0.6908172369003296,
            "answer": "molecules",
            "hit": false
          },
          {
            "score": 0.6906609535217285,
            "answer": "molecule",
            "hit": false
          },
          {
            "score": 0.6885813474655151,
            "answer": "mic",
            "hit": false
          }
        ],
        "set_exclude": [
          "mole"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.697246640920639
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "tree",
          "grove",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8423528671264648,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7709444761276245,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7238821983337402,
            "answer": "monastery",
            "hit": false
          },
          {
            "score": 0.7203364372253418,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7093932032585144,
            "answer": "monks",
            "hit": false
          },
          {
            "score": 0.7019640803337097,
            "answer": "banana",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 43,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6584448516368866
      },
      {
        "question verbose": "What is to mouse ",
        "b": "mouse",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7596812844276428,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7421227097511292,
            "answer": "mice",
            "hit": false
          },
          {
            "score": 0.7362500429153442,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7279532551765442,
            "answer": "menu",
            "hit": false
          },
          {
            "score": 0.7209154367446899,
            "answer": "keys",
            "hit": false
          },
          {
            "score": 0.7153765559196472,
            "answer": "mic",
            "hit": false
          }
        ],
        "set_exclude": [
          "mouse"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7596812844276428
      },
      {
        "question verbose": "What is to rat ",
        "b": "rat",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7458393573760986,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7119762897491455,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7023711800575256,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.6871560215950012,
            "answer": "ass",
            "hit": false
          },
          {
            "score": 0.6758313179016113,
            "answer": "rats",
            "hit": false
          },
          {
            "score": 0.6727232933044434,
            "answer": "sewer",
            "hit": false
          }
        ],
        "set_exclude": [
          "rat"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.745839312672615
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7762553095817566,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7150102853775024,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.7145302295684814,
            "answer": "starving",
            "hit": false
          },
          {
            "score": 0.7127354145050049,
            "answer": "thirst",
            "hit": false
          },
          {
            "score": 0.7121602296829224,
            "answer": "longing",
            "hit": false
          },
          {
            "score": 0.7118526101112366,
            "answer": "cavern",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7762552797794342
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8547333478927612,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.7921334505081177,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7324355840682983,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.730705738067627,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.7301121950149536,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.7228176593780518,
            "answer": "elephants",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 79,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6747223138809204
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sea",
          "sanctuary"
        ],
        "predictions": [
          {
            "score": 0.7755569219589233,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7650404572486877,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7128146886825562,
            "answer": "hole",
            "hit": false
          },
          {
            "score": 0.7027931213378906,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6959406137466431,
            "answer": "bottle",
            "hit": false
          },
          {
            "score": 0.6928600668907166,
            "answer": "glen",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.688443511724472
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7611639499664307,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.7407892942428589,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.6847333312034607,
            "answer": "tower",
            "hit": false
          },
          {
            "score": 0.6840648651123047,
            "answer": "den",
            "hit": true
          },
          {
            "score": 0.6793923377990723,
            "answer": "lords",
            "hit": false
          },
          {
            "score": 0.6779578924179077,
            "answer": "lars",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6840648353099823
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 18,
      "accuracy": 0.2777777777777778
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E08 [animal - shelter].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "b42c5066-30fb-4318-9842-462cb907ed1c",
      "timestamp": "2025-05-17T17:12:47.553402"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ant ",
        "b": "ant",
        "expected answer": [
          "black",
          "brown",
          "red"
        ],
        "predictions": [
          {
            "score": 0.7913299798965454,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7413088083267212,
            "answer": "anton",
            "hit": false
          },
          {
            "score": 0.7408119440078735,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7306619882583618,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7279307842254639,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7175385355949402,
            "answer": "red",
            "hit": true
          }
        ],
        "set_exclude": [
          "ant"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7408119291067123
      },
      {
        "question verbose": "What is to apple ",
        "b": "apple",
        "expected answer": [
          "red",
          "orange",
          "yellow",
          "golden"
        ],
        "predictions": [
          {
            "score": 0.813413143157959,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7578282356262207,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7528333067893982,
            "answer": "iphone",
            "hit": false
          },
          {
            "score": 0.7488911151885986,
            "answer": "pink",
            "hit": false
          },
          {
            "score": 0.7463146448135376,
            "answer": "ios",
            "hit": false
          },
          {
            "score": 0.7412047386169434,
            "answer": "google",
            "hit": false
          }
        ],
        "set_exclude": [
          "apple"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7019679397344589
      },
      {
        "question verbose": "What is to blood ",
        "b": "blood",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.789320170879364,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7633233666419983,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7546255588531494,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.739603579044342,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7147186994552612,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7085932493209839,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "blood"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7546255886554718
      },
      {
        "question verbose": "What is to cabbage ",
        "b": "cabbage",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.7715867757797241,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7706977128982544,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7578641176223755,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.7561321258544922,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.7558289766311646,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.7512686252593994,
            "answer": "vegetables",
            "hit": false
          }
        ],
        "set_exclude": [
          "cabbage"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7558289468288422
      },
      {
        "question verbose": "What is to carrot ",
        "b": "carrot",
        "expected answer": [
          "orange",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7630895376205444,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7602398991584778,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7589683532714844,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.7492252588272095,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.748257577419281,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7429673075675964,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "carrot"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6662457883358002
      },
      {
        "question verbose": "What is to cherry ",
        "b": "cherry",
        "expected answer": [
          "red",
          "yellow",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7749185562133789,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7717599868774414,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7483224272727966,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7307785153388977,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7153587341308594,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.7148072719573975,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "cherry"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7307785153388977
      },
      {
        "question verbose": "What is to chocolate ",
        "b": "chocolate",
        "expected answer": [
          "white",
          "brown",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7880507111549377,
            "answer": "brown",
            "hit": true
          },
          {
            "score": 0.78667813539505,
            "answer": "cocoa",
            "hit": false
          },
          {
            "score": 0.771364688873291,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7640508413314819,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7636712789535522,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7543282508850098,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "chocolate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7713646590709686
      },
      {
        "question verbose": "What is to cloud ",
        "b": "cloud",
        "expected answer": [
          "white",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7800652980804443,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7552378177642822,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7492175102233887,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7405589818954468,
            "answer": "clouds",
            "hit": false
          },
          {
            "score": 0.7168654203414917,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7084333896636963,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloud"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.780065268278122
      },
      {
        "question verbose": "What is to coal ",
        "b": "coal",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7763350605964661,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7658275961875916,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7453852295875549,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7380400896072388,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7332429885864258,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.724374532699585,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "coal"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7658275961875916
      },
      {
        "question verbose": "What is to coffee ",
        "b": "coffee",
        "expected answer": [
          "black",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7692508101463318,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.754884660243988,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7429181933403015,
            "answer": "brown",
            "hit": true
          },
          {
            "score": 0.7388566136360168,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7338772416114807,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7292529344558716,
            "answer": "cafe",
            "hit": false
          }
        ],
        "set_exclude": [
          "coffee"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.754884660243988
      },
      {
        "question verbose": "What is to cream ",
        "b": "cream",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7827947735786438,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7602354288101196,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7433593273162842,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.7421377897262573,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7345053553581238,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7324565649032593,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "cream"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7827947735786438
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.762599527835846,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7553285360336304,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7319251298904419,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.7310730218887329,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7185269594192505,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7084982395172119,
            "answer": "gray",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7553285360336304
      },
      {
        "question verbose": "What is to fridge ",
        "b": "fridge",
        "expected answer": [
          "white",
          "silver",
          "black"
        ],
        "predictions": [
          {
            "score": 0.8673776388168335,
            "answer": "refrigerator",
            "hit": false
          },
          {
            "score": 0.7546602487564087,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7509981393814087,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7418591976165771,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.7369091510772705,
            "answer": "closet",
            "hit": false
          },
          {
            "score": 0.7308517694473267,
            "answer": "bathroom",
            "hit": false
          }
        ],
        "set_exclude": [
          "fridge"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7546601891517639
      },
      {
        "question verbose": "What is to frog ",
        "b": "frog",
        "expected answer": [
          "green",
          "brown",
          "grey",
          "gray"
        ],
        "predictions": [
          {
            "score": 0.7779715061187744,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7539122104644775,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7225641012191772,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.72147536277771,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7095305323600769,
            "answer": "brown",
            "hit": true
          },
          {
            "score": 0.7007743716239929,
            "answer": "gold",
            "hit": false
          }
        ],
        "set_exclude": [
          "frog"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6966934651136398
      },
      {
        "question verbose": "What is to grapes ",
        "b": "grapes",
        "expected answer": [
          "black",
          "red",
          "green",
          "purple"
        ],
        "predictions": [
          {
            "score": 0.767679750919342,
            "answer": "wines",
            "hit": false
          },
          {
            "score": 0.7648018598556519,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7536336779594421,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7518879175186157,
            "answer": "wine",
            "hit": false
          },
          {
            "score": 0.7517427206039429,
            "answer": "purple",
            "hit": true
          },
          {
            "score": 0.7480862140655518,
            "answer": "black",
            "hit": true
          }
        ],
        "set_exclude": [
          "grapes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7480861991643906
      },
      {
        "question verbose": "What is to grass ",
        "b": "grass",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.7824395298957825,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7540944218635559,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7439348101615906,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.7273428440093994,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7193641066551208,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7185270190238953,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "grass"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7439347952604294
      },
      {
        "question verbose": "What is to leaves ",
        "b": "leaves",
        "expected answer": [
          "green",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7875849008560181,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7613250017166138,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7344272136688232,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7292114496231079,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.723902702331543,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.7223786115646362,
            "answer": "leaf",
            "hit": false
          }
        ],
        "set_exclude": [
          "leaves"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7239026725292206
      },
      {
        "question verbose": "What is to milk ",
        "b": "milk",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7729073762893677,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7718881368637085,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7408488392829895,
            "answer": "mil",
            "hit": false
          },
          {
            "score": 0.7329069972038269,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.7300920486450195,
            "answer": "pink",
            "hit": false
          },
          {
            "score": 0.7178308963775635,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "milk"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7729073464870453
      },
      {
        "question verbose": "What is to paper ",
        "b": "paper",
        "expected answer": [
          "white",
          "color"
        ],
        "predictions": [
          {
            "score": 0.782478928565979,
            "answer": "papers",
            "hit": false
          },
          {
            "score": 0.7548485994338989,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7439719438552856,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7126356363296509,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7012814283370972,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.6985092163085938,
            "answer": "yellow",
            "hit": false
          }
        ],
        "set_exclude": [
          "paper"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7439718991518021
      },
      {
        "question verbose": "What is to pepper ",
        "b": "pepper",
        "expected answer": [
          "black",
          "red",
          "green",
          "yellow",
          "orange"
        ],
        "predictions": [
          {
            "score": 0.7754220962524414,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7569893002510071,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7292576432228088,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.7255189418792725,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7222365140914917,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7214653491973877,
            "answer": "peppers",
            "hit": false
          }
        ],
        "set_exclude": [
          "pepper"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7569893002510071
      },
      {
        "question verbose": "What is to potato ",
        "b": "potato",
        "expected answer": [
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7768933176994324,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7605670690536499,
            "answer": "potatoes",
            "hit": false
          },
          {
            "score": 0.7516497373580933,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7505680322647095,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.731791615486145,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.7293705940246582,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "potato"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7208641767501831
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7710897922515869,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7636979222297668,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7601845264434814,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.7493553161621094,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7467296719551086,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.7330987453460693,
            "answer": "grey",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7636979222297668
      },
      {
        "question verbose": "What is to rose ",
        "b": "rose",
        "expected answer": [
          "red",
          "yellow",
          "pink",
          "white",
          "blue"
        ],
        "predictions": [
          {
            "score": 0.7549875378608704,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7529588937759399,
            "answer": "risen",
            "hit": false
          },
          {
            "score": 0.7519339323043823,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7503117322921753,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7432766556739807,
            "answer": "rises",
            "hit": false
          },
          {
            "score": 0.7358137369155884,
            "answer": "grew",
            "hit": false
          }
        ],
        "set_exclude": [
          "rose"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7519339323043823
      },
      {
        "question verbose": "What is to ruby ",
        "b": "ruby",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7668434381484985,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7624351978302002,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7328461408615112,
            "answer": "weiss",
            "hit": false
          },
          {
            "score": 0.7292578220367432,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7214668989181519,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7172638773918152,
            "answer": "yang",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruby"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7292578667402267
      },
      {
        "question verbose": "What is to salt ",
        "b": "salt",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7576858997344971,
            "answer": "utah",
            "hit": false
          },
          {
            "score": 0.7550933361053467,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7472128868103027,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7449694871902466,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7232931852340698,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7147911190986633,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "salt"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7550933361053467
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "blue",
          "green",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7634536027908325,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7455753684043884,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.7391422986984253,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.737369954586029,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7216306924819946,
            "answer": "ocean",
            "hit": false
          },
          {
            "score": 0.708046019077301,
            "answer": "green",
            "hit": true
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7391422688961029
      },
      {
        "question verbose": "What is to sky ",
        "b": "sky",
        "expected answer": [
          "blue",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7921936511993408,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7542901039123535,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.738752007484436,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7136093378067017,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7130155563354492,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7102166414260864,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "sky"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7542900741100311
      },
      {
        "question verbose": "What is to snow ",
        "b": "snow",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7755724191665649,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.759087085723877,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7403024435043335,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.728542685508728,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7229425311088562,
            "answer": "grey",
            "hit": false
          },
          {
            "score": 0.7224085330963135,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "snow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7755724787712097
      },
      {
        "question verbose": "What is to soil ",
        "b": "soil",
        "expected answer": [
          "black",
          "brown",
          "dark"
        ],
        "predictions": [
          {
            "score": 0.8095171451568604,
            "answer": "soils",
            "hit": false
          },
          {
            "score": 0.7617635726928711,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7394570112228394,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7377442121505737,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7275848388671875,
            "answer": "brown",
            "hit": true
          },
          {
            "score": 0.7207056879997253,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "soil"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7377441823482513
      },
      {
        "question verbose": "What is to sugar ",
        "b": "sugar",
        "expected answer": [
          "white",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7635669708251953,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7605711221694946,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7589493989944458,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7412731647491455,
            "answer": "glucose",
            "hit": false
          },
          {
            "score": 0.7407947778701782,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7301178574562073,
            "answer": "brown",
            "hit": true
          }
        ],
        "set_exclude": [
          "sugar"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7605710625648499
      },
      {
        "question verbose": "What is to sun ",
        "b": "sun",
        "expected answer": [
          "yellow",
          "gold"
        ],
        "predictions": [
          {
            "score": 0.758497416973114,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7452480792999268,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7232998609542847,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7184853553771973,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.7166445255279541,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7136809825897217,
            "answer": "sunset",
            "hit": false
          }
        ],
        "set_exclude": [
          "sun"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7184853553771973
      },
      {
        "question verbose": "What is to swan ",
        "b": "swan",
        "expected answer": [
          "white",
          "black",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7668120861053467,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7483465075492859,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.7298985719680786,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7148182392120361,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.7117773294448853,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7106509208679199,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "swan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7668120861053467
      },
      {
        "question verbose": "What is to tea ",
        "b": "tea",
        "expected answer": [
          "black",
          "green",
          "white",
          "red",
          "brown",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.8118659257888794,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7570173740386963,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7469778060913086,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.7379700541496277,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.730470597743988,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.723413348197937,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "tea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7379700690507889
      },
      {
        "question verbose": "What is to tomato ",
        "b": "tomato",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.8474987745285034,
            "answer": "tomatoes",
            "hit": false
          },
          {
            "score": 0.7784390449523926,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7727735638618469,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.766719400882721,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7610594630241394,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7554631233215332,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "tomato"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7784390449523926
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 34,
      "accuracy": 0.20588235294117646
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E09 [things - color].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "5621d18c-e10b-49ed-b5e8-2381a78e8649",
      "timestamp": "2025-05-17T17:12:47.616099"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to actor ",
        "b": "actor",
        "expected answer": [
          "actress"
        ],
        "predictions": [
          {
            "score": 0.7624269723892212,
            "answer": "actress",
            "hit": true
          },
          {
            "score": 0.7372299432754517,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.7121497392654419,
            "answer": "actors",
            "hit": false
          },
          {
            "score": 0.7087096571922302,
            "answer": "actions",
            "hit": false
          },
          {
            "score": 0.6999136209487915,
            "answer": "reactor",
            "hit": false
          },
          {
            "score": 0.6974406242370605,
            "answer": "sister",
            "hit": false
          }
        ],
        "set_exclude": [
          "actor"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7624270021915436
      },
      {
        "question verbose": "What is to boy ",
        "b": "boy",
        "expected answer": [
          "girl"
        ],
        "predictions": [
          {
            "score": 0.7869089841842651,
            "answer": "boys",
            "hit": false
          },
          {
            "score": 0.7681294679641724,
            "answer": "girl",
            "hit": true
          },
          {
            "score": 0.7510669231414795,
            "answer": "woman",
            "hit": false
          },
          {
            "score": 0.7360997200012207,
            "answer": "girls",
            "hit": false
          },
          {
            "score": 0.7320884466171265,
            "answer": "sister",
            "hit": false
          },
          {
            "score": 0.7146515250205994,
            "answer": "wife",
            "hit": false
          }
        ],
        "set_exclude": [
          "boy"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7681294083595276
      },
      {
        "question verbose": "What is to brother ",
        "b": "brother",
        "expected answer": [
          "sister"
        ],
        "predictions": [
          {
            "score": 0.8370387554168701,
            "answer": "sisters",
            "hit": false
          },
          {
            "score": 0.8283015489578247,
            "answer": "sibling",
            "hit": false
          },
          {
            "score": 0.8155006170272827,
            "answer": "sister",
            "hit": true
          },
          {
            "score": 0.811772882938385,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.8009145259857178,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.8001759052276611,
            "answer": "siblings",
            "hit": false
          }
        ],
        "set_exclude": [
          "brother"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8155006170272827
      },
      {
        "question verbose": "What is to buck ",
        "b": "buck",
        "expected answer": [
          "doe"
        ],
        "predictions": [
          {
            "score": 0.74045729637146,
            "answer": "bucket",
            "hit": false
          },
          {
            "score": 0.6982810497283936,
            "answer": "bucks",
            "hit": false
          },
          {
            "score": 0.6981633901596069,
            "answer": "becca",
            "hit": false
          },
          {
            "score": 0.6974026560783386,
            "answer": "peggy",
            "hit": false
          },
          {
            "score": 0.6951202154159546,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.6906312108039856,
            "answer": "annie",
            "hit": false
          }
        ],
        "set_exclude": [
          "buck"
        ],
        "rank": 1894,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6369549632072449
      },
      {
        "question verbose": "What is to bull ",
        "b": "bull",
        "expected answer": [
          "cow"
        ],
        "predictions": [
          {
            "score": 0.7605881690979004,
            "answer": "bulls",
            "hit": false
          },
          {
            "score": 0.7166624665260315,
            "answer": "betty",
            "hit": false
          },
          {
            "score": 0.7157889604568481,
            "answer": "bullying",
            "hit": false
          },
          {
            "score": 0.6967199444770813,
            "answer": "bitch",
            "hit": false
          },
          {
            "score": 0.6962443590164185,
            "answer": "rachel",
            "hit": false
          },
          {
            "score": 0.6959291696548462,
            "answer": "stud",
            "hit": false
          }
        ],
        "set_exclude": [
          "bull"
        ],
        "rank": 1333,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6416034996509552
      },
      {
        "question verbose": "What is to dad ",
        "b": "dad",
        "expected answer": [
          "mom",
          "mum"
        ],
        "predictions": [
          {
            "score": 0.7555697560310364,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.7453312277793884,
            "answer": "mom",
            "hit": true
          },
          {
            "score": 0.7315355539321899,
            "answer": "daddy",
            "hit": false
          },
          {
            "score": 0.7281743884086609,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.7270017862319946,
            "answer": "kids",
            "hit": false
          },
          {
            "score": 0.7256078720092773,
            "answer": "grandmother",
            "hit": false
          }
        ],
        "set_exclude": [
          "dad"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7453312575817108
      },
      {
        "question verbose": "What is to duke ",
        "b": "duke",
        "expected answer": [
          "duchess"
        ],
        "predictions": [
          {
            "score": 0.793199896812439,
            "answer": "duchess",
            "hit": true
          },
          {
            "score": 0.7335919737815857,
            "answer": "durham",
            "hit": false
          },
          {
            "score": 0.731921911239624,
            "answer": "virginia",
            "hit": false
          },
          {
            "score": 0.7307658791542053,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.7263643741607666,
            "answer": "earl",
            "hit": false
          },
          {
            "score": 0.7259318828582764,
            "answer": "diana",
            "hit": false
          }
        ],
        "set_exclude": [
          "duke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.793199896812439
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "mother"
        ],
        "predictions": [
          {
            "score": 0.8408937454223633,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.8386924862861633,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.8245528936386108,
            "answer": "mothers",
            "hit": false
          },
          {
            "score": 0.8108644485473633,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.7888382077217102,
            "answer": "daughters",
            "hit": false
          },
          {
            "score": 0.7851285934448242,
            "answer": "maternal",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7727260887622833
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "goddess"
        ],
        "predictions": [
          {
            "score": 0.7815556526184082,
            "answer": "goddess",
            "hit": true
          },
          {
            "score": 0.7572793960571289,
            "answer": "gods",
            "hit": false
          },
          {
            "score": 0.7495986223220825,
            "answer": "divine",
            "hit": false
          },
          {
            "score": 0.7364563941955566,
            "answer": "holy",
            "hit": false
          },
          {
            "score": 0.7303671836853027,
            "answer": "deity",
            "hit": false
          },
          {
            "score": 0.727554440498352,
            "answer": "jesus",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7815556526184082
      },
      {
        "question verbose": "What is to grandfather ",
        "b": "grandfather",
        "expected answer": [
          "grandmother"
        ],
        "predictions": [
          {
            "score": 0.9030636548995972,
            "answer": "grandmother",
            "hit": true
          },
          {
            "score": 0.8650823831558228,
            "answer": "grandparents",
            "hit": false
          },
          {
            "score": 0.8029652833938599,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.8029019236564636,
            "answer": "father",
            "hit": false
          },
          {
            "score": 0.7910215258598328,
            "answer": "grandchildren",
            "hit": false
          },
          {
            "score": 0.7886001467704773,
            "answer": "mothers",
            "hit": false
          }
        ],
        "set_exclude": [
          "grandfather"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9030637145042419
      },
      {
        "question verbose": "What is to groom ",
        "b": "groom",
        "expected answer": [
          "bride"
        ],
        "predictions": [
          {
            "score": 0.7396748065948486,
            "answer": "bride",
            "hit": true
          },
          {
            "score": 0.7353891134262085,
            "answer": "marry",
            "hit": false
          },
          {
            "score": 0.7218201160430908,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.7211167812347412,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.7187026143074036,
            "answer": "actress",
            "hit": false
          },
          {
            "score": 0.7172666192054749,
            "answer": "wife",
            "hit": false
          }
        ],
        "set_exclude": [
          "groom"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7396747767925262
      },
      {
        "question verbose": "What is to husband ",
        "b": "husband",
        "expected answer": [
          "wife"
        ],
        "predictions": [
          {
            "score": 0.8239391446113586,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.7930564880371094,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.7887503504753113,
            "answer": "wives",
            "hit": false
          },
          {
            "score": 0.7867797613143921,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.7864647507667542,
            "answer": "boyfriend",
            "hit": false
          },
          {
            "score": 0.7812889814376831,
            "answer": "spouse",
            "hit": false
          }
        ],
        "set_exclude": [
          "husband"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7774159908294678
      },
      {
        "question verbose": "What is to king ",
        "b": "king",
        "expected answer": [
          "queen"
        ],
        "predictions": [
          {
            "score": 0.8216332197189331,
            "answer": "ked",
            "hit": false
          },
          {
            "score": 0.7080416679382324,
            "answer": "lady",
            "hit": false
          },
          {
            "score": 0.7045260071754456,
            "answer": "ching",
            "hit": false
          },
          {
            "score": 0.7031145095825195,
            "answer": "queen",
            "hit": true
          },
          {
            "score": 0.6884909272193909,
            "answer": "kiss",
            "hit": false
          },
          {
            "score": 0.6852070093154907,
            "answer": "ping",
            "hit": false
          }
        ],
        "set_exclude": [
          "king"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7031145095825195
      },
      {
        "question verbose": "What is to man ",
        "b": "man",
        "expected answer": [
          "woman"
        ],
        "predictions": [
          {
            "score": 0.7894302606582642,
            "answer": "woman",
            "hit": true
          },
          {
            "score": 0.755046010017395,
            "answer": "men",
            "hit": false
          },
          {
            "score": 0.7274246215820312,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.7259683609008789,
            "answer": "manning",
            "hit": false
          },
          {
            "score": 0.7253143191337585,
            "answer": "lady",
            "hit": false
          },
          {
            "score": 0.7177848815917969,
            "answer": "guy",
            "hit": false
          }
        ],
        "set_exclude": [
          "man"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7894302606582642
      },
      {
        "question verbose": "What is to nephew ",
        "b": "nephew",
        "expected answer": [
          "niece"
        ],
        "predictions": [
          {
            "score": 0.9049545526504517,
            "answer": "niece",
            "hit": true
          },
          {
            "score": 0.8436568975448608,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.8241189122200012,
            "answer": "daughters",
            "hit": false
          },
          {
            "score": 0.8073580861091614,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.7923811674118042,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.7896769642829895,
            "answer": "sisters",
            "hit": false
          }
        ],
        "set_exclude": [
          "nephew"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9049544632434845
      },
      {
        "question verbose": "What is to prince ",
        "b": "prince",
        "expected answer": [
          "princess"
        ],
        "predictions": [
          {
            "score": 0.8644287586212158,
            "answer": "princes",
            "hit": false
          },
          {
            "score": 0.7959296703338623,
            "answer": "princess",
            "hit": true
          },
          {
            "score": 0.7704086303710938,
            "answer": "duchess",
            "hit": false
          },
          {
            "score": 0.7634119391441345,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.7599405646324158,
            "answer": "goddess",
            "hit": false
          },
          {
            "score": 0.7558483481407166,
            "answer": "monarch",
            "hit": false
          }
        ],
        "set_exclude": [
          "prince"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7959297001361847
      },
      {
        "question verbose": "What is to son ",
        "b": "son",
        "expected answer": [
          "daughter"
        ],
        "predictions": [
          {
            "score": 0.7890884876251221,
            "answer": "daughter",
            "hit": true
          },
          {
            "score": 0.7063261270523071,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.692060649394989,
            "answer": "wife",
            "hit": false
          },
          {
            "score": 0.691025972366333,
            "answer": "daughters",
            "hit": false
          },
          {
            "score": 0.6864575147628784,
            "answer": "sons",
            "hit": false
          },
          {
            "score": 0.6852433681488037,
            "answer": "sister",
            "hit": false
          }
        ],
        "set_exclude": [
          "son"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7890884876251221
      },
      {
        "question verbose": "What is to uncle ",
        "b": "uncle",
        "expected answer": [
          "aunt"
        ],
        "predictions": [
          {
            "score": 0.8253016471862793,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.8118194341659546,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.7904176115989685,
            "answer": "nephew",
            "hit": false
          },
          {
            "score": 0.779184877872467,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.7726536989212036,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.7523593306541443,
            "answer": "grandparents",
            "hit": false
          }
        ],
        "set_exclude": [
          "uncle"
        ],
        "rank": 1404,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6598044037818909
      }
    ],
    "result": {
      "cnt_questions_correct": 8,
      "cnt_questions_total": 18,
      "accuracy": 0.4444444444444444
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E10 [male - female].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "34bc480f-7069-41b6-82d9-a2185534e717",
      "timestamp": "2025-05-17T17:12:47.737064"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to atmosphere ",
        "b": "atmosphere",
        "expected answer": [
          "gas",
          "oxygen",
          "hydrogen",
          "nitrogen",
          "ozone"
        ],
        "predictions": [
          {
            "score": 0.7455382943153381,
            "answer": "atmospheric",
            "hit": false
          },
          {
            "score": 0.7395683526992798,
            "answer": "vibe",
            "hit": false
          },
          {
            "score": 0.7275407314300537,
            "answer": "attitude",
            "hit": false
          },
          {
            "score": 0.7267680168151855,
            "answer": "surroundings",
            "hit": false
          },
          {
            "score": 0.7245599031448364,
            "answer": "environments",
            "hit": false
          },
          {
            "score": 0.7197542190551758,
            "answer": "ambient",
            "hit": false
          }
        ],
        "set_exclude": [
          "atmosphere"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6418204605579376
      },
      {
        "question verbose": "What is to bag ",
        "b": "bag",
        "expected answer": [
          "leather",
          "fabric",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.7568459510803223,
            "answer": "bags",
            "hit": false
          },
          {
            "score": 0.7436666488647461,
            "answer": "backpack",
            "hit": false
          },
          {
            "score": 0.7351965308189392,
            "answer": "luggage",
            "hit": false
          },
          {
            "score": 0.7299700975418091,
            "answer": "suitcase",
            "hit": false
          },
          {
            "score": 0.7279446721076965,
            "answer": "pouch",
            "hit": false
          },
          {
            "score": 0.7083674073219299,
            "answer": "baggage",
            "hit": false
          }
        ],
        "set_exclude": [
          "bag"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7046643942594528
      },
      {
        "question verbose": "What is to beard ",
        "b": "beard",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.7291823029518127,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.704994261264801,
            "answer": "beer",
            "hit": false
          },
          {
            "score": 0.7039276957511902,
            "answer": "hair",
            "hit": true
          },
          {
            "score": 0.7031282186508179,
            "answer": "cosmetic",
            "hit": false
          },
          {
            "score": 0.7022285461425781,
            "answer": "facial",
            "hit": false
          },
          {
            "score": 0.7019851803779602,
            "answer": "bacon",
            "hit": false
          }
        ],
        "set_exclude": [
          "beard"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7039276957511902
      },
      {
        "question verbose": "What is to body ",
        "b": "body",
        "expected answer": [
          "flesh",
          "bones"
        ],
        "predictions": [
          {
            "score": 0.8477518558502197,
            "answer": "bodies",
            "hit": false
          },
          {
            "score": 0.7283208966255188,
            "answer": "torso",
            "hit": false
          },
          {
            "score": 0.7268232107162476,
            "answer": "corpse",
            "hit": false
          },
          {
            "score": 0.7155874371528625,
            "answer": "organs",
            "hit": false
          },
          {
            "score": 0.7150086760520935,
            "answer": "limbs",
            "hit": false
          },
          {
            "score": 0.7116032838821411,
            "answer": "bodily",
            "hit": false
          }
        ],
        "set_exclude": [
          "body"
        ],
        "rank": 48,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6641956269741058
      },
      {
        "question verbose": "What is to boots ",
        "b": "boots",
        "expected answer": [
          "leather",
          "canvas"
        ],
        "predictions": [
          {
            "score": 0.7653141021728516,
            "answer": "shoes",
            "hit": false
          },
          {
            "score": 0.7618269920349121,
            "answer": "socks",
            "hit": false
          },
          {
            "score": 0.7608035802841187,
            "answer": "trousers",
            "hit": false
          },
          {
            "score": 0.7566723823547363,
            "answer": "gloves",
            "hit": false
          },
          {
            "score": 0.7423624396324158,
            "answer": "jeans",
            "hit": false
          },
          {
            "score": 0.7397497892379761,
            "answer": "boot",
            "hit": false
          }
        ],
        "set_exclude": [
          "boots"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7347767055034637
      },
      {
        "question verbose": "What is to bottle ",
        "b": "bottle",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8181978464126587,
            "answer": "bottles",
            "hit": false
          },
          {
            "score": 0.7545853853225708,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.7531969547271729,
            "answer": "drink",
            "hit": false
          },
          {
            "score": 0.7510992884635925,
            "answer": "beer",
            "hit": false
          },
          {
            "score": 0.740585207939148,
            "answer": "drank",
            "hit": false
          },
          {
            "score": 0.7312570214271545,
            "answer": "water",
            "hit": false
          }
        ],
        "set_exclude": [
          "bottle"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7545853555202484
      },
      {
        "question verbose": "What is to bowl ",
        "b": "bowl",
        "expected answer": [
          "glass",
          "china",
          "aluminium",
          "wood",
          "steel",
          "plastic",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.7996825575828552,
            "answer": "bowls",
            "hit": false
          },
          {
            "score": 0.7248660326004028,
            "answer": "cups",
            "hit": false
          },
          {
            "score": 0.7165771126747131,
            "answer": "stadium",
            "hit": false
          },
          {
            "score": 0.710586428642273,
            "answer": "touchdowns",
            "hit": false
          },
          {
            "score": 0.7053076028823853,
            "answer": "nfl",
            "hit": false
          },
          {
            "score": 0.7032232284545898,
            "answer": "broncos",
            "hit": false
          }
        ],
        "set_exclude": [
          "bowl"
        ],
        "rank": 37,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6869071274995804
      },
      {
        "question verbose": "What is to cocktail ",
        "b": "cocktail",
        "expected answer": [
          "alcohol",
          "juice",
          "water"
        ],
        "predictions": [
          {
            "score": 0.7535032033920288,
            "answer": "vodka",
            "hit": false
          },
          {
            "score": 0.7505632638931274,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.7465235590934753,
            "answer": "drinks",
            "hit": false
          },
          {
            "score": 0.742755115032196,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.7369486689567566,
            "answer": "champagne",
            "hit": false
          },
          {
            "score": 0.7367531657218933,
            "answer": "drank",
            "hit": false
          }
        ],
        "set_exclude": [
          "cocktail"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6943269968032837
      },
      {
        "question verbose": "What is to desk ",
        "b": "desk",
        "expected answer": [
          "wood",
          "metal",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.7037334442138672,
            "answer": "aluminium",
            "hit": false
          },
          {
            "score": 0.6999409198760986,
            "answer": "bed",
            "hit": false
          },
          {
            "score": 0.6984169483184814,
            "answer": "cabinets",
            "hit": false
          },
          {
            "score": 0.6983628273010254,
            "answer": "pocket",
            "hit": false
          },
          {
            "score": 0.6980099678039551,
            "answer": "sarah",
            "hit": false
          },
          {
            "score": 0.697860598564148,
            "answer": "books",
            "hit": false
          }
        ],
        "set_exclude": [
          "desk"
        ],
        "rank": 82,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6378213465213776
      },
      {
        "question verbose": "What is to diamond ",
        "b": "diamond",
        "expected answer": [
          "carbon"
        ],
        "predictions": [
          {
            "score": 0.8732783198356628,
            "answer": "diamonds",
            "hit": false
          },
          {
            "score": 0.7589541673660278,
            "answer": "platinum",
            "hit": false
          },
          {
            "score": 0.7482062578201294,
            "answer": "jewels",
            "hit": false
          },
          {
            "score": 0.7400493621826172,
            "answer": "granite",
            "hit": false
          },
          {
            "score": 0.7383618354797363,
            "answer": "leather",
            "hit": false
          },
          {
            "score": 0.7369870543479919,
            "answer": "titanium",
            "hit": false
          }
        ],
        "set_exclude": [
          "diamond"
        ],
        "rank": 130,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6735102534294128
      },
      {
        "question verbose": "What is to flag ",
        "b": "flag",
        "expected answer": [
          "fabric",
          "paper"
        ],
        "predictions": [
          {
            "score": 0.7887484431266785,
            "answer": "flags",
            "hit": false
          },
          {
            "score": 0.7045382261276245,
            "answer": "empty",
            "hit": false
          },
          {
            "score": 0.702472984790802,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.7014686465263367,
            "answer": "government",
            "hit": false
          },
          {
            "score": 0.7011252641677856,
            "answer": "jump",
            "hit": false
          },
          {
            "score": 0.700502872467041,
            "answer": "lock",
            "hit": false
          }
        ],
        "set_exclude": [
          "flag"
        ],
        "rank": 3190,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6452586650848389
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "bricks",
          "cement",
          "wood",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.8092676997184753,
            "answer": "senate",
            "hit": false
          },
          {
            "score": 0.7899211049079895,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.746464729309082,
            "answer": "household",
            "hit": false
          },
          {
            "score": 0.746008038520813,
            "answer": "sen",
            "hit": false
          },
          {
            "score": 0.7382466793060303,
            "answer": "households",
            "hit": false
          },
          {
            "score": 0.7244171500205994,
            "answer": "government",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 96,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.65622878074646
      },
      {
        "question verbose": "What is to jam ",
        "b": "jam",
        "expected answer": [
          "fruit",
          "sugar",
          "berries"
        ],
        "predictions": [
          {
            "score": 0.7142674922943115,
            "answer": "rash",
            "hit": false
          },
          {
            "score": 0.709498405456543,
            "answer": "corn",
            "hit": false
          },
          {
            "score": 0.7083420157432556,
            "answer": "brad",
            "hit": false
          },
          {
            "score": 0.7078249454498291,
            "answer": "isa",
            "hit": false
          },
          {
            "score": 0.7070210576057434,
            "answer": "mix",
            "hit": false
          },
          {
            "score": 0.7047684192657471,
            "answer": "jordan",
            "hit": false
          }
        ],
        "set_exclude": [
          "jam"
        ],
        "rank": 3310,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6325486153364182
      },
      {
        "question verbose": "What is to lawn ",
        "b": "lawn",
        "expected answer": [
          "grass"
        ],
        "predictions": [
          {
            "score": 0.7636603116989136,
            "answer": "garden",
            "hit": false
          },
          {
            "score": 0.7602551579475403,
            "answer": "porch",
            "hit": false
          },
          {
            "score": 0.7580763101577759,
            "answer": "patio",
            "hit": false
          },
          {
            "score": 0.7495235800743103,
            "answer": "driveway",
            "hit": false
          },
          {
            "score": 0.7488511800765991,
            "answer": "gardening",
            "hit": false
          },
          {
            "score": 0.7462252378463745,
            "answer": "sidewalk",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawn"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7205495983362198
      },
      {
        "question verbose": "What is to lens ",
        "b": "lens",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.7888834476470947,
            "answer": "lenses",
            "hit": false
          },
          {
            "score": 0.71123206615448,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.7107336521148682,
            "answer": "glasses",
            "hit": false
          },
          {
            "score": 0.7080953121185303,
            "answer": "aluminum",
            "hit": false
          },
          {
            "score": 0.7069873809814453,
            "answer": "plastics",
            "hit": false
          },
          {
            "score": 0.7059634327888489,
            "answer": "bulbs",
            "hit": false
          }
        ],
        "set_exclude": [
          "lens"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7112320363521576
      },
      {
        "question verbose": "What is to mirror ",
        "b": "mirror",
        "expected answer": [
          "glass",
          "bronze"
        ],
        "predictions": [
          {
            "score": 0.7567808628082275,
            "answer": "mirrors",
            "hit": false
          },
          {
            "score": 0.7242932915687561,
            "answer": "mir",
            "hit": false
          },
          {
            "score": 0.715385913848877,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.7120224237442017,
            "answer": "reflect",
            "hit": false
          },
          {
            "score": 0.7097344994544983,
            "answer": "telegraph",
            "hit": false
          },
          {
            "score": 0.703208327293396,
            "answer": "stones",
            "hit": false
          }
        ],
        "set_exclude": [
          "mirror"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7153858989477158
      },
      {
        "question verbose": "What is to money ",
        "b": "money",
        "expected answer": [
          "paper",
          "metal",
          "silver",
          "gold",
          "iron",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.8060895800590515,
            "answer": "funds",
            "hit": false
          },
          {
            "score": 0.7706338763237,
            "answer": "funding",
            "hit": false
          },
          {
            "score": 0.760830819606781,
            "answer": "monetary",
            "hit": false
          },
          {
            "score": 0.753939688205719,
            "answer": "revenue",
            "hit": false
          },
          {
            "score": 0.7470608949661255,
            "answer": "finances",
            "hit": false
          },
          {
            "score": 0.7329281568527222,
            "answer": "dollars",
            "hit": false
          }
        ],
        "set_exclude": [
          "money"
        ],
        "rank": 164,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6461360156536102
      },
      {
        "question verbose": "What is to ocean ",
        "b": "ocean",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.8668117523193359,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7699844837188721,
            "answer": "aquatic",
            "hit": false
          },
          {
            "score": 0.7671473622322083,
            "answer": "maritime",
            "hit": false
          },
          {
            "score": 0.7631224393844604,
            "answer": "underwater",
            "hit": false
          },
          {
            "score": 0.7629204988479614,
            "answer": "freshwater",
            "hit": false
          },
          {
            "score": 0.7518295645713806,
            "answer": "naval",
            "hit": false
          }
        ],
        "set_exclude": [
          "ocean"
        ],
        "rank": 30,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7222290337085724
      },
      {
        "question verbose": "What is to pastry ",
        "b": "pastry",
        "expected answer": [
          "flour",
          "egg",
          "butter",
          "filling"
        ],
        "predictions": [
          {
            "score": 0.787958025932312,
            "answer": "culinary",
            "hit": false
          },
          {
            "score": 0.7727984189987183,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.7657331824302673,
            "answer": "pasta",
            "hit": false
          },
          {
            "score": 0.7633216977119446,
            "answer": "dough",
            "hit": false
          },
          {
            "score": 0.7614461183547974,
            "answer": "chefs",
            "hit": false
          },
          {
            "score": 0.7531421184539795,
            "answer": "chocolate",
            "hit": false
          }
        ],
        "set_exclude": [
          "pastry"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7269182801246643
      },
      {
        "question verbose": "What is to penny ",
        "b": "penny",
        "expected answer": [
          "metal",
          "alloy",
          "bronze",
          "nickel",
          "zinc",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.7435091137886047,
            "answer": "penn",
            "hit": false
          },
          {
            "score": 0.7358945608139038,
            "answer": "cents",
            "hit": false
          },
          {
            "score": 0.7262429594993591,
            "answer": "dollar",
            "hit": false
          },
          {
            "score": 0.7214949727058411,
            "answer": "coins",
            "hit": false
          },
          {
            "score": 0.7159265279769897,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.7147979736328125,
            "answer": "ounce",
            "hit": false
          }
        ],
        "set_exclude": [
          "penny"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6544481366872787
      },
      {
        "question verbose": "What is to pill ",
        "b": "pill",
        "expected answer": [
          "medicine",
          "drug"
        ],
        "predictions": [
          {
            "score": 0.7614789605140686,
            "answer": "pills",
            "hit": false
          },
          {
            "score": 0.7324572205543518,
            "answer": "pillars",
            "hit": false
          },
          {
            "score": 0.704529881477356,
            "answer": "pillow",
            "hit": false
          },
          {
            "score": 0.7022473216056824,
            "answer": "drug",
            "hit": true
          },
          {
            "score": 0.6949509382247925,
            "answer": "herbs",
            "hit": false
          },
          {
            "score": 0.6929143667221069,
            "answer": "silver",
            "hit": false
          }
        ],
        "set_exclude": [
          "pill"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6669297814369202
      },
      {
        "question verbose": "What is to plastic ",
        "b": "plastic",
        "expected answer": [
          "polymer",
          "oil",
          "gas",
          "coal"
        ],
        "predictions": [
          {
            "score": 0.837208092212677,
            "answer": "plastics",
            "hit": false
          },
          {
            "score": 0.7723814249038696,
            "answer": "cardboard",
            "hit": false
          },
          {
            "score": 0.7619836330413818,
            "answer": "ceramic",
            "hit": false
          },
          {
            "score": 0.7572416067123413,
            "answer": "nylon",
            "hit": false
          },
          {
            "score": 0.7568167448043823,
            "answer": "wooden",
            "hit": false
          },
          {
            "score": 0.7483906149864197,
            "answer": "vinyl",
            "hit": false
          }
        ],
        "set_exclude": [
          "plastic"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7422956973314285
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.7818930149078369,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.7331480979919434,
            "answer": "maritime",
            "hit": false
          },
          {
            "score": 0.7316720485687256,
            "answer": "ocean",
            "hit": false
          },
          {
            "score": 0.7156524658203125,
            "answer": "freshwater",
            "hit": false
          },
          {
            "score": 0.7139255404472351,
            "answer": "naval",
            "hit": false
          },
          {
            "score": 0.7136614918708801,
            "answer": "arctic",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7043154835700989
      },
      {
        "question verbose": "What is to spoon ",
        "b": "spoon",
        "expected answer": [
          "aluminium",
          "wood",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.7123597860336304,
            "answer": "simmons",
            "hit": false
          },
          {
            "score": 0.7110499739646912,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.7096080780029297,
            "answer": "shovel",
            "hit": false
          },
          {
            "score": 0.7080010175704956,
            "answer": "bottle",
            "hit": false
          },
          {
            "score": 0.7037317156791687,
            "answer": "plum",
            "hit": false
          },
          {
            "score": 0.7017199397087097,
            "answer": "beans",
            "hit": false
          }
        ],
        "set_exclude": [
          "spoon"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6442720890045166
      },
      {
        "question verbose": "What is to table ",
        "b": "table",
        "expected answer": [
          "wood",
          "metal",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.7904678583145142,
            "answer": "tables",
            "hit": false
          },
          {
            "score": 0.6877701282501221,
            "answer": "charts",
            "hit": false
          },
          {
            "score": 0.6871956586837769,
            "answer": "sheet",
            "hit": false
          },
          {
            "score": 0.6837262511253357,
            "answer": "shelf",
            "hit": false
          },
          {
            "score": 0.6818016171455383,
            "answer": "podium",
            "hit": false
          },
          {
            "score": 0.681665301322937,
            "answer": "wooden",
            "hit": false
          }
        ],
        "set_exclude": [
          "table"
        ],
        "rank": 63,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6583172231912613
      },
      {
        "question verbose": "What is to wig ",
        "b": "wig",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.7216895818710327,
            "answer": "ludwig",
            "hit": false
          },
          {
            "score": 0.7115503549575806,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.6893080472946167,
            "answer": "haired",
            "hit": false
          },
          {
            "score": 0.6869544982910156,
            "answer": "witch",
            "hit": false
          },
          {
            "score": 0.6840100288391113,
            "answer": "glared",
            "hit": false
          },
          {
            "score": 0.6815184354782104,
            "answer": "wit",
            "hit": false
          }
        ],
        "set_exclude": [
          "wig"
        ],
        "rank": 904,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6466494649648666
      },
      {
        "question verbose": "What is to wine ",
        "b": "wine",
        "expected answer": [
          "grapes",
          "grape"
        ],
        "predictions": [
          {
            "score": 0.880752682685852,
            "answer": "wines",
            "hit": false
          },
          {
            "score": 0.8004851341247559,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.7896898984909058,
            "answer": "liquor",
            "hit": false
          },
          {
            "score": 0.7850372791290283,
            "answer": "grapes",
            "hit": true
          },
          {
            "score": 0.7811479568481445,
            "answer": "champagne",
            "hit": false
          },
          {
            "score": 0.771966278553009,
            "answer": "vinegar",
            "hit": false
          }
        ],
        "set_exclude": [
          "wine"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7850372195243835
      },
      {
        "question verbose": "What is to wire ",
        "b": "wire",
        "expected answer": [
          "metal"
        ],
        "predictions": [
          {
            "score": 0.7599797248840332,
            "answer": "wireless",
            "hit": false
          },
          {
            "score": 0.7574759721755981,
            "answer": "wires",
            "hit": false
          },
          {
            "score": 0.7313358187675476,
            "answer": "wiring",
            "hit": false
          },
          {
            "score": 0.7159378528594971,
            "answer": "wired",
            "hit": false
          },
          {
            "score": 0.7108010649681091,
            "answer": "water",
            "hit": false
          },
          {
            "score": 0.708320677280426,
            "answer": "cell",
            "hit": false
          }
        ],
        "set_exclude": [
          "wire"
        ],
        "rank": 109,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.672529548406601
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 28,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L04 [meronyms - substance].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "78148557-ab1f-40d3-83fe-f58e6c8620c6",
      "timestamp": "2025-05-17T17:12:47.801051"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bird ",
        "b": "bird",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.7547486424446106,
            "answer": "birds",
            "hit": false
          },
          {
            "score": 0.7050917148590088,
            "answer": "flock",
            "hit": true
          },
          {
            "score": 0.6975840926170349,
            "answer": "feathers",
            "hit": false
          },
          {
            "score": 0.6937216520309448,
            "answer": "hawk",
            "hit": false
          },
          {
            "score": 0.6920685172080994,
            "answer": "frog",
            "hit": false
          },
          {
            "score": 0.6902296543121338,
            "answer": "flying",
            "hit": false
          }
        ],
        "set_exclude": [
          "bird"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7050917446613312
      },
      {
        "question verbose": "What is to calf ",
        "b": "calf",
        "expected answer": [
          "cattle",
          "herd"
        ],
        "predictions": [
          {
            "score": 0.863469660282135,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.7877327799797058,
            "answer": "thigh",
            "hit": false
          },
          {
            "score": 0.7581325173377991,
            "answer": "ankle",
            "hit": false
          },
          {
            "score": 0.7483991384506226,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.7323758602142334,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7320684194564819,
            "answer": "forearm",
            "hit": false
          }
        ],
        "set_exclude": [
          "calf"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7147364616394043
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "train",
          "procession"
        ],
        "predictions": [
          {
            "score": 0.7417398691177368,
            "answer": "carol",
            "hit": false
          },
          {
            "score": 0.73269122838974,
            "answer": "cars",
            "hit": false
          },
          {
            "score": 0.730380654335022,
            "answer": "carroll",
            "hit": false
          },
          {
            "score": 0.7302492260932922,
            "answer": "carbon",
            "hit": false
          },
          {
            "score": 0.7291067838668823,
            "answer": "carrie",
            "hit": false
          },
          {
            "score": 0.7255465984344482,
            "answer": "carolina",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 2984,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6288884282112122
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8740462064743042,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.8361150026321411,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7959858179092407,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7782955169677734,
            "answer": "poultry",
            "hit": false
          },
          {
            "score": 0.773989200592041,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7710089087486267,
            "answer": "herd",
            "hit": true
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7710089683532715
      },
      {
        "question verbose": "What is to christian ",
        "b": "christian",
        "expected answer": [
          "congregation",
          "church",
          "parish"
        ],
        "predictions": [
          {
            "score": 0.8392080664634705,
            "answer": "christianity",
            "hit": false
          },
          {
            "score": 0.829135537147522,
            "answer": "christians",
            "hit": false
          },
          {
            "score": 0.7881743311882019,
            "answer": "theological",
            "hit": false
          },
          {
            "score": 0.7864317297935486,
            "answer": "evangelical",
            "hit": false
          },
          {
            "score": 0.7849966883659363,
            "answer": "protestant",
            "hit": false
          },
          {
            "score": 0.7840954065322876,
            "answer": "catholic",
            "hit": false
          }
        ],
        "set_exclude": [
          "christian"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7235238254070282
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "university"
        ],
        "predictions": [
          {
            "score": 0.8088947534561157,
            "answer": "colleges",
            "hit": false
          },
          {
            "score": 0.7680429816246033,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.7465108036994934,
            "answer": "graduating",
            "hit": false
          },
          {
            "score": 0.7459549903869629,
            "answer": "universities",
            "hit": false
          },
          {
            "score": 0.7448045015335083,
            "answer": "graduation",
            "hit": false
          },
          {
            "score": 0.7388433218002319,
            "answer": "undergraduate",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7315508127212524
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "state",
          "country"
        ],
        "predictions": [
          {
            "score": 0.8040392398834229,
            "answer": "counties",
            "hit": false
          },
          {
            "score": 0.7702419757843018,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.7445616722106934,
            "answer": "sheriff",
            "hit": false
          },
          {
            "score": 0.7295092344284058,
            "answer": "parish",
            "hit": false
          },
          {
            "score": 0.728958249092102,
            "answer": "province",
            "hit": false
          },
          {
            "score": 0.7232726812362671,
            "answer": "district",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6958300918340683
      },
      {
        "question verbose": "What is to cow ",
        "b": "cow",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.7405886650085449,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.717216968536377,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.7168145179748535,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.7042422890663147,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.6986759901046753,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.6984285712242126,
            "answer": "coward",
            "hit": false
          }
        ],
        "set_exclude": [
          "cow"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7168145179748535
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "murder"
        ],
        "predictions": [
          {
            "score": 0.7176848649978638,
            "answer": "flock",
            "hit": false
          },
          {
            "score": 0.7090825438499451,
            "answer": "raven",
            "hit": false
          },
          {
            "score": 0.7004069089889526,
            "answer": "exclaimed",
            "hit": false
          },
          {
            "score": 0.6966682076454163,
            "answer": "chuckled",
            "hit": false
          },
          {
            "score": 0.6966558694839478,
            "answer": "rook",
            "hit": false
          },
          {
            "score": 0.6944485306739807,
            "answer": "screamed",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 2997,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.632347971200943
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8901624083518982,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7655213475227356,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.7543084025382996,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.7292212843894958,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.7259583473205566,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.720967173576355,
            "answer": "buffalo",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7259583473205566
      },
      {
        "question verbose": "What is to employee ",
        "b": "employee",
        "expected answer": [
          "staff",
          "company"
        ],
        "predictions": [
          {
            "score": 0.8113524317741394,
            "answer": "employees",
            "hit": false
          },
          {
            "score": 0.7906343340873718,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.7839070558547974,
            "answer": "employment",
            "hit": false
          },
          {
            "score": 0.7638936042785645,
            "answer": "employer",
            "hit": false
          },
          {
            "score": 0.7594958543777466,
            "answer": "workforce",
            "hit": false
          },
          {
            "score": 0.7577279210090637,
            "answer": "workplace",
            "hit": false
          }
        ],
        "set_exclude": [
          "employee"
        ],
        "rank": 32,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7156851887702942
      },
      {
        "question verbose": "What is to fish ",
        "b": "fish",
        "expected answer": [
          "school"
        ],
        "predictions": [
          {
            "score": 0.7588047981262207,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.7559022903442383,
            "answer": "fishing",
            "hit": false
          },
          {
            "score": 0.7446517944335938,
            "answer": "seafood",
            "hit": false
          },
          {
            "score": 0.7316523194313049,
            "answer": "salmon",
            "hit": false
          },
          {
            "score": 0.7305279970169067,
            "answer": "fishermen",
            "hit": false
          },
          {
            "score": 0.7228291034698486,
            "answer": "trout",
            "hit": false
          }
        ],
        "set_exclude": [
          "fish"
        ],
        "rank": 7525,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.613936573266983
      },
      {
        "question verbose": "What is to galaxy ",
        "b": "galaxy",
        "expected answer": [
          "universe"
        ],
        "predictions": [
          {
            "score": 0.8498754501342773,
            "answer": "galaxies",
            "hit": false
          },
          {
            "score": 0.790075421333313,
            "answer": "milky",
            "hit": false
          },
          {
            "score": 0.7791178822517395,
            "answer": "galactic",
            "hit": false
          },
          {
            "score": 0.7729945182800293,
            "answer": "planet",
            "hit": false
          },
          {
            "score": 0.7628005743026733,
            "answer": "universe",
            "hit": true
          },
          {
            "score": 0.7540541291236877,
            "answer": "planets",
            "hit": false
          }
        ],
        "set_exclude": [
          "galaxy"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7628005743026733
      },
      {
        "question verbose": "What is to letter ",
        "b": "letter",
        "expected answer": [
          "alphabet"
        ],
        "predictions": [
          {
            "score": 0.7266215085983276,
            "answer": "letters",
            "hit": false
          },
          {
            "score": 0.7151781320571899,
            "answer": "correspondence",
            "hit": false
          },
          {
            "score": 0.7128736972808838,
            "answer": "memorandum",
            "hit": false
          },
          {
            "score": 0.7094410061836243,
            "answer": "memo",
            "hit": false
          },
          {
            "score": 0.7053688764572144,
            "answer": "essay",
            "hit": false
          },
          {
            "score": 0.6992024183273315,
            "answer": "agreement",
            "hit": false
          }
        ],
        "set_exclude": [
          "letter"
        ],
        "rank": 88,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.668096125125885
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "pride"
        ],
        "predictions": [
          {
            "score": 0.7698335647583008,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.7306878566741943,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.7283923625946045,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.7202128171920776,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.7150758504867554,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.7133256196975708,
            "answer": "elephants",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 372,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.658753827214241
      },
      {
        "question verbose": "What is to listener ",
        "b": "listener",
        "expected answer": [
          "audience"
        ],
        "predictions": [
          {
            "score": 0.8886080980300903,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.7880799770355225,
            "answer": "viewer",
            "hit": false
          },
          {
            "score": 0.7840409874916077,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7535924911499023,
            "answer": "listen",
            "hit": false
          },
          {
            "score": 0.7526546716690063,
            "answer": "viewers",
            "hit": false
          },
          {
            "score": 0.7486969232559204,
            "answer": "audience",
            "hit": true
          }
        ],
        "set_exclude": [
          "listener"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.748696967959404
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "club",
          "team",
          "group",
          "band",
          "community"
        ],
        "predictions": [
          {
            "score": 0.769255518913269,
            "answer": "members",
            "hit": false
          },
          {
            "score": 0.7594133615493774,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.7355223894119263,
            "answer": "chairman",
            "hit": false
          },
          {
            "score": 0.7097207903862,
            "answer": "minister",
            "hit": false
          },
          {
            "score": 0.708945095539093,
            "answer": "partner",
            "hit": false
          },
          {
            "score": 0.7041116952896118,
            "answer": "representative",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 331,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6562927067279816
      },
      {
        "question verbose": "What is to musician ",
        "b": "musician",
        "expected answer": [
          "orchestra",
          "band"
        ],
        "predictions": [
          {
            "score": 0.8943955898284912,
            "answer": "musicians",
            "hit": false
          },
          {
            "score": 0.8383065462112427,
            "answer": "guitarist",
            "hit": false
          },
          {
            "score": 0.8329110145568848,
            "answer": "rapper",
            "hit": false
          },
          {
            "score": 0.8283267021179199,
            "answer": "drummer",
            "hit": false
          },
          {
            "score": 0.8119711875915527,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.8082593679428101,
            "answer": "composer",
            "hit": false
          }
        ],
        "set_exclude": [
          "musician"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7801443338394165
      },
      {
        "question verbose": "What is to person ",
        "b": "person",
        "expected answer": [
          "society",
          "company",
          "party",
          "world"
        ],
        "predictions": [
          {
            "score": 0.7584035396575928,
            "answer": "personal",
            "hit": false
          },
          {
            "score": 0.7436734437942505,
            "answer": "want",
            "hit": false
          },
          {
            "score": 0.7414799928665161,
            "answer": "personnel",
            "hit": false
          },
          {
            "score": 0.737933874130249,
            "answer": "persons",
            "hit": false
          },
          {
            "score": 0.7279567718505859,
            "answer": "need",
            "hit": false
          },
          {
            "score": 0.7279033660888672,
            "answer": "two",
            "hit": false
          }
        ],
        "set_exclude": [
          "person"
        ],
        "rank": 600,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6463492214679718
      },
      {
        "question verbose": "What is to photo ",
        "b": "photo",
        "expected answer": [
          "album",
          "collection",
          "library"
        ],
        "predictions": [
          {
            "score": 0.7952146530151367,
            "answer": "photos",
            "hit": false
          },
          {
            "score": 0.780535101890564,
            "answer": "picture",
            "hit": false
          },
          {
            "score": 0.756168007850647,
            "answer": "photograph",
            "hit": false
          },
          {
            "score": 0.7549746036529541,
            "answer": "photographs",
            "hit": false
          },
          {
            "score": 0.7546359300613403,
            "answer": "photographed",
            "hit": false
          },
          {
            "score": 0.7526962757110596,
            "answer": "photography",
            "hit": false
          }
        ],
        "set_exclude": [
          "photo"
        ],
        "rank": 147,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6617312729358673
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "team",
          "group",
          "orchestra"
        ],
        "predictions": [
          {
            "score": 0.8926482200622559,
            "answer": "players",
            "hit": false
          },
          {
            "score": 0.7275491952896118,
            "answer": "defender",
            "hit": false
          },
          {
            "score": 0.7259778380393982,
            "answer": "user",
            "hit": false
          },
          {
            "score": 0.7256720066070557,
            "answer": "midfielder",
            "hit": false
          },
          {
            "score": 0.7222214341163635,
            "answer": "league",
            "hit": false
          },
          {
            "score": 0.7216135263442993,
            "answer": "tournament",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 52,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6736203134059906
      },
      {
        "question verbose": "What is to policeman ",
        "b": "policeman",
        "expected answer": [
          "police"
        ],
        "predictions": [
          {
            "score": 0.8225834965705872,
            "answer": "police",
            "hit": true
          },
          {
            "score": 0.8066322207450867,
            "answer": "cops",
            "hit": false
          },
          {
            "score": 0.7740911245346069,
            "answer": "officers",
            "hit": false
          },
          {
            "score": 0.7698594331741333,
            "answer": "policing",
            "hit": false
          },
          {
            "score": 0.7548804879188538,
            "answer": "prosecutor",
            "hit": false
          },
          {
            "score": 0.7508924007415771,
            "answer": "magistrate",
            "hit": false
          }
        ],
        "set_exclude": [
          "policeman"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8225835561752319
      },
      {
        "question verbose": "What is to secretary ",
        "b": "secretary",
        "expected answer": [
          "staff"
        ],
        "predictions": [
          {
            "score": 0.7787941694259644,
            "answer": "mayor",
            "hit": false
          },
          {
            "score": 0.7780313491821289,
            "answer": "department",
            "hit": false
          },
          {
            "score": 0.7766621708869934,
            "answer": "minister",
            "hit": false
          },
          {
            "score": 0.766789972782135,
            "answer": "director",
            "hit": false
          },
          {
            "score": 0.7637766599655151,
            "answer": "senate",
            "hit": false
          },
          {
            "score": 0.7625080943107605,
            "answer": "government",
            "hit": false
          }
        ],
        "set_exclude": [
          "secretary"
        ],
        "rank": 2231,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.671741783618927
      },
      {
        "question verbose": "What is to senator ",
        "b": "senator",
        "expected answer": [
          "senate",
          "house"
        ],
        "predictions": [
          {
            "score": 0.8740755319595337,
            "answer": "senators",
            "hit": false
          },
          {
            "score": 0.8491103649139404,
            "answer": "congressman",
            "hit": false
          },
          {
            "score": 0.8061898946762085,
            "answer": "sen",
            "hit": false
          },
          {
            "score": 0.8005949258804321,
            "answer": "politician",
            "hit": false
          },
          {
            "score": 0.8001371026039124,
            "answer": "senate",
            "hit": true
          },
          {
            "score": 0.7723193764686584,
            "answer": "legislators",
            "hit": false
          }
        ],
        "set_exclude": [
          "senator"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8001371026039124
      },
      {
        "question verbose": "What is to sheep ",
        "b": "sheep",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.7887370586395264,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7727676630020142,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.7711126804351807,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.7656334042549133,
            "answer": "chickens",
            "hit": false
          },
          {
            "score": 0.7619346380233765,
            "answer": "flock",
            "hit": true
          },
          {
            "score": 0.7534516453742981,
            "answer": "herd",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheep"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7619346082210541
      },
      {
        "question verbose": "What is to soldier ",
        "b": "soldier",
        "expected answer": [
          "army",
          "unit",
          "division",
          "troop"
        ],
        "predictions": [
          {
            "score": 0.7747698426246643,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.7629042863845825,
            "answer": "sold",
            "hit": false
          },
          {
            "score": 0.7415196895599365,
            "answer": "army",
            "hit": true
          },
          {
            "score": 0.7291818857192993,
            "answer": "regiment",
            "hit": false
          },
          {
            "score": 0.7264971733093262,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.7149151563644409,
            "answer": "infantry",
            "hit": false
          }
        ],
        "set_exclude": [
          "soldier"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7415197193622589
      },
      {
        "question verbose": "What is to spouse ",
        "b": "spouse",
        "expected answer": [
          "couple",
          "relationship",
          "family"
        ],
        "predictions": [
          {
            "score": 0.7902626395225525,
            "answer": "marital",
            "hit": false
          },
          {
            "score": 0.788001298904419,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.7705311179161072,
            "answer": "married",
            "hit": false
          },
          {
            "score": 0.7691460847854614,
            "answer": "wife",
            "hit": false
          },
          {
            "score": 0.7670375108718872,
            "answer": "boyfriend",
            "hit": false
          },
          {
            "score": 0.7588542699813843,
            "answer": "husband",
            "hit": false
          }
        ],
        "set_exclude": [
          "spouse"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6902715414762497
      },
      {
        "question verbose": "What is to state ",
        "b": "state",
        "expected answer": [
          "country",
          "province"
        ],
        "predictions": [
          {
            "score": 0.7416579723358154,
            "answer": "government",
            "hit": false
          },
          {
            "score": 0.7316417098045349,
            "answer": "senate",
            "hit": false
          },
          {
            "score": 0.7290058135986328,
            "answer": "legislature",
            "hit": false
          },
          {
            "score": 0.7262301445007324,
            "answer": "statewide",
            "hit": false
          },
          {
            "score": 0.7245358228683472,
            "answer": "governmental",
            "hit": false
          },
          {
            "score": 0.7219853401184082,
            "answer": "govern",
            "hit": false
          }
        ],
        "set_exclude": [
          "state"
        ],
        "rank": 42,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6806959062814713
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "class",
          "school"
        ],
        "predictions": [
          {
            "score": 0.8309458494186401,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.7852983474731445,
            "answer": "school",
            "hit": true
          },
          {
            "score": 0.7763713598251343,
            "answer": "classroom",
            "hit": false
          },
          {
            "score": 0.7726678848266602,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.7687171697616577,
            "answer": "academic",
            "hit": false
          },
          {
            "score": 0.7648378610610962,
            "answer": "tuition",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6876476854085922
      },
      {
        "question verbose": "What is to tree ",
        "b": "tree",
        "expected answer": [
          "forest",
          "wood",
          "grove"
        ],
        "predictions": [
          {
            "score": 0.8218056559562683,
            "answer": "trees",
            "hit": false
          },
          {
            "score": 0.7188380360603333,
            "answer": "forest",
            "hit": true
          },
          {
            "score": 0.7145905494689941,
            "answer": "garden",
            "hit": false
          },
          {
            "score": 0.7135294675827026,
            "answer": "leaf",
            "hit": false
          },
          {
            "score": 0.7055401802062988,
            "answer": "vegetation",
            "hit": false
          },
          {
            "score": 0.7016505002975464,
            "answer": "forests",
            "hit": false
          }
        ],
        "set_exclude": [
          "tree"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7188380211591721
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "pack"
        ],
        "predictions": [
          {
            "score": 0.7811025977134705,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.7041745781898499,
            "answer": "vampire",
            "hit": false
          },
          {
            "score": 0.7037081718444824,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.6954724788665771,
            "answer": "flock",
            "hit": false
          },
          {
            "score": 0.6903982758522034,
            "answer": "breeding",
            "hit": false
          },
          {
            "score": 0.6881628632545471,
            "answer": "shepherd",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 550,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6469596028327942
      },
      {
        "question verbose": "What is to word ",
        "b": "word",
        "expected answer": [
          "paragraph",
          "sentence",
          "text"
        ],
        "predictions": [
          {
            "score": 0.7275663614273071,
            "answer": "words",
            "hit": false
          },
          {
            "score": 0.7165524959564209,
            "answer": "vocabulary",
            "hit": false
          },
          {
            "score": 0.70801842212677,
            "answer": "html",
            "hit": false
          },
          {
            "score": 0.7080057859420776,
            "answer": "text",
            "hit": true
          },
          {
            "score": 0.7065175771713257,
            "answer": "phrase",
            "hit": false
          },
          {
            "score": 0.7027630805969238,
            "answer": "though",
            "hit": false
          }
        ],
        "set_exclude": [
          "word"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6551730632781982
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 32,
      "accuracy": 0.03125
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L05 [meronyms - member].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "8f14cdbe-90d2-433d-ac47-0155ea776c66",
      "timestamp": "2025-05-17T17:12:47.905958"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bus ",
        "b": "bus",
        "expected answer": [
          "seats",
          "conductor",
          "window",
          "driver",
          "roof"
        ],
        "predictions": [
          {
            "score": 0.7275961637496948,
            "answer": "buses",
            "hit": false
          },
          {
            "score": 0.6939477920532227,
            "answer": "bit",
            "hit": false
          },
          {
            "score": 0.6914676427841187,
            "answer": "cent",
            "hit": false
          },
          {
            "score": 0.6795544028282166,
            "answer": "almost",
            "hit": false
          },
          {
            "score": 0.6773853898048401,
            "answer": "passengers",
            "hit": false
          },
          {
            "score": 0.6757435202598572,
            "answer": "beer",
            "hit": false
          }
        ],
        "set_exclude": [
          "bus"
        ],
        "rank": 625,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6343494057655334
      },
      {
        "question verbose": "What is to byte ",
        "b": "byte",
        "expected answer": [
          "bit"
        ],
        "predictions": [
          {
            "score": 0.7380629777908325,
            "answer": "bytes",
            "hit": false
          },
          {
            "score": 0.7233912348747253,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.7150779962539673,
            "answer": "seats",
            "hit": false
          },
          {
            "score": 0.6949872970581055,
            "answer": "bites",
            "hit": false
          },
          {
            "score": 0.692401111125946,
            "answer": "seconds",
            "hit": false
          },
          {
            "score": 0.6889218091964722,
            "answer": "pixels",
            "hit": false
          }
        ],
        "set_exclude": [
          "byte"
        ],
        "rank": 1091,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6325172185897827
      },
      {
        "question verbose": "What is to comb ",
        "b": "comb",
        "expected answer": [
          "teeth",
          "shaft",
          "grip",
          "tooth",
          "handle"
        ],
        "predictions": [
          {
            "score": 0.6700667142868042,
            "answer": "seats",
            "hit": false
          },
          {
            "score": 0.669461190700531,
            "answer": "cent",
            "hit": false
          },
          {
            "score": 0.6667872667312622,
            "answer": "confront",
            "hit": false
          },
          {
            "score": 0.6608070731163025,
            "answer": "battling",
            "hit": false
          },
          {
            "score": 0.6600355505943298,
            "answer": "contests",
            "hit": false
          },
          {
            "score": 0.6598989963531494,
            "answer": "brushes",
            "hit": false
          }
        ],
        "set_exclude": [
          "comb"
        ],
        "rank": 1825,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6103481724858284
      },
      {
        "question verbose": "What is to dollar ",
        "b": "dollar",
        "expected answer": [
          "cent"
        ],
        "predictions": [
          {
            "score": 0.7931869029998779,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.7246263027191162,
            "answer": "usd",
            "hit": false
          },
          {
            "score": 0.7235894203186035,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.7208187580108643,
            "answer": "bit",
            "hit": false
          },
          {
            "score": 0.7058001756668091,
            "answer": "yuan",
            "hit": false
          },
          {
            "score": 0.705712080001831,
            "answer": "penny",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollar"
        ],
        "rank": 2500,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6299338191747665
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L06 [meronyms - part].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "f091728b-3f6e-4803-9f60-03fb6da26d80",
      "timestamp": "2025-05-17T17:12:48.028847"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to excited ",
        "b": "excited",
        "expected answer": [
          "agitated",
          "nervous"
        ],
        "predictions": [
          {
            "score": 0.8319963216781616,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.8169373273849487,
            "answer": "delighted",
            "hit": false
          },
          {
            "score": 0.8034944534301758,
            "answer": "intrigued",
            "hit": false
          },
          {
            "score": 0.8021458983421326,
            "answer": "excitement",
            "hit": false
          },
          {
            "score": 0.7941535711288452,
            "answer": "enthusiastic",
            "hit": false
          },
          {
            "score": 0.7831376791000366,
            "answer": "exciting",
            "hit": false
          }
        ],
        "set_exclude": [
          "excited"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7701645791530609
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "palace",
          "castle"
        ],
        "predictions": [
          {
            "score": 0.810272216796875,
            "answer": "senate",
            "hit": false
          },
          {
            "score": 0.7807848453521729,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.750205397605896,
            "answer": "household",
            "hit": false
          },
          {
            "score": 0.7455093860626221,
            "answer": "households",
            "hit": false
          },
          {
            "score": 0.737631618976593,
            "answer": "sen",
            "hit": false
          },
          {
            "score": 0.7313723564147949,
            "answer": "mansion",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 28,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.702661469578743
      },
      {
        "question verbose": "What is to lake ",
        "b": "lake",
        "expected answer": [
          "sea",
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.6954352855682373,
            "answer": "creek",
            "hit": false
          },
          {
            "score": 0.693069577217102,
            "answer": "ocean",
            "hit": true
          },
          {
            "score": 0.6918465495109558,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.690658450126648,
            "answer": "colonial",
            "hit": false
          },
          {
            "score": 0.6903241276741028,
            "answer": "meal",
            "hit": false
          },
          {
            "score": 0.6887823939323425,
            "answer": "horse",
            "hit": false
          }
        ],
        "set_exclude": [
          "lake"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.618049867451191
      },
      {
        "question verbose": "What is to pain ",
        "b": "pain",
        "expected answer": [
          "torment",
          "torture",
          "agony"
        ],
        "predictions": [
          {
            "score": 0.759209394454956,
            "answer": "painting",
            "hit": false
          },
          {
            "score": 0.738697350025177,
            "answer": "painter",
            "hit": false
          },
          {
            "score": 0.7360490560531616,
            "answer": "painful",
            "hit": false
          },
          {
            "score": 0.7350478768348694,
            "answer": "agony",
            "hit": true
          },
          {
            "score": 0.7345702052116394,
            "answer": "anguish",
            "hit": false
          },
          {
            "score": 0.7297024130821228,
            "answer": "discomfort",
            "hit": false
          }
        ],
        "set_exclude": [
          "pain"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6828681528568268
      },
      {
        "question verbose": "What is to pony ",
        "b": "pony",
        "expected answer": [
          "horse"
        ],
        "predictions": [
          {
            "score": 0.7131689786911011,
            "answer": "pig",
            "hit": false
          },
          {
            "score": 0.7086682319641113,
            "answer": "horses",
            "hit": false
          },
          {
            "score": 0.7019662857055664,
            "answer": "ranger",
            "hit": false
          },
          {
            "score": 0.6991647481918335,
            "answer": "dragon",
            "hit": false
          },
          {
            "score": 0.6960179805755615,
            "answer": "cavalry",
            "hit": false
          },
          {
            "score": 0.6958831548690796,
            "answer": "wagon",
            "hit": false
          }
        ],
        "set_exclude": [
          "pony"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6934718191623688
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.7705203890800476,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.7385401725769043,
            "answer": "ocean",
            "hit": true
          },
          {
            "score": 0.7230319976806641,
            "answer": "maritime",
            "hit": false
          },
          {
            "score": 0.7119209170341492,
            "answer": "naval",
            "hit": false
          },
          {
            "score": 0.7086471915245056,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.6977229714393616,
            "answer": "whale",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7385401427745819
      },
      {
        "question verbose": "What is to snack ",
        "b": "snack",
        "expected answer": [
          "meal",
          "eat"
        ],
        "predictions": [
          {
            "score": 0.8806318640708923,
            "answer": "snacks",
            "hit": false
          },
          {
            "score": 0.7855079174041748,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.7762266397476196,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.7745941281318665,
            "answer": "eat",
            "hit": true
          },
          {
            "score": 0.7627599239349365,
            "answer": "breakfast",
            "hit": false
          },
          {
            "score": 0.7613422274589539,
            "answer": "beverages",
            "hit": false
          }
        ],
        "set_exclude": [
          "snack"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6538147181272507
      },
      {
        "question verbose": "What is to tired ",
        "b": "tired",
        "expected answer": [
          "exhausted",
          "drained"
        ],
        "predictions": [
          {
            "score": 0.8188170194625854,
            "answer": "weary",
            "hit": false
          },
          {
            "score": 0.8010348081588745,
            "answer": "bored",
            "hit": false
          },
          {
            "score": 0.798407256603241,
            "answer": "exhausted",
            "hit": true
          },
          {
            "score": 0.7776366472244263,
            "answer": "frustrated",
            "hit": false
          },
          {
            "score": 0.7736803889274597,
            "answer": "fatigue",
            "hit": false
          },
          {
            "score": 0.7699921131134033,
            "answer": "annoyed",
            "hit": false
          }
        ],
        "set_exclude": [
          "tired"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.798407256603241
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 8,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L07 [synonyms - intensity].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "1429c9e6-638d-46dd-9826-0c0c4463733b",
      "timestamp": "2025-05-17T17:12:48.045900"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bicycle ",
        "b": "bicycle",
        "expected answer": [
          "bike",
          "wheel",
          "cycle"
        ],
        "predictions": [
          {
            "score": 0.8197340369224548,
            "answer": "bike",
            "hit": true
          },
          {
            "score": 0.797229528427124,
            "answer": "cyclists",
            "hit": false
          },
          {
            "score": 0.7861520648002625,
            "answer": "bikes",
            "hit": false
          },
          {
            "score": 0.7859567403793335,
            "answer": "cycling",
            "hit": false
          },
          {
            "score": 0.7756267786026001,
            "answer": "motorcycle",
            "hit": false
          },
          {
            "score": 0.7493671178817749,
            "answer": "roadway",
            "hit": false
          }
        ],
        "set_exclude": [
          "bicycle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8197340369224548
      },
      {
        "question verbose": "What is to cloth ",
        "b": "cloth",
        "expected answer": [
          "fabric",
          "material",
          "textile"
        ],
        "predictions": [
          {
            "score": 0.7162721157073975,
            "answer": "robe",
            "hit": false
          },
          {
            "score": 0.7077164053916931,
            "answer": "linen",
            "hit": false
          },
          {
            "score": 0.7065061330795288,
            "answer": "towel",
            "hit": false
          },
          {
            "score": 0.700488269329071,
            "answer": "fabrics",
            "hit": false
          },
          {
            "score": 0.7003684639930725,
            "answer": "textile",
            "hit": true
          },
          {
            "score": 0.7002734541893005,
            "answer": "garments",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloth"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6485473215579987
      },
      {
        "question verbose": "What is to dollars ",
        "b": "dollars",
        "expected answer": [
          "bucks"
        ],
        "predictions": [
          {
            "score": 0.8171917200088501,
            "answer": "dollar",
            "hit": false
          },
          {
            "score": 0.7548056840896606,
            "answer": "usd",
            "hit": false
          },
          {
            "score": 0.752536952495575,
            "answer": "bucks",
            "hit": true
          },
          {
            "score": 0.7425525188446045,
            "answer": "euros",
            "hit": false
          },
          {
            "score": 0.7409238815307617,
            "answer": "cents",
            "hit": false
          },
          {
            "score": 0.7392709255218506,
            "answer": "gallons",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollars"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7525369226932526
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "dad",
          "daddy"
        ],
        "predictions": [
          {
            "score": 0.8421248197555542,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.8358080983161926,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.8073415160179138,
            "answer": "brother",
            "hit": false
          },
          {
            "score": 0.8006210327148438,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.7815248966217041,
            "answer": "mothers",
            "hit": false
          },
          {
            "score": 0.7809664011001587,
            "answer": "parent",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 38,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.717003121972084
      },
      {
        "question verbose": "What is to help ",
        "b": "help",
        "expected answer": [
          "aid",
          "assist"
        ],
        "predictions": [
          {
            "score": 0.7331061363220215,
            "answer": "helped",
            "hit": false
          },
          {
            "score": 0.7295497059822083,
            "answer": "helping",
            "hit": false
          },
          {
            "score": 0.7277590036392212,
            "answer": "services",
            "hit": false
          },
          {
            "score": 0.7250152230262756,
            "answer": "say",
            "hit": false
          },
          {
            "score": 0.7247589230537415,
            "answer": "assistance",
            "hit": false
          },
          {
            "score": 0.7217459082603455,
            "answer": "work",
            "hit": false
          }
        ],
        "set_exclude": [
          "help"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7002059668302536
      },
      {
        "question verbose": "What is to intelligent ",
        "b": "intelligent",
        "expected answer": [
          "clever",
          "smart"
        ],
        "predictions": [
          {
            "score": 0.7817920446395874,
            "answer": "smarter",
            "hit": false
          },
          {
            "score": 0.7726486921310425,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.7718895673751831,
            "answer": "thoughtful",
            "hit": false
          },
          {
            "score": 0.7506306171417236,
            "answer": "sophisticated",
            "hit": false
          },
          {
            "score": 0.7495741844177246,
            "answer": "ignorant",
            "hit": false
          },
          {
            "score": 0.7488845586776733,
            "answer": "intellect",
            "hit": false
          }
        ],
        "set_exclude": [
          "intelligent"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6959008872509003
      },
      {
        "question verbose": "What is to jewel ",
        "b": "jewel",
        "expected answer": [
          "gem",
          "stone"
        ],
        "predictions": [
          {
            "score": 0.8068981170654297,
            "answer": "jewelry",
            "hit": false
          },
          {
            "score": 0.7762303352355957,
            "answer": "jewels",
            "hit": false
          },
          {
            "score": 0.7371917963027954,
            "answer": "jew",
            "hit": false
          },
          {
            "score": 0.7279428243637085,
            "answer": "necklace",
            "hit": false
          },
          {
            "score": 0.7213173508644104,
            "answer": "gems",
            "hit": false
          },
          {
            "score": 0.7179188132286072,
            "answer": "shoes",
            "hit": false
          }
        ],
        "set_exclude": [
          "jewel"
        ],
        "rank": 373,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6658751368522644
      },
      {
        "question verbose": "What is to monument ",
        "b": "monument",
        "expected answer": [
          "memorial"
        ],
        "predictions": [
          {
            "score": 0.8136963844299316,
            "answer": "monuments",
            "hit": false
          },
          {
            "score": 0.744001030921936,
            "answer": "memorial",
            "hit": true
          },
          {
            "score": 0.7301905751228333,
            "answer": "cemetery",
            "hit": false
          },
          {
            "score": 0.7263927459716797,
            "answer": "erected",
            "hit": false
          },
          {
            "score": 0.723888099193573,
            "answer": "sculpture",
            "hit": false
          },
          {
            "score": 0.7228993773460388,
            "answer": "statues",
            "hit": false
          }
        ],
        "set_exclude": [
          "monument"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7440010011196136
      },
      {
        "question verbose": "What is to new ",
        "b": "new",
        "expected answer": [
          "modern",
          "recent"
        ],
        "predictions": [
          {
            "score": 0.741011917591095,
            "answer": "nyc",
            "hit": false
          },
          {
            "score": 0.7375414371490479,
            "answer": "los",
            "hit": false
          },
          {
            "score": 0.7236250042915344,
            "answer": "manhattan",
            "hit": false
          },
          {
            "score": 0.7153564691543579,
            "answer": "brooklyn",
            "hit": false
          },
          {
            "score": 0.7034693956375122,
            "answer": "connecticut",
            "hit": false
          },
          {
            "score": 0.700006365776062,
            "answer": "massachusetts",
            "hit": false
          }
        ],
        "set_exclude": [
          "new"
        ],
        "rank": 1249,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6078815758228302
      },
      {
        "question verbose": "What is to package ",
        "b": "package",
        "expected answer": [
          "parcel",
          "pack",
          "packet",
          "bundle"
        ],
        "predictions": [
          {
            "score": 0.7824333906173706,
            "answer": "packages",
            "hit": false
          },
          {
            "score": 0.7327252626419067,
            "answer": "modules",
            "hit": false
          },
          {
            "score": 0.7304511070251465,
            "answer": "import",
            "hit": false
          },
          {
            "score": 0.7297465801239014,
            "answer": "packaging",
            "hit": false
          },
          {
            "score": 0.7171233892440796,
            "answer": "install",
            "hit": false
          },
          {
            "score": 0.7170841097831726,
            "answer": "packaged",
            "hit": false
          }
        ],
        "set_exclude": [
          "package"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7004341781139374
      },
      {
        "question verbose": "What is to railway ",
        "b": "railway",
        "expected answer": [
          "railroad"
        ],
        "predictions": [
          {
            "score": 0.8055946826934814,
            "answer": "railroad",
            "hit": true
          },
          {
            "score": 0.7406110763549805,
            "answer": "rail",
            "hit": false
          },
          {
            "score": 0.7387831807136536,
            "answer": "coal",
            "hit": false
          },
          {
            "score": 0.733784556388855,
            "answer": "transportation",
            "hit": false
          },
          {
            "score": 0.7334358096122742,
            "answer": "trains",
            "hit": false
          },
          {
            "score": 0.7253110408782959,
            "answer": "rural",
            "hit": false
          }
        ],
        "set_exclude": [
          "railway"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8055946826934814
      },
      {
        "question verbose": "What is to rational ",
        "b": "rational",
        "expected answer": [
          "logical",
          "coherent",
          "reasonable",
          "sane"
        ],
        "predictions": [
          {
            "score": 0.7829484939575195,
            "answer": "irrational",
            "hit": false
          },
          {
            "score": 0.7280533313751221,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.7262251377105713,
            "answer": "sane",
            "hit": true
          },
          {
            "score": 0.7205294370651245,
            "answer": "reasoning",
            "hit": false
          },
          {
            "score": 0.7195913791656494,
            "answer": "semantic",
            "hit": false
          },
          {
            "score": 0.7178558111190796,
            "answer": "logical",
            "hit": true
          }
        ],
        "set_exclude": [
          "rational"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7178557515144348
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "sensible"
        ],
        "predictions": [
          {
            "score": 0.8120741248130798,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.7904225587844849,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.7792403697967529,
            "answer": "reason",
            "hit": false
          },
          {
            "score": 0.7781728506088257,
            "answer": "necessary",
            "hit": false
          },
          {
            "score": 0.7740446329116821,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.7738626003265381,
            "answer": "feasible",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7643158137798309
      },
      {
        "question verbose": "What is to rock ",
        "b": "rock",
        "expected answer": [
          "stone"
        ],
        "predictions": [
          {
            "score": 0.7179334163665771,
            "answer": "rocks",
            "hit": false
          },
          {
            "score": 0.7108449339866638,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.7055965662002563,
            "answer": "brock",
            "hit": false
          },
          {
            "score": 0.6968145370483398,
            "answer": "rocking",
            "hit": false
          },
          {
            "score": 0.6869300007820129,
            "answer": "punk",
            "hit": false
          },
          {
            "score": 0.6835402846336365,
            "answer": "climbing",
            "hit": false
          }
        ],
        "set_exclude": [
          "rock"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6696159690618515
      },
      {
        "question verbose": "What is to sofa ",
        "b": "sofa",
        "expected answer": [
          "couch",
          "lounge"
        ],
        "predictions": [
          {
            "score": 0.7751119136810303,
            "answer": "mattress",
            "hit": false
          },
          {
            "score": 0.7624173164367676,
            "answer": "patio",
            "hit": false
          },
          {
            "score": 0.7610421776771545,
            "answer": "fireplace",
            "hit": false
          },
          {
            "score": 0.7595638632774353,
            "answer": "furniture",
            "hit": false
          },
          {
            "score": 0.7537867426872253,
            "answer": "porch",
            "hit": false
          },
          {
            "score": 0.7515875697135925,
            "answer": "bedroom",
            "hit": false
          }
        ],
        "set_exclude": [
          "sofa"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7296201884746552
      },
      {
        "question verbose": "What is to style ",
        "b": "style",
        "expected answer": [
          "manner",
          "mode",
          "fashion",
          "way"
        ],
        "predictions": [
          {
            "score": 0.7678921818733215,
            "answer": "styled",
            "hit": false
          },
          {
            "score": 0.7558375597000122,
            "answer": "styling",
            "hit": false
          },
          {
            "score": 0.7529526352882385,
            "answer": "fashion",
            "hit": true
          },
          {
            "score": 0.7312176823616028,
            "answer": "styles",
            "hit": false
          },
          {
            "score": 0.7175887823104858,
            "answer": "manner",
            "hit": true
          },
          {
            "score": 0.7164731025695801,
            "answer": "aesthetics",
            "hit": false
          }
        ],
        "set_exclude": [
          "style"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7175888270139694
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 16,
      "accuracy": 0.125
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L08 [synonyms - exact].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "a7a5e467-8b47-40f7-91aa-ca8c2a09671b",
      "timestamp": "2025-05-17T17:12:48.072433"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to after ",
        "b": "after",
        "expected answer": [
          "before",
          "earlier",
          "previously"
        ],
        "predictions": [
          {
            "score": 0.821750819683075,
            "answer": "since",
            "hit": false
          },
          {
            "score": 0.8185757994651794,
            "answer": "while",
            "hit": false
          },
          {
            "score": 0.8036541938781738,
            "answer": "when",
            "hit": false
          },
          {
            "score": 0.7838274240493774,
            "answer": "however",
            "hit": false
          },
          {
            "score": 0.7823946475982666,
            "answer": "upon",
            "hit": false
          },
          {
            "score": 0.7740120887756348,
            "answer": "they",
            "hit": false
          }
        ],
        "set_exclude": [
          "after"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7088987827301025
      },
      {
        "question verbose": "What is to ahead ",
        "b": "ahead",
        "expected answer": [
          "behind",
          "rear",
          "after",
          "tail",
          "beforehand"
        ],
        "predictions": [
          {
            "score": 0.7401569485664368,
            "answer": "beforehand",
            "hit": true
          },
          {
            "score": 0.7183917164802551,
            "answer": "alongside",
            "hit": false
          },
          {
            "score": 0.7133429646492004,
            "answer": "amid",
            "hit": false
          },
          {
            "score": 0.7081928253173828,
            "answer": "behind",
            "hit": true
          },
          {
            "score": 0.70169597864151,
            "answer": "trailing",
            "hit": false
          },
          {
            "score": 0.7002154588699341,
            "answer": "amidst",
            "hit": false
          }
        ],
        "set_exclude": [
          "ahead"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7081928104162216
      },
      {
        "question verbose": "What is to anterior ",
        "b": "anterior",
        "expected answer": [
          "posterior"
        ],
        "predictions": [
          {
            "score": 0.8660632967948914,
            "answer": "posterior",
            "hit": true
          },
          {
            "score": 0.8296973705291748,
            "answer": "medial",
            "hit": false
          },
          {
            "score": 0.8054372072219849,
            "answer": "dorsal",
            "hit": false
          },
          {
            "score": 0.7922970652580261,
            "answer": "lateral",
            "hit": false
          },
          {
            "score": 0.7667685747146606,
            "answer": "abdomen",
            "hit": false
          },
          {
            "score": 0.7614213228225708,
            "answer": "abdominal",
            "hit": false
          }
        ],
        "set_exclude": [
          "anterior"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8660632967948914
      },
      {
        "question verbose": "What is to before ",
        "b": "before",
        "expected answer": [
          "after",
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "ahead"
        ],
        "predictions": [
          {
            "score": 0.7803183197975159,
            "answer": "without",
            "hit": false
          },
          {
            "score": 0.7778005599975586,
            "answer": "beforehand",
            "hit": false
          },
          {
            "score": 0.7624753713607788,
            "answer": "only",
            "hit": false
          },
          {
            "score": 0.7618842124938965,
            "answer": "this",
            "hit": false
          },
          {
            "score": 0.7463732957839966,
            "answer": "make",
            "hit": false
          },
          {
            "score": 0.7404968738555908,
            "answer": "will",
            "hit": false
          }
        ],
        "set_exclude": [
          "before"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7088749557733536
      },
      {
        "question verbose": "What is to beginning ",
        "b": "beginning",
        "expected answer": [
          "end",
          "terminal",
          "ending",
          "last",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.7536229491233826,
            "answer": "begun",
            "hit": false
          },
          {
            "score": 0.7526935338973999,
            "answer": "beginnings",
            "hit": false
          },
          {
            "score": 0.751213550567627,
            "answer": "begins",
            "hit": false
          },
          {
            "score": 0.7411723136901855,
            "answer": "begin",
            "hit": false
          },
          {
            "score": 0.7353528738021851,
            "answer": "began",
            "hit": false
          },
          {
            "score": 0.733535647392273,
            "answer": "continuing",
            "hit": false
          }
        ],
        "set_exclude": [
          "beginning"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7007773220539093
      },
      {
        "question verbose": "What is to dead ",
        "b": "dead",
        "expected answer": [
          "alive",
          "living",
          "live"
        ],
        "predictions": [
          {
            "score": 0.7740603685379028,
            "answer": "death",
            "hit": false
          },
          {
            "score": 0.7558009028434753,
            "answer": "deadline",
            "hit": false
          },
          {
            "score": 0.7432248592376709,
            "answer": "corpse",
            "hit": false
          },
          {
            "score": 0.7406802773475647,
            "answer": "deceased",
            "hit": false
          },
          {
            "score": 0.738017201423645,
            "answer": "lifeless",
            "hit": false
          },
          {
            "score": 0.7334578633308411,
            "answer": "dying",
            "hit": false
          }
        ],
        "set_exclude": [
          "dead"
        ],
        "rank": 30,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7039875984191895
      },
      {
        "question verbose": "What is to dive ",
        "b": "dive",
        "expected answer": [
          "emerge"
        ],
        "predictions": [
          {
            "score": 0.8633295297622681,
            "answer": "diving",
            "hit": false
          },
          {
            "score": 0.7561765909194946,
            "answer": "plunge",
            "hit": false
          },
          {
            "score": 0.7520880103111267,
            "answer": "dove",
            "hit": false
          },
          {
            "score": 0.7234927415847778,
            "answer": "divers",
            "hit": false
          },
          {
            "score": 0.7222412824630737,
            "answer": "explore",
            "hit": false
          },
          {
            "score": 0.7181128263473511,
            "answer": "dip",
            "hit": false
          }
        ],
        "set_exclude": [
          "dive"
        ],
        "rank": 4886,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6297412514686584
      },
      {
        "question verbose": "What is to fall ",
        "b": "fall",
        "expected answer": [
          "rise",
          "upward",
          "climb"
        ],
        "predictions": [
          {
            "score": 0.759842038154602,
            "answer": "autumn",
            "hit": false
          },
          {
            "score": 0.7450997829437256,
            "answer": "spring",
            "hit": false
          },
          {
            "score": 0.7449447512626648,
            "answer": "winter",
            "hit": false
          },
          {
            "score": 0.7415788173675537,
            "answer": "falling",
            "hit": false
          },
          {
            "score": 0.7333085536956787,
            "answer": "fallen",
            "hit": false
          },
          {
            "score": 0.7326440215110779,
            "answer": "fell",
            "hit": false
          }
        ],
        "set_exclude": [
          "fall"
        ],
        "rank": 26,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.677326038479805
      },
      {
        "question verbose": "What is to first ",
        "b": "first",
        "expected answer": [
          "last",
          "end",
          "terminal",
          "ending",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.7847211360931396,
            "answer": "firstly",
            "hit": false
          },
          {
            "score": 0.7320217490196228,
            "answer": "sixth",
            "hit": false
          },
          {
            "score": 0.7180464863777161,
            "answer": "after",
            "hit": false
          },
          {
            "score": 0.7129994630813599,
            "answer": "initially",
            "hit": false
          },
          {
            "score": 0.7009695172309875,
            "answer": "while",
            "hit": false
          },
          {
            "score": 0.6993913650512695,
            "answer": "since",
            "hit": false
          }
        ],
        "set_exclude": [
          "first"
        ],
        "rank": 158,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6495772451162338
      },
      {
        "question verbose": "What is to input ",
        "b": "input",
        "expected answer": [
          "output"
        ],
        "predictions": [
          {
            "score": 0.8220339417457581,
            "answer": "inputs",
            "hit": false
          },
          {
            "score": 0.7740600109100342,
            "answer": "outputs",
            "hit": false
          },
          {
            "score": 0.7464615106582642,
            "answer": "output",
            "hit": true
          },
          {
            "score": 0.734726071357727,
            "answer": "feedback",
            "hit": false
          },
          {
            "score": 0.7344596982002258,
            "answer": "parameters",
            "hit": false
          },
          {
            "score": 0.7249842286109924,
            "answer": "stimuli",
            "hit": false
          }
        ],
        "set_exclude": [
          "input"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7464615404605865
      },
      {
        "question verbose": "What is to inside ",
        "b": "inside",
        "expected answer": [
          "outside",
          "exterior",
          "out"
        ],
        "predictions": [
          {
            "score": 0.7885589599609375,
            "answer": "outside",
            "hit": true
          },
          {
            "score": 0.7627965807914734,
            "answer": "within",
            "hit": false
          },
          {
            "score": 0.7452086806297302,
            "answer": "underneath",
            "hit": false
          },
          {
            "score": 0.7279569506645203,
            "answer": "around",
            "hit": false
          },
          {
            "score": 0.7219364643096924,
            "answer": "beneath",
            "hit": false
          },
          {
            "score": 0.7170931696891785,
            "answer": "every",
            "hit": false
          }
        ],
        "set_exclude": [
          "inside"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7885589003562927
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "external",
          "outer",
          "outside"
        ],
        "predictions": [
          {
            "score": 0.7543777227401733,
            "answer": "internally",
            "hit": false
          },
          {
            "score": 0.7514013648033142,
            "answer": "external",
            "hit": true
          },
          {
            "score": 0.7450076937675476,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.7220339775085449,
            "answer": "intra",
            "hit": false
          },
          {
            "score": 0.7055644392967224,
            "answer": "metaphysical",
            "hit": false
          },
          {
            "score": 0.7039737701416016,
            "answer": "micro",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7514013648033142
      },
      {
        "question verbose": "What is to mortal ",
        "b": "mortal",
        "expected answer": [
          "immortal"
        ],
        "predictions": [
          {
            "score": 0.7472248077392578,
            "answer": "mortality",
            "hit": false
          },
          {
            "score": 0.7444337606430054,
            "answer": "immortal",
            "hit": true
          },
          {
            "score": 0.7261785864830017,
            "answer": "divine",
            "hit": false
          },
          {
            "score": 0.7258808612823486,
            "answer": "miserable",
            "hit": false
          },
          {
            "score": 0.7188907861709595,
            "answer": "human",
            "hit": false
          },
          {
            "score": 0.7174597978591919,
            "answer": "pathetic",
            "hit": false
          }
        ],
        "set_exclude": [
          "mortal"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7444338202476501
      },
      {
        "question verbose": "What is to occupied ",
        "b": "occupied",
        "expected answer": [
          "vacant",
          "free"
        ],
        "predictions": [
          {
            "score": 0.786322832107544,
            "answer": "occupy",
            "hit": false
          },
          {
            "score": 0.780568540096283,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.7714020013809204,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.7461341023445129,
            "answer": "inhabited",
            "hit": false
          },
          {
            "score": 0.7341396808624268,
            "answer": "vacant",
            "hit": true
          },
          {
            "score": 0.7331967353820801,
            "answer": "occupation",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupied"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7341396510601044
      },
      {
        "question verbose": "What is to over ",
        "b": "over",
        "expected answer": [
          "under",
          "below",
          "beneath"
        ],
        "predictions": [
          {
            "score": 0.789215624332428,
            "answer": "under",
            "hit": true
          },
          {
            "score": 0.7533131837844849,
            "answer": "for",
            "hit": false
          },
          {
            "score": 0.7444487810134888,
            "answer": "this",
            "hit": false
          },
          {
            "score": 0.7420332431793213,
            "answer": "into",
            "hit": false
          },
          {
            "score": 0.7364689707756042,
            "answer": "kill",
            "hit": false
          },
          {
            "score": 0.7326539158821106,
            "answer": "need",
            "hit": false
          }
        ],
        "set_exclude": [
          "over"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.789215624332428
      },
      {
        "question verbose": "What is to previously ",
        "b": "previously",
        "expected answer": [
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "after",
          "subsequent"
        ],
        "predictions": [
          {
            "score": 0.799626350402832,
            "answer": "originally",
            "hit": false
          },
          {
            "score": 0.7890599966049194,
            "answer": "recently",
            "hit": false
          },
          {
            "score": 0.7428100109100342,
            "answer": "subsequently",
            "hit": true
          },
          {
            "score": 0.7409423589706421,
            "answer": "traditionally",
            "hit": false
          },
          {
            "score": 0.7337545156478882,
            "answer": "formerly",
            "hit": false
          },
          {
            "score": 0.7251783609390259,
            "answer": "historically",
            "hit": false
          }
        ],
        "set_exclude": [
          "previously"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7428100556135178
      },
      {
        "question verbose": "What is to proceed ",
        "b": "proceed",
        "expected answer": [
          "retreat",
          "return"
        ],
        "predictions": [
          {
            "score": 0.8242760896682739,
            "answer": "proceeds",
            "hit": false
          },
          {
            "score": 0.7780479192733765,
            "answer": "proceeded",
            "hit": false
          },
          {
            "score": 0.7559700608253479,
            "answer": "proceeding",
            "hit": false
          },
          {
            "score": 0.7307464480400085,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.727757453918457,
            "answer": "progresses",
            "hit": false
          },
          {
            "score": 0.7186765074729919,
            "answer": "ultimately",
            "hit": false
          }
        ],
        "set_exclude": [
          "proceed"
        ],
        "rank": 5617,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6410361379384995
      },
      {
        "question verbose": "What is to rise ",
        "b": "rise",
        "expected answer": [
          "sink",
          "drop",
          "fall"
        ],
        "predictions": [
          {
            "score": 0.7417104244232178,
            "answer": "rises",
            "hit": false
          },
          {
            "score": 0.7363256216049194,
            "answer": "risen",
            "hit": false
          },
          {
            "score": 0.7245484590530396,
            "answer": "rising",
            "hit": false
          },
          {
            "score": 0.7240746021270752,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7182345986366272,
            "answer": "emergence",
            "hit": false
          },
          {
            "score": 0.7084035873413086,
            "answer": "surge",
            "hit": false
          }
        ],
        "set_exclude": [
          "rise"
        ],
        "rank": 125,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6097914204001427
      },
      {
        "question verbose": "What is to south ",
        "b": "south",
        "expected answer": [
          "north"
        ],
        "predictions": [
          {
            "score": 0.8622035384178162,
            "answer": "southeast",
            "hit": false
          },
          {
            "score": 0.8575554490089417,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.8542894124984741,
            "answer": "northeast",
            "hit": false
          },
          {
            "score": 0.776483952999115,
            "answer": "north",
            "hit": true
          },
          {
            "score": 0.7664741277694702,
            "answer": "southwest",
            "hit": false
          },
          {
            "score": 0.7592296600341797,
            "answer": "inland",
            "hit": false
          }
        ],
        "set_exclude": [
          "south"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7764840126037598
      },
      {
        "question verbose": "What is to southeast ",
        "b": "southeast",
        "expected answer": [
          "southwest",
          "northeast"
        ],
        "predictions": [
          {
            "score": 0.9245654940605164,
            "answer": "northeast",
            "hit": true
          },
          {
            "score": 0.9196772575378418,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.8602389693260193,
            "answer": "south",
            "hit": false
          },
          {
            "score": 0.7871131896972656,
            "answer": "southwest",
            "hit": true
          },
          {
            "score": 0.7765281200408936,
            "answer": "east",
            "hit": false
          },
          {
            "score": 0.775270402431488,
            "answer": "inland",
            "hit": false
          }
        ],
        "set_exclude": [
          "southeast"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7871131896972656
      },
      {
        "question verbose": "What is to toward ",
        "b": "toward",
        "expected answer": [
          "away",
          "off",
          "forth",
          "aside"
        ],
        "predictions": [
          {
            "score": 0.8062304258346558,
            "answer": "towards",
            "hit": false
          },
          {
            "score": 0.7179300785064697,
            "answer": "leans",
            "hit": false
          },
          {
            "score": 0.7165156602859497,
            "answer": "upward",
            "hit": false
          },
          {
            "score": 0.710561215877533,
            "answer": "downward",
            "hit": false
          },
          {
            "score": 0.7102741003036499,
            "answer": "steadily",
            "hit": false
          },
          {
            "score": 0.7097619771957397,
            "answer": "regarding",
            "hit": false
          }
        ],
        "set_exclude": [
          "toward"
        ],
        "rank": 139,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6777419000864029
      },
      {
        "question verbose": "What is to true ",
        "b": "true",
        "expected answer": [
          "false",
          "incorrect",
          "wrong",
          "mistaken"
        ],
        "predictions": [
          {
            "score": 0.7465090155601501,
            "answer": "real",
            "hit": false
          },
          {
            "score": 0.7410033345222473,
            "answer": "genuine",
            "hit": false
          },
          {
            "score": 0.7319775819778442,
            "answer": "accurate",
            "hit": false
          },
          {
            "score": 0.7210714817047119,
            "answer": "actual",
            "hit": false
          },
          {
            "score": 0.7206467390060425,
            "answer": "false",
            "hit": true
          },
          {
            "score": 0.7107192277908325,
            "answer": "authentic",
            "hit": false
          }
        ],
        "set_exclude": [
          "true"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7206467688083649
      },
      {
        "question verbose": "What is to west ",
        "b": "west",
        "expected answer": [
          "east"
        ],
        "predictions": [
          {
            "score": 0.829268217086792,
            "answer": "east",
            "hit": true
          },
          {
            "score": 0.7691486477851868,
            "answer": "north",
            "hit": false
          },
          {
            "score": 0.7503343820571899,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.7390826344490051,
            "answer": "southwest",
            "hit": false
          },
          {
            "score": 0.7348980903625488,
            "answer": "northeast",
            "hit": false
          },
          {
            "score": 0.7309430837631226,
            "answer": "southeast",
            "hit": false
          }
        ],
        "set_exclude": [
          "west"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.829268217086792
      }
    ],
    "result": {
      "cnt_questions_correct": 6,
      "cnt_questions_total": 23,
      "accuracy": 0.2608695652173913
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L10 [antonyms - binary].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "b2cd91a4-ff03-403f-8349-b14f7d4415b7",
      "timestamp": "2025-05-17T17:12:48.125594"
    }
  }
]