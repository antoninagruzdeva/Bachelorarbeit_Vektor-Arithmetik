[
  {
    "details": [
      {
        "question verbose": "What is to album ",
        "b": "album",
        "expected answer": [
          "albums"
        ],
        "predictions": [
          {
            "score": 0.896033525466919,
            "answer": "albums",
            "hit": true
          },
          {
            "score": 0.7832365036010742,
            "answer": "songs",
            "hit": false
          },
          {
            "score": 0.761835515499115,
            "answer": "soundtrack",
            "hit": false
          },
          {
            "score": 0.7527031898498535,
            "answer": "lyrics",
            "hit": false
          },
          {
            "score": 0.7483131885528564,
            "answer": "beatles",
            "hit": false
          },
          {
            "score": 0.7474666833877563,
            "answer": "vinyl",
            "hit": false
          }
        ],
        "set_exclude": [
          "album"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.896033525466919,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to application ",
        "b": "application",
        "expected answer": [
          "applications"
        ],
        "predictions": [
          {
            "score": 0.787334680557251,
            "answer": "applications",
            "hit": true
          },
          {
            "score": 0.7482214570045471,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7348519563674927,
            "answer": "payment",
            "hit": false
          },
          {
            "score": 0.734330415725708,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.7326620817184448,
            "answer": "applicants",
            "hit": false
          },
          {
            "score": 0.7177733778953552,
            "answer": "directory",
            "hit": false
          }
        ],
        "set_exclude": [
          "application"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7873347103595734,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to area ",
        "b": "area",
        "expected answer": [
          "areas"
        ],
        "predictions": [
          {
            "score": 0.7953037619590759,
            "answer": "areas",
            "hit": true
          },
          {
            "score": 0.7600023746490479,
            "answer": "vicinity",
            "hit": false
          },
          {
            "score": 0.7337040901184082,
            "answer": "regions",
            "hit": false
          },
          {
            "score": 0.7194803953170776,
            "answer": "corridor",
            "hit": false
          },
          {
            "score": 0.7164100408554077,
            "answer": "territory",
            "hit": false
          },
          {
            "score": 0.7122272253036499,
            "answer": "neighbourhood",
            "hit": false
          }
        ],
        "set_exclude": [
          "area"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7953037619590759,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "cars"
        ],
        "predictions": [
          {
            "score": 0.7539123296737671,
            "answer": "carol",
            "hit": false
          },
          {
            "score": 0.743114709854126,
            "answer": "carbon",
            "hit": false
          },
          {
            "score": 0.7410986423492432,
            "answer": "carroll",
            "hit": false
          },
          {
            "score": 0.7396153211593628,
            "answer": "carrie",
            "hit": false
          },
          {
            "score": 0.7378537654876709,
            "answer": "caroline",
            "hit": false
          },
          {
            "score": 0.7370608448982239,
            "answer": "carolina",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7347415685653687,
        "b in neighbourhood of b_prime": 42,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "colleges"
        ],
        "predictions": [
          {
            "score": 0.8130283951759338,
            "answer": "colleges",
            "hit": true
          },
          {
            "score": 0.759343683719635,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.7561167478561401,
            "answer": "student",
            "hit": false
          },
          {
            "score": 0.7542060613632202,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.750249981880188,
            "answer": "universities",
            "hit": false
          },
          {
            "score": 0.7487351894378662,
            "answer": "graduate",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8130284547805786,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to council ",
        "b": "council",
        "expected answer": [
          "councils"
        ],
        "predictions": [
          {
            "score": 0.815468430519104,
            "answer": "councils",
            "hit": true
          },
          {
            "score": 0.7329786419868469,
            "answer": "association",
            "hit": false
          },
          {
            "score": 0.7323514223098755,
            "answer": "mayor",
            "hit": false
          },
          {
            "score": 0.7320964336395264,
            "answer": "committee",
            "hit": false
          },
          {
            "score": 0.7297000288963318,
            "answer": "coalition",
            "hit": false
          },
          {
            "score": 0.7237213850021362,
            "answer": "parliament",
            "hit": false
          }
        ],
        "set_exclude": [
          "council"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.815468430519104,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to customer ",
        "b": "customer",
        "expected answer": [
          "customers"
        ],
        "predictions": [
          {
            "score": 0.8178746700286865,
            "answer": "customers",
            "hit": true
          },
          {
            "score": 0.7766937613487244,
            "answer": "custom",
            "hit": false
          },
          {
            "score": 0.7654672861099243,
            "answer": "consumer",
            "hit": false
          },
          {
            "score": 0.7565128207206726,
            "answer": "employee",
            "hit": false
          },
          {
            "score": 0.7558681964874268,
            "answer": "sales",
            "hit": false
          },
          {
            "score": 0.7506667375564575,
            "answer": "consumers",
            "hit": false
          }
        ],
        "set_exclude": [
          "customer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8178746998310089,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to day ",
        "b": "day",
        "expected answer": [
          "days"
        ],
        "predictions": [
          {
            "score": 0.7697474360466003,
            "answer": "days",
            "hit": true
          },
          {
            "score": 0.7367237210273743,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.734959065914154,
            "answer": "morning",
            "hit": false
          },
          {
            "score": 0.7300541400909424,
            "answer": "friday",
            "hit": false
          },
          {
            "score": 0.7285887002944946,
            "answer": "tuesday",
            "hit": false
          },
          {
            "score": 0.7246989011764526,
            "answer": "wednesday",
            "hit": false
          }
        ],
        "set_exclude": [
          "day"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7697474956512451,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to death ",
        "b": "death",
        "expected answer": [
          "deaths"
        ],
        "predictions": [
          {
            "score": 0.8151264786720276,
            "answer": "deaths",
            "hit": true
          },
          {
            "score": 0.7815893888473511,
            "answer": "died",
            "hit": false
          },
          {
            "score": 0.7699320316314697,
            "answer": "dead",
            "hit": false
          },
          {
            "score": 0.7691714763641357,
            "answer": "demise",
            "hit": false
          },
          {
            "score": 0.7666382789611816,
            "answer": "mortality",
            "hit": false
          },
          {
            "score": 0.7622627019882202,
            "answer": "birth",
            "hit": false
          }
        ],
        "set_exclude": [
          "death"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8151264786720276,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to department ",
        "b": "department",
        "expected answer": [
          "departments"
        ],
        "predictions": [
          {
            "score": 0.8159469962120056,
            "answer": "dept",
            "hit": false
          },
          {
            "score": 0.8096271753311157,
            "answer": "departments",
            "hit": true
          },
          {
            "score": 0.779728889465332,
            "answer": "secretary",
            "hit": false
          },
          {
            "score": 0.7789691686630249,
            "answer": "government",
            "hit": false
          },
          {
            "score": 0.7679333686828613,
            "answer": "office",
            "hit": false
          },
          {
            "score": 0.7560429573059082,
            "answer": "director",
            "hit": false
          }
        ],
        "set_exclude": [
          "department"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8096271753311157,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to development ",
        "b": "development",
        "expected answer": [
          "developments"
        ],
        "predictions": [
          {
            "score": 0.7821511030197144,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.7778234481811523,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.765015721321106,
            "answer": "building",
            "hit": false
          },
          {
            "score": 0.762765645980835,
            "answer": "developmental",
            "hit": false
          },
          {
            "score": 0.7562825679779053,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7525767087936401,
            "answer": "construction",
            "hit": false
          }
        ],
        "set_exclude": [
          "development"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7507080733776093,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to difference ",
        "b": "difference",
        "expected answer": [
          "differences"
        ],
        "predictions": [
          {
            "score": 0.7761588096618652,
            "answer": "differences",
            "hit": true
          },
          {
            "score": 0.7525779604911804,
            "answer": "comparison",
            "hit": false
          },
          {
            "score": 0.7415878772735596,
            "answer": "distinction",
            "hit": false
          },
          {
            "score": 0.7413896918296814,
            "answer": "different",
            "hit": false
          },
          {
            "score": 0.7404131889343262,
            "answer": "distinguishes",
            "hit": false
          },
          {
            "score": 0.7354598045349121,
            "answer": "differed",
            "hit": false
          }
        ],
        "set_exclude": [
          "difference"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7761588096618652,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to director ",
        "b": "director",
        "expected answer": [
          "directors"
        ],
        "predictions": [
          {
            "score": 0.8069034218788147,
            "answer": "directors",
            "hit": true
          },
          {
            "score": 0.7826780080795288,
            "answer": "filmmaker",
            "hit": false
          },
          {
            "score": 0.7781148552894592,
            "answer": "secretary",
            "hit": false
          },
          {
            "score": 0.7717791795730591,
            "answer": "executive",
            "hit": false
          },
          {
            "score": 0.7578674554824829,
            "answer": "founder",
            "hit": false
          },
          {
            "score": 0.7575395107269287,
            "answer": "coordinator",
            "hit": false
          }
        ],
        "set_exclude": [
          "director"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8069034516811371,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to event ",
        "b": "event",
        "expected answer": [
          "events"
        ],
        "predictions": [
          {
            "score": 0.8219681978225708,
            "answer": "events",
            "hit": true
          },
          {
            "score": 0.741950511932373,
            "answer": "fest",
            "hit": false
          },
          {
            "score": 0.7351421117782593,
            "answer": "message",
            "hit": false
          },
          {
            "score": 0.729135274887085,
            "answer": "server",
            "hit": false
          },
          {
            "score": 0.7288659811019897,
            "answer": "result",
            "hit": false
          },
          {
            "score": 0.7279431819915771,
            "answer": "experience",
            "hit": false
          }
        ],
        "set_exclude": [
          "event"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8219681978225708,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to example ",
        "b": "example",
        "expected answer": [
          "examples"
        ],
        "predictions": [
          {
            "score": 0.8126710653305054,
            "answer": "examples",
            "hit": true
          },
          {
            "score": 0.763823390007019,
            "answer": "typical",
            "hit": false
          },
          {
            "score": 0.752316951751709,
            "answer": "sample",
            "hit": false
          },
          {
            "score": 0.7454495429992676,
            "answer": "instance",
            "hit": false
          },
          {
            "score": 0.7437238693237305,
            "answer": "analogy",
            "hit": false
          },
          {
            "score": 0.7373923063278198,
            "answer": "illustration",
            "hit": false
          }
        ],
        "set_exclude": [
          "example"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8126711249351501,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to fact ",
        "b": "fact",
        "expected answer": [
          "facts"
        ],
        "predictions": [
          {
            "score": 0.7310101985931396,
            "answer": "truth",
            "hit": false
          },
          {
            "score": 0.7238122224807739,
            "answer": "factual",
            "hit": false
          },
          {
            "score": 0.7212287187576294,
            "answer": "facts",
            "hit": true
          },
          {
            "score": 0.7190836668014526,
            "answer": "factors",
            "hit": false
          },
          {
            "score": 0.7061466574668884,
            "answer": "myth",
            "hit": false
          },
          {
            "score": 0.7032844424247742,
            "answer": "factor",
            "hit": false
          }
        ],
        "set_exclude": [
          "fact"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7212287336587906,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to friend ",
        "b": "friend",
        "expected answer": [
          "friends"
        ],
        "predictions": [
          {
            "score": 0.762475311756134,
            "answer": "friends",
            "hit": true
          },
          {
            "score": 0.7618294954299927,
            "answer": "buddy",
            "hit": false
          },
          {
            "score": 0.7503466606140137,
            "answer": "friendship",
            "hit": false
          },
          {
            "score": 0.7400286793708801,
            "answer": "friendships",
            "hit": false
          },
          {
            "score": 0.7309232950210571,
            "answer": "lover",
            "hit": false
          },
          {
            "score": 0.724636435508728,
            "answer": "colleague",
            "hit": false
          }
        ],
        "set_exclude": [
          "friend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.762475311756134,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "gods"
        ],
        "predictions": [
          {
            "score": 0.7506275177001953,
            "answer": "gods",
            "hit": true
          },
          {
            "score": 0.7503312230110168,
            "answer": "goddess",
            "hit": false
          },
          {
            "score": 0.7422109842300415,
            "answer": "divine",
            "hit": false
          },
          {
            "score": 0.7373530268669128,
            "answer": "holy",
            "hit": false
          },
          {
            "score": 0.7314649820327759,
            "answer": "righteous",
            "hit": false
          },
          {
            "score": 0.729637622833252,
            "answer": "jesus",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7506275177001953,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to government ",
        "b": "government",
        "expected answer": [
          "governments"
        ],
        "predictions": [
          {
            "score": 0.8464515805244446,
            "answer": "governmental",
            "hit": false
          },
          {
            "score": 0.8277266621589661,
            "answer": "governments",
            "hit": true
          },
          {
            "score": 0.780159592628479,
            "answer": "liberal",
            "hit": false
          },
          {
            "score": 0.7789691686630249,
            "answer": "department",
            "hit": false
          },
          {
            "score": 0.7755388021469116,
            "answer": "govern",
            "hit": false
          },
          {
            "score": 0.7729873657226562,
            "answer": "foreign",
            "hit": false
          }
        ],
        "set_exclude": [
          "government"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8277266919612885,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to hour ",
        "b": "hour",
        "expected answer": [
          "hours"
        ],
        "predictions": [
          {
            "score": 0.8259317278862,
            "answer": "minute",
            "hit": false
          },
          {
            "score": 0.8255077600479126,
            "answer": "hours",
            "hit": true
          },
          {
            "score": 0.7514357566833496,
            "answer": "hourly",
            "hit": false
          },
          {
            "score": 0.7444010972976685,
            "answer": "morning",
            "hit": false
          },
          {
            "score": 0.7364569902420044,
            "answer": "dozen",
            "hit": false
          },
          {
            "score": 0.7360482215881348,
            "answer": "afternoon",
            "hit": false
          }
        ],
        "set_exclude": [
          "hour"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.825507789850235,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to idea ",
        "b": "idea",
        "expected answer": [
          "ideas"
        ],
        "predictions": [
          {
            "score": 0.785510778427124,
            "answer": "ideas",
            "hit": true
          },
          {
            "score": 0.758809506893158,
            "answer": "notion",
            "hit": false
          },
          {
            "score": 0.7492967247962952,
            "answer": "concept",
            "hit": false
          },
          {
            "score": 0.7368918061256409,
            "answer": "notions",
            "hit": false
          },
          {
            "score": 0.7365989685058594,
            "answer": "think",
            "hit": false
          },
          {
            "score": 0.7311751842498779,
            "answer": "thinking",
            "hit": false
          }
        ],
        "set_exclude": [
          "idea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.785510778427124,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to language ",
        "b": "language",
        "expected answer": [
          "languages"
        ],
        "predictions": [
          {
            "score": 0.7897580862045288,
            "answer": "speaking",
            "hit": false
          },
          {
            "score": 0.7882921695709229,
            "answer": "languages",
            "hit": true
          },
          {
            "score": 0.7699486613273621,
            "answer": "linguistic",
            "hit": false
          },
          {
            "score": 0.740167498588562,
            "answer": "translation",
            "hit": false
          },
          {
            "score": 0.7270709276199341,
            "answer": "translations",
            "hit": false
          },
          {
            "score": 0.7259869575500488,
            "answer": "translator",
            "hit": false
          }
        ],
        "set_exclude": [
          "language"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7882921397686005,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to law ",
        "b": "law",
        "expected answer": [
          "laws"
        ],
        "predictions": [
          {
            "score": 0.7642370462417603,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.7628908157348633,
            "answer": "laws",
            "hit": true
          },
          {
            "score": 0.7518477439880371,
            "answer": "lawyer",
            "hit": false
          },
          {
            "score": 0.7353112697601318,
            "answer": "legal",
            "hit": false
          },
          {
            "score": 0.7256250381469727,
            "answer": "court",
            "hit": false
          },
          {
            "score": 0.7240984439849854,
            "answer": "will",
            "hit": false
          }
        ],
        "set_exclude": [
          "law"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7628907561302185,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "members"
        ],
        "predictions": [
          {
            "score": 0.7721220850944519,
            "answer": "members",
            "hit": true
          },
          {
            "score": 0.7577340602874756,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.7467868328094482,
            "answer": "chairman",
            "hit": false
          },
          {
            "score": 0.7212650775909424,
            "answer": "partner",
            "hit": false
          },
          {
            "score": 0.719831109046936,
            "answer": "supporter",
            "hit": false
          },
          {
            "score": 0.71694415807724,
            "answer": "representative",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7721220850944519,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to month ",
        "b": "month",
        "expected answer": [
          "months"
        ],
        "predictions": [
          {
            "score": 0.8066878914833069,
            "answer": "months",
            "hit": true
          },
          {
            "score": 0.7653049230575562,
            "answer": "year",
            "hit": false
          },
          {
            "score": 0.754608690738678,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.7481186985969543,
            "answer": "weeks",
            "hit": false
          },
          {
            "score": 0.7458940744400024,
            "answer": "monthly",
            "hit": false
          },
          {
            "score": 0.7407033443450928,
            "answer": "days",
            "hit": false
          }
        ],
        "set_exclude": [
          "month"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8066878914833069,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to night ",
        "b": "night",
        "expected answer": [
          "nights"
        ],
        "predictions": [
          {
            "score": 0.8782854676246643,
            "answer": "evening",
            "hit": false
          },
          {
            "score": 0.8514196276664734,
            "answer": "nights",
            "hit": true
          },
          {
            "score": 0.8286052942276001,
            "answer": "afternoon",
            "hit": false
          },
          {
            "score": 0.7779662013053894,
            "answer": "weekend",
            "hit": false
          },
          {
            "score": 0.7684661746025085,
            "answer": "evenings",
            "hit": false
          },
          {
            "score": 0.7591622471809387,
            "answer": "daytime",
            "hit": false
          }
        ],
        "set_exclude": [
          "night"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8514196276664734,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to office ",
        "b": "office",
        "expected answer": [
          "offices"
        ],
        "predictions": [
          {
            "score": 0.7892382740974426,
            "answer": "offices",
            "hit": true
          },
          {
            "score": 0.7679333686828613,
            "answer": "department",
            "hit": false
          },
          {
            "score": 0.7391207218170166,
            "answer": "executive",
            "hit": false
          },
          {
            "score": 0.7349541783332825,
            "answer": "senate",
            "hit": false
          },
          {
            "score": 0.7311047315597534,
            "answer": "secretary",
            "hit": false
          },
          {
            "score": 0.7285017967224121,
            "answer": "agency",
            "hit": false
          }
        ],
        "set_exclude": [
          "office"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7892382740974426,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to period ",
        "b": "period",
        "expected answer": [
          "periods"
        ],
        "predictions": [
          {
            "score": 0.8749403953552246,
            "answer": "periods",
            "hit": true
          },
          {
            "score": 0.7362369298934937,
            "answer": "interval",
            "hit": false
          },
          {
            "score": 0.7300937175750732,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.721359133720398,
            "answer": "eras",
            "hit": false
          },
          {
            "score": 0.7204859256744385,
            "answer": "epoch",
            "hit": false
          },
          {
            "score": 0.7115644812583923,
            "answer": "era",
            "hit": false
          }
        ],
        "set_exclude": [
          "period"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.874940425157547,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "players"
        ],
        "predictions": [
          {
            "score": 0.8904734253883362,
            "answer": "players",
            "hit": true
          },
          {
            "score": 0.7460964918136597,
            "answer": "footballer",
            "hit": false
          },
          {
            "score": 0.7446168661117554,
            "answer": "midfielder",
            "hit": false
          },
          {
            "score": 0.743523895740509,
            "answer": "defender",
            "hit": false
          },
          {
            "score": 0.7379502058029175,
            "answer": "user",
            "hit": false
          },
          {
            "score": 0.7316170334815979,
            "answer": "athlete",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8904734253883362,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to population ",
        "b": "population",
        "expected answer": [
          "populations"
        ],
        "predictions": [
          {
            "score": 0.8004253506660461,
            "answer": "populations",
            "hit": true
          },
          {
            "score": 0.749305009841919,
            "answer": "demographic",
            "hit": false
          },
          {
            "score": 0.7458178400993347,
            "answer": "breeding",
            "hit": false
          },
          {
            "score": 0.7410601377487183,
            "answer": "demographics",
            "hit": false
          },
          {
            "score": 0.7405979633331299,
            "answer": "capita",
            "hit": false
          },
          {
            "score": 0.7401821613311768,
            "answer": "immigration",
            "hit": false
          }
        ],
        "set_exclude": [
          "population"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8004252910614014,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to problem ",
        "b": "problem",
        "expected answer": [
          "problems"
        ],
        "predictions": [
          {
            "score": 0.8036221265792847,
            "answer": "problems",
            "hit": true
          },
          {
            "score": 0.7638317942619324,
            "answer": "question",
            "hit": false
          },
          {
            "score": 0.749671995639801,
            "answer": "unfortunately",
            "hit": false
          },
          {
            "score": 0.7482704520225525,
            "answer": "issues",
            "hit": false
          },
          {
            "score": 0.7477623820304871,
            "answer": "dilemma",
            "hit": false
          },
          {
            "score": 0.7463407516479492,
            "answer": "symptoms",
            "hit": false
          }
        ],
        "set_exclude": [
          "problem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8036221861839294,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to product ",
        "b": "product",
        "expected answer": [
          "products"
        ],
        "predictions": [
          {
            "score": 0.7761543989181519,
            "answer": "products",
            "hit": true
          },
          {
            "score": 0.7123503684997559,
            "answer": "component",
            "hit": false
          },
          {
            "score": 0.7107635736465454,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.7049731612205505,
            "answer": "device",
            "hit": false
          },
          {
            "score": 0.7021929025650024,
            "answer": "marketed",
            "hit": false
          },
          {
            "score": 0.7013522386550903,
            "answer": "consequence",
            "hit": false
          }
        ],
        "set_exclude": [
          "product"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7761543691158295,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to resource ",
        "b": "resource",
        "expected answer": [
          "resources"
        ],
        "predictions": [
          {
            "score": 0.7715306878089905,
            "answer": "resources",
            "hit": true
          },
          {
            "score": 0.727355420589447,
            "answer": "nutrient",
            "hit": false
          },
          {
            "score": 0.7241672277450562,
            "answer": "tool",
            "hit": false
          },
          {
            "score": 0.7241299152374268,
            "answer": "cultural",
            "hit": false
          },
          {
            "score": 0.722316324710846,
            "answer": "strategic",
            "hit": false
          },
          {
            "score": 0.7211005687713623,
            "answer": "policy",
            "hit": false
          }
        ],
        "set_exclude": [
          "resource"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7715307474136353,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to river ",
        "b": "river",
        "expected answer": [
          "rivers"
        ],
        "predictions": [
          {
            "score": 0.7090164422988892,
            "answer": "downstream",
            "hit": false
          },
          {
            "score": 0.6997791528701782,
            "answer": "inland",
            "hit": false
          },
          {
            "score": 0.6979342103004456,
            "answer": "paddle",
            "hit": false
          },
          {
            "score": 0.6965648531913757,
            "answer": "creek",
            "hit": false
          },
          {
            "score": 0.6957708597183228,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.69481360912323,
            "answer": "freshwater",
            "hit": false
          }
        ],
        "set_exclude": [
          "river"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6904982477426529,
        "b in neighbourhood of b_prime": 79,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to road ",
        "b": "road",
        "expected answer": [
          "roads"
        ],
        "predictions": [
          {
            "score": 0.8529215455055237,
            "answer": "roads",
            "hit": true
          },
          {
            "score": 0.810370147228241,
            "answer": "roadway",
            "hit": false
          },
          {
            "score": 0.7733492851257324,
            "answer": "highways",
            "hit": false
          },
          {
            "score": 0.7609589695930481,
            "answer": "highway",
            "hit": false
          },
          {
            "score": 0.7433485388755798,
            "answer": "pavement",
            "hit": false
          },
          {
            "score": 0.7345273494720459,
            "answer": "trail",
            "hit": false
          }
        ],
        "set_exclude": [
          "road"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8529215455055237,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to role ",
        "b": "role",
        "expected answer": [
          "roles"
        ],
        "predictions": [
          {
            "score": 0.7800173163414001,
            "answer": "roles",
            "hit": true
          },
          {
            "score": 0.7079049944877625,
            "answer": "relation",
            "hit": false
          },
          {
            "score": 0.700397253036499,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6997756958007812,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.6977609395980835,
            "answer": "pivotal",
            "hit": false
          },
          {
            "score": 0.6961826086044312,
            "answer": "characterization",
            "hit": false
          }
        ],
        "set_exclude": [
          "role"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7800173163414001,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to science ",
        "b": "science",
        "expected answer": [
          "sciences"
        ],
        "predictions": [
          {
            "score": 0.8212045431137085,
            "answer": "scientific",
            "hit": false
          },
          {
            "score": 0.8025476932525635,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.7923707365989685,
            "answer": "scientists",
            "hit": false
          },
          {
            "score": 0.791599690914154,
            "answer": "sci",
            "hit": false
          },
          {
            "score": 0.7795977592468262,
            "answer": "sciences",
            "hit": true
          },
          {
            "score": 0.7689299583435059,
            "answer": "technology",
            "hit": false
          }
        ],
        "set_exclude": [
          "science"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7795977592468262,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to solution ",
        "b": "solution",
        "expected answer": [
          "solutions"
        ],
        "predictions": [
          {
            "score": 0.7976967096328735,
            "answer": "solve",
            "hit": false
          },
          {
            "score": 0.7804320454597473,
            "answer": "solutions",
            "hit": true
          },
          {
            "score": 0.7759805917739868,
            "answer": "remedy",
            "hit": false
          },
          {
            "score": 0.7623357176780701,
            "answer": "solved",
            "hit": false
          },
          {
            "score": 0.7600181102752686,
            "answer": "solving",
            "hit": false
          },
          {
            "score": 0.7410624623298645,
            "answer": "proposal",
            "hit": false
          }
        ],
        "set_exclude": [
          "solution"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7804320454597473,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to song ",
        "b": "song",
        "expected answer": [
          "songs"
        ],
        "predictions": [
          {
            "score": 0.8099334836006165,
            "answer": "songs",
            "hit": true
          },
          {
            "score": 0.7606890797615051,
            "answer": "sings",
            "hit": false
          },
          {
            "score": 0.7606410980224609,
            "answer": "singing",
            "hit": false
          },
          {
            "score": 0.7531391382217407,
            "answer": "sung",
            "hit": false
          },
          {
            "score": 0.7528045177459717,
            "answer": "melody",
            "hit": false
          },
          {
            "score": 0.7403266429901123,
            "answer": "singers",
            "hit": false
          }
        ],
        "set_exclude": [
          "song"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8099335134029388,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to street ",
        "b": "street",
        "expected answer": [
          "streets"
        ],
        "predictions": [
          {
            "score": 0.8230364322662354,
            "answer": "avenue",
            "hit": false
          },
          {
            "score": 0.8070125579833984,
            "answer": "streets",
            "hit": true
          },
          {
            "score": 0.7591180205345154,
            "answer": "boulevard",
            "hit": false
          },
          {
            "score": 0.7367231845855713,
            "answer": "drive",
            "hit": false
          },
          {
            "score": 0.7344898581504822,
            "answer": "sidewalk",
            "hit": false
          },
          {
            "score": 0.7182778120040894,
            "answer": "pavement",
            "hit": false
          }
        ],
        "set_exclude": [
          "street"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8070126175880432,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "students"
        ],
        "predictions": [
          {
            "score": 0.8302891254425049,
            "answer": "students",
            "hit": true
          },
          {
            "score": 0.7793548107147217,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.7724264860153198,
            "answer": "pupil",
            "hit": false
          },
          {
            "score": 0.7706528306007385,
            "answer": "classroom",
            "hit": false
          },
          {
            "score": 0.7705467343330383,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.7687652111053467,
            "answer": "tuition",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8302891254425049,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to system ",
        "b": "system",
        "expected answer": [
          "systems"
        ],
        "predictions": [
          {
            "score": 0.8197033405303955,
            "answer": "systems",
            "hit": true
          },
          {
            "score": 0.734458863735199,
            "answer": "process",
            "hit": false
          },
          {
            "score": 0.7289057374000549,
            "answer": "systemic",
            "hit": false
          },
          {
            "score": 0.7251218557357788,
            "answer": "processor",
            "hit": false
          },
          {
            "score": 0.7246831655502319,
            "answer": "manager",
            "hit": false
          },
          {
            "score": 0.7224085330963135,
            "answer": "sciences",
            "hit": false
          }
        ],
        "set_exclude": [
          "system"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8197033703327179,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to thing ",
        "b": "thing",
        "expected answer": [
          "things"
        ],
        "predictions": [
          {
            "score": 0.7489819526672363,
            "answer": "things",
            "hit": true
          },
          {
            "score": 0.7190744876861572,
            "answer": "dude",
            "hit": false
          },
          {
            "score": 0.7031660079956055,
            "answer": "inventions",
            "hit": false
          },
          {
            "score": 0.7020632028579712,
            "answer": "something",
            "hit": false
          },
          {
            "score": 0.7000997066497803,
            "answer": "tangible",
            "hit": false
          },
          {
            "score": 0.6998813152313232,
            "answer": "creature",
            "hit": false
          }
        ],
        "set_exclude": [
          "thing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7489819228649139,
        "b in neighbourhood of b_prime": 20,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to town ",
        "b": "town",
        "expected answer": [
          "towns"
        ],
        "predictions": [
          {
            "score": 0.8284405469894409,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.8191015720367432,
            "answer": "village",
            "hit": false
          },
          {
            "score": 0.7618292570114136,
            "answer": "hometown",
            "hit": false
          },
          {
            "score": 0.7602787017822266,
            "answer": "villages",
            "hit": false
          },
          {
            "score": 0.7582950592041016,
            "answer": "suburb",
            "hit": false
          },
          {
            "score": 0.7559982538223267,
            "answer": "municipality",
            "hit": false
          }
        ],
        "set_exclude": [
          "town"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7227281481027603,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to user ",
        "b": "user",
        "expected answer": [
          "users"
        ],
        "predictions": [
          {
            "score": 0.7729105949401855,
            "answer": "users",
            "hit": true
          },
          {
            "score": 0.7379502058029175,
            "answer": "player",
            "hit": false
          },
          {
            "score": 0.7346289157867432,
            "answer": "programmer",
            "hit": false
          },
          {
            "score": 0.7331134080886841,
            "answer": "developer",
            "hit": false
          },
          {
            "score": 0.7252940535545349,
            "answer": "customer",
            "hit": false
          },
          {
            "score": 0.7201206684112549,
            "answer": "hacker",
            "hit": false
          }
        ],
        "set_exclude": [
          "user"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7729106545448303,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to version ",
        "b": "version",
        "expected answer": [
          "versions"
        ],
        "predictions": [
          {
            "score": 0.746211051940918,
            "answer": "versions",
            "hit": true
          },
          {
            "score": 0.7359113693237305,
            "answer": "features",
            "hit": false
          },
          {
            "score": 0.7345264554023743,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.7300475239753723,
            "answer": "release",
            "hit": false
          },
          {
            "score": 0.7285301089286804,
            "answer": "width",
            "hit": false
          },
          {
            "score": 0.726798951625824,
            "answer": "implementations",
            "hit": false
          }
        ],
        "set_exclude": [
          "version"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7462110668420792,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to village ",
        "b": "village",
        "expected answer": [
          "villages"
        ],
        "predictions": [
          {
            "score": 0.884143054485321,
            "answer": "villages",
            "hit": true
          },
          {
            "score": 0.8313786387443542,
            "answer": "villagers",
            "hit": false
          },
          {
            "score": 0.8191016316413879,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.7761261463165283,
            "answer": "tribe",
            "hit": false
          },
          {
            "score": 0.7756403088569641,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.7666940689086914,
            "answer": "monastery",
            "hit": false
          }
        ],
        "set_exclude": [
          "village"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.884143054485321,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to website ",
        "b": "website",
        "expected answer": [
          "websites"
        ],
        "predictions": [
          {
            "score": 0.8793126344680786,
            "answer": "websites",
            "hit": true
          },
          {
            "score": 0.7739419937133789,
            "answer": "www",
            "hit": false
          },
          {
            "score": 0.7500614523887634,
            "answer": "facebook",
            "hit": false
          },
          {
            "score": 0.7477379441261292,
            "answer": "forum",
            "hit": false
          },
          {
            "score": 0.7472155094146729,
            "answer": "blogger",
            "hit": false
          },
          {
            "score": 0.7426440715789795,
            "answer": "blogs",
            "hit": false
          }
        ],
        "set_exclude": [
          "website"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.879312664270401,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to week ",
        "b": "week",
        "expected answer": [
          "weeks"
        ],
        "predictions": [
          {
            "score": 0.7593149542808533,
            "answer": "weekend",
            "hit": false
          },
          {
            "score": 0.754608690738678,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.7441728711128235,
            "answer": "weekly",
            "hit": false
          },
          {
            "score": 0.7440835237503052,
            "answer": "wednesday",
            "hit": false
          },
          {
            "score": 0.7389960289001465,
            "answer": "friday",
            "hit": false
          },
          {
            "score": 0.7384542226791382,
            "answer": "weeks",
            "hit": true
          }
        ],
        "set_exclude": [
          "week"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7384542524814606,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to year ",
        "b": "year",
        "expected answer": [
          "years"
        ],
        "predictions": [
          {
            "score": 0.7848342061042786,
            "answer": "years",
            "hit": true
          },
          {
            "score": 0.7683447599411011,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.7653049826622009,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.7646140456199646,
            "answer": "yearly",
            "hit": false
          },
          {
            "score": 0.7625444531440735,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.7547512054443359,
            "answer": "days",
            "hit": false
          }
        ],
        "set_exclude": [
          "year"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7848342061042786,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 35,
      "cnt_questions_total": 50,
      "accuracy": 0.7
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I01 [noun - plural_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "27d17c7f-cd4b-4b8e-a223-90e935d236c7",
      "timestamp": "2025-05-17T17:08:11.306497"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ability ",
        "b": "ability",
        "expected answer": [
          "abilities"
        ],
        "predictions": [
          {
            "score": 0.8280230760574341,
            "answer": "abilities",
            "hit": true
          },
          {
            "score": 0.8222715258598328,
            "answer": "able",
            "hit": false
          },
          {
            "score": 0.7082289457321167,
            "answer": "capability",
            "hit": false
          },
          {
            "score": 0.7034146785736084,
            "answer": "reliability",
            "hit": false
          },
          {
            "score": 0.6978101134300232,
            "answer": "compatibility",
            "hit": false
          },
          {
            "score": 0.6951746940612793,
            "answer": "functionality",
            "hit": false
          }
        ],
        "set_exclude": [
          "ability"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8280231058597565,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to activity ",
        "b": "activity",
        "expected answer": [
          "activities"
        ],
        "predictions": [
          {
            "score": 0.8415008783340454,
            "answer": "activities",
            "hit": true
          },
          {
            "score": 0.7161277532577515,
            "answer": "structure",
            "hit": false
          },
          {
            "score": 0.7122540473937988,
            "answer": "inactive",
            "hit": false
          },
          {
            "score": 0.7119448184967041,
            "answer": "applications",
            "hit": false
          },
          {
            "score": 0.7095736861228943,
            "answer": "behaviors",
            "hit": false
          },
          {
            "score": 0.707356333732605,
            "answer": "transactions",
            "hit": false
          }
        ],
        "set_exclude": [
          "activity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8415009081363678,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to agency ",
        "b": "agency",
        "expected answer": [
          "agencies"
        ],
        "predictions": [
          {
            "score": 0.8136978149414062,
            "answer": "agencies",
            "hit": true
          },
          {
            "score": 0.7598247528076172,
            "answer": "agents",
            "hit": false
          },
          {
            "score": 0.7497796416282654,
            "answer": "enforcement",
            "hit": false
          },
          {
            "score": 0.7403132915496826,
            "answer": "government",
            "hit": false
          },
          {
            "score": 0.7355092167854309,
            "answer": "contractor",
            "hit": false
          },
          {
            "score": 0.7348536252975464,
            "answer": "department",
            "hit": false
          }
        ],
        "set_exclude": [
          "agency"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.813697874546051,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to analysis ",
        "b": "analysis",
        "expected answer": [
          "analyses"
        ],
        "predictions": [
          {
            "score": 0.7825760841369629,
            "answer": "analyses",
            "hit": true
          },
          {
            "score": 0.769109845161438,
            "answer": "analyze",
            "hit": false
          },
          {
            "score": 0.7641539573669434,
            "answer": "analyzing",
            "hit": false
          },
          {
            "score": 0.753828227519989,
            "answer": "analytical",
            "hit": false
          },
          {
            "score": 0.7508320808410645,
            "answer": "analytic",
            "hit": false
          },
          {
            "score": 0.7503925561904907,
            "answer": "analyzed",
            "hit": false
          }
        ],
        "set_exclude": [
          "analysis"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7825760543346405,
        "b in neighbourhood of b_prime": 12,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to army ",
        "b": "army",
        "expected answer": [
          "armies"
        ],
        "predictions": [
          {
            "score": 0.7990980744361877,
            "answer": "military",
            "hit": false
          },
          {
            "score": 0.7879651784896851,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.7734918594360352,
            "answer": "armies",
            "hit": true
          },
          {
            "score": 0.7608429193496704,
            "answer": "infantry",
            "hit": false
          },
          {
            "score": 0.7592666149139404,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.758980393409729,
            "answer": "air",
            "hit": false
          }
        ],
        "set_exclude": [
          "army"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7734918594360352,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to authority ",
        "b": "authority",
        "expected answer": [
          "authorities"
        ],
        "predictions": [
          {
            "score": 0.7562969923019409,
            "answer": "authorities",
            "hit": true
          },
          {
            "score": 0.7247934937477112,
            "answer": "authoritative",
            "hit": false
          },
          {
            "score": 0.7213889360427856,
            "answer": "administration",
            "hit": false
          },
          {
            "score": 0.7134747505187988,
            "answer": "appeals",
            "hit": false
          },
          {
            "score": 0.7130590081214905,
            "answer": "minister",
            "hit": false
          },
          {
            "score": 0.7103800773620605,
            "answer": "commissioner",
            "hit": false
          }
        ],
        "set_exclude": [
          "authority"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7562969923019409,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to basis ",
        "b": "basis",
        "expected answer": [
          "bases"
        ],
        "predictions": [
          {
            "score": 0.7409772872924805,
            "answer": "backbone",
            "hit": false
          },
          {
            "score": 0.7386327981948853,
            "answer": "premise",
            "hit": false
          },
          {
            "score": 0.7324627041816711,
            "answer": "justification",
            "hit": false
          },
          {
            "score": 0.727246880531311,
            "answer": "principle",
            "hit": false
          },
          {
            "score": 0.7260278463363647,
            "answer": "assumption",
            "hit": false
          },
          {
            "score": 0.7211477160453796,
            "answer": "bases",
            "hit": true
          }
        ],
        "set_exclude": [
          "basis"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7211476862430573,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to business ",
        "b": "business",
        "expected answer": [
          "businesses"
        ],
        "predictions": [
          {
            "score": 0.8194789886474609,
            "answer": "businesses",
            "hit": true
          },
          {
            "score": 0.7715822458267212,
            "answer": "corporate",
            "hit": false
          },
          {
            "score": 0.7441897392272949,
            "answer": "entrepreneurs",
            "hit": false
          },
          {
            "score": 0.7435941100120544,
            "answer": "businessman",
            "hit": false
          },
          {
            "score": 0.7375873327255249,
            "answer": "industry",
            "hit": false
          },
          {
            "score": 0.7354276180267334,
            "answer": "commerce",
            "hit": false
          }
        ],
        "set_exclude": [
          "business"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8194789588451385,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to category ",
        "b": "category",
        "expected answer": [
          "categories"
        ],
        "predictions": [
          {
            "score": 0.7614052295684814,
            "answer": "categories",
            "hit": true
          },
          {
            "score": 0.7507802248001099,
            "answer": "categorized",
            "hit": false
          },
          {
            "score": 0.7386013865470886,
            "answer": "genre",
            "hit": false
          },
          {
            "score": 0.7374798059463501,
            "answer": "classification",
            "hit": false
          },
          {
            "score": 0.7353877425193787,
            "answer": "classify",
            "hit": false
          },
          {
            "score": 0.7302237749099731,
            "answer": "grouping",
            "hit": false
          }
        ],
        "set_exclude": [
          "category"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7614052295684814,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to century ",
        "b": "century",
        "expected answer": [
          "centuries"
        ],
        "predictions": [
          {
            "score": 0.7978684306144714,
            "answer": "centuries",
            "hit": true
          },
          {
            "score": 0.7882846593856812,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.7825642228126526,
            "answer": "millennium",
            "hit": false
          },
          {
            "score": 0.7560827732086182,
            "answer": "decades",
            "hit": false
          },
          {
            "score": 0.7412466406822205,
            "answer": "dozen",
            "hit": false
          },
          {
            "score": 0.7400984168052673,
            "answer": "nineteenth",
            "hit": false
          }
        ],
        "set_exclude": [
          "century"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7978684306144714,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to child ",
        "b": "child",
        "expected answer": [
          "children"
        ],
        "predictions": [
          {
            "score": 0.7722627520561218,
            "answer": "kids",
            "hit": false
          },
          {
            "score": 0.7680143713951111,
            "answer": "children",
            "hit": true
          },
          {
            "score": 0.7415631413459778,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.7393410801887512,
            "answer": "childhood",
            "hit": false
          },
          {
            "score": 0.7299942970275879,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.7267699837684631,
            "answer": "parents",
            "hit": false
          }
        ],
        "set_exclude": [
          "child"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7680143713951111,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to city ",
        "b": "city",
        "expected answer": [
          "cities"
        ],
        "predictions": [
          {
            "score": 0.8284405469894409,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.7829315662384033,
            "answer": "mayor",
            "hit": false
          },
          {
            "score": 0.7797068357467651,
            "answer": "municipality",
            "hit": false
          },
          {
            "score": 0.7756403088569641,
            "answer": "village",
            "hit": false
          },
          {
            "score": 0.7741724848747253,
            "answer": "cities",
            "hit": true
          },
          {
            "score": 0.7563415765762329,
            "answer": "country",
            "hit": false
          }
        ],
        "set_exclude": [
          "city"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7741725444793701,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to community ",
        "b": "community",
        "expected answer": [
          "communities"
        ],
        "predictions": [
          {
            "score": 0.7659121751785278,
            "answer": "communities",
            "hit": true
          },
          {
            "score": 0.7497600317001343,
            "answer": "ecosystem",
            "hit": false
          },
          {
            "score": 0.7263838648796082,
            "answer": "neighbourhood",
            "hit": false
          },
          {
            "score": 0.7242356538772583,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.7239099740982056,
            "answer": "forum",
            "hit": false
          },
          {
            "score": 0.7234197854995728,
            "answer": "village",
            "hit": false
          }
        ],
        "set_exclude": [
          "community"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7659121155738831,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to country ",
        "b": "country",
        "expected answer": [
          "countries"
        ],
        "predictions": [
          {
            "score": 0.8831682801246643,
            "answer": "nation",
            "hit": false
          },
          {
            "score": 0.8236032724380493,
            "answer": "countries",
            "hit": true
          },
          {
            "score": 0.7649204730987549,
            "answer": "nations",
            "hit": false
          },
          {
            "score": 0.7611925005912781,
            "answer": "continent",
            "hit": false
          },
          {
            "score": 0.7563415765762329,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.7320197820663452,
            "answer": "planet",
            "hit": false
          }
        ],
        "set_exclude": [
          "country"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8236033022403717,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "counties"
        ],
        "predictions": [
          {
            "score": 0.8201019763946533,
            "answer": "counties",
            "hit": true
          },
          {
            "score": 0.7804955244064331,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.7661525011062622,
            "answer": "sheriff",
            "hit": false
          },
          {
            "score": 0.7337665557861328,
            "answer": "parish",
            "hit": false
          },
          {
            "score": 0.7320931553840637,
            "answer": "province",
            "hit": false
          },
          {
            "score": 0.7297446727752686,
            "answer": "municipality",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8201020359992981,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to duty ",
        "b": "duty",
        "expected answer": [
          "duties"
        ],
        "predictions": [
          {
            "score": 0.7721684575080872,
            "answer": "duties",
            "hit": true
          },
          {
            "score": 0.7608245611190796,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.7293384075164795,
            "answer": "responsibility",
            "hit": false
          },
          {
            "score": 0.7237743735313416,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.711986780166626,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.7014915347099304,
            "answer": "warrant",
            "hit": false
          }
        ],
        "set_exclude": [
          "duty"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7721684873104095,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to economy ",
        "b": "economy",
        "expected answer": [
          "economies"
        ],
        "predictions": [
          {
            "score": 0.781956672668457,
            "answer": "economies",
            "hit": true
          },
          {
            "score": 0.7587817311286926,
            "answer": "economic",
            "hit": false
          },
          {
            "score": 0.7455123662948608,
            "answer": "economical",
            "hit": false
          },
          {
            "score": 0.7431332468986511,
            "answer": "economics",
            "hit": false
          },
          {
            "score": 0.7363314628601074,
            "answer": "agriculture",
            "hit": false
          },
          {
            "score": 0.7318576574325562,
            "answer": "economists",
            "hit": false
          }
        ],
        "set_exclude": [
          "economy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7819567024707794,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to energy ",
        "b": "energy",
        "expected answer": [
          "energies"
        ],
        "predictions": [
          {
            "score": 0.8008567690849304,
            "answer": "energies",
            "hit": true
          },
          {
            "score": 0.7637678384780884,
            "answer": "energetic",
            "hit": false
          },
          {
            "score": 0.760786771774292,
            "answer": "electricity",
            "hit": false
          },
          {
            "score": 0.746296763420105,
            "answer": "intensity",
            "hit": false
          },
          {
            "score": 0.7356868982315063,
            "answer": "electric",
            "hit": false
          },
          {
            "score": 0.7283554673194885,
            "answer": "emissions",
            "hit": false
          }
        ],
        "set_exclude": [
          "energy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8008568286895752,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to entry ",
        "b": "entry",
        "expected answer": [
          "entries"
        ],
        "predictions": [
          {
            "score": 0.7857077717781067,
            "answer": "entries",
            "hit": true
          },
          {
            "score": 0.7274209260940552,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.7259474396705627,
            "answer": "leave",
            "hit": false
          },
          {
            "score": 0.7232475876808167,
            "answer": "entrance",
            "hit": false
          },
          {
            "score": 0.7186263799667358,
            "answer": "coming",
            "hit": false
          },
          {
            "score": 0.71678626537323,
            "answer": "location",
            "hit": false
          }
        ],
        "set_exclude": [
          "entry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7857078313827515,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to facility ",
        "b": "facility",
        "expected answer": [
          "facilities"
        ],
        "predictions": [
          {
            "score": 0.8084148168563843,
            "answer": "facilities",
            "hit": true
          },
          {
            "score": 0.7369589805603027,
            "answer": "capability",
            "hit": false
          },
          {
            "score": 0.7362453937530518,
            "answer": "equipment",
            "hit": false
          },
          {
            "score": 0.734656810760498,
            "answer": "warehouse",
            "hit": false
          },
          {
            "score": 0.7339007258415222,
            "answer": "program",
            "hit": false
          },
          {
            "score": 0.7266499996185303,
            "answer": "hotel",
            "hit": false
          }
        ],
        "set_exclude": [
          "facility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8084148168563843,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to family ",
        "b": "family",
        "expected answer": [
          "families"
        ],
        "predictions": [
          {
            "score": 0.7880077958106995,
            "answer": "families",
            "hit": true
          },
          {
            "score": 0.7785634398460388,
            "answer": "parents",
            "hit": false
          },
          {
            "score": 0.776508092880249,
            "answer": "relatives",
            "hit": false
          },
          {
            "score": 0.743770956993103,
            "answer": "parental",
            "hit": false
          },
          {
            "score": 0.7380908131599426,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.7380013465881348,
            "answer": "siblings",
            "hit": false
          }
        ],
        "set_exclude": [
          "family"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7880078554153442,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to history ",
        "b": "history",
        "expected answer": [
          "histories"
        ],
        "predictions": [
          {
            "score": 0.8086482286453247,
            "answer": "histories",
            "hit": true
          },
          {
            "score": 0.7634910345077515,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.752639889717102,
            "answer": "historical",
            "hit": false
          },
          {
            "score": 0.7519872784614563,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.7511882781982422,
            "answer": "overview",
            "hit": false
          },
          {
            "score": 0.737289547920227,
            "answer": "biography",
            "hit": false
          }
        ],
        "set_exclude": [
          "history"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8086482286453247,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to industry ",
        "b": "industry",
        "expected answer": [
          "industries"
        ],
        "predictions": [
          {
            "score": 0.7817726135253906,
            "answer": "industries",
            "hit": true
          },
          {
            "score": 0.7571127414703369,
            "answer": "industrial",
            "hit": false
          },
          {
            "score": 0.7378851175308228,
            "answer": "manufacturers",
            "hit": false
          },
          {
            "score": 0.7375873327255249,
            "answer": "business",
            "hit": false
          },
          {
            "score": 0.7348302006721497,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.7335821390151978,
            "answer": "innovation",
            "hit": false
          }
        ],
        "set_exclude": [
          "industry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7817725539207458,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to library ",
        "b": "library",
        "expected answer": [
          "libraries"
        ],
        "predictions": [
          {
            "score": 0.785825788974762,
            "answer": "libraries",
            "hit": true
          },
          {
            "score": 0.7440869808197021,
            "answer": "directory",
            "hit": false
          },
          {
            "score": 0.729397177696228,
            "answer": "collection",
            "hit": false
          },
          {
            "score": 0.7189574241638184,
            "answer": "literary",
            "hit": false
          },
          {
            "score": 0.7160632610321045,
            "answer": "movie",
            "hit": false
          },
          {
            "score": 0.7152220010757446,
            "answer": "databases",
            "hit": false
          }
        ],
        "set_exclude": [
          "library"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7858258187770844,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to life ",
        "b": "life",
        "expected answer": [
          "lives"
        ],
        "predictions": [
          {
            "score": 0.7288457155227661,
            "answer": "lifespan",
            "hit": false
          },
          {
            "score": 0.7247629165649414,
            "answer": "choice",
            "hit": false
          },
          {
            "score": 0.716622531414032,
            "answer": "lifetime",
            "hit": false
          },
          {
            "score": 0.7157558798789978,
            "answer": "being",
            "hit": false
          },
          {
            "score": 0.7144706845283508,
            "answer": "lifestyle",
            "hit": false
          },
          {
            "score": 0.7135211825370789,
            "answer": "live",
            "hit": false
          }
        ],
        "set_exclude": [
          "life"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7093494087457657,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to loss ",
        "b": "loss",
        "expected answer": [
          "losses"
        ],
        "predictions": [
          {
            "score": 0.8655632734298706,
            "answer": "losses",
            "hit": true
          },
          {
            "score": 0.8057748079299927,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.779605507850647,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7359005212783813,
            "answer": "destruction",
            "hit": false
          },
          {
            "score": 0.7342705726623535,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.7283258438110352,
            "answer": "collapse",
            "hit": false
          }
        ],
        "set_exclude": [
          "loss"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8655632734298706,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to memory ",
        "b": "memory",
        "expected answer": [
          "memories"
        ],
        "predictions": [
          {
            "score": 0.7843354940414429,
            "answer": "memories",
            "hit": true
          },
          {
            "score": 0.7555990219116211,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.737708330154419,
            "answer": "cognition",
            "hit": false
          },
          {
            "score": 0.7306321859359741,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.729939341545105,
            "answer": "cache",
            "hit": false
          },
          {
            "score": 0.7293440103530884,
            "answer": "kernel",
            "hit": false
          }
        ],
        "set_exclude": [
          "memory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7843354940414429,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to opportunity ",
        "b": "opportunity",
        "expected answer": [
          "opportunities"
        ],
        "predictions": [
          {
            "score": 0.8814229965209961,
            "answer": "opportunities",
            "hit": true
          },
          {
            "score": 0.7555429339408875,
            "answer": "possibility",
            "hit": false
          },
          {
            "score": 0.7289609909057617,
            "answer": "invitation",
            "hit": false
          },
          {
            "score": 0.7260267734527588,
            "answer": "initiative",
            "hit": false
          },
          {
            "score": 0.7253747582435608,
            "answer": "incentive",
            "hit": false
          },
          {
            "score": 0.7252763509750366,
            "answer": "chances",
            "hit": false
          }
        ],
        "set_exclude": [
          "opportunity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8814229369163513,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to policy ",
        "b": "policy",
        "expected answer": [
          "policies"
        ],
        "predictions": [
          {
            "score": 0.8591141104698181,
            "answer": "policies",
            "hit": true
          },
          {
            "score": 0.7408751249313354,
            "answer": "strategy",
            "hit": false
          },
          {
            "score": 0.7383874654769897,
            "answer": "political",
            "hit": false
          },
          {
            "score": 0.7363002896308899,
            "answer": "planning",
            "hit": false
          },
          {
            "score": 0.7342858910560608,
            "answer": "strategies",
            "hit": false
          },
          {
            "score": 0.7327383160591125,
            "answer": "affairs",
            "hit": false
          }
        ],
        "set_exclude": [
          "policy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8591141402721405,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to property ",
        "b": "property",
        "expected answer": [
          "properties"
        ],
        "predictions": [
          {
            "score": 0.7794351577758789,
            "answer": "properties",
            "hit": true
          },
          {
            "score": 0.7380315661430359,
            "answer": "render",
            "hit": false
          },
          {
            "score": 0.7363988161087036,
            "answer": "value",
            "hit": false
          },
          {
            "score": 0.7350045442581177,
            "answer": "own",
            "hit": false
          },
          {
            "score": 0.7274379730224609,
            "answer": "attribute",
            "hit": false
          },
          {
            "score": 0.7252233028411865,
            "answer": "rents",
            "hit": false
          }
        ],
        "set_exclude": [
          "property"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7794351577758789,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to responsibility ",
        "b": "responsibility",
        "expected answer": [
          "responsibilities"
        ],
        "predictions": [
          {
            "score": 0.788187563419342,
            "answer": "responsibilities",
            "hit": true
          },
          {
            "score": 0.7662631273269653,
            "answer": "accountability",
            "hit": false
          },
          {
            "score": 0.7476444244384766,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.7404985427856445,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.7368354797363281,
            "answer": "responsible",
            "hit": false
          },
          {
            "score": 0.7293384075164795,
            "answer": "duty",
            "hit": false
          }
        ],
        "set_exclude": [
          "responsibility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7881876230239868,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to security ",
        "b": "security",
        "expected answer": [
          "securities"
        ],
        "predictions": [
          {
            "score": 0.766383171081543,
            "answer": "secure",
            "hit": false
          },
          {
            "score": 0.753107488155365,
            "answer": "government",
            "hit": false
          },
          {
            "score": 0.7511721253395081,
            "answer": "terrorism",
            "hit": false
          },
          {
            "score": 0.7484936714172363,
            "answer": "safety",
            "hit": false
          },
          {
            "score": 0.7462994456291199,
            "answer": "encryption",
            "hit": false
          },
          {
            "score": 0.7457287311553955,
            "answer": "investigators",
            "hit": false
          }
        ],
        "set_exclude": [
          "security"
        ],
        "rank": 167,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7043658494949341,
        "b in neighbourhood of b_prime": 92,
        "b_prime in neighbourhood of b": 168
      },
      {
        "question verbose": "What is to series ",
        "b": "series",
        "expected answer": [
          "series"
        ],
        "predictions": [
          {
            "score": 0.7149620652198792,
            "answer": "trilogy",
            "hit": false
          },
          {
            "score": 0.7121553421020508,
            "answer": "season",
            "hit": false
          },
          {
            "score": 0.6971086859703064,
            "answer": "volume",
            "hit": false
          },
          {
            "score": 0.6884620189666748,
            "answer": "classic",
            "hit": false
          },
          {
            "score": 0.6882409453392029,
            "answer": "sequence",
            "hit": false
          },
          {
            "score": 0.6860118508338928,
            "answer": "chassis",
            "hit": false
          }
        ],
        "set_exclude": [
          "series"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 1.0,
        "b in neighbourhood of b_prime": 0,
        "b_prime in neighbourhood of b": 0
      },
      {
        "question verbose": "What is to society ",
        "b": "society",
        "expected answer": [
          "societies"
        ],
        "predictions": [
          {
            "score": 0.8686873316764832,
            "answer": "societies",
            "hit": true
          },
          {
            "score": 0.8257899284362793,
            "answer": "societal",
            "hit": false
          },
          {
            "score": 0.7909311056137085,
            "answer": "civilization",
            "hit": false
          },
          {
            "score": 0.774186372756958,
            "answer": "soc",
            "hit": false
          },
          {
            "score": 0.7541481852531433,
            "answer": "culture",
            "hit": false
          },
          {
            "score": 0.7504845857620239,
            "answer": "humanity",
            "hit": false
          }
        ],
        "set_exclude": [
          "society"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8686873316764832,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to species ",
        "b": "species",
        "expected answer": [
          "species"
        ],
        "predictions": [
          {
            "score": 0.7775713205337524,
            "answer": "genus",
            "hit": false
          },
          {
            "score": 0.7639937400817871,
            "answer": "biodiversity",
            "hit": false
          },
          {
            "score": 0.7505108118057251,
            "answer": "mammalian",
            "hit": false
          },
          {
            "score": 0.7500563263893127,
            "answer": "ecological",
            "hit": false
          },
          {
            "score": 0.7496432065963745,
            "answer": "organism",
            "hit": false
          },
          {
            "score": 0.748619019985199,
            "answer": "evolutionary",
            "hit": false
          }
        ],
        "set_exclude": [
          "species"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 1.0000000596046448,
        "b in neighbourhood of b_prime": 0,
        "b_prime in neighbourhood of b": 0
      },
      {
        "question verbose": "What is to story ",
        "b": "story",
        "expected answer": [
          "stories"
        ],
        "predictions": [
          {
            "score": 0.7793334722518921,
            "answer": "stories",
            "hit": true
          },
          {
            "score": 0.7736349105834961,
            "answer": "storyline",
            "hit": false
          },
          {
            "score": 0.7696505784988403,
            "answer": "storytelling",
            "hit": false
          },
          {
            "score": 0.7610739469528198,
            "answer": "narrative",
            "hit": false
          },
          {
            "score": 0.7538141012191772,
            "answer": "narratives",
            "hit": false
          },
          {
            "score": 0.7337138056755066,
            "answer": "this",
            "hit": false
          }
        ],
        "set_exclude": [
          "story"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7793334722518921,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to strategy ",
        "b": "strategy",
        "expected answer": [
          "strategies"
        ],
        "predictions": [
          {
            "score": 0.8214318752288818,
            "answer": "strategies",
            "hit": true
          },
          {
            "score": 0.7961248755455017,
            "answer": "strategic",
            "hit": false
          },
          {
            "score": 0.7718233466148376,
            "answer": "tactic",
            "hit": false
          },
          {
            "score": 0.7646763920783997,
            "answer": "tactics",
            "hit": false
          },
          {
            "score": 0.7408751249313354,
            "answer": "policy",
            "hit": false
          },
          {
            "score": 0.7340577840805054,
            "answer": "adviser",
            "hit": false
          }
        ],
        "set_exclude": [
          "strategy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8214319050312042,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to success ",
        "b": "success",
        "expected answer": [
          "successes"
        ],
        "predictions": [
          {
            "score": 0.7886512279510498,
            "answer": "successful",
            "hit": false
          },
          {
            "score": 0.7865323424339294,
            "answer": "successes",
            "hit": true
          },
          {
            "score": 0.7652146816253662,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.7533880472183228,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.7521305680274963,
            "answer": "succeeded",
            "hit": false
          },
          {
            "score": 0.7516301870346069,
            "answer": "succeeds",
            "hit": false
          }
        ],
        "set_exclude": [
          "success"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7865323424339294,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to technology ",
        "b": "technology",
        "expected answer": [
          "technologies"
        ],
        "predictions": [
          {
            "score": 0.8409011363983154,
            "answer": "technologies",
            "hit": true
          },
          {
            "score": 0.8237625956535339,
            "answer": "technological",
            "hit": false
          },
          {
            "score": 0.7773413062095642,
            "answer": "tech",
            "hit": false
          },
          {
            "score": 0.7689299583435059,
            "answer": "science",
            "hit": false
          },
          {
            "score": 0.7618863582611084,
            "answer": "inventions",
            "hit": false
          },
          {
            "score": 0.7609373331069946,
            "answer": "innovations",
            "hit": false
          }
        ],
        "set_exclude": [
          "technology"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8409011363983154,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to theory ",
        "b": "theory",
        "expected answer": [
          "theories"
        ],
        "predictions": [
          {
            "score": 0.8334142565727234,
            "answer": "theories",
            "hit": true
          },
          {
            "score": 0.7802008986473083,
            "answer": "hypothesis",
            "hit": false
          },
          {
            "score": 0.7598255276679993,
            "answer": "theoretical",
            "hit": false
          },
          {
            "score": 0.7461349964141846,
            "answer": "concept",
            "hit": false
          },
          {
            "score": 0.7358497381210327,
            "answer": "technique",
            "hit": false
          },
          {
            "score": 0.7345864176750183,
            "answer": "studies",
            "hit": false
          }
        ],
        "set_exclude": [
          "theory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8334142565727234,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to university ",
        "b": "university",
        "expected answer": [
          "universities"
        ],
        "predictions": [
          {
            "score": 0.816670835018158,
            "answer": "universities",
            "hit": true
          },
          {
            "score": 0.7618266344070435,
            "answer": "harvard",
            "hit": false
          },
          {
            "score": 0.7572538256645203,
            "answer": "ucla",
            "hit": false
          },
          {
            "score": 0.7571227550506592,
            "answer": "professor",
            "hit": false
          },
          {
            "score": 0.7498939037322998,
            "answer": "yale",
            "hit": false
          },
          {
            "score": 0.7497634291648865,
            "answer": "academic",
            "hit": false
          }
        ],
        "set_exclude": [
          "university"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8166708648204803,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to variety ",
        "b": "variety",
        "expected answer": [
          "varieties"
        ],
        "predictions": [
          {
            "score": 0.8128669261932373,
            "answer": "multitude",
            "hit": false
          },
          {
            "score": 0.7996400594711304,
            "answer": "varieties",
            "hit": true
          },
          {
            "score": 0.7781884074211121,
            "answer": "assortment",
            "hit": false
          },
          {
            "score": 0.7721814513206482,
            "answer": "myriad",
            "hit": false
          },
          {
            "score": 0.7623534202575684,
            "answer": "diversity",
            "hit": false
          },
          {
            "score": 0.761818528175354,
            "answer": "variation",
            "hit": false
          }
        ],
        "set_exclude": [
          "variety"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7996399998664856,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to wife ",
        "b": "wife",
        "expected answer": [
          "wives"
        ],
        "predictions": [
          {
            "score": 0.7783046960830688,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.7628751993179321,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.7605835199356079,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.7569128274917603,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.7528703808784485,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.7517741918563843,
            "answer": "niece",
            "hit": false
          }
        ],
        "set_exclude": [
          "wife"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.745681568980217,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to woman ",
        "b": "woman",
        "expected answer": [
          "women"
        ],
        "predictions": [
          {
            "score": 0.8411144614219666,
            "answer": "women",
            "hit": true
          },
          {
            "score": 0.7778722047805786,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.7599718570709229,
            "answer": "female",
            "hit": false
          },
          {
            "score": 0.7586418390274048,
            "answer": "feminist",
            "hit": false
          },
          {
            "score": 0.751012921333313,
            "answer": "lady",
            "hit": false
          },
          {
            "score": 0.7487943172454834,
            "answer": "wife",
            "hit": false
          }
        ],
        "set_exclude": [
          "woman"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8411145210266113,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 32,
      "cnt_questions_total": 44,
      "accuracy": 0.7272727272727273
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I02 [noun - plural_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "afc855e9-eb7d-463f-a3ed-6c164a7a735b",
      "timestamp": "2025-05-17T17:08:11.735521"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to cheap ",
        "b": "cheap",
        "expected answer": [
          "cheaper"
        ],
        "predictions": [
          {
            "score": 0.8701518177986145,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.8650216460227966,
            "answer": "cheaper",
            "hit": true
          },
          {
            "score": 0.8079574108123779,
            "answer": "expensive",
            "hit": false
          },
          {
            "score": 0.7891738414764404,
            "answer": "affordable",
            "hit": false
          },
          {
            "score": 0.7539528608322144,
            "answer": "costly",
            "hit": false
          },
          {
            "score": 0.7475275993347168,
            "answer": "economical",
            "hit": false
          }
        ],
        "set_exclude": [
          "cheap"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8650216460227966,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happier"
        ],
        "predictions": [
          {
            "score": 0.7712745070457458,
            "answer": "happier",
            "hit": true
          },
          {
            "score": 0.7580035924911499,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.7530027031898499,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.7511183023452759,
            "answer": "lucky",
            "hit": false
          },
          {
            "score": 0.7497065663337708,
            "answer": "cheerful",
            "hit": false
          },
          {
            "score": 0.7447563409805298,
            "answer": "enjoy",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7712745070457458,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "stronger"
        ],
        "predictions": [
          {
            "score": 0.7748849987983704,
            "answer": "stronger",
            "hit": true
          },
          {
            "score": 0.7661842107772827,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.7377214431762695,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.7354097962379456,
            "answer": "strength",
            "hit": false
          },
          {
            "score": 0.7247874140739441,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.719794750213623,
            "answer": "strongly",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7748850286006927,
        "b in neighbourhood of b_prime": 18,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weaker"
        ],
        "predictions": [
          {
            "score": 0.7931559085845947,
            "answer": "weaker",
            "hit": true
          },
          {
            "score": 0.7796528935432434,
            "answer": "weakness",
            "hit": false
          },
          {
            "score": 0.762973427772522,
            "answer": "weaken",
            "hit": false
          },
          {
            "score": 0.7604753971099854,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.7537059783935547,
            "answer": "weaknesses",
            "hit": false
          },
          {
            "score": 0.7400948405265808,
            "answer": "weakened",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7931559681892395,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 4,
      "accuracy": 0.75
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I03 [adj - comparative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "57047d91-e2cf-48bc-86fd-3db977cf9583",
      "timestamp": "2025-05-17T17:08:12.122866"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to hot ",
        "b": "hot",
        "expected answer": [
          "hottest"
        ],
        "predictions": [
          {
            "score": 0.7167495489120483,
            "answer": "hottest",
            "hit": true
          },
          {
            "score": 0.699228823184967,
            "answer": "heat",
            "hit": false
          },
          {
            "score": 0.693631649017334,
            "answer": "chili",
            "hit": false
          },
          {
            "score": 0.6909817457199097,
            "answer": "cool",
            "hit": false
          },
          {
            "score": 0.6882011294364929,
            "answer": "spicy",
            "hit": false
          },
          {
            "score": 0.6842126846313477,
            "answer": "fresh",
            "hit": false
          }
        ],
        "set_exclude": [
          "hot"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7167496085166931,
        "b in neighbourhood of b_prime": 40,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongest"
        ],
        "predictions": [
          {
            "score": 0.7748849987983704,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.7661842107772827,
            "answer": "strongest",
            "hit": true
          },
          {
            "score": 0.7377214431762695,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.7354097962379456,
            "answer": "strength",
            "hit": false
          },
          {
            "score": 0.7247874140739441,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.719794750213623,
            "answer": "strongly",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7661842703819275,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 2
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 2,
      "accuracy": 0.5
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I04 [adj - superlative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "d5c6a918-a21a-4db7-88a3-cd6b4cd6a156",
      "timestamp": "2025-05-17T17:08:12.158314"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepts"
        ],
        "predictions": [
          {
            "score": 0.881279468536377,
            "answer": "accepts",
            "hit": true
          },
          {
            "score": 0.8616923093795776,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.8471611142158508,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.8135776519775391,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.789398729801178,
            "answer": "reject",
            "hit": false
          },
          {
            "score": 0.7829883098602295,
            "answer": "acknowledge",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8812794387340546,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.7313344478607178,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.7168073058128357,
            "answer": "need",
            "hit": false
          },
          {
            "score": 0.7154136896133423,
            "answer": "adds",
            "hit": true
          },
          {
            "score": 0.7151359915733337,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.7139960527420044,
            "answer": "additive",
            "hit": false
          },
          {
            "score": 0.713074803352356,
            "answer": "update",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7154136598110199,
        "b in neighbourhood of b_prime": 193,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agrees"
        ],
        "predictions": [
          {
            "score": 0.8747720122337341,
            "answer": "agrees",
            "hit": true
          },
          {
            "score": 0.8463097810745239,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.837645411491394,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8146491646766663,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7868742942810059,
            "answer": "acknowledge",
            "hit": false
          },
          {
            "score": 0.7832205295562744,
            "answer": "disagreed",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8747720420360565,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.8863883018493652,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.846862256526947,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.8188943862915039,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.8138890266418457,
            "answer": "permit",
            "hit": false
          },
          {
            "score": 0.8078088164329529,
            "answer": "let",
            "hit": false
          },
          {
            "score": 0.8069967031478882,
            "answer": "provide",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8863883018493652,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.8739266395568848,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8625186085700989,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8230941891670227,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7743961811065674,
            "answer": "resemble",
            "hit": false
          },
          {
            "score": 0.7738533020019531,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7735451459884644,
            "answer": "occur",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 41,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7186704576015472,
        "b in neighbourhood of b_prime": 16,
        "b_prime in neighbourhood of b": 42
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.8130729794502258,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7910484075546265,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.7787295579910278,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.744622528553009,
            "answer": "evaluate",
            "hit": false
          },
          {
            "score": 0.743034839630127,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.7427865862846375,
            "answer": "applications",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7910484075546265,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.7570203542709351,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.7567336559295654,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.7550273537635803,
            "answer": "questions",
            "hit": false
          },
          {
            "score": 0.7531464099884033,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.7515357136726379,
            "answer": "question",
            "hit": false
          },
          {
            "score": 0.7509892582893372,
            "answer": "meet",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 105,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7122947871685028,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 106
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoids"
        ],
        "predictions": [
          {
            "score": 0.8361502885818481,
            "answer": "avoiding",
            "hit": false
          },
          {
            "score": 0.8214715719223022,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.8176989555358887,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.8151977062225342,
            "answer": "avoids",
            "hit": true
          },
          {
            "score": 0.7592869400978088,
            "answer": "minimize",
            "hit": false
          },
          {
            "score": 0.7578601837158203,
            "answer": "evade",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.815197765827179,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.7469394207000732,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.7458730936050415,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.7457171678543091,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.73344886302948,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.730496883392334,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.7303129434585571,
            "answer": "join",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7304969429969788,
        "b in neighbourhood of b_prime": 177,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.78984534740448,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.7771393656730652,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7683236002922058,
            "answer": "honestly",
            "hit": false
          },
          {
            "score": 0.7655804753303528,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.763603687286377,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7557419538497925,
            "answer": "bel",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7898454070091248,
        "b in neighbourhood of b_prime": 31,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.7909044623374939,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7676159143447876,
            "answer": "increasing",
            "hit": false
          },
          {
            "score": 0.7553883194923401,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.7509335279464722,
            "answer": "reasonable",
            "hit": false
          },
          {
            "score": 0.7501152753829956,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7478833794593811,
            "answer": "particularly",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7553883492946625,
        "b in neighbourhood of b_prime": 125,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to consist ",
        "b": "consist",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.9067750573158264,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.8884533643722534,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.8441696763038635,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.8169542551040649,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.811370313167572,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.8037418127059937,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "consist"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9067750573158264,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.8914589881896973,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.8442292213439941,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.841410756111145,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.774734616279602,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.768433153629303,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.7669106721878052,
            "answer": "encompass",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8914589881896973,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.7568832635879517,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.748924732208252,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.748767077922821,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.737725019454956,
            "answer": "proceed",
            "hit": false
          },
          {
            "score": 0.7294521331787109,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7238302230834961,
            "answer": "repeat",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7568832635879517,
        "b in neighbourhood of b_prime": 32,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.8098041415214539,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.8094359040260315,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.7707169055938721,
            "answer": "generate",
            "hit": false
          },
          {
            "score": 0.7619770765304565,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.7558480501174927,
            "answer": "ensure",
            "hit": false
          },
          {
            "score": 0.7492598295211792,
            "answer": "achieve",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8098041713237762,
        "b in neighbourhood of b_prime": 17,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.88374924659729,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.8542947769165039,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.7950342297554016,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.7949916124343872,
            "answer": "depict",
            "hit": false
          },
          {
            "score": 0.7934595346450806,
            "answer": "define",
            "hit": false
          },
          {
            "score": 0.7860919833183289,
            "answer": "specify",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8837492763996124,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.8854014873504639,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.8651421070098877,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8541511297225952,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7938932776451111,
            "answer": "evolve",
            "hit": false
          },
          {
            "score": 0.7821511626243591,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7779421210289001,
            "answer": "produce",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.885401576757431,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to enable ",
        "b": "enable",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.7897839546203613,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.7740115523338318,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.7582275867462158,
            "answer": "enabled",
            "hit": false
          },
          {
            "score": 0.7571460604667664,
            "answer": "ensure",
            "hit": false
          },
          {
            "score": 0.7455483078956604,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.743034839630127,
            "answer": "apply",
            "hit": false
          }
        ],
        "set_exclude": [
          "enable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7897839248180389,
        "b in neighbourhood of b_prime": 43,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoys"
        ],
        "predictions": [
          {
            "score": 0.8120999932289124,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7885305285453796,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.7876150608062744,
            "answer": "enjoys",
            "hit": true
          },
          {
            "score": 0.7674121856689453,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7522728443145752,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7516811490058899,
            "answer": "feel",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7876150906085968,
        "b in neighbourhood of b_prime": 20,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensures"
        ],
        "predictions": [
          {
            "score": 0.8099716305732727,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7980961799621582,
            "answer": "ensures",
            "hit": true
          },
          {
            "score": 0.7935063242912292,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.788062572479248,
            "answer": "verify",
            "hit": false
          },
          {
            "score": 0.7702281475067139,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.7657747864723206,
            "answer": "ideally",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.798096239566803,
        "b in neighbourhood of b_prime": 27,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.8064945936203003,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.7613704800605774,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.7486529350280762,
            "answer": "survive",
            "hit": false
          },
          {
            "score": 0.7449991703033447,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.7441450357437134,
            "answer": "thrive",
            "hit": false
          },
          {
            "score": 0.7427960634231567,
            "answer": "existent",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7613704800605774,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to explain ",
        "b": "explain",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.7829393148422241,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.7743982672691345,
            "answer": "tell",
            "hit": false
          },
          {
            "score": 0.7708548307418823,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.7616366147994995,
            "answer": "clarify",
            "hit": false
          },
          {
            "score": 0.761407732963562,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.761222779750824,
            "answer": "describe",
            "hit": false
          }
        ],
        "set_exclude": [
          "explain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7708548307418823,
        "b in neighbourhood of b_prime": 39,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.8120335340499878,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.7988346219062805,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.7367404699325562,
            "answer": "adhere",
            "hit": false
          },
          {
            "score": 0.7360302209854126,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7356061935424805,
            "answer": "obey",
            "hit": false
          },
          {
            "score": 0.7283647656440735,
            "answer": "accompany",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8120335340499878,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.8663467168807983,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.8623930215835571,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8607242107391357,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8445168733596802,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.7768685221672058,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7760797739028931,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.866346687078476,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.8442500829696655,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.8140237331390381,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.7647870182991028,
            "answer": "heard",
            "hit": false
          },
          {
            "score": 0.758767306804657,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7527258396148682,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7504315376281738,
            "answer": "auditory",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8442500829696655,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifies"
        ],
        "predictions": [
          {
            "score": 0.8861641883850098,
            "answer": "identifies",
            "hit": true
          },
          {
            "score": 0.8696592450141907,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7913675308227539,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7898815870285034,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7776312828063965,
            "answer": "recognize",
            "hit": false
          },
          {
            "score": 0.7740652561187744,
            "answer": "describe",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8861642777919769,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.8441023826599121,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.8371005058288574,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.810447096824646,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8089033365249634,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.8048802018165588,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.7805802226066589,
            "answer": "alleviate",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8048802614212036,
        "b in neighbourhood of b_prime": 12,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.849853515625,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.7960958480834961,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7944343090057373,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7879039645195007,
            "answer": "incorporate",
            "hit": false
          },
          {
            "score": 0.7634400129318237,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.7630188465118408,
            "answer": "provide",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7580384910106659,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.8940294981002808,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.8378790616989136,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.8019938468933105,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.7944343090057373,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.7883403897285461,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7867710590362549,
            "answer": "incorporate",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8940294981002808,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.845826268196106,
            "answer": "learning",
            "hit": false
          },
          {
            "score": 0.8437538743019104,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.7977147698402405,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.7956241965293884,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.7753303050994873,
            "answer": "find",
            "hit": false
          },
          {
            "score": 0.7641406059265137,
            "answer": "educate",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 26,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7295675575733185,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 27
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintains"
        ],
        "predictions": [
          {
            "score": 0.8606421947479248,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.8603721857070923,
            "answer": "maintains",
            "hit": true
          },
          {
            "score": 0.85854172706604,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.8179596662521362,
            "answer": "keep",
            "hit": false
          },
          {
            "score": 0.8006415367126465,
            "answer": "retain",
            "hit": false
          },
          {
            "score": 0.7786121368408203,
            "answer": "remain",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8603721857070923,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to occur ",
        "b": "occur",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.8982232213020325,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.8714165091514587,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.8623930215835571,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8536937832832336,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.8221359252929688,
            "answer": "arise",
            "hit": false
          },
          {
            "score": 0.7933357357978821,
            "answer": "originate",
            "hit": false
          }
        ],
        "set_exclude": [
          "occur"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8982232213020325,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.8997929096221924,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.7812240123748779,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.77809739112854,
            "answer": "operating",
            "hit": false
          },
          {
            "score": 0.7721706628799438,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7719317674636841,
            "answer": "behave",
            "hit": false
          },
          {
            "score": 0.767077624797821,
            "answer": "manipulate",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.89979287981987,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "prevents"
        ],
        "predictions": [
          {
            "score": 0.8593286275863647,
            "answer": "prevents",
            "hit": true
          },
          {
            "score": 0.8589674830436707,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.8461397886276245,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.804451584815979,
            "answer": "prohibit",
            "hit": false
          },
          {
            "score": 0.7939602136611938,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.7795811891555786,
            "answer": "discourage",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8593286573886871,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.8944275975227356,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8781294226646423,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.8345465660095215,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.833759069442749,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.8177255392074585,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.7867518663406372,
            "answer": "promotion",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.894427627325058,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protects"
        ],
        "predictions": [
          {
            "score": 0.8219524621963501,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.8138759732246399,
            "answer": "protects",
            "hit": true
          },
          {
            "score": 0.7913086414337158,
            "answer": "safeguard",
            "hit": false
          },
          {
            "score": 0.7837619781494141,
            "answer": "protection",
            "hit": false
          },
          {
            "score": 0.7833858132362366,
            "answer": "protections",
            "hit": false
          },
          {
            "score": 0.7485654354095459,
            "answer": "secure",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8138760030269623,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.8921548128128052,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.86236971616745,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8529132008552551,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.8069967031478882,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8006588220596313,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.7988947629928589,
            "answer": "bring",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8921548426151276,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.8786818385124207,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.8465611934661865,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.785489559173584,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.7792428731918335,
            "answer": "obtain",
            "hit": false
          },
          {
            "score": 0.7741402983665466,
            "answer": "participate",
            "hit": false
          },
          {
            "score": 0.7644912004470825,
            "answer": "provide",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8786818385124207,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.8797934055328369,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.8762949705123901,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.8542691469192505,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.8334847688674927,
            "answer": "eliminate",
            "hit": false
          },
          {
            "score": 0.8330191373825073,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.8316742181777954,
            "answer": "reduced",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8797934949398041,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.7856975793838501,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7638955116271973,
            "answer": "although",
            "hit": false
          },
          {
            "score": 0.7597116231918335,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.7556465864181519,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.7524508833885193,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.7522768974304199,
            "answer": "furthermore",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7556465566158295,
        "b in neighbourhood of b_prime": 60,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.8815199136734009,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.8517293930053711,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.7932473421096802,
            "answer": "keep",
            "hit": false
          },
          {
            "score": 0.7923961281776428,
            "answer": "retain",
            "hit": false
          },
          {
            "score": 0.7906454801559448,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.7786121368408203,
            "answer": "maintain",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8517293930053711,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembers"
        ],
        "predictions": [
          {
            "score": 0.8590993881225586,
            "answer": "remembers",
            "hit": true
          },
          {
            "score": 0.8265721797943115,
            "answer": "remembering",
            "hit": false
          },
          {
            "score": 0.8189079761505127,
            "answer": "recall",
            "hit": false
          },
          {
            "score": 0.8188691139221191,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.773202657699585,
            "answer": "forget",
            "hit": false
          },
          {
            "score": 0.7707406878471375,
            "answer": "recalls",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8590994477272034,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.8469552397727966,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.8085759878158569,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.793499231338501,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.7826929092407227,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.760224461555481,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.7362172603607178,
            "answer": "representative",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7602244913578033,
        "b in neighbourhood of b_prime": 51,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.839923083782196,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.8019938468933105,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.781915545463562,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.780232310295105,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7796525955200195,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7783592343330383,
            "answer": "prohibit",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7696396112442017,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.8755486011505127,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8625186085700989,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7907825708389282,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7764207720756531,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.7723559141159058,
            "answer": "have",
            "hit": false
          },
          {
            "score": 0.7668259143829346,
            "answer": "appeared",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7764208316802979,
        "b in neighbourhood of b_prime": 18,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sends"
        ],
        "predictions": [
          {
            "score": 0.790214478969574,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7900911569595337,
            "answer": "sends",
            "hit": true
          },
          {
            "score": 0.7430071830749512,
            "answer": "sent",
            "hit": false
          },
          {
            "score": 0.7203497290611267,
            "answer": "communicate",
            "hit": false
          },
          {
            "score": 0.7185301780700684,
            "answer": "push",
            "hit": false
          },
          {
            "score": 0.7172192335128784,
            "answer": "received",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7900911569595337,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to suggest ",
        "b": "suggest",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.8040969371795654,
            "answer": "suggestions",
            "hit": false
          },
          {
            "score": 0.8005856275558472,
            "answer": "suggested",
            "hit": false
          },
          {
            "score": 0.7961275577545166,
            "answer": "suggestion",
            "hit": false
          },
          {
            "score": 0.7748633623123169,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.7708531618118286,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.7532129883766174,
            "answer": "recommends",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggest"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7708532214164734,
        "b in neighbourhood of b_prime": 61,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.782664954662323,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.7743982672691345,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.7598927617073059,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.7279639840126038,
            "answer": "convince",
            "hit": false
          },
          {
            "score": 0.727655827999115,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.7270291447639465,
            "answer": "talking",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.782664954662323,
        "b in neighbourhood of b_prime": 24,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.8037042021751404,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.7822238802909851,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7812536358833313,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.7774640917778015,
            "answer": "understanding",
            "hit": false
          },
          {
            "score": 0.7719600796699524,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.7671339511871338,
            "answer": "clearly",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8037042617797852,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 26,
      "cnt_questions_total": 49,
      "accuracy": 0.5306122448979592
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I05 [verb_inf - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "59e321c1-575b-439f-b1fb-a7fa46480659",
      "timestamp": "2025-05-17T17:08:12.176505"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieving"
        ],
        "predictions": [
          {
            "score": 0.7977390289306641,
            "answer": "achieving",
            "hit": true
          },
          {
            "score": 0.7924083471298218,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7867431044578552,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.7702281475067139,
            "answer": "ensure",
            "hit": false
          },
          {
            "score": 0.7625571489334106,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.7618892192840576,
            "answer": "attain",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7977390289306641,
        "b in neighbourhood of b_prime": 12,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adding"
        ],
        "predictions": [
          {
            "score": 0.7313344478607178,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.7168073058128357,
            "answer": "need",
            "hit": false
          },
          {
            "score": 0.7154136896133423,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.7151359915733337,
            "answer": "adding",
            "hit": true
          },
          {
            "score": 0.7139960527420044,
            "answer": "additive",
            "hit": false
          },
          {
            "score": 0.713074803352356,
            "answer": "update",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7151360213756561,
        "b in neighbourhood of b_prime": 157,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowing"
        ],
        "predictions": [
          {
            "score": 0.8863883018493652,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.846862256526947,
            "answer": "allowing",
            "hit": true
          },
          {
            "score": 0.8188943862915039,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.8138890266418457,
            "answer": "permit",
            "hit": false
          },
          {
            "score": 0.8078088164329529,
            "answer": "let",
            "hit": false
          },
          {
            "score": 0.8069967031478882,
            "answer": "provide",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.846862256526947,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appearing"
        ],
        "predictions": [
          {
            "score": 0.8739266395568848,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8625186085700989,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8230941891670227,
            "answer": "appearing",
            "hit": true
          },
          {
            "score": 0.7743961811065674,
            "answer": "resemble",
            "hit": false
          },
          {
            "score": 0.7738533020019531,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7735451459884644,
            "answer": "occur",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8230941891670227,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applying"
        ],
        "predictions": [
          {
            "score": 0.8130729794502258,
            "answer": "applying",
            "hit": true
          },
          {
            "score": 0.7910484075546265,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.7787295579910278,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.744622528553009,
            "answer": "evaluate",
            "hit": false
          },
          {
            "score": 0.743034839630127,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.7427865862846375,
            "answer": "applications",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8130729496479034,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asking"
        ],
        "predictions": [
          {
            "score": 0.7570203542709351,
            "answer": "asking",
            "hit": true
          },
          {
            "score": 0.7567336559295654,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.7550273537635803,
            "answer": "questions",
            "hit": false
          },
          {
            "score": 0.7531464099884033,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.7515357136726379,
            "answer": "question",
            "hit": false
          },
          {
            "score": 0.7509892582893372,
            "answer": "meet",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7570203840732574,
        "b in neighbourhood of b_prime": 35,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attending"
        ],
        "predictions": [
          {
            "score": 0.8697313070297241,
            "answer": "attending",
            "hit": true
          },
          {
            "score": 0.8631066083908081,
            "answer": "attended",
            "hit": false
          },
          {
            "score": 0.8096510171890259,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.8064194321632385,
            "answer": "participate",
            "hit": false
          },
          {
            "score": 0.7947337627410889,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.7504538297653198,
            "answer": "participates",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8697313070297241,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoiding"
        ],
        "predictions": [
          {
            "score": 0.8361502885818481,
            "answer": "avoiding",
            "hit": true
          },
          {
            "score": 0.8214715719223022,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.8176989555358887,
            "answer": "avoided",
            "hit": false
          },
          {
            "score": 0.8151977062225342,
            "answer": "avoids",
            "hit": false
          },
          {
            "score": 0.7592869400978088,
            "answer": "minimize",
            "hit": false
          },
          {
            "score": 0.7578601837158203,
            "answer": "evade",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8361502885818481,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becoming"
        ],
        "predictions": [
          {
            "score": 0.7469394207000732,
            "answer": "becoming",
            "hit": true
          },
          {
            "score": 0.7458730936050415,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.7457171678543091,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.73344886302948,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.730496883392334,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.7303129434585571,
            "answer": "join",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7469394356012344,
        "b in neighbourhood of b_prime": 28,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believing"
        ],
        "predictions": [
          {
            "score": 0.78984534740448,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.7771393656730652,
            "answer": "believing",
            "hit": true
          },
          {
            "score": 0.7683236002922058,
            "answer": "honestly",
            "hit": false
          },
          {
            "score": 0.7655804753303528,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.763603687286377,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7557419538497925,
            "answer": "bel",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7771393954753876,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considering"
        ],
        "predictions": [
          {
            "score": 0.7909044623374939,
            "answer": "considering",
            "hit": true
          },
          {
            "score": 0.7676159143447876,
            "answer": "increasing",
            "hit": false
          },
          {
            "score": 0.7553883194923401,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7509335279464722,
            "answer": "reasonable",
            "hit": false
          },
          {
            "score": 0.7501152753829956,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7478833794593811,
            "answer": "particularly",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7909044623374939,
        "b in neighbourhood of b_prime": 23,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "containing"
        ],
        "predictions": [
          {
            "score": 0.8914589881896973,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.8442292213439941,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.841410756111145,
            "answer": "containing",
            "hit": true
          },
          {
            "score": 0.774734616279602,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.768433153629303,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.7669106721878052,
            "answer": "encompass",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.841410756111145,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuing"
        ],
        "predictions": [
          {
            "score": 0.7568832635879517,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.748924732208252,
            "answer": "continuing",
            "hit": true
          },
          {
            "score": 0.748767077922821,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.737725019454956,
            "answer": "proceed",
            "hit": false
          },
          {
            "score": 0.7294521331787109,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7238302230834961,
            "answer": "repeat",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7489247620105743,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creating"
        ],
        "predictions": [
          {
            "score": 0.8098041415214539,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8094359040260315,
            "answer": "creating",
            "hit": true
          },
          {
            "score": 0.7707169055938721,
            "answer": "generate",
            "hit": false
          },
          {
            "score": 0.7619770765304565,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.7558480501174927,
            "answer": "ensure",
            "hit": false
          },
          {
            "score": 0.7492598295211792,
            "answer": "achieve",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8094358742237091,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developing"
        ],
        "predictions": [
          {
            "score": 0.8854014873504639,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.8651421070098877,
            "answer": "developing",
            "hit": true
          },
          {
            "score": 0.8541511297225952,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7938932776451111,
            "answer": "evolve",
            "hit": false
          },
          {
            "score": 0.7821511626243591,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7779421210289001,
            "answer": "produce",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8651420772075653,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouraging"
        ],
        "predictions": [
          {
            "score": 0.8907161355018616,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8901094794273376,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.8493248820304871,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.8345465660095215,
            "answer": "promote",
            "hit": false
          },
          {
            "score": 0.8242634534835815,
            "answer": "encouraging",
            "hit": true
          },
          {
            "score": 0.8124820590019226,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8242635130882263,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoying"
        ],
        "predictions": [
          {
            "score": 0.8120999932289124,
            "answer": "enjoying",
            "hit": true
          },
          {
            "score": 0.7885305285453796,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.7876150608062744,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.7674121856689453,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7522728443145752,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7516811490058899,
            "answer": "feel",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8121000528335571,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensuring"
        ],
        "predictions": [
          {
            "score": 0.8099716305732727,
            "answer": "ensuring",
            "hit": true
          },
          {
            "score": 0.7980961799621582,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7935063242912292,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.788062572479248,
            "answer": "verify",
            "hit": false
          },
          {
            "score": 0.7702281475067139,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.7657747864723206,
            "answer": "ideally",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8099716901779175,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishing"
        ],
        "predictions": [
          {
            "score": 0.8520770072937012,
            "answer": "establishing",
            "hit": true
          },
          {
            "score": 0.8274535536766052,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7631235122680664,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.7612297534942627,
            "answer": "initiating",
            "hit": false
          },
          {
            "score": 0.7596732378005981,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7570483684539795,
            "answer": "restoring",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8520770370960236,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "existing"
        ],
        "predictions": [
          {
            "score": 0.8064945936203003,
            "answer": "existence",
            "hit": false
          },
          {
            "score": 0.7613704800605774,
            "answer": "exists",
            "hit": false
          },
          {
            "score": 0.7486529350280762,
            "answer": "survive",
            "hit": false
          },
          {
            "score": 0.7449991703033447,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.7441450357437134,
            "answer": "thrive",
            "hit": false
          },
          {
            "score": 0.7427960634231567,
            "answer": "existent",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 1915,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6669920980930328,
        "b in neighbourhood of b_prime": 124,
        "b_prime in neighbourhood of b": 1916
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expecting"
        ],
        "predictions": [
          {
            "score": 0.7997400164604187,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.7891153693199158,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.779319703578949,
            "answer": "expecting",
            "hit": true
          },
          {
            "score": 0.7621015310287476,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7465555667877197,
            "answer": "expected",
            "hit": false
          },
          {
            "score": 0.739812970161438,
            "answer": "considering",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.779319703578949,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "following"
        ],
        "predictions": [
          {
            "score": 0.8120335340499878,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.7988346219062805,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.7367404699325562,
            "answer": "adhere",
            "hit": false
          },
          {
            "score": 0.7360302209854126,
            "answer": "following",
            "hit": true
          },
          {
            "score": 0.7356061935424805,
            "answer": "obey",
            "hit": false
          },
          {
            "score": 0.7283647656440735,
            "answer": "accompany",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.736030250787735,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happening"
        ],
        "predictions": [
          {
            "score": 0.8663467168807983,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.8623930215835571,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8607242107391357,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8445168733596802,
            "answer": "happening",
            "hit": true
          },
          {
            "score": 0.7768685221672058,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7760797739028931,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8445169031620026,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifying"
        ],
        "predictions": [
          {
            "score": 0.8861641883850098,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8696592450141907,
            "answer": "identifying",
            "hit": true
          },
          {
            "score": 0.7913675308227539,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7898815870285034,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7776312828063965,
            "answer": "recognize",
            "hit": false
          },
          {
            "score": 0.7740652561187744,
            "answer": "describe",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8696592748165131,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improving"
        ],
        "predictions": [
          {
            "score": 0.8441023826599121,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.8371005058288574,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.810447096824646,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8089033365249634,
            "answer": "improving",
            "hit": true
          },
          {
            "score": 0.8048802018165588,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7805802226066589,
            "answer": "alleviate",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8089033663272858,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "including"
        ],
        "predictions": [
          {
            "score": 0.849853515625,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.7960958480834961,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7944343090057373,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7879039645195007,
            "answer": "incorporate",
            "hit": false
          },
          {
            "score": 0.7634400129318237,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.7630188465118408,
            "answer": "provide",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7505121827125549,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involving"
        ],
        "predictions": [
          {
            "score": 0.8940294981002808,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8378790616989136,
            "answer": "involving",
            "hit": true
          },
          {
            "score": 0.8019938468933105,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.7944343090057373,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.7883403897285461,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7867710590362549,
            "answer": "incorporate",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8378791213035583,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learning"
        ],
        "predictions": [
          {
            "score": 0.845826268196106,
            "answer": "learning",
            "hit": true
          },
          {
            "score": 0.8437538743019104,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.7977147698402405,
            "answer": "learnt",
            "hit": false
          },
          {
            "score": 0.7956241965293884,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.7753303050994873,
            "answer": "find",
            "hit": false
          },
          {
            "score": 0.7641406059265137,
            "answer": "educate",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8458263278007507,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "losing"
        ],
        "predictions": [
          {
            "score": 0.7982927560806274,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7737860679626465,
            "answer": "losing",
            "hit": true
          },
          {
            "score": 0.759117066860199,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.7580106854438782,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.7436167001724243,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7336412668228149,
            "answer": "regain",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7737861573696136,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintaining"
        ],
        "predictions": [
          {
            "score": 0.8606421947479248,
            "answer": "maintaining",
            "hit": true
          },
          {
            "score": 0.8603721857070923,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.85854172706604,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.8179596662521362,
            "answer": "keep",
            "hit": false
          },
          {
            "score": 0.8006415367126465,
            "answer": "retain",
            "hit": false
          },
          {
            "score": 0.7786121368408203,
            "answer": "remain",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8606421947479248,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managing"
        ],
        "predictions": [
          {
            "score": 0.8691065311431885,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7773045301437378,
            "answer": "managing",
            "hit": true
          },
          {
            "score": 0.7756030559539795,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.7727968692779541,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.7606368660926819,
            "answer": "manipulate",
            "hit": false
          },
          {
            "score": 0.7549307346343994,
            "answer": "administer",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7773045301437378,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operating"
        ],
        "predictions": [
          {
            "score": 0.8997929096221924,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7812240123748779,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.77809739112854,
            "answer": "operating",
            "hit": true
          },
          {
            "score": 0.7721706628799438,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7719317674636841,
            "answer": "behave",
            "hit": false
          },
          {
            "score": 0.767077624797821,
            "answer": "manipulate",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.77809739112854,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performing"
        ],
        "predictions": [
          {
            "score": 0.9005298614501953,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.8682640790939331,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.7821890115737915,
            "answer": "execute",
            "hit": false
          },
          {
            "score": 0.7739981412887573,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7658475637435913,
            "answer": "participate",
            "hit": false
          },
          {
            "score": 0.7641125321388245,
            "answer": "performing",
            "hit": true
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7641125321388245,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "preventing"
        ],
        "predictions": [
          {
            "score": 0.8593286275863647,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.8589674830436707,
            "answer": "preventing",
            "hit": true
          },
          {
            "score": 0.8461397886276245,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.804451584815979,
            "answer": "prohibit",
            "hit": false
          },
          {
            "score": 0.7939602136611938,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.7795811891555786,
            "answer": "discourage",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8589675426483154,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoting"
        ],
        "predictions": [
          {
            "score": 0.8944275975227356,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.8781294226646423,
            "answer": "promoting",
            "hit": true
          },
          {
            "score": 0.8345465660095215,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.833759069442749,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.8177255392074585,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.7867518663406372,
            "answer": "promotion",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8781293630599976,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protecting"
        ],
        "predictions": [
          {
            "score": 0.8219524621963501,
            "answer": "protecting",
            "hit": true
          },
          {
            "score": 0.8138759732246399,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.7913086414337158,
            "answer": "safeguard",
            "hit": false
          },
          {
            "score": 0.7837619781494141,
            "answer": "protection",
            "hit": false
          },
          {
            "score": 0.7833858132362366,
            "answer": "protections",
            "hit": false
          },
          {
            "score": 0.7485654354095459,
            "answer": "secure",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8219524621963501,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "providing"
        ],
        "predictions": [
          {
            "score": 0.8921548128128052,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.86236971616745,
            "answer": "providing",
            "hit": true
          },
          {
            "score": 0.8529132008552551,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.8069967031478882,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8006588220596313,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.7988947629928589,
            "answer": "bring",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8623696565628052,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiving"
        ],
        "predictions": [
          {
            "score": 0.8786818385124207,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8465611934661865,
            "answer": "receiving",
            "hit": true
          },
          {
            "score": 0.785489559173584,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.7792428731918335,
            "answer": "obtain",
            "hit": false
          },
          {
            "score": 0.7741402983665466,
            "answer": "participate",
            "hit": false
          },
          {
            "score": 0.7644912004470825,
            "answer": "provide",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8465611934661865,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reducing"
        ],
        "predictions": [
          {
            "score": 0.8797934055328369,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8762949705123901,
            "answer": "reducing",
            "hit": true
          },
          {
            "score": 0.8542691469192505,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.8334847688674927,
            "answer": "eliminate",
            "hit": false
          },
          {
            "score": 0.8330191373825073,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.8316742181777954,
            "answer": "reduced",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8762950003147125,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referring"
        ],
        "predictions": [
          {
            "score": 0.7856975793838501,
            "answer": "referring",
            "hit": true
          },
          {
            "score": 0.7638955116271973,
            "answer": "although",
            "hit": false
          },
          {
            "score": 0.7597116231918335,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.7556465864181519,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7524508833885193,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.7522768974304199,
            "answer": "furthermore",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7856975793838501,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remaining"
        ],
        "predictions": [
          {
            "score": 0.8815199136734009,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.8517293930053711,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.7932473421096802,
            "answer": "keep",
            "hit": false
          },
          {
            "score": 0.7923961281776428,
            "answer": "retain",
            "hit": false
          },
          {
            "score": 0.7906454801559448,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.7786121368408203,
            "answer": "maintain",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.772882729768753,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembering"
        ],
        "predictions": [
          {
            "score": 0.8590993881225586,
            "answer": "remembers",
            "hit": false
          },
          {
            "score": 0.8265721797943115,
            "answer": "remembering",
            "hit": true
          },
          {
            "score": 0.8189079761505127,
            "answer": "recall",
            "hit": false
          },
          {
            "score": 0.8188691139221191,
            "answer": "remembered",
            "hit": false
          },
          {
            "score": 0.773202657699585,
            "answer": "forget",
            "hit": false
          },
          {
            "score": 0.7707406878471375,
            "answer": "recalls",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8265721797943115,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "representing"
        ],
        "predictions": [
          {
            "score": 0.8469552397727966,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.8085759878158569,
            "answer": "representations",
            "hit": false
          },
          {
            "score": 0.793499231338501,
            "answer": "representing",
            "hit": true
          },
          {
            "score": 0.7826929092407227,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.760224461555481,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.7362172603607178,
            "answer": "representative",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7934992015361786,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requiring"
        ],
        "predictions": [
          {
            "score": 0.839923083782196,
            "answer": "requiring",
            "hit": true
          },
          {
            "score": 0.8019938468933105,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.781915545463562,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.780232310295105,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7796525955200195,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7783592343330383,
            "answer": "prohibit",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8399231433868408,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seeming"
        ],
        "predictions": [
          {
            "score": 0.8755486011505127,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8625186085700989,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7907825708389282,
            "answer": "seeming",
            "hit": true
          },
          {
            "score": 0.7764207720756531,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7723559141159058,
            "answer": "have",
            "hit": false
          },
          {
            "score": 0.7668259143829346,
            "answer": "appeared",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7907825708389282,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to sit ",
        "b": "sit",
        "expected answer": [
          "sitting"
        ],
        "predictions": [
          {
            "score": 0.8413590788841248,
            "answer": "sits",
            "hit": false
          },
          {
            "score": 0.8263450860977173,
            "answer": "sitting",
            "hit": true
          },
          {
            "score": 0.7351970076560974,
            "answer": "walk",
            "hit": false
          },
          {
            "score": 0.7348076701164246,
            "answer": "occupy",
            "hit": false
          },
          {
            "score": 0.733014702796936,
            "answer": "stood",
            "hit": false
          },
          {
            "score": 0.7323826551437378,
            "answer": "seated",
            "hit": false
          }
        ],
        "set_exclude": [
          "sit"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8263450562953949,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spending"
        ],
        "predictions": [
          {
            "score": 0.8888776302337646,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8606454133987427,
            "answer": "spending",
            "hit": true
          },
          {
            "score": 0.8601102828979492,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.7721158266067505,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.768273115158081,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7457724213600159,
            "answer": "devote",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8606454133987427,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teaching"
        ],
        "predictions": [
          {
            "score": 0.889914333820343,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8749581575393677,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.8298712968826294,
            "answer": "teaching",
            "hit": true
          },
          {
            "score": 0.8006123304367065,
            "answer": "educate",
            "hit": false
          },
          {
            "score": 0.7956241965293884,
            "answer": "learn",
            "hit": false
          },
          {
            "score": 0.7828569412231445,
            "answer": "preach",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8298712968826294,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "telling"
        ],
        "predictions": [
          {
            "score": 0.782664954662323,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.7743982672691345,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.7598927617073059,
            "answer": "telling",
            "hit": true
          },
          {
            "score": 0.7279639840126038,
            "answer": "convince",
            "hit": false
          },
          {
            "score": 0.727655827999115,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.7270291447639465,
            "answer": "talking",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7598927915096283,
        "b in neighbourhood of b_prime": 19,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understanding"
        ],
        "predictions": [
          {
            "score": 0.8037042021751404,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7822238802909851,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7812536358833313,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.7774640917778015,
            "answer": "understanding",
            "hit": true
          },
          {
            "score": 0.7719600796699524,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.7671339511871338,
            "answer": "clearly",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7774641215801239,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 4
      }
    ],
    "result": {
      "cnt_questions_correct": 15,
      "cnt_questions_total": 50,
      "accuracy": 0.3
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I06 [verb_inf - Ving].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "03b64790-fa0c-43cc-850f-c2f50da8c3dd",
      "timestamp": "2025-05-17T17:08:12.590329"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepted"
        ],
        "predictions": [
          {
            "score": 0.881279468536377,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.8616923093795776,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.8471611142158508,
            "answer": "accepted",
            "hit": true
          },
          {
            "score": 0.8135776519775391,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.789398729801178,
            "answer": "reject",
            "hit": false
          },
          {
            "score": 0.7829883098602295,
            "answer": "acknowledge",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8471611142158508,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieved"
        ],
        "predictions": [
          {
            "score": 0.7977390289306641,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7924083471298218,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7867431044578552,
            "answer": "achieved",
            "hit": true
          },
          {
            "score": 0.7702281475067139,
            "answer": "ensure",
            "hit": false
          },
          {
            "score": 0.7625571489334106,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.7618892192840576,
            "answer": "attain",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7867431044578552,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.7313344478607178,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.7168073058128357,
            "answer": "need",
            "hit": false
          },
          {
            "score": 0.7154136896133423,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.7151359915733337,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.7139960527420044,
            "answer": "additive",
            "hit": false
          },
          {
            "score": 0.713074803352356,
            "answer": "update",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7313344478607178,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8747720122337341,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8463097810745239,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.837645411491394,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8146491646766663,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7868742942810059,
            "answer": "acknowledge",
            "hit": false
          },
          {
            "score": 0.7832205295562744,
            "answer": "disagreed",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8463097810745239,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.8863883018493652,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.846862256526947,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.8188943862915039,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.8138890266418457,
            "answer": "permit",
            "hit": false
          },
          {
            "score": 0.8078088164329529,
            "answer": "let",
            "hit": false
          },
          {
            "score": 0.8069967031478882,
            "answer": "provide",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 38,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7387400269508362,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 39
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.838386058807373,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8196549415588379,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.7855234146118164,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.7711190581321716,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.7337414026260376,
            "answer": "announced",
            "hit": true
          },
          {
            "score": 0.7332971692085266,
            "answer": "notification",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7337413877248764,
        "b in neighbourhood of b_prime": 16,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8739266395568848,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8625186085700989,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.8230941891670227,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7743961811065674,
            "answer": "resemble",
            "hit": false
          },
          {
            "score": 0.7738533020019531,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7735451459884644,
            "answer": "occur",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8739266991615295,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8130729794502258,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7910484075546265,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.7787295579910278,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.744622528553009,
            "answer": "evaluate",
            "hit": false
          },
          {
            "score": 0.743034839630127,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.7427865862846375,
            "answer": "applications",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7787295579910278,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.7570203542709351,
            "answer": "asking",
            "hit": false
          },
          {
            "score": 0.7567336559295654,
            "answer": "asked",
            "hit": true
          },
          {
            "score": 0.7550273537635803,
            "answer": "questions",
            "hit": false
          },
          {
            "score": 0.7531464099884033,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.7515357136726379,
            "answer": "question",
            "hit": false
          },
          {
            "score": 0.7509892582893372,
            "answer": "meet",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.756733626127243,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.8697313070297241,
            "answer": "attending",
            "hit": false
          },
          {
            "score": 0.8631066083908081,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.8096510171890259,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.8064194321632385,
            "answer": "participate",
            "hit": false
          },
          {
            "score": 0.7947337627410889,
            "answer": "attendees",
            "hit": false
          },
          {
            "score": 0.7504538297653198,
            "answer": "participates",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8631066381931305,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.7469394207000732,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.7458730936050415,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.7457171678543091,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.73344886302948,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.730496883392334,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.7303129434585571,
            "answer": "join",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7458731532096863,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.78984534740448,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.7771393656730652,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7683236002922058,
            "answer": "honestly",
            "hit": false
          },
          {
            "score": 0.7655804753303528,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.763603687286377,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7557419538497925,
            "answer": "bel",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7655804753303528,
        "b in neighbourhood of b_prime": 17,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.7909044623374939,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7676159143447876,
            "answer": "increasing",
            "hit": false
          },
          {
            "score": 0.7553883194923401,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7509335279464722,
            "answer": "reasonable",
            "hit": false
          },
          {
            "score": 0.7501152753829956,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7478833794593811,
            "answer": "particularly",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 101,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7082402408123016,
        "b in neighbourhood of b_prime": 160,
        "b_prime in neighbourhood of b": 102
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.7568832635879517,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.748924732208252,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.748767077922821,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.737725019454956,
            "answer": "proceed",
            "hit": false
          },
          {
            "score": 0.7294521331787109,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7238302230834961,
            "answer": "repeat",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7487670332193375,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.8098041415214539,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8094359040260315,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.7707169055938721,
            "answer": "generate",
            "hit": false
          },
          {
            "score": 0.7619770765304565,
            "answer": "created",
            "hit": true
          },
          {
            "score": 0.7558480501174927,
            "answer": "ensure",
            "hit": false
          },
          {
            "score": 0.7492598295211792,
            "answer": "achieve",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7619771361351013,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to decide ",
        "b": "decide",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8918406367301941,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.860167384147644,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.850515604019165,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8342084884643555,
            "answer": "choose",
            "hit": false
          },
          {
            "score": 0.8217923641204834,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.8027645945549011,
            "answer": "chooses",
            "hit": false
          }
        ],
        "set_exclude": [
          "decide"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8505156636238098,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.88374924659729,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8542947769165039,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.7950342297554016,
            "answer": "descriptions",
            "hit": false
          },
          {
            "score": 0.7949916124343872,
            "answer": "depict",
            "hit": false
          },
          {
            "score": 0.7934595346450806,
            "answer": "define",
            "hit": false
          },
          {
            "score": 0.7860919833183289,
            "answer": "specify",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7563444972038269,
        "b in neighbourhood of b_prime": 12,
        "b_prime in neighbourhood of b": 15
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8854014873504639,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.8651421070098877,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8541511297225952,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.7938932776451111,
            "answer": "evolve",
            "hit": false
          },
          {
            "score": 0.7821511626243591,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7779421210289001,
            "answer": "produce",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8541511595249176,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to discover ",
        "b": "discover",
        "expected answer": [
          "discovered"
        ],
        "predictions": [
          {
            "score": 0.770028293132782,
            "answer": "discovers",
            "hit": false
          },
          {
            "score": 0.7666359543800354,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.7612583637237549,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.754886269569397,
            "answer": "finding",
            "hit": false
          },
          {
            "score": 0.7458150386810303,
            "answer": "uncover",
            "hit": false
          },
          {
            "score": 0.7372421026229858,
            "answer": "discovery",
            "hit": false
          }
        ],
        "set_exclude": [
          "discover"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7231311202049255,
        "b in neighbourhood of b_prime": 105,
        "b_prime in neighbourhood of b": 20
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyed"
        ],
        "predictions": [
          {
            "score": 0.8120999932289124,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7885305285453796,
            "answer": "enjoyed",
            "hit": true
          },
          {
            "score": 0.7876150608062744,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.7674121856689453,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7522728443145752,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7516811490058899,
            "answer": "feel",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7885305285453796,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensured"
        ],
        "predictions": [
          {
            "score": 0.8099716305732727,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7980961799621582,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7935063242912292,
            "answer": "ensured",
            "hit": true
          },
          {
            "score": 0.788062572479248,
            "answer": "verify",
            "hit": false
          },
          {
            "score": 0.7702281475067139,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.7657747864723206,
            "answer": "ideally",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.793506383895874,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8520770072937012,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8274535536766052,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7631235122680664,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.7612297534942627,
            "answer": "initiating",
            "hit": false
          },
          {
            "score": 0.7596732378005981,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7570483684539795,
            "answer": "restoring",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7631235122680664,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.7997400164604187,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.7891153693199158,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.779319703578949,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.7621015310287476,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.7465555667877197,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.739812970161438,
            "answer": "considering",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7465555965900421,
        "b in neighbourhood of b_prime": 16,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.8120335340499878,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.7988346219062805,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.7367404699325562,
            "answer": "adhere",
            "hit": false
          },
          {
            "score": 0.7360302209854126,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7356061935424805,
            "answer": "obey",
            "hit": false
          },
          {
            "score": 0.7283647656440735,
            "answer": "accompany",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7988346219062805,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8442500829696655,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.8140237331390381,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.7647870182991028,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.758767306804657,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7527258396148682,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7504315376281738,
            "answer": "auditory",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7647870182991028,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identified"
        ],
        "predictions": [
          {
            "score": 0.8861641883850098,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8696592450141907,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7913675308227539,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7898815870285034,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7776312828063965,
            "answer": "recognize",
            "hit": false
          },
          {
            "score": 0.7740652561187744,
            "answer": "describe",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 29,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7399286180734634,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 30
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.8441023826599121,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.8371005058288574,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.810447096824646,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8089033365249634,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.8048802018165588,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7805802226066589,
            "answer": "alleviate",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8371005058288574,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.849853515625,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.7960958480834961,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7944343090057373,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7879039645195007,
            "answer": "incorporate",
            "hit": false
          },
          {
            "score": 0.7634400129318237,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.7630188465118408,
            "answer": "provide",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8498534858226776,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to introduce ",
        "b": "introduce",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8941555023193359,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.893486499786377,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.8750905990600586,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8187789916992188,
            "answer": "introduction",
            "hit": false
          },
          {
            "score": 0.7829998135566711,
            "answer": "bring",
            "hit": false
          },
          {
            "score": 0.7701992988586426,
            "answer": "propose",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduce"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8750905990600586,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8940294981002808,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8378790616989136,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.8019938468933105,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.7944343090057373,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.7883403897285461,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7867710590362549,
            "answer": "incorporate",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7563971281051636,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 20
      },
      {
        "question verbose": "What is to locate ",
        "b": "locate",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8807605504989624,
            "answer": "locating",
            "hit": false
          },
          {
            "score": 0.8060806393623352,
            "answer": "located",
            "hit": true
          },
          {
            "score": 0.7957620024681091,
            "answer": "find",
            "hit": false
          },
          {
            "score": 0.794559121131897,
            "answer": "retrieve",
            "hit": false
          },
          {
            "score": 0.7898815870285034,
            "answer": "identify",
            "hit": false
          },
          {
            "score": 0.7722024917602539,
            "answer": "determine",
            "hit": false
          }
        ],
        "set_exclude": [
          "locate"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8060806393623352,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.7982927560806274,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7737860679626465,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.759117066860199,
            "answer": "lost",
            "hit": true
          },
          {
            "score": 0.7580106854438782,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.7436167001724243,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7336412668228149,
            "answer": "regain",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.759117066860199,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8691065311431885,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7773045301437378,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7756030559539795,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.7727968692779541,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.7606368660926819,
            "answer": "manipulate",
            "hit": false
          },
          {
            "score": 0.7549307346343994,
            "answer": "administer",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7756030559539795,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to marry ",
        "b": "marry",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.8953391313552856,
            "answer": "marrying",
            "hit": false
          },
          {
            "score": 0.8352612257003784,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.8123355507850647,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.8058747053146362,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.7755287885665894,
            "answer": "marital",
            "hit": false
          },
          {
            "score": 0.771725058555603,
            "answer": "kissed",
            "hit": false
          }
        ],
        "set_exclude": [
          "marry"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8352612555027008,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.9005298614501953,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.8682640790939331,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.7821890115737915,
            "answer": "execute",
            "hit": false
          },
          {
            "score": 0.7739981412887573,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7658475637435913,
            "answer": "participate",
            "hit": false
          },
          {
            "score": 0.7641125321388245,
            "answer": "performing",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8682640790939331,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8921548128128052,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.86236971616745,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8529132008552551,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.8069967031478882,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8006588220596313,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.7988947629928589,
            "answer": "bring",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 179,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7136726677417755,
        "b in neighbourhood of b_prime": 15,
        "b_prime in neighbourhood of b": 180
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.8743718862533569,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.8227976560592651,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7942847013473511,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.7913978695869446,
            "answer": "published",
            "hit": true
          },
          {
            "score": 0.7909828424453735,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.7680726647377014,
            "answer": "disclose",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7913978695869446,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8786818385124207,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8465611934661865,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.785489559173584,
            "answer": "received",
            "hit": true
          },
          {
            "score": 0.7792428731918335,
            "answer": "obtain",
            "hit": false
          },
          {
            "score": 0.7741402983665466,
            "answer": "participate",
            "hit": false
          },
          {
            "score": 0.7644912004470825,
            "answer": "provide",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7854895293712616,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.8797934055328369,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8762949705123901,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.8542691469192505,
            "answer": "decrease",
            "hit": false
          },
          {
            "score": 0.8334847688674927,
            "answer": "eliminate",
            "hit": false
          },
          {
            "score": 0.8330191373825073,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.8316742181777954,
            "answer": "reduced",
            "hit": true
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8316742181777954,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.7856975793838501,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7638955116271973,
            "answer": "although",
            "hit": false
          },
          {
            "score": 0.7597116231918335,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.7556465864181519,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7524508833885193,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.7522768974304199,
            "answer": "furthermore",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7597116231918335,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to relate ",
        "b": "relate",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8807252645492554,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.8156638145446777,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.767379641532898,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7643427848815918,
            "answer": "arise",
            "hit": false
          },
          {
            "score": 0.7635799646377563,
            "answer": "derive",
            "hit": false
          },
          {
            "score": 0.7553499937057495,
            "answer": "depict",
            "hit": false
          }
        ],
        "set_exclude": [
          "relate"
        ],
        "rank": 98,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7111083418130875,
        "b in neighbourhood of b_prime": 60,
        "b_prime in neighbourhood of b": 99
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8815199136734009,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.8517293930053711,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.7932473421096802,
            "answer": "keep",
            "hit": false
          },
          {
            "score": 0.7923961281776428,
            "answer": "retain",
            "hit": false
          },
          {
            "score": 0.7906454801559448,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.7786121368408203,
            "answer": "maintain",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8815199136734009,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.7788068056106567,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.7621755599975586,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.758103609085083,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.75592041015625,
            "answer": "split",
            "hit": false
          },
          {
            "score": 0.7505188584327698,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7365209460258484,
            "answer": "replacement",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7581036686897278,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.839923083782196,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.8019938468933105,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.781915545463562,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.780232310295105,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7796525955200195,
            "answer": "requirement",
            "hit": false
          },
          {
            "score": 0.7783592343330383,
            "answer": "prohibit",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7464366406202316,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 18
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.8755486011505127,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.8625186085700989,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7907825708389282,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7764207720756531,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7723559141159058,
            "answer": "have",
            "hit": false
          },
          {
            "score": 0.7668259143829346,
            "answer": "appeared",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8755486309528351,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.790214478969574,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7900911569595337,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.7430071830749512,
            "answer": "sent",
            "hit": true
          },
          {
            "score": 0.7203497290611267,
            "answer": "communicate",
            "hit": false
          },
          {
            "score": 0.7185301780700684,
            "answer": "push",
            "hit": false
          },
          {
            "score": 0.7172192335128784,
            "answer": "received",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.743007242679596,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8888776302337646,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8606454133987427,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.8601102828979492,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.7721158266067505,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.768273115158081,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7457724213600159,
            "answer": "devote",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8601102828979492,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.782664954662323,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.7743982672691345,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.7598927617073059,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.7279639840126038,
            "answer": "convince",
            "hit": false
          },
          {
            "score": 0.727655827999115,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.7270291447639465,
            "answer": "talking",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7276557832956314,
        "b in neighbourhood of b_prime": 56,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8037042021751404,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7822238802909851,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7812536358833313,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.7774640917778015,
            "answer": "understanding",
            "hit": false
          },
          {
            "score": 0.7719600796699524,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.7671339511871338,
            "answer": "clearly",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7812536358833313,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to unite ",
        "b": "unite",
        "expected answer": [
          "united"
        ],
        "predictions": [
          {
            "score": 0.7874167561531067,
            "answer": "unity",
            "hit": false
          },
          {
            "score": 0.7717949748039246,
            "answer": "unified",
            "hit": false
          },
          {
            "score": 0.7680478692054749,
            "answer": "converge",
            "hit": false
          },
          {
            "score": 0.766789436340332,
            "answer": "organize",
            "hit": false
          },
          {
            "score": 0.7665219306945801,
            "answer": "collaborate",
            "hit": false
          },
          {
            "score": 0.7587113380432129,
            "answer": "gather",
            "hit": false
          }
        ],
        "set_exclude": [
          "unite"
        ],
        "rank": 177,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7005601972341537,
        "b in neighbourhood of b_prime": 28,
        "b_prime in neighbourhood of b": 178
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 50,
      "accuracy": 0.1
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I07 [verb_inf - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "da6997dd-b019-47f1-bd54-6da7424e8262",
      "timestamp": "2025-05-17T17:08:13.015864"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.8023260831832886,
            "answer": "putting",
            "hit": false
          },
          {
            "score": 0.7976491451263428,
            "answer": "adds",
            "hit": true
          },
          {
            "score": 0.7803846001625061,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.7775750160217285,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7748430967330933,
            "answer": "additionally",
            "hit": false
          },
          {
            "score": 0.7598051428794861,
            "answer": "changing",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7976491451263428,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.8805684447288513,
            "answer": "letting",
            "hit": false
          },
          {
            "score": 0.846862256526947,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8465179204940796,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.8377118110656738,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.8372436761856079,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8342371582984924,
            "answer": "granting",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8377118110656738,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.8240270614624023,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8230941891670227,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7906527519226074,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7858110666275024,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7659994959831238,
            "answer": "exhibiting",
            "hit": false
          },
          {
            "score": 0.764356255531311,
            "answer": "showing",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 168,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7068353593349457,
        "b in neighbourhood of b_prime": 52,
        "b_prime in neighbourhood of b": 169
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.8538740873336792,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.8140385150909424,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.813072919845581,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.7952889204025269,
            "answer": "evaluating",
            "hit": false
          },
          {
            "score": 0.7861205339431763,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.783545196056366,
            "answer": "administering",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8140385150909424,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.850979208946228,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.8119216561317444,
            "answer": "saying",
            "hit": false
          },
          {
            "score": 0.8055951595306396,
            "answer": "urging",
            "hit": false
          },
          {
            "score": 0.7997996211051941,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.796433687210083,
            "answer": "begging",
            "hit": false
          },
          {
            "score": 0.796387255191803,
            "answer": "insisting",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 768,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6695484519004822,
        "b in neighbourhood of b_prime": 221,
        "b_prime in neighbourhood of b": 769
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.8165639042854309,
            "answer": "getting",
            "hit": false
          },
          {
            "score": 0.8090686798095703,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.7996583580970764,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.7836909890174866,
            "answer": "joining",
            "hit": false
          },
          {
            "score": 0.7723737359046936,
            "answer": "turning",
            "hit": false
          },
          {
            "score": 0.7705320715904236,
            "answer": "acquiring",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7996584177017212,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to believing ",
        "b": "believing",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.8212485909461975,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.8179312944412231,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.8176817297935486,
            "answer": "trusting",
            "hit": false
          },
          {
            "score": 0.7990610599517822,
            "answer": "insisting",
            "hit": false
          },
          {
            "score": 0.7990425825119019,
            "answer": "knowing",
            "hit": false
          },
          {
            "score": 0.7980232238769531,
            "answer": "believed",
            "hit": false
          }
        ],
        "set_exclude": [
          "believing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8212485909461975,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.8214640617370605,
            "answer": "honestly",
            "hit": false
          },
          {
            "score": 0.8179839253425598,
            "answer": "clearly",
            "hit": false
          },
          {
            "score": 0.8178960084915161,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.8178218007087708,
            "answer": "depending",
            "hit": false
          },
          {
            "score": 0.8112767338752747,
            "answer": "besides",
            "hit": false
          },
          {
            "score": 0.8100048303604126,
            "answer": "compared",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7870941758155823,
        "b in neighbourhood of b_prime": 34,
        "b_prime in neighbourhood of b": 25
      },
      {
        "question verbose": "What is to consisting ",
        "b": "consisting",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.8877516984939575,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.8729672431945801,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.8652016520500183,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.8608614802360535,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.8441696763038635,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.820319414138794,
            "answer": "containing",
            "hit": false
          }
        ],
        "set_exclude": [
          "consisting"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8729672431945801,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.841410756111145,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.8383350372314453,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.820319414138794,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.7932730913162231,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.7916790246963501,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.7879116535186768,
            "answer": "featuring",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8383350372314453,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.7582324147224426,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7565861940383911,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.7565268278121948,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.748924732208252,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.7433263659477234,
            "answer": "further",
            "hit": false
          },
          {
            "score": 0.7420872449874878,
            "answer": "continued",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7565861642360687,
        "b in neighbourhood of b_prime": 36,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.834180474281311,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8327337503433228,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.8263342976570129,
            "answer": "generating",
            "hit": false
          },
          {
            "score": 0.8261294364929199,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.8207293152809143,
            "answer": "producing",
            "hit": false
          },
          {
            "score": 0.8196457028388977,
            "answer": "designing",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8327338099479675,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to depending ",
        "b": "depending",
        "expected answer": [
          "depends"
        ],
        "predictions": [
          {
            "score": 0.8361135721206665,
            "answer": "generally",
            "hit": false
          },
          {
            "score": 0.833524227142334,
            "answer": "ideally",
            "hit": false
          },
          {
            "score": 0.8284063935279846,
            "answer": "alternatively",
            "hit": false
          },
          {
            "score": 0.8222631216049194,
            "answer": "regardless",
            "hit": false
          },
          {
            "score": 0.8178218007087708,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.8168479204177856,
            "answer": "although",
            "hit": false
          }
        ],
        "set_exclude": [
          "depending"
        ],
        "rank": 28,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7801868915557861,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 29
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.8571397662162781,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.8542947769165039,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.8399685621261597,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.8249880075454712,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.8200824856758118,
            "answer": "discussing",
            "hit": false
          },
          {
            "score": 0.8197376132011414,
            "answer": "stating",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8399685323238373,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.8651420474052429,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.8299149870872498,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.8193261623382568,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.7782414555549622,
            "answer": "producing",
            "hit": false
          },
          {
            "score": 0.7711923122406006,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7706097960472107,
            "answer": "creating",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8193261325359344,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to discovering ",
        "b": "discovering",
        "expected answer": [
          "discovers"
        ],
        "predictions": [
          {
            "score": 0.8497799634933472,
            "answer": "discovers",
            "hit": true
          },
          {
            "score": 0.8265970945358276,
            "answer": "uncover",
            "hit": false
          },
          {
            "score": 0.8221617937088013,
            "answer": "discoveries",
            "hit": false
          },
          {
            "score": 0.8212943077087402,
            "answer": "realizing",
            "hit": false
          },
          {
            "score": 0.8168169260025024,
            "answer": "discovered",
            "hit": false
          },
          {
            "score": 0.8153431415557861,
            "answer": "noticing",
            "hit": false
          }
        ],
        "set_exclude": [
          "discovering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8497799038887024,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to enabling ",
        "b": "enabling",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.8465179204940796,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.8396036028862,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.8309773802757263,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.8105962872505188,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8086460828781128,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.790839433670044,
            "answer": "enhancing",
            "hit": false
          }
        ],
        "set_exclude": [
          "enabling"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8396036028862,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.7585311532020569,
            "answer": "extant",
            "hit": false
          },
          {
            "score": 0.7440080642700195,
            "answer": "old",
            "hit": false
          },
          {
            "score": 0.7310587167739868,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.7269026041030884,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.7177855968475342,
            "answer": "emerging",
            "hit": false
          },
          {
            "score": 0.715660810470581,
            "answer": "proposed",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7139834314584732,
        "b in neighbourhood of b_prime": 159,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to explaining ",
        "b": "explaining",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.8571397662162781,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8216339349746704,
            "answer": "explanation",
            "hit": false
          },
          {
            "score": 0.8170673847198486,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.8149409294128418,
            "answer": "discussing",
            "hit": false
          },
          {
            "score": 0.8141903281211853,
            "answer": "arguing",
            "hit": false
          },
          {
            "score": 0.8124223351478577,
            "answer": "informing",
            "hit": false
          }
        ],
        "set_exclude": [
          "explaining"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8170673549175262,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.7634216547012329,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.7449294328689575,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.7360302209854126,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.7266919016838074,
            "answer": "after",
            "hit": false
          },
          {
            "score": 0.7138140201568604,
            "answer": "resulting",
            "hit": false
          },
          {
            "score": 0.7094191312789917,
            "answer": "followed",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7634216547012329,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to happening ",
        "b": "happening",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.8795504570007324,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.844516932964325,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8293793201446533,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8156317472457886,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.7821776866912842,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7695676684379578,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happening"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8156318068504333,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.8248400688171387,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.8140237331390381,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.778506338596344,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7673536539077759,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.7539170980453491,
            "answer": "witnessing",
            "hit": false
          },
          {
            "score": 0.747908353805542,
            "answer": "auditory",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7673537135124207,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.8430691361427307,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.8414095640182495,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.8320558667182922,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8228130340576172,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.8125424385070801,
            "answer": "expanding",
            "hit": false
          },
          {
            "score": 0.811168372631073,
            "answer": "strengthening",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8414096236228943,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.8403870463371277,
            "answer": "excluding",
            "hit": false
          },
          {
            "score": 0.8101387619972229,
            "answer": "particularly",
            "hit": false
          },
          {
            "score": 0.7872829437255859,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.7784334421157837,
            "answer": "mostly",
            "hit": false
          },
          {
            "score": 0.7759799957275391,
            "answer": "even",
            "hit": false
          },
          {
            "score": 0.7752958536148071,
            "answer": "that",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7872829437255859,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.8378791213035583,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8286670446395874,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.8139055967330933,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7970918416976929,
            "answer": "featuring",
            "hit": false
          },
          {
            "score": 0.7925362586975098,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.790252685546875,
            "answer": "consisting",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.828667014837265,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to learning ",
        "b": "learning",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.8458263278007507,
            "answer": "learn",
            "hit": false
          },
          {
            "score": 0.7892601490020752,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.7781909704208374,
            "answer": "learners",
            "hit": false
          },
          {
            "score": 0.7733219265937805,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.7580814957618713,
            "answer": "studying",
            "hit": false
          },
          {
            "score": 0.7454609274864197,
            "answer": "learnt",
            "hit": false
          }
        ],
        "set_exclude": [
          "learning"
        ],
        "rank": 47,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7014208436012268,
        "b in neighbourhood of b_prime": 72,
        "b_prime in neighbourhood of b": 48
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "loses"
        ],
        "predictions": [
          {
            "score": 0.8325502872467041,
            "answer": "loses",
            "hit": true
          },
          {
            "score": 0.8057748079299927,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7985756993293762,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7942529916763306,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.7744964361190796,
            "answer": "getting",
            "hit": false
          },
          {
            "score": 0.7737861275672913,
            "answer": "lose",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8325502872467041,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "manages"
        ],
        "predictions": [
          {
            "score": 0.7773045301437378,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.752347469329834,
            "answer": "manages",
            "hit": true
          },
          {
            "score": 0.7520676851272583,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.7479680776596069,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.7445934414863586,
            "answer": "ceo",
            "hit": false
          },
          {
            "score": 0.739648699760437,
            "answer": "chairman",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7523475289344788,
        "b in neighbourhood of b_prime": 71,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to occurring ",
        "b": "occurring",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.8795504570007324,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.8536938428878784,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8349947929382324,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.822311520576477,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.7999231815338135,
            "answer": "arising",
            "hit": false
          },
          {
            "score": 0.7936985492706299,
            "answer": "occurrence",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurring"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8349947333335876,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.7780974507331848,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7723298072814941,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.7611726522445679,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7373482584953308,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.7304688692092896,
            "answer": "running",
            "hit": false
          },
          {
            "score": 0.7293651103973389,
            "answer": "programming",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7723297774791718,
        "b in neighbourhood of b_prime": 66,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performs"
        ],
        "predictions": [
          {
            "score": 0.8086994290351868,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.7730962634086609,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7721922993659973,
            "answer": "performs",
            "hit": true
          },
          {
            "score": 0.7653701305389404,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7641124725341797,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.7590222954750061,
            "answer": "achieving",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7721923589706421,
        "b in neighbourhood of b_prime": 25,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to promoting ",
        "b": "promoting",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.8781294226646423,
            "answer": "promote",
            "hit": false
          },
          {
            "score": 0.8544712066650391,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8413748145103455,
            "answer": "advocating",
            "hit": false
          },
          {
            "score": 0.8217085599899292,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.8120217323303223,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.8058310151100159,
            "answer": "encouraging",
            "hit": false
          }
        ],
        "set_exclude": [
          "promoting"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8544712662696838,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.8623696565628052,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8584535717964172,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.8422452211380005,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.8372436761856079,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.8369290828704834,
            "answer": "delivering",
            "hit": false
          },
          {
            "score": 0.8362303972244263,
            "answer": "facilitating",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8327502608299255,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.8465611934661865,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.819614052772522,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.7700979709625244,
            "answer": "getting",
            "hit": false
          },
          {
            "score": 0.7698832750320435,
            "answer": "experiencing",
            "hit": false
          },
          {
            "score": 0.7698342204093933,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7648700475692749,
            "answer": "obtaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8196139931678772,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.8762949705123901,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.8581956624984741,
            "answer": "eliminating",
            "hit": false
          },
          {
            "score": 0.8560569286346436,
            "answer": "lowering",
            "hit": false
          },
          {
            "score": 0.8543565273284912,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.8497282862663269,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.8442760109901428,
            "answer": "preventing",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8497283458709717,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to referring ",
        "b": "referring",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.8742337822914124,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.8249880075454712,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8140431046485901,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.8118383288383484,
            "answer": "implying",
            "hit": false
          },
          {
            "score": 0.8062158226966858,
            "answer": "mentioning",
            "hit": false
          },
          {
            "score": 0.7892925143241882,
            "answer": "pointing",
            "hit": false
          }
        ],
        "set_exclude": [
          "referring"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8140430748462677,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "relates"
        ],
        "predictions": [
          {
            "score": 0.8730314373970032,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.8297833204269409,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.815876841545105,
            "answer": "relates",
            "hit": true
          },
          {
            "score": 0.8156638145446777,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.8139055967330933,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7996578216552734,
            "answer": "concerning",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.815876841545105,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.8293273448944092,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.7835555076599121,
            "answer": "surviving",
            "hit": false
          },
          {
            "score": 0.7728826999664307,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7656394839286804,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7412064075469971,
            "answer": "lingering",
            "hit": false
          },
          {
            "score": 0.7377996444702148,
            "answer": "remains",
            "hit": true
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7377996891736984,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.8312925696372986,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.793499231338501,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.7922893762588501,
            "answer": "depicting",
            "hit": false
          },
          {
            "score": 0.7864215970039368,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7844321131706238,
            "answer": "indicating",
            "hit": false
          },
          {
            "score": 0.7800514698028564,
            "answer": "presenting",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8312925696372986,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.8470609784126282,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.839923083782196,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.8197528123855591,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.8118526935577393,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.7961612939834595,
            "answer": "restricting",
            "hit": false
          },
          {
            "score": 0.7925362586975098,
            "answer": "involving",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7628599405288696,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 22
      },
      {
        "question verbose": "What is to seeming ",
        "b": "seeming",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.8384592533111572,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.806757926940918,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.8001495003700256,
            "answer": "startling",
            "hit": false
          },
          {
            "score": 0.7907825708389282,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7906527519226074,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7789488434791565,
            "answer": "apparent",
            "hit": false
          }
        ],
        "set_exclude": [
          "seeming"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7712662220001221,
        "b in neighbourhood of b_prime": 21,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to sitting ",
        "b": "sitting",
        "expected answer": [
          "sits"
        ],
        "predictions": [
          {
            "score": 0.8263450860977173,
            "answer": "sit",
            "hit": false
          },
          {
            "score": 0.8027852773666382,
            "answer": "sits",
            "hit": true
          },
          {
            "score": 0.7860844135284424,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.7776098251342773,
            "answer": "staring",
            "hit": false
          },
          {
            "score": 0.7702003121376038,
            "answer": "lying",
            "hit": false
          },
          {
            "score": 0.7684087753295898,
            "answer": "hanging",
            "hit": false
          }
        ],
        "set_exclude": [
          "sitting"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8027852773666382,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spends"
        ],
        "predictions": [
          {
            "score": 0.8606454133987427,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8273289203643799,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.8231542706489563,
            "answer": "spends",
            "hit": true
          },
          {
            "score": 0.8168399333953857,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7780892848968506,
            "answer": "funding",
            "hit": false
          },
          {
            "score": 0.7749680280685425,
            "answer": "investing",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8231542706489563,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to suggesting ",
        "b": "suggesting",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.8956377506256104,
            "answer": "implying",
            "hit": false
          },
          {
            "score": 0.8888639211654663,
            "answer": "indicating",
            "hit": false
          },
          {
            "score": 0.8414487838745117,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.8278371095657349,
            "answer": "proposing",
            "hit": false
          },
          {
            "score": 0.8218141198158264,
            "answer": "insisting",
            "hit": false
          },
          {
            "score": 0.817699670791626,
            "answer": "noting",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggesting"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8414487540721893,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "teaches"
        ],
        "predictions": [
          {
            "score": 0.8298712968826294,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.8162739872932434,
            "answer": "teachers",
            "hit": false
          },
          {
            "score": 0.8119668960571289,
            "answer": "teaches",
            "hit": true
          },
          {
            "score": 0.8110901117324829,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.8083999156951904,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.7824462056159973,
            "answer": "classrooms",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8119668364524841,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.8398401737213135,
            "answer": "saying",
            "hit": false
          },
          {
            "score": 0.8211597204208374,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.8117085695266724,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.8063598871231079,
            "answer": "stating",
            "hit": false
          },
          {
            "score": 0.8007603883743286,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.7997996807098389,
            "answer": "asking",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8117085695266724,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.7774640917778015,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7751771211624146,
            "answer": "comprehension",
            "hit": false
          },
          {
            "score": 0.7716500163078308,
            "answer": "knowing",
            "hit": false
          },
          {
            "score": 0.7700459957122803,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.769393265247345,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.7661163806915283,
            "answer": "insight",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7700459957122803,
        "b in neighbourhood of b_prime": 29,
        "b_prime in neighbourhood of b": 4
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 47,
      "accuracy": 0.10638297872340426
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I08 [verb_Ving - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "6a4cdff5-57cb-42e4-8477-3f62c17ee765",
      "timestamp": "2025-05-17T17:08:13.442909"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.8023260831832886,
            "answer": "putting",
            "hit": false
          },
          {
            "score": 0.7976491451263428,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.7803846001625061,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.7775750160217285,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7748430967330933,
            "answer": "additionally",
            "hit": false
          },
          {
            "score": 0.7598051428794861,
            "answer": "changing",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 44,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.737041786313057,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 45
      },
      {
        "question verbose": "What is to agreeing ",
        "b": "agreeing",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.837645411491394,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.8330535888671875,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.825223982334137,
            "answer": "acknowledging",
            "hit": false
          },
          {
            "score": 0.8244300484657288,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8096877932548523,
            "answer": "insisting",
            "hit": false
          },
          {
            "score": 0.8025482296943665,
            "answer": "rejecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "agreeing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8330535888671875,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.8805684447288513,
            "answer": "letting",
            "hit": false
          },
          {
            "score": 0.846862256526947,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8465179204940796,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.8377118110656738,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8372436761856079,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8342371582984924,
            "answer": "granting",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 181,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7197819352149963,
        "b in neighbourhood of b_prime": 16,
        "b_prime in neighbourhood of b": 182
      },
      {
        "question verbose": "What is to announcing ",
        "b": "announcing",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8456185460090637,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.8339987993240356,
            "answer": "declaring",
            "hit": false
          },
          {
            "score": 0.8334438800811768,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.8203961849212646,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8081061840057373,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.7959564328193665,
            "answer": "informing",
            "hit": false
          }
        ],
        "set_exclude": [
          "announcing"
        ],
        "rank": 46,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7559496164321899,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 47
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8240270614624023,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.8230941891670227,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7906527519226074,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7858110666275024,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7659994959831238,
            "answer": "exhibiting",
            "hit": false
          },
          {
            "score": 0.764356255531311,
            "answer": "showing",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8240270912647247,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8538740873336792,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.8140385150909424,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.813072919845581,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.7952889204025269,
            "answer": "evaluating",
            "hit": false
          },
          {
            "score": 0.7861205339431763,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.783545196056366,
            "answer": "administering",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.853874146938324,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.850979208946228,
            "answer": "requesting",
            "hit": false
          },
          {
            "score": 0.8119216561317444,
            "answer": "saying",
            "hit": false
          },
          {
            "score": 0.8055951595306396,
            "answer": "urging",
            "hit": false
          },
          {
            "score": 0.7997996211051941,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.796433687210083,
            "answer": "begging",
            "hit": false
          },
          {
            "score": 0.796387255191803,
            "answer": "insisting",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 84,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7316432893276215,
        "b in neighbourhood of b_prime": 54,
        "b_prime in neighbourhood of b": 85
      },
      {
        "question verbose": "What is to attending ",
        "b": "attending",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.8697313070297241,
            "answer": "attend",
            "hit": false
          },
          {
            "score": 0.8334460854530334,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.8164137601852417,
            "answer": "participating",
            "hit": false
          },
          {
            "score": 0.8053804039955139,
            "answer": "visiting",
            "hit": false
          },
          {
            "score": 0.7893428206443787,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.7803452014923096,
            "answer": "attendees",
            "hit": false
          }
        ],
        "set_exclude": [
          "attending"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8334460854530334,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8165639042854309,
            "answer": "getting",
            "hit": false
          },
          {
            "score": 0.8090686798095703,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.7996583580970764,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.7836909890174866,
            "answer": "joining",
            "hit": false
          },
          {
            "score": 0.7723737359046936,
            "answer": "turning",
            "hit": false
          },
          {
            "score": 0.7705320715904236,
            "answer": "acquiring",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 96,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7194072157144547,
        "b in neighbourhood of b_prime": 20,
        "b_prime in neighbourhood of b": 97
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8214640617370605,
            "answer": "honestly",
            "hit": false
          },
          {
            "score": 0.8179839253425598,
            "answer": "clearly",
            "hit": false
          },
          {
            "score": 0.8178960084915161,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.8178218007087708,
            "answer": "depending",
            "hit": false
          },
          {
            "score": 0.8112767338752747,
            "answer": "besides",
            "hit": false
          },
          {
            "score": 0.8100048303604126,
            "answer": "compared",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 139,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7401957511901855,
        "b in neighbourhood of b_prime": 34,
        "b_prime in neighbourhood of b": 140
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.841410756111145,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.8383350372314453,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.820319414138794,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.7932730913162231,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.7916790246963501,
            "answer": "comprising",
            "hit": false
          },
          {
            "score": 0.7879116535186768,
            "answer": "featuring",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7932730913162231,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.7582324147224426,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7565861940383911,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7565268278121948,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.748924732208252,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.7433263659477234,
            "answer": "further",
            "hit": false
          },
          {
            "score": 0.7420872449874878,
            "answer": "continued",
            "hit": true
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7420872300863266,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.834180474281311,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8327337503433228,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8263342976570129,
            "answer": "generating",
            "hit": false
          },
          {
            "score": 0.8261294364929199,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.8207293152809143,
            "answer": "producing",
            "hit": false
          },
          {
            "score": 0.8196457028388977,
            "answer": "designing",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 96,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7479609847068787,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 97
      },
      {
        "question verbose": "What is to deciding ",
        "b": "deciding",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8810975551605225,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.8217923641204834,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8212913870811462,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8206204175949097,
            "answer": "choosing",
            "hit": false
          },
          {
            "score": 0.8081712126731873,
            "answer": "figuring",
            "hit": false
          },
          {
            "score": 0.7988177537918091,
            "answer": "selecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "deciding"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7888827323913574,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8571397662162781,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.8542947769165039,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.8399685621261597,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8249880075454712,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.8200824856758118,
            "answer": "discussing",
            "hit": false
          },
          {
            "score": 0.8197376132011414,
            "answer": "stating",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 87,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7428240031003952,
        "b in neighbourhood of b_prime": 28,
        "b_prime in neighbourhood of b": 88
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8651420474052429,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.8299149870872498,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.8193261623382568,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7782414555549622,
            "answer": "producing",
            "hit": false
          },
          {
            "score": 0.7711923122406006,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.7706097960472107,
            "answer": "creating",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8299149870872498,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to establishing ",
        "b": "establishing",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8520770072937012,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.8505575060844421,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8170538544654846,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.8168438076972961,
            "answer": "initiating",
            "hit": false
          },
          {
            "score": 0.8090993762016296,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.8090117573738098,
            "answer": "introducing",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishing"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7999331057071686,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "existed"
        ],
        "predictions": [
          {
            "score": 0.7585311532020569,
            "answer": "extant",
            "hit": false
          },
          {
            "score": 0.7440080642700195,
            "answer": "old",
            "hit": false
          },
          {
            "score": 0.7310587167739868,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.7269026041030884,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.7177855968475342,
            "answer": "emerging",
            "hit": false
          },
          {
            "score": 0.715660810470581,
            "answer": "proposed",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7071128487586975,
        "b in neighbourhood of b_prime": 159,
        "b_prime in neighbourhood of b": 16
      },
      {
        "question verbose": "What is to expecting ",
        "b": "expecting",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8436504602432251,
            "answer": "hoping",
            "hit": false
          },
          {
            "score": 0.8146368265151978,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.8144382834434509,
            "answer": "intending",
            "hit": false
          },
          {
            "score": 0.7868671417236328,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.779319703578949,
            "answer": "expect",
            "hit": false
          },
          {
            "score": 0.7662110328674316,
            "answer": "wondering",
            "hit": false
          }
        ],
        "set_exclude": [
          "expecting"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7612682580947876,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to failing ",
        "b": "failing",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.8188007473945618,
            "answer": "fails",
            "hit": false
          },
          {
            "score": 0.810699462890625,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.8065700531005859,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.8018266558647156,
            "answer": "refusing",
            "hit": false
          },
          {
            "score": 0.7966307997703552,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.7717344760894775,
            "answer": "struggling",
            "hit": false
          }
        ],
        "set_exclude": [
          "failing"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7665868997573853,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.7634216547012329,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.7449294328689575,
            "answer": "preceding",
            "hit": false
          },
          {
            "score": 0.7360302209854126,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.7266919016838074,
            "answer": "after",
            "hit": false
          },
          {
            "score": 0.7138140201568604,
            "answer": "resulting",
            "hit": false
          },
          {
            "score": 0.7094191312789917,
            "answer": "followed",
            "hit": true
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7094191312789917,
        "b in neighbourhood of b_prime": 22,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8248400688171387,
            "answer": "hearings",
            "hit": false
          },
          {
            "score": 0.8140237331390381,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.778506338596344,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7673536539077759,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.7539170980453491,
            "answer": "witnessing",
            "hit": false
          },
          {
            "score": 0.747908353805542,
            "answer": "auditory",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7327021360397339,
        "b in neighbourhood of b_prime": 18,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.8430691361427307,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.8414095640182495,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.8320558667182922,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.8228130340576172,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.8125424385070801,
            "answer": "expanding",
            "hit": false
          },
          {
            "score": 0.811168372631073,
            "answer": "strengthening",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8056606650352478,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.8403870463371277,
            "answer": "excluding",
            "hit": false
          },
          {
            "score": 0.8101387619972229,
            "answer": "particularly",
            "hit": false
          },
          {
            "score": 0.7872829437255859,
            "answer": "includes",
            "hit": false
          },
          {
            "score": 0.7784334421157837,
            "answer": "mostly",
            "hit": false
          },
          {
            "score": 0.7759799957275391,
            "answer": "even",
            "hit": false
          },
          {
            "score": 0.7752958536148071,
            "answer": "that",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 44,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7219796925783157,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 45
      },
      {
        "question verbose": "What is to introducing ",
        "b": "introducing",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.893486499786377,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.8608716726303101,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.8430356383323669,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8294069170951843,
            "answer": "introduction",
            "hit": false
          },
          {
            "score": 0.8090118169784546,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8081061840057373,
            "answer": "announcing",
            "hit": false
          }
        ],
        "set_exclude": [
          "introducing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8430355787277222,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8378791213035583,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8286670446395874,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8139055967330933,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7970918416976929,
            "answer": "featuring",
            "hit": false
          },
          {
            "score": 0.7925362586975098,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.790252685546875,
            "answer": "consisting",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 33,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.735726997256279,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 34
      },
      {
        "question verbose": "What is to locating ",
        "b": "locating",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8807604908943176,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7936885356903076,
            "answer": "discovering",
            "hit": false
          },
          {
            "score": 0.7917861938476562,
            "answer": "obtaining",
            "hit": false
          },
          {
            "score": 0.7916122674942017,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7896577715873718,
            "answer": "detecting",
            "hit": false
          },
          {
            "score": 0.7886368632316589,
            "answer": "finding",
            "hit": false
          }
        ],
        "set_exclude": [
          "locating"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.774185299873352,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 14
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8325502872467041,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8057748079299927,
            "answer": "loss",
            "hit": false
          },
          {
            "score": 0.7985756993293762,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7942529916763306,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.7744964361190796,
            "answer": "getting",
            "hit": false
          },
          {
            "score": 0.7737861275672913,
            "answer": "lose",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7530457973480225,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 15
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.7773045301437378,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.752347469329834,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7520676851272583,
            "answer": "management",
            "hit": false
          },
          {
            "score": 0.7479680776596069,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.7445934414863586,
            "answer": "ceo",
            "hit": false
          },
          {
            "score": 0.739648699760437,
            "answer": "chairman",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7380009740591049,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to marrying ",
        "b": "marrying",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.8953391313552856,
            "answer": "marry",
            "hit": false
          },
          {
            "score": 0.8325667381286621,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.8196845054626465,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.8003837466239929,
            "answer": "marriage",
            "hit": false
          },
          {
            "score": 0.7781419157981873,
            "answer": "marital",
            "hit": false
          },
          {
            "score": 0.7769708633422852,
            "answer": "kissing",
            "hit": false
          }
        ],
        "set_exclude": [
          "marrying"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8325667977333069,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.7780974507331848,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7723298072814941,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7611726522445679,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.7373482584953308,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.7304688692092896,
            "answer": "running",
            "hit": false
          },
          {
            "score": 0.7293651103973389,
            "answer": "programming",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7082774937152863,
        "b in neighbourhood of b_prime": 44,
        "b_prime in neighbourhood of b": 26
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.8086994290351868,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.7730962634086609,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.7721922993659973,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7653701305389404,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7641124725341797,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.7590222954750061,
            "answer": "achieving",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.740428239107132,
        "b in neighbourhood of b_prime": 30,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to proposing ",
        "b": "proposing",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8741022348403931,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8723580241203308,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.8369839191436768,
            "answer": "advocating",
            "hit": false
          },
          {
            "score": 0.8333554267883301,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.8278371095657349,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.8224918842315674,
            "answer": "proposals",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposing"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8164028525352478,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8623696565628052,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8584535717964172,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.8422452211380005,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.8372436761856079,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.8369290828704834,
            "answer": "delivering",
            "hit": false
          },
          {
            "score": 0.8362303972244263,
            "answer": "facilitating",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 276,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7173047363758087,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 277
      },
      {
        "question verbose": "What is to publishing ",
        "b": "publishing",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.8743718862533569,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.8377082347869873,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.8323054313659668,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.8287009596824646,
            "answer": "publisher",
            "hit": false
          },
          {
            "score": 0.7694764137268066,
            "answer": "releasing",
            "hit": false
          },
          {
            "score": 0.7647154927253723,
            "answer": "published",
            "hit": true
          }
        ],
        "set_exclude": [
          "publishing"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7647154927253723,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8465611934661865,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.819614052772522,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7700979709625244,
            "answer": "getting",
            "hit": false
          },
          {
            "score": 0.7698832750320435,
            "answer": "experiencing",
            "hit": false
          },
          {
            "score": 0.7698342204093933,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.7648700475692749,
            "answer": "obtaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.744457870721817,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 18
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.8762949705123901,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.8581956624984741,
            "answer": "eliminating",
            "hit": false
          },
          {
            "score": 0.8560569286346436,
            "answer": "lowering",
            "hit": false
          },
          {
            "score": 0.8543565273284912,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.8497282862663269,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.8442760109901428,
            "answer": "preventing",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8189268410205841,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 14
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8730314373970032,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.8297833204269409,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.815876841545105,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.8156638145446777,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.8139055967330933,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7996578216552734,
            "answer": "concerning",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 179,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7070422470569611,
        "b in neighbourhood of b_prime": 81,
        "b_prime in neighbourhood of b": 180
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8293273448944092,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.7835555076599121,
            "answer": "surviving",
            "hit": false
          },
          {
            "score": 0.7728826999664307,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.7656394839286804,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.7412064075469971,
            "answer": "lingering",
            "hit": false
          },
          {
            "score": 0.7377996444702148,
            "answer": "remains",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7656394243240356,
        "b in neighbourhood of b_prime": 21,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to replacing ",
        "b": "replacing",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8484846949577332,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.8466726541519165,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8320814967155457,
            "answer": "removing",
            "hit": false
          },
          {
            "score": 0.8190291523933411,
            "answer": "replacement",
            "hit": false
          },
          {
            "score": 0.8060009479522705,
            "answer": "eliminating",
            "hit": false
          },
          {
            "score": 0.801030158996582,
            "answer": "replacements",
            "hit": false
          }
        ],
        "set_exclude": [
          "replacing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8466725945472717,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.8312925696372986,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.793499231338501,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.7922893762588501,
            "answer": "depicting",
            "hit": false
          },
          {
            "score": 0.7864215970039368,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.7844321131706238,
            "answer": "indicating",
            "hit": false
          },
          {
            "score": 0.7800514698028564,
            "answer": "presenting",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7571667730808258,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 17
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.8470609784126282,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.839923083782196,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.8197528123855591,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.8118526935577393,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.7961612939834595,
            "answer": "restricting",
            "hit": false
          },
          {
            "score": 0.7925362586975098,
            "answer": "involving",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 125,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7268489301204681,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 126
      },
      {
        "question verbose": "What is to sending ",
        "b": "sending",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8479409217834473,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.8012664914131165,
            "answer": "bringing",
            "hit": false
          },
          {
            "score": 0.7927972078323364,
            "answer": "handing",
            "hit": false
          },
          {
            "score": 0.7902145385742188,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.7848127484321594,
            "answer": "exchanging",
            "hit": false
          },
          {
            "score": 0.7838711738586426,
            "answer": "transmitting",
            "hit": false
          }
        ],
        "set_exclude": [
          "sending"
        ],
        "rank": 114,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7257100343704224,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 115
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8606454133987427,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8273289203643799,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.8231542706489563,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.8168399333953857,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7780892848968506,
            "answer": "funding",
            "hit": false
          },
          {
            "score": 0.7749680280685425,
            "answer": "investing",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7728435099124908,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to suffering ",
        "b": "suffering",
        "expected answer": [
          "suffered"
        ],
        "predictions": [
          {
            "score": 0.8419623374938965,
            "answer": "suffer",
            "hit": false
          },
          {
            "score": 0.8072612881660461,
            "answer": "suffered",
            "hit": true
          },
          {
            "score": 0.8043465614318848,
            "answer": "misery",
            "hit": false
          },
          {
            "score": 0.8002091646194458,
            "answer": "experiencing",
            "hit": false
          },
          {
            "score": 0.7929847240447998,
            "answer": "suffers",
            "hit": false
          },
          {
            "score": 0.7896697521209717,
            "answer": "anguish",
            "hit": false
          }
        ],
        "set_exclude": [
          "suffering"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8072612583637238,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "taught"
        ],
        "predictions": [
          {
            "score": 0.8298712968826294,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.8162739872932434,
            "answer": "teachers",
            "hit": false
          },
          {
            "score": 0.8119668960571289,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8110901117324829,
            "answer": "teacher",
            "hit": false
          },
          {
            "score": 0.8083999156951904,
            "answer": "taught",
            "hit": true
          },
          {
            "score": 0.7824462056159973,
            "answer": "classrooms",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8083999156951904,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.8398401737213135,
            "answer": "saying",
            "hit": false
          },
          {
            "score": 0.8211597204208374,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.8117085695266724,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.8063598871231079,
            "answer": "stating",
            "hit": false
          },
          {
            "score": 0.8007603883743286,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.7997996807098389,
            "answer": "asking",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 55,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7408797889947891,
        "b in neighbourhood of b_prime": 22,
        "b_prime in neighbourhood of b": 56
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.7774640917778015,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7751771211624146,
            "answer": "comprehension",
            "hit": false
          },
          {
            "score": 0.7716500163078308,
            "answer": "knowing",
            "hit": false
          },
          {
            "score": 0.7700459957122803,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.769393265247345,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.7661163806915283,
            "answer": "insight",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.769393265247345,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 5
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 48,
      "accuracy": 0.041666666666666664
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I09 [verb_Ving - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "a885c24d-ff70-4684-a247-edf97d0c3921",
      "timestamp": "2025-05-17T17:08:13.843163"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adds ",
        "b": "adds",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.7976491451263428,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.7796981930732727,
            "answer": "removes",
            "hit": false
          },
          {
            "score": 0.7768109440803528,
            "answer": "expands",
            "hit": false
          },
          {
            "score": 0.7663935422897339,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.765814483165741,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7636296153068542,
            "answer": "requires",
            "hit": false
          }
        ],
        "set_exclude": [
          "adds"
        ],
        "rank": 37,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7359844595193863,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 38
      },
      {
        "question verbose": "What is to agrees ",
        "b": "agrees",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8747720122337341,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.8528726696968079,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.8244300484657288,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8164276480674744,
            "answer": "acknowledges",
            "hit": false
          },
          {
            "score": 0.8103814721107483,
            "answer": "confirms",
            "hit": false
          },
          {
            "score": 0.8068186044692993,
            "answer": "admits",
            "hit": false
          }
        ],
        "set_exclude": [
          "agrees"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8528726696968079,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to allows ",
        "b": "allows",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.9065201282501221,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8863883018493652,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8793103098869324,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.8756293654441833,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8676744699478149,
            "answer": "lets",
            "hit": false
          },
          {
            "score": 0.8486732244491577,
            "answer": "ensures",
            "hit": false
          }
        ],
        "set_exclude": [
          "allows"
        ],
        "rank": 214,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.732612133026123,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 215
      },
      {
        "question verbose": "What is to announces ",
        "b": "announces",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8456185460090637,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.8293529748916626,
            "answer": "declares",
            "hit": false
          },
          {
            "score": 0.8170453310012817,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8098113536834717,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.807262659072876,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8062039613723755,
            "answer": "informs",
            "hit": false
          }
        ],
        "set_exclude": [
          "announces"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7857375144958496,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 19
      },
      {
        "question verbose": "What is to appears ",
        "b": "appears",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.7657554149627686,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7465241551399231,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.7318876385688782,
            "answer": "apparently",
            "hit": false
          },
          {
            "score": 0.7285364866256714,
            "answer": "begins",
            "hit": false
          },
          {
            "score": 0.7278622388839722,
            "answer": "presumably",
            "hit": false
          },
          {
            "score": 0.7252312898635864,
            "answer": "referred",
            "hit": false
          }
        ],
        "set_exclude": [
          "appears"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7465241551399231,
        "b in neighbourhood of b_prime": 40,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to applies ",
        "b": "applies",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8205852508544922,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.8140385150909424,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7986422777175903,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7951480746269226,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7910484075546265,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.7897738218307495,
            "answer": "prohibits",
            "hit": false
          }
        ],
        "set_exclude": [
          "applies"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.820585310459137,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to asks ",
        "b": "asks",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.74382084608078,
            "answer": "tasks",
            "hit": false
          },
          {
            "score": 0.730085015296936,
            "answer": "task",
            "hit": false
          },
          {
            "score": 0.7122948169708252,
            "answer": "ask",
            "hit": false
          },
          {
            "score": 0.7027777433395386,
            "answer": "masks",
            "hit": false
          },
          {
            "score": 0.6997609734535217,
            "answer": "demanded",
            "hit": false
          },
          {
            "score": 0.6965228915214539,
            "answer": "activities",
            "hit": false
          }
        ],
        "set_exclude": [
          "asks"
        ],
        "rank": 224,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6694849133491516,
        "b in neighbourhood of b_prime": 2068,
        "b_prime in neighbourhood of b": 225
      },
      {
        "question verbose": "What is to becomes ",
        "b": "becomes",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8496649265289307,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.8242595195770264,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8129492402076721,
            "answer": "disappears",
            "hit": false
          },
          {
            "score": 0.8042256236076355,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8028156757354736,
            "answer": "grows",
            "hit": false
          },
          {
            "score": 0.8008505702018738,
            "answer": "enters",
            "hit": false
          }
        ],
        "set_exclude": [
          "becomes"
        ],
        "rank": 74,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7552168965339661,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 75
      },
      {
        "question verbose": "What is to believes ",
        "b": "believes",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.8925972580909729,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.8455010056495667,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.8419137001037598,
            "answer": "insists",
            "hit": false
          },
          {
            "score": 0.838901698589325,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.8356260657310486,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.8349181413650513,
            "answer": "understands",
            "hit": false
          }
        ],
        "set_exclude": [
          "believes"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8455010056495667,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to considers ",
        "b": "considers",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8564579486846924,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.8356260657310486,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.8347040414810181,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.8245655298233032,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.822488009929657,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.8158692717552185,
            "answer": "discusses",
            "hit": false
          }
        ],
        "set_exclude": [
          "considers"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8347040414810181,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to consists ",
        "b": "consists",
        "expected answer": [
          "consisted"
        ],
        "predictions": [
          {
            "score": 0.921204686164856,
            "answer": "consisted",
            "hit": true
          },
          {
            "score": 0.9067750573158264,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.8851553201675415,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.8729672431945801,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.8432488441467285,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8285194635391235,
            "answer": "contains",
            "hit": false
          }
        ],
        "set_exclude": [
          "consists"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.9212046265602112,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to contains ",
        "b": "contains",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.8914589881896973,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.8383350372314453,
            "answer": "containing",
            "hit": false
          },
          {
            "score": 0.8285194635391235,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.8279129266738892,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.8218501210212708,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.812386155128479,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "contains"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8279129862785339,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to continues ",
        "b": "continues",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.8128390312194824,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.8098058104515076,
            "answer": "keeps",
            "hit": false
          },
          {
            "score": 0.8015217781066895,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.7884429693222046,
            "answer": "progresses",
            "hit": false
          },
          {
            "score": 0.7849419713020325,
            "answer": "hasn",
            "hit": false
          },
          {
            "score": 0.7846924662590027,
            "answer": "remained",
            "hit": false
          }
        ],
        "set_exclude": [
          "continues"
        ],
        "rank": 50,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7521780729293823,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 51
      },
      {
        "question verbose": "What is to creates ",
        "b": "creates",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.8742117881774902,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.8542531728744507,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.841776430606842,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.8353201150894165,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.8351882696151733,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.8340350389480591,
            "answer": "destroys",
            "hit": false
          }
        ],
        "set_exclude": [
          "creates"
        ],
        "rank": 129,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7571043074131012,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 130
      },
      {
        "question verbose": "What is to decides ",
        "b": "decides",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.892780601978302,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.8918406963348389,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8714337944984436,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8645504117012024,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.822488009929657,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.8221563100814819,
            "answer": "thinks",
            "hit": false
          }
        ],
        "set_exclude": [
          "decides"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8714338541030884,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to describes ",
        "b": "describes",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.88374924659729,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.8481958508491516,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.8459333181381226,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.8414384722709656,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.8399685621261597,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.8348979949951172,
            "answer": "identifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "describes"
        ],
        "rank": 40,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7809711992740631,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 41
      },
      {
        "question verbose": "What is to develops ",
        "b": "develops",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8854014873504639,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.8255078196525574,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.8231130242347717,
            "answer": "progresses",
            "hit": false
          },
          {
            "score": 0.8193261623382568,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8178901076316833,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.8116201758384705,
            "answer": "improves",
            "hit": false
          }
        ],
        "set_exclude": [
          "develops"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8255078196525574,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to establishes ",
        "b": "establishes",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.8505575656890869,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8325164914131165,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.82745361328125,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.8267426490783691,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.8246573209762573,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.8230719566345215,
            "answer": "demonstrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishes"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8090403378009796,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to expects ",
        "b": "expects",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8512431979179382,
            "answer": "intends",
            "hit": false
          },
          {
            "score": 0.838901698589325,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.8350449204444885,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.8158069849014282,
            "answer": "wants",
            "hit": false
          },
          {
            "score": 0.8146368265151978,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.8027923107147217,
            "answer": "assumes",
            "hit": false
          }
        ],
        "set_exclude": [
          "expects"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7940843999385834,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to fails ",
        "b": "fails",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.8842957019805908,
            "answer": "fail",
            "hit": false
          },
          {
            "score": 0.8253394365310669,
            "answer": "succeeds",
            "hit": false
          },
          {
            "score": 0.8211037516593933,
            "answer": "refuses",
            "hit": false
          },
          {
            "score": 0.818800687789917,
            "answer": "failing",
            "hit": false
          },
          {
            "score": 0.8129639625549316,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.8116240501403809,
            "answer": "failures",
            "hit": false
          }
        ],
        "set_exclude": [
          "fails"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7864912748336792,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 12
      },
      {
        "question verbose": "What is to follows ",
        "b": "follows",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.8120335340499878,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.7952641844749451,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.7699538469314575,
            "answer": "comes",
            "hit": false
          },
          {
            "score": 0.7634216547012329,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7422757148742676,
            "answer": "goes",
            "hit": false
          },
          {
            "score": 0.7402021884918213,
            "answer": "emerges",
            "hit": false
          }
        ],
        "set_exclude": [
          "follows"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7952641248703003,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to happens ",
        "b": "happens",
        "expected answer": [
          "happened"
        ],
        "predictions": [
          {
            "score": 0.9004914164543152,
            "answer": "happened",
            "hit": true
          },
          {
            "score": 0.879920244216919,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.8663467168807983,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.8156317472457886,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.7984939217567444,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.7960696220397949,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.90049147605896,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to hears ",
        "b": "hears",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8442500829696655,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.7756377458572388,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.7752333879470825,
            "answer": "sees",
            "hit": false
          },
          {
            "score": 0.7673536539077759,
            "answer": "hearing",
            "hit": false
          },
          {
            "score": 0.7567241787910461,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7484864592552185,
            "answer": "whispers",
            "hit": false
          }
        ],
        "set_exclude": [
          "hears"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7756377756595612,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to includes ",
        "b": "includes",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.7872828841209412,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.7803367972373962,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.7717299461364746,
            "answer": "excluding",
            "hit": false
          },
          {
            "score": 0.766983687877655,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7636158466339111,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.7580384612083435,
            "answer": "include",
            "hit": false
          }
        ],
        "set_exclude": [
          "includes"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7321600615978241,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 14
      },
      {
        "question verbose": "What is to intends ",
        "b": "intends",
        "expected answer": [
          "intended"
        ],
        "predictions": [
          {
            "score": 0.8512431383132935,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.8383243680000305,
            "answer": "seeks",
            "hit": false
          },
          {
            "score": 0.8373141288757324,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.8350841403007507,
            "answer": "intending",
            "hit": false
          },
          {
            "score": 0.8308549523353577,
            "answer": "wants",
            "hit": false
          },
          {
            "score": 0.8264670372009277,
            "answer": "believes",
            "hit": false
          }
        ],
        "set_exclude": [
          "intends"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.788706511259079,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 26
      },
      {
        "question verbose": "What is to introduces ",
        "b": "introduces",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8941555023193359,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.8608716726303101,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.8586193323135376,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8170422315597534,
            "answer": "brings",
            "hit": false
          },
          {
            "score": 0.8159246444702148,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.8158019781112671,
            "answer": "proposes",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduces"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8586193323135376,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to involves ",
        "b": "involves",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8940294981002808,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.8432488441467285,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.8286670446395874,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.8217064738273621,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.8209150433540344,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.8202604055404663,
            "answer": "encompasses",
            "hit": false
          }
        ],
        "set_exclude": [
          "involves"
        ],
        "rank": 144,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7403717041015625,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 145
      },
      {
        "question verbose": "What is to loses ",
        "b": "loses",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.8325502276420593,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.8325051069259644,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.8299222588539124,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.8254669904708862,
            "answer": "suffers",
            "hit": false
          },
          {
            "score": 0.8242595195770264,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.8135380148887634,
            "answer": "wins",
            "hit": false
          }
        ],
        "set_exclude": [
          "loses"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7850146889686584,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 18
      },
      {
        "question verbose": "What is to manages ",
        "b": "manages",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8691065311431885,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.820166826248169,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.7966043949127197,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.7931231260299683,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7878668308258057,
            "answer": "owns",
            "hit": false
          },
          {
            "score": 0.7869035601615906,
            "answer": "succeeds",
            "hit": false
          }
        ],
        "set_exclude": [
          "manages"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7732073664665222,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 17
      },
      {
        "question verbose": "What is to occurs ",
        "b": "occurs",
        "expected answer": [
          "occurred"
        ],
        "predictions": [
          {
            "score": 0.8982231616973877,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.887545108795166,
            "answer": "occurred",
            "hit": true
          },
          {
            "score": 0.879920244216919,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.8427894115447998,
            "answer": "arises",
            "hit": false
          },
          {
            "score": 0.8349947333335876,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.820000410079956,
            "answer": "involves",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurs"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.887545108795166,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to operates ",
        "b": "operates",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.8997929692268372,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.8275932669639587,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.8250488042831421,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.8186953067779541,
            "answer": "regulates",
            "hit": false
          },
          {
            "score": 0.8147776126861572,
            "answer": "owns",
            "hit": false
          },
          {
            "score": 0.814034640789032,
            "answer": "relies",
            "hit": false
          }
        ],
        "set_exclude": [
          "operates"
        ],
        "rank": 110,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7597003877162933,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 111
      },
      {
        "question verbose": "What is to performs ",
        "b": "performs",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.9005298614501953,
            "answer": "perform",
            "hit": false
          },
          {
            "score": 0.869326114654541,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.8109897375106812,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.8057969808578491,
            "answer": "delivers",
            "hit": false
          },
          {
            "score": 0.7980248332023621,
            "answer": "participates",
            "hit": false
          },
          {
            "score": 0.797122061252594,
            "answer": "receives",
            "hit": false
          }
        ],
        "set_exclude": [
          "performs"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.869326114654541,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to proposes ",
        "b": "proposes",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8939199447631836,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8723580241203308,
            "answer": "proposing",
            "hit": false
          },
          {
            "score": 0.8373141288757324,
            "answer": "intends",
            "hit": false
          },
          {
            "score": 0.8299405574798584,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.825432538986206,
            "answer": "argues",
            "hit": false
          },
          {
            "score": 0.8250172138214111,
            "answer": "seeks",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposes"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8299405872821808,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to provides ",
        "b": "provides",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.8921548128128052,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.8895424604415894,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.8756293654441833,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.85793536901474,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.8478845357894897,
            "answer": "offers",
            "hit": false
          },
          {
            "score": 0.8456268310546875,
            "answer": "ensures",
            "hit": false
          }
        ],
        "set_exclude": [
          "provides"
        ],
        "rank": 374,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7040128111839294,
        "b in neighbourhood of b_prime": 36,
        "b_prime in neighbourhood of b": 375
      },
      {
        "question verbose": "What is to receives ",
        "b": "receives",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8786817789077759,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.8458071947097778,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.8196139931678772,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.817409873008728,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.8134377598762512,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.8107390403747559,
            "answer": "loses",
            "hit": false
          }
        ],
        "set_exclude": [
          "receives"
        ],
        "rank": 37,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7795012295246124,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 38
      },
      {
        "question verbose": "What is to refers ",
        "b": "refers",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.8481958508491516,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.819044828414917,
            "answer": "denotes",
            "hit": false
          },
          {
            "score": 0.819028913974762,
            "answer": "implies",
            "hit": false
          },
          {
            "score": 0.8140431046485901,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.8127367496490479,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.8126161694526672,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "refers"
        ],
        "rank": 146,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7326054722070694,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 147
      },
      {
        "question verbose": "What is to relates ",
        "b": "relates",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8807253241539001,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.815876841545105,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.8139015436172485,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.8099148273468018,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7968936562538147,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7951481342315674,
            "answer": "applies",
            "hit": false
          }
        ],
        "set_exclude": [
          "relates"
        ],
        "rank": 224,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7152583003044128,
        "b in neighbourhood of b_prime": 44,
        "b_prime in neighbourhood of b": 225
      },
      {
        "question verbose": "What is to remains ",
        "b": "remains",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8531619310379028,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.8517293930053711,
            "answer": "remain",
            "hit": false
          },
          {
            "score": 0.8128390312194824,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7861440181732178,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.7792515754699707,
            "answer": "stays",
            "hit": false
          },
          {
            "score": 0.7646777033805847,
            "answer": "hasn",
            "hit": false
          }
        ],
        "set_exclude": [
          "remains"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8531619310379028,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to replaces ",
        "b": "replaces",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8585361838340759,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8484847545623779,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.8171390295028687,
            "answer": "removes",
            "hit": false
          },
          {
            "score": 0.7956880331039429,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7917692065238953,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.7913601398468018,
            "answer": "incorporates",
            "hit": false
          }
        ],
        "set_exclude": [
          "replaces"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8585361540317535,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to represents ",
        "b": "represents",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.8312926292419434,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.8219106793403625,
            "answer": "reflects",
            "hit": false
          },
          {
            "score": 0.8200604915618896,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.8187317252159119,
            "answer": "constitutes",
            "hit": false
          },
          {
            "score": 0.808828592300415,
            "answer": "illustrates",
            "hit": false
          },
          {
            "score": 0.806889533996582,
            "answer": "encompasses",
            "hit": false
          }
        ],
        "set_exclude": [
          "represents"
        ],
        "rank": 70,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7514010965824127,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 71
      },
      {
        "question verbose": "What is to requires ",
        "b": "requires",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.7696396112442017,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.7636296153068542,
            "answer": "adds",
            "hit": false
          },
          {
            "score": 0.7628599405288696,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.7551760673522949,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.7542885541915894,
            "answer": "prohibits",
            "hit": false
          },
          {
            "score": 0.743942141532898,
            "answer": "ensure",
            "hit": false
          }
        ],
        "set_exclude": [
          "requires"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7357464730739594,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 19
      },
      {
        "question verbose": "What is to seems ",
        "b": "seems",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.8332898020744324,
            "answer": "looks",
            "hit": false
          },
          {
            "score": 0.8202411532402039,
            "answer": "apparently",
            "hit": false
          },
          {
            "score": 0.8132553100585938,
            "answer": "didn",
            "hit": false
          },
          {
            "score": 0.8130879998207092,
            "answer": "hmm",
            "hit": false
          },
          {
            "score": 0.8097383379936218,
            "answer": "somehow",
            "hit": false
          },
          {
            "score": 0.7974216341972351,
            "answer": "presumably",
            "hit": false
          }
        ],
        "set_exclude": [
          "seems"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7877308428287506,
        "b in neighbourhood of b_prime": 12,
        "b_prime in neighbourhood of b": 14
      },
      {
        "question verbose": "What is to sends ",
        "b": "sends",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8479409217834473,
            "answer": "sending",
            "hit": false
          },
          {
            "score": 0.817409873008728,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8144023418426514,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.8083217144012451,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.8012294769287109,
            "answer": "delivers",
            "hit": false
          },
          {
            "score": 0.7973614931106567,
            "answer": "brings",
            "hit": false
          }
        ],
        "set_exclude": [
          "sends"
        ],
        "rank": 173,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7336592823266983,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 174
      },
      {
        "question verbose": "What is to spends ",
        "b": "spends",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8888776302337646,
            "answer": "spend",
            "hit": false
          },
          {
            "score": 0.8543120622634888,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.8231543302536011,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.7890914678573608,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.7890771627426147,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7881950736045837,
            "answer": "receives",
            "hit": false
          }
        ],
        "set_exclude": [
          "spends"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.854312002658844,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to suggests ",
        "b": "suggests",
        "expected answer": [
          "suggested"
        ],
        "predictions": [
          {
            "score": 0.8872430920600891,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.8738651275634766,
            "answer": "implies",
            "hit": false
          },
          {
            "score": 0.8452375531196594,
            "answer": "suggested",
            "hit": true
          },
          {
            "score": 0.8414487838745117,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.8341811299324036,
            "answer": "argues",
            "hit": false
          },
          {
            "score": 0.8326647877693176,
            "answer": "demonstrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggests"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8452376127243042,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to tells ",
        "b": "tells",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.8470267653465271,
            "answer": "says",
            "hit": false
          },
          {
            "score": 0.8460195064544678,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.8302206993103027,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.826100766658783,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.821060836315155,
            "answer": "suggests",
            "hit": false
          },
          {
            "score": 0.8136680126190186,
            "answer": "describes",
            "hit": false
          }
        ],
        "set_exclude": [
          "tells"
        ],
        "rank": 29,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7789216935634613,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 30
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 46,
      "accuracy": 0.10869565217391304
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I10 [verb_3pSg - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "89c106b8-49c3-4cb7-b348-3dcd9974f126",
      "timestamp": "2025-05-17T17:08:14.252123"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to home ",
        "b": "home",
        "expected answer": [
          "homeless"
        ],
        "predictions": [
          {
            "score": 0.7761024236679077,
            "answer": "homes",
            "hit": false
          },
          {
            "score": 0.7228165864944458,
            "answer": "hometown",
            "hit": false
          },
          {
            "score": 0.7149925231933594,
            "answer": "residence",
            "hit": false
          },
          {
            "score": 0.7090355157852173,
            "answer": "house",
            "hit": false
          },
          {
            "score": 0.703158438205719,
            "answer": "mansion",
            "hit": false
          },
          {
            "score": 0.7031146883964539,
            "answer": "away",
            "hit": false
          }
        ],
        "set_exclude": [
          "home"
        ],
        "rank": 739,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6513836234807968,
        "b in neighbourhood of b_prime": 4160,
        "b_prime in neighbourhood of b": 740
      },
      {
        "question verbose": "What is to ruth ",
        "b": "ruth",
        "expected answer": [
          "ruthless"
        ],
        "predictions": [
          {
            "score": 0.8426638841629028,
            "answer": "ruthless",
            "hit": true
          },
          {
            "score": 0.7883598804473877,
            "answer": "fiercely",
            "hit": false
          },
          {
            "score": 0.7642779350280762,
            "answer": "brutality",
            "hit": false
          },
          {
            "score": 0.7633911967277527,
            "answer": "violently",
            "hit": false
          },
          {
            "score": 0.7623924016952515,
            "answer": "angrily",
            "hit": false
          },
          {
            "score": 0.7609837055206299,
            "answer": "systematically",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruth"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8426639437675476,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 2,
      "accuracy": 0.5
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D01 [noun+less_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "e871a503-b7a6-4c52-b93a-9ee3d934515d",
      "timestamp": "2025-05-17T17:08:14.646774"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to able ",
        "b": "able",
        "expected answer": [
          "unable"
        ],
        "predictions": [
          {
            "score": 0.8222715258598328,
            "answer": "ability",
            "hit": false
          },
          {
            "score": 0.7074826955795288,
            "answer": "abilities",
            "hit": false
          },
          {
            "score": 0.682300329208374,
            "answer": "usable",
            "hit": false
          },
          {
            "score": 0.674780547618866,
            "answer": "acceptable",
            "hit": false
          },
          {
            "score": 0.6738501191139221,
            "answer": "ate",
            "hit": false
          },
          {
            "score": 0.670719563961029,
            "answer": "ally",
            "hit": false
          }
        ],
        "set_exclude": [
          "able"
        ],
        "rank": 594,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6214259266853333,
        "b in neighbourhood of b_prime": 11736,
        "b_prime in neighbourhood of b": 595
      },
      {
        "question verbose": "What is to acceptable ",
        "b": "acceptable",
        "expected answer": [
          "unacceptable"
        ],
        "predictions": [
          {
            "score": 0.8435769081115723,
            "answer": "unacceptable",
            "hit": true
          },
          {
            "score": 0.780083179473877,
            "answer": "reasonable",
            "hit": false
          },
          {
            "score": 0.7528842687606812,
            "answer": "tolerated",
            "hit": false
          },
          {
            "score": 0.7476513981819153,
            "answer": "satisfactory",
            "hit": false
          },
          {
            "score": 0.7418687343597412,
            "answer": "necessary",
            "hit": false
          },
          {
            "score": 0.7404265403747559,
            "answer": "respectable",
            "hit": false
          }
        ],
        "set_exclude": [
          "acceptable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8435769379138947,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to affected ",
        "b": "affected",
        "expected answer": [
          "unaffected"
        ],
        "predictions": [
          {
            "score": 0.9052873253822327,
            "answer": "impacted",
            "hit": false
          },
          {
            "score": 0.8073656558990479,
            "answer": "affect",
            "hit": false
          },
          {
            "score": 0.807288408279419,
            "answer": "affects",
            "hit": false
          },
          {
            "score": 0.8016058206558228,
            "answer": "unaffected",
            "hit": true
          },
          {
            "score": 0.7750364542007446,
            "answer": "harmed",
            "hit": false
          },
          {
            "score": 0.7735700011253357,
            "answer": "affecting",
            "hit": false
          }
        ],
        "set_exclude": [
          "affected"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8016058206558228,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to available ",
        "b": "available",
        "expected answer": [
          "unavailable"
        ],
        "predictions": [
          {
            "score": 0.8004538416862488,
            "answer": "unavailable",
            "hit": true
          },
          {
            "score": 0.748009979724884,
            "answer": "offered",
            "hit": false
          },
          {
            "score": 0.7441005110740662,
            "answer": "possible",
            "hit": false
          },
          {
            "score": 0.7338912487030029,
            "answer": "suitable",
            "hit": false
          },
          {
            "score": 0.7310777902603149,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.726974606513977,
            "answer": "known",
            "hit": false
          }
        ],
        "set_exclude": [
          "available"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8004538714885712,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "unaware"
        ],
        "predictions": [
          {
            "score": 0.7342839241027832,
            "answer": "unaware",
            "hit": true
          },
          {
            "score": 0.7303744554519653,
            "answer": "conscious",
            "hit": false
          },
          {
            "score": 0.7103815078735352,
            "answer": "focused",
            "hit": false
          },
          {
            "score": 0.7088901996612549,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.7085369825363159,
            "answer": "ignorant",
            "hit": false
          },
          {
            "score": 0.7072590589523315,
            "answer": "considering",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7342839539051056,
        "b in neighbourhood of b_prime": 40,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to certain ",
        "b": "certain",
        "expected answer": [
          "uncertain"
        ],
        "predictions": [
          {
            "score": 0.7815929055213928,
            "answer": "generally",
            "hit": false
          },
          {
            "score": 0.7770653367042542,
            "answer": "some",
            "hit": false
          },
          {
            "score": 0.7626084685325623,
            "answer": "various",
            "hit": false
          },
          {
            "score": 0.7625858187675476,
            "answer": "several",
            "hit": false
          },
          {
            "score": 0.7529503107070923,
            "answer": "depending",
            "hit": false
          },
          {
            "score": 0.7521787881851196,
            "answer": "obviously",
            "hit": false
          }
        ],
        "set_exclude": [
          "certain"
        ],
        "rank": 284,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6860932409763336,
        "b in neighbourhood of b_prime": 376,
        "b_prime in neighbourhood of b": 285
      },
      {
        "question verbose": "What is to changed ",
        "b": "changed",
        "expected answer": [
          "unchanged"
        ],
        "predictions": [
          {
            "score": 0.7912907600402832,
            "answer": "changing",
            "hit": false
          },
          {
            "score": 0.7867583632469177,
            "answer": "removed",
            "hit": false
          },
          {
            "score": 0.772686243057251,
            "answer": "altered",
            "hit": false
          },
          {
            "score": 0.7589877843856812,
            "answer": "change",
            "hit": false
          },
          {
            "score": 0.7578995227813721,
            "answer": "increased",
            "hit": false
          },
          {
            "score": 0.7519506812095642,
            "answer": "became",
            "hit": false
          }
        ],
        "set_exclude": [
          "changed"
        ],
        "rank": 213,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7058831751346588,
        "b in neighbourhood of b_prime": 46,
        "b_prime in neighbourhood of b": 214
      },
      {
        "question verbose": "What is to comfortable ",
        "b": "comfortable",
        "expected answer": [
          "uncomfortable"
        ],
        "predictions": [
          {
            "score": 0.8312690854072571,
            "answer": "uncomfortable",
            "hit": true
          },
          {
            "score": 0.8094367980957031,
            "answer": "comfortably",
            "hit": false
          },
          {
            "score": 0.7950467467308044,
            "answer": "confident",
            "hit": false
          },
          {
            "score": 0.7784325480461121,
            "answer": "cozy",
            "hit": false
          },
          {
            "score": 0.7693608999252319,
            "answer": "luxurious",
            "hit": false
          },
          {
            "score": 0.765781044960022,
            "answer": "accustomed",
            "hit": false
          }
        ],
        "set_exclude": [
          "comfortable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8312691152095795,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "unconscious"
        ],
        "predictions": [
          {
            "score": 0.8330436944961548,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.8281259536743164,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.777314305305481,
            "answer": "unconscious",
            "hit": true
          },
          {
            "score": 0.7649669647216797,
            "answer": "deliberate",
            "hit": false
          },
          {
            "score": 0.7503176927566528,
            "answer": "intentional",
            "hit": false
          },
          {
            "score": 0.7486288547515869,
            "answer": "awareness",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7773143351078033,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to employed ",
        "b": "employed",
        "expected answer": [
          "unemployed"
        ],
        "predictions": [
          {
            "score": 0.8082537055015564,
            "answer": "unemployed",
            "hit": true
          },
          {
            "score": 0.773504376411438,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.763413667678833,
            "answer": "proclaimed",
            "hit": false
          },
          {
            "score": 0.7625395059585571,
            "answer": "educated",
            "hit": false
          },
          {
            "score": 0.7554020285606384,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.7541866302490234,
            "answer": "employing",
            "hit": false
          }
        ],
        "set_exclude": [
          "employed"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8082537055015564,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to expected ",
        "b": "expected",
        "expected answer": [
          "unexpected"
        ],
        "predictions": [
          {
            "score": 0.8050647377967834,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.794084370136261,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.781944990158081,
            "answer": "hoped",
            "hit": false
          },
          {
            "score": 0.7685185670852661,
            "answer": "projected",
            "hit": false
          },
          {
            "score": 0.7612682580947876,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.7605626583099365,
            "answer": "planned",
            "hit": false
          }
        ],
        "set_exclude": [
          "expected"
        ],
        "rank": 27,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7170704752206802,
        "b in neighbourhood of b_prime": 81,
        "b_prime in neighbourhood of b": 28
      },
      {
        "question verbose": "What is to finished ",
        "b": "finished",
        "expected answer": [
          "unfinished"
        ],
        "predictions": [
          {
            "score": 0.7912247180938721,
            "answer": "unfinished",
            "hit": true
          },
          {
            "score": 0.754448652267456,
            "answer": "finishing",
            "hit": false
          },
          {
            "score": 0.7487572431564331,
            "answer": "finishes",
            "hit": false
          },
          {
            "score": 0.7461684346199036,
            "answer": "completed",
            "hit": false
          },
          {
            "score": 0.7453756332397461,
            "answer": "assembled",
            "hit": false
          },
          {
            "score": 0.7350138425827026,
            "answer": "finish",
            "hit": false
          }
        ],
        "set_exclude": [
          "finished"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7912247478961945,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to fortunate ",
        "b": "fortunate",
        "expected answer": [
          "unfortunate"
        ],
        "predictions": [
          {
            "score": 0.8137775659561157,
            "answer": "unfortunate",
            "hit": true
          },
          {
            "score": 0.7847865223884583,
            "answer": "thankful",
            "hit": false
          },
          {
            "score": 0.7836074233055115,
            "answer": "privileged",
            "hit": false
          },
          {
            "score": 0.7715394496917725,
            "answer": "luckily",
            "hit": false
          },
          {
            "score": 0.7518436312675476,
            "answer": "prosperous",
            "hit": false
          },
          {
            "score": 0.747157096862793,
            "answer": "foolish",
            "hit": false
          }
        ],
        "set_exclude": [
          "fortunate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8137775659561157,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "unhappy"
        ],
        "predictions": [
          {
            "score": 0.7712745070457458,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.7580035924911499,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.7530027031898499,
            "answer": "unhappy",
            "hit": true
          },
          {
            "score": 0.7511183023452759,
            "answer": "lucky",
            "hit": false
          },
          {
            "score": 0.7497065663337708,
            "answer": "cheerful",
            "hit": false
          },
          {
            "score": 0.7447563409805298,
            "answer": "enjoy",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7530027031898499,
        "b in neighbourhood of b_prime": 35,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to identified ",
        "b": "identified",
        "expected answer": [
          "unidentified"
        ],
        "predictions": [
          {
            "score": 0.7825770378112793,
            "answer": "reached",
            "hit": false
          },
          {
            "score": 0.7710950970649719,
            "answer": "noticed",
            "hit": false
          },
          {
            "score": 0.7549583315849304,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7461707592010498,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.7411245703697205,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.7403461933135986,
            "answer": "bought",
            "hit": false
          }
        ],
        "set_exclude": [
          "identified"
        ],
        "rank": 112,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7013034075498581,
        "b in neighbourhood of b_prime": 66,
        "b_prime in neighbourhood of b": 113
      },
      {
        "question verbose": "What is to known ",
        "b": "known",
        "expected answer": [
          "unknown"
        ],
        "predictions": [
          {
            "score": 0.7550156116485596,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.750917911529541,
            "answer": "commonly",
            "hit": false
          },
          {
            "score": 0.7475306987762451,
            "answer": "renowned",
            "hit": false
          },
          {
            "score": 0.7408576011657715,
            "answer": "seen",
            "hit": false
          },
          {
            "score": 0.7323228716850281,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7319748401641846,
            "answer": "knew",
            "hit": false
          }
        ],
        "set_exclude": [
          "known"
        ],
        "rank": 241,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.656144991517067,
        "b in neighbourhood of b_prime": 1614,
        "b_prime in neighbourhood of b": 242
      },
      {
        "question verbose": "What is to lawful ",
        "b": "lawful",
        "expected answer": [
          "unlawful"
        ],
        "predictions": [
          {
            "score": 0.8503908514976501,
            "answer": "unlawful",
            "hit": true
          },
          {
            "score": 0.7763298749923706,
            "answer": "legitimate",
            "hit": false
          },
          {
            "score": 0.7721156477928162,
            "answer": "legally",
            "hit": false
          },
          {
            "score": 0.756651759147644,
            "answer": "illegal",
            "hit": false
          },
          {
            "score": 0.7474480867385864,
            "answer": "peaceful",
            "hit": false
          },
          {
            "score": 0.7457253932952881,
            "answer": "reasonable",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8503909111022949,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to paid ",
        "b": "paid",
        "expected answer": [
          "unpaid"
        ],
        "predictions": [
          {
            "score": 0.8238652944564819,
            "answer": "pays",
            "hit": false
          },
          {
            "score": 0.7734817266464233,
            "answer": "compensated",
            "hit": false
          },
          {
            "score": 0.7719970345497131,
            "answer": "unpaid",
            "hit": true
          },
          {
            "score": 0.7593518495559692,
            "answer": "financed",
            "hit": false
          },
          {
            "score": 0.7546358704566956,
            "answer": "hired",
            "hit": false
          },
          {
            "score": 0.753482460975647,
            "answer": "paying",
            "hit": false
          }
        ],
        "set_exclude": [
          "paid"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7719970345497131,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to pleasant ",
        "b": "pleasant",
        "expected answer": [
          "unpleasant"
        ],
        "predictions": [
          {
            "score": 0.8541801571846008,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.8455061912536621,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.8443321585655212,
            "answer": "unpleasant",
            "hit": true
          },
          {
            "score": 0.8069357872009277,
            "answer": "charming",
            "hit": false
          },
          {
            "score": 0.802282452583313,
            "answer": "pleasing",
            "hit": false
          },
          {
            "score": 0.8000736832618713,
            "answer": "cheerful",
            "hit": false
          }
        ],
        "set_exclude": [
          "pleasant"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8443321585655212,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to popular ",
        "b": "popular",
        "expected answer": [
          "unpopular"
        ],
        "predictions": [
          {
            "score": 0.7804481983184814,
            "answer": "unpopular",
            "hit": true
          },
          {
            "score": 0.7774603366851807,
            "answer": "popularity",
            "hit": false
          },
          {
            "score": 0.7668694257736206,
            "answer": "fashionable",
            "hit": false
          },
          {
            "score": 0.7524037957191467,
            "answer": "beloved",
            "hit": false
          },
          {
            "score": 0.7509913444519043,
            "answer": "prevalent",
            "hit": false
          },
          {
            "score": 0.7495805025100708,
            "answer": "influential",
            "hit": false
          }
        ],
        "set_exclude": [
          "popular"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7804481983184814,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to predictable ",
        "b": "predictable",
        "expected answer": [
          "unpredictable"
        ],
        "predictions": [
          {
            "score": 0.8082832098007202,
            "answer": "unpredictable",
            "hit": true
          },
          {
            "score": 0.7567852139472961,
            "answer": "inevitable",
            "hit": false
          },
          {
            "score": 0.7512564659118652,
            "answer": "predict",
            "hit": false
          },
          {
            "score": 0.750356137752533,
            "answer": "consistent",
            "hit": false
          },
          {
            "score": 0.7488588094711304,
            "answer": "reliable",
            "hit": false
          },
          {
            "score": 0.7474135160446167,
            "answer": "sensible",
            "hit": false
          }
        ],
        "set_exclude": [
          "predictable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.808283269405365,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to published ",
        "b": "published",
        "expected answer": [
          "unpublished"
        ],
        "predictions": [
          {
            "score": 0.8049447536468506,
            "answer": "authored",
            "hit": false
          },
          {
            "score": 0.7913978695869446,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.7836558818817139,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7747455835342407,
            "answer": "unpublished",
            "hit": true
          },
          {
            "score": 0.7647154331207275,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.7641940116882324,
            "answer": "reprinted",
            "hit": false
          }
        ],
        "set_exclude": [
          "published"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7747455537319183,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "unreasonable"
        ],
        "predictions": [
          {
            "score": 0.819106936454773,
            "answer": "unreasonable",
            "hit": true
          },
          {
            "score": 0.795109748840332,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.7881217002868652,
            "answer": "reason",
            "hit": false
          },
          {
            "score": 0.7865856885910034,
            "answer": "necessary",
            "hit": false
          },
          {
            "score": 0.780083179473877,
            "answer": "acceptable",
            "hit": false
          },
          {
            "score": 0.778426468372345,
            "answer": "plausible",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.819106936454773,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to related ",
        "b": "related",
        "expected answer": [
          "unrelated"
        ],
        "predictions": [
          {
            "score": 0.7593612670898438,
            "answer": "specific",
            "hit": false
          },
          {
            "score": 0.7556979656219482,
            "answer": "further",
            "hit": false
          },
          {
            "score": 0.7554895281791687,
            "answer": "recommended",
            "hit": false
          },
          {
            "score": 0.750995397567749,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.7481945753097534,
            "answer": "associated",
            "hit": false
          },
          {
            "score": 0.7432811260223389,
            "answer": "aside",
            "hit": false
          }
        ],
        "set_exclude": [
          "related"
        ],
        "rank": 58,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7111288905143738,
        "b in neighbourhood of b_prime": 38,
        "b_prime in neighbourhood of b": 59
      },
      {
        "question verbose": "What is to reliable ",
        "b": "reliable",
        "expected answer": [
          "unreliable"
        ],
        "predictions": [
          {
            "score": 0.8463416695594788,
            "answer": "unreliable",
            "hit": true
          },
          {
            "score": 0.8134254217147827,
            "answer": "reliability",
            "hit": false
          },
          {
            "score": 0.8105077147483826,
            "answer": "credible",
            "hit": false
          },
          {
            "score": 0.8028892874717712,
            "answer": "accurate",
            "hit": false
          },
          {
            "score": 0.7826771140098572,
            "answer": "trusted",
            "hit": false
          },
          {
            "score": 0.775801420211792,
            "answer": "durable",
            "hit": false
          }
        ],
        "set_exclude": [
          "reliable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.846341609954834,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to specified ",
        "b": "specified",
        "expected answer": [
          "unspecified"
        ],
        "predictions": [
          {
            "score": 0.7809630632400513,
            "answer": "defined",
            "hit": false
          },
          {
            "score": 0.7766919136047363,
            "answer": "specify",
            "hit": false
          },
          {
            "score": 0.7707396745681763,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.7547264695167542,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.7516087293624878,
            "answer": "unspecified",
            "hit": true
          },
          {
            "score": 0.7384936809539795,
            "answer": "employed",
            "hit": false
          }
        ],
        "set_exclude": [
          "specified"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7516087889671326,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "unsuccessful"
        ],
        "predictions": [
          {
            "score": 0.8469046950340271,
            "answer": "unsuccessful",
            "hit": true
          },
          {
            "score": 0.801691472530365,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.7886512279510498,
            "answer": "success",
            "hit": false
          },
          {
            "score": 0.7870626449584961,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.7648879885673523,
            "answer": "succeeds",
            "hit": false
          },
          {
            "score": 0.7639549970626831,
            "answer": "prosperous",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8469047248363495,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to used ",
        "b": "used",
        "expected answer": [
          "unused"
        ],
        "predictions": [
          {
            "score": 0.8067799806594849,
            "answer": "uses",
            "hit": false
          },
          {
            "score": 0.7590318322181702,
            "answer": "usable",
            "hit": false
          },
          {
            "score": 0.7344987392425537,
            "answer": "utilized",
            "hit": false
          },
          {
            "score": 0.7146297693252563,
            "answer": "recycled",
            "hit": false
          },
          {
            "score": 0.7136495113372803,
            "answer": "played",
            "hit": false
          },
          {
            "score": 0.7092797756195068,
            "answer": "abused",
            "hit": false
          }
        ],
        "set_exclude": [
          "used"
        ],
        "rank": 31,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6902861595153809,
        "b in neighbourhood of b_prime": 64,
        "b_prime in neighbourhood of b": 32
      },
      {
        "question verbose": "What is to usual ",
        "b": "usual",
        "expected answer": [
          "unusual"
        ],
        "predictions": [
          {
            "score": 0.7682988047599792,
            "answer": "usually",
            "hit": false
          },
          {
            "score": 0.7620221376419067,
            "answer": "unusual",
            "hit": true
          },
          {
            "score": 0.7541557550430298,
            "answer": "customary",
            "hit": false
          },
          {
            "score": 0.7420395016670227,
            "answer": "necessary",
            "hit": false
          },
          {
            "score": 0.7393201589584351,
            "answer": "anticipated",
            "hit": false
          },
          {
            "score": 0.7389324307441711,
            "answer": "reasonable",
            "hit": false
          }
        ],
        "set_exclude": [
          "usual"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7620221078395844,
        "b in neighbourhood of b_prime": 20,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to wanted ",
        "b": "wanted",
        "expected answer": [
          "unwanted"
        ],
        "predictions": [
          {
            "score": 0.8677766919136047,
            "answer": "wants",
            "hit": false
          },
          {
            "score": 0.8229504823684692,
            "answer": "wished",
            "hit": false
          },
          {
            "score": 0.8015713691711426,
            "answer": "liked",
            "hit": false
          },
          {
            "score": 0.7999486923217773,
            "answer": "want",
            "hit": false
          },
          {
            "score": 0.7904492020606995,
            "answer": "needed",
            "hit": false
          },
          {
            "score": 0.7870661020278931,
            "answer": "sought",
            "hit": false
          }
        ],
        "set_exclude": [
          "wanted"
        ],
        "rank": 426,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6814739406108856,
        "b in neighbourhood of b_prime": 330,
        "b_prime in neighbourhood of b": 427
      }
    ],
    "result": {
      "cnt_questions_correct": 13,
      "cnt_questions_total": 30,
      "accuracy": 0.43333333333333335
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D02 [un+adj_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "ca14d67c-b55f-40aa-966a-b2a466696c33",
      "timestamp": "2025-05-17T17:08:14.667850"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to according ",
        "b": "according",
        "expected answer": [
          "accordingly"
        ],
        "predictions": [
          {
            "score": 0.7419852018356323,
            "answer": "says",
            "hit": false
          },
          {
            "score": 0.7415439486503601,
            "answer": "accordance",
            "hit": false
          },
          {
            "score": 0.7385110855102539,
            "answer": "reportedly",
            "hit": false
          },
          {
            "score": 0.7282524108886719,
            "answer": "although",
            "hit": false
          },
          {
            "score": 0.7274270057678223,
            "answer": "depending",
            "hit": false
          },
          {
            "score": 0.7267767190933228,
            "answer": "amid",
            "hit": false
          }
        ],
        "set_exclude": [
          "according"
        ],
        "rank": 121,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.678425669670105,
        "b in neighbourhood of b_prime": 3297,
        "b_prime in neighbourhood of b": 122
      },
      {
        "question verbose": "What is to actual ",
        "b": "actual",
        "expected answer": [
          "actually"
        ],
        "predictions": [
          {
            "score": 0.8027273416519165,
            "answer": "real",
            "hit": false
          },
          {
            "score": 0.7484583854675293,
            "answer": "genuine",
            "hit": false
          },
          {
            "score": 0.7464561462402344,
            "answer": "exact",
            "hit": false
          },
          {
            "score": 0.7451569437980652,
            "answer": "entire",
            "hit": false
          },
          {
            "score": 0.7329996824264526,
            "answer": "actually",
            "hit": true
          },
          {
            "score": 0.7254170775413513,
            "answer": "true",
            "hit": false
          }
        ],
        "set_exclude": [
          "actual"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7329996824264526,
        "b in neighbourhood of b_prime": 85,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to additional ",
        "b": "additional",
        "expected answer": [
          "additionally"
        ],
        "predictions": [
          {
            "score": 0.7951034903526306,
            "answer": "further",
            "hit": false
          },
          {
            "score": 0.7790777087211609,
            "answer": "additionally",
            "hit": true
          },
          {
            "score": 0.7610183954238892,
            "answer": "furthermore",
            "hit": false
          },
          {
            "score": 0.7590546607971191,
            "answer": "although",
            "hit": false
          },
          {
            "score": 0.7481472492218018,
            "answer": "alternative",
            "hit": false
          },
          {
            "score": 0.7452110052108765,
            "answer": "optional",
            "hit": false
          }
        ],
        "set_exclude": [
          "additional"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7790777683258057,
        "b in neighbourhood of b_prime": 30,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to apparent ",
        "b": "apparent",
        "expected answer": [
          "apparently"
        ],
        "predictions": [
          {
            "score": 0.8408745527267456,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.8280141353607178,
            "answer": "obvious",
            "hit": false
          },
          {
            "score": 0.7789488434791565,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7789080142974854,
            "answer": "noticeable",
            "hit": false
          },
          {
            "score": 0.7634861469268799,
            "answer": "alleged",
            "hit": false
          },
          {
            "score": 0.7500762343406677,
            "answer": "unclear",
            "hit": false
          }
        ],
        "set_exclude": [
          "apparent"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7277630269527435,
        "b in neighbourhood of b_prime": 333,
        "b_prime in neighbourhood of b": 18
      },
      {
        "question verbose": "What is to beautiful ",
        "b": "beautiful",
        "expected answer": [
          "beautifully"
        ],
        "predictions": [
          {
            "score": 0.9124862551689148,
            "answer": "gorgeous",
            "hit": false
          },
          {
            "score": 0.8715444803237915,
            "answer": "wonderful",
            "hit": false
          },
          {
            "score": 0.8688166737556458,
            "answer": "magnificent",
            "hit": false
          },
          {
            "score": 0.8384212851524353,
            "answer": "beautifully",
            "hit": true
          },
          {
            "score": 0.836438000202179,
            "answer": "delightful",
            "hit": false
          },
          {
            "score": 0.8300737738609314,
            "answer": "glorious",
            "hit": false
          }
        ],
        "set_exclude": [
          "beautiful"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8384212851524353,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to critical ",
        "b": "critical",
        "expected answer": [
          "critically"
        ],
        "predictions": [
          {
            "score": 0.7501527667045593,
            "answer": "critically",
            "hit": true
          },
          {
            "score": 0.7500345706939697,
            "answer": "critics",
            "hit": false
          },
          {
            "score": 0.743587076663971,
            "answer": "specific",
            "hit": false
          },
          {
            "score": 0.7411534786224365,
            "answer": "significant",
            "hit": false
          },
          {
            "score": 0.7329018712043762,
            "answer": "pivotal",
            "hit": false
          },
          {
            "score": 0.7317710518836975,
            "answer": "physical",
            "hit": false
          }
        ],
        "set_exclude": [
          "critical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7501528263092041,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to cultural ",
        "b": "cultural",
        "expected answer": [
          "culturally"
        ],
        "predictions": [
          {
            "score": 0.7970399260520935,
            "answer": "culturally",
            "hit": true
          },
          {
            "score": 0.7583073377609253,
            "answer": "societal",
            "hit": false
          },
          {
            "score": 0.7535803914070129,
            "answer": "socio",
            "hit": false
          },
          {
            "score": 0.7533753514289856,
            "answer": "archaeological",
            "hit": false
          },
          {
            "score": 0.7507200241088867,
            "answer": "political",
            "hit": false
          },
          {
            "score": 0.7497859001159668,
            "answer": "ecological",
            "hit": false
          }
        ],
        "set_exclude": [
          "cultural"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7970399856567383,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to decided ",
        "b": "decided",
        "expected answer": [
          "decidedly"
        ],
        "predictions": [
          {
            "score": 0.8714337944984436,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.850515604019165,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8187980055809021,
            "answer": "chose",
            "hit": false
          },
          {
            "score": 0.8101649284362793,
            "answer": "opted",
            "hit": false
          },
          {
            "score": 0.7888827323913574,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.7872387766838074,
            "answer": "determined",
            "hit": false
          }
        ],
        "set_exclude": [
          "decided"
        ],
        "rank": 562,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6854291260242462,
        "b in neighbourhood of b_prime": 1737,
        "b_prime in neighbourhood of b": 563
      },
      {
        "question verbose": "What is to different ",
        "b": "different",
        "expected answer": [
          "differently"
        ],
        "predictions": [
          {
            "score": 0.7915919423103333,
            "answer": "depending",
            "hit": false
          },
          {
            "score": 0.7870932221412659,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.786931574344635,
            "answer": "differed",
            "hit": false
          },
          {
            "score": 0.7845855951309204,
            "answer": "differs",
            "hit": false
          },
          {
            "score": 0.7839645147323608,
            "answer": "differently",
            "hit": true
          },
          {
            "score": 0.7789583802223206,
            "answer": "differing",
            "hit": false
          }
        ],
        "set_exclude": [
          "different"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7839645147323608,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to digital ",
        "b": "digital",
        "expected answer": [
          "digitally"
        ],
        "predictions": [
          {
            "score": 0.8345556259155273,
            "answer": "digitally",
            "hit": true
          },
          {
            "score": 0.7976672649383545,
            "answer": "electronic",
            "hit": false
          },
          {
            "score": 0.7759125232696533,
            "answer": "virtual",
            "hit": false
          },
          {
            "score": 0.7645118236541748,
            "answer": "technological",
            "hit": false
          },
          {
            "score": 0.7476744651794434,
            "answer": "software",
            "hit": false
          },
          {
            "score": 0.744504988193512,
            "answer": "smartphone",
            "hit": false
          }
        ],
        "set_exclude": [
          "digital"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8345555663108826,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectively"
        ],
        "predictions": [
          {
            "score": 0.7568016648292542,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.7451818585395813,
            "answer": "efficient",
            "hit": false
          },
          {
            "score": 0.7431133985519409,
            "answer": "effectiveness",
            "hit": false
          },
          {
            "score": 0.7386809587478638,
            "answer": "specific",
            "hit": false
          },
          {
            "score": 0.7338383197784424,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.731692910194397,
            "answer": "whenever",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 56,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7102836072444916,
        "b in neighbourhood of b_prime": 86,
        "b_prime in neighbourhood of b": 57
      },
      {
        "question verbose": "What is to environmental ",
        "b": "environmental",
        "expected answer": [
          "environmentally"
        ],
        "predictions": [
          {
            "score": 0.8107276558876038,
            "answer": "environment",
            "hit": false
          },
          {
            "score": 0.7964699268341064,
            "answer": "ecological",
            "hit": false
          },
          {
            "score": 0.7916909456253052,
            "answer": "epa",
            "hit": false
          },
          {
            "score": 0.7901877760887146,
            "answer": "environmentally",
            "hit": true
          },
          {
            "score": 0.7895862460136414,
            "answer": "climate",
            "hit": false
          },
          {
            "score": 0.7606605887413025,
            "answer": "ecology",
            "hit": false
          }
        ],
        "set_exclude": [
          "environmental"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7901877760887146,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to extensive ",
        "b": "extensive",
        "expected answer": [
          "extensively"
        ],
        "predictions": [
          {
            "score": 0.820777416229248,
            "answer": "lengthy",
            "hit": false
          },
          {
            "score": 0.8181259036064148,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.8147099018096924,
            "answer": "expansive",
            "hit": false
          },
          {
            "score": 0.8091086149215698,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.8043943643569946,
            "answer": "comprehensive",
            "hit": false
          },
          {
            "score": 0.79798424243927,
            "answer": "numerous",
            "hit": false
          }
        ],
        "set_exclude": [
          "extensive"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7884172797203064,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to famous ",
        "b": "famous",
        "expected answer": [
          "famously"
        ],
        "predictions": [
          {
            "score": 0.7846253514289856,
            "answer": "famed",
            "hit": false
          },
          {
            "score": 0.7665417790412903,
            "answer": "renowned",
            "hit": false
          },
          {
            "score": 0.7661213278770447,
            "answer": "infamous",
            "hit": false
          },
          {
            "score": 0.7605608701705933,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.7566512823104858,
            "answer": "iconic",
            "hit": false
          },
          {
            "score": 0.7431759834289551,
            "answer": "typical",
            "hit": false
          }
        ],
        "set_exclude": [
          "famous"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.729505866765976,
        "b in neighbourhood of b_prime": 58,
        "b_prime in neighbourhood of b": 20
      },
      {
        "question verbose": "What is to financial ",
        "b": "financial",
        "expected answer": [
          "financially"
        ],
        "predictions": [
          {
            "score": 0.7647751569747925,
            "answer": "investment",
            "hit": false
          },
          {
            "score": 0.7619742155075073,
            "answer": "securities",
            "hit": false
          },
          {
            "score": 0.7594857215881348,
            "answer": "banking",
            "hit": false
          },
          {
            "score": 0.7581598162651062,
            "answer": "monetary",
            "hit": false
          },
          {
            "score": 0.7560533881187439,
            "answer": "economic",
            "hit": false
          },
          {
            "score": 0.7550387382507324,
            "answer": "finance",
            "hit": false
          }
        ],
        "set_exclude": [
          "financial"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7517244219779968,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to global ",
        "b": "global",
        "expected answer": [
          "globally"
        ],
        "predictions": [
          {
            "score": 0.8049120903015137,
            "answer": "globally",
            "hit": true
          },
          {
            "score": 0.7683990001678467,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.7604889869689941,
            "answer": "international",
            "hit": false
          },
          {
            "score": 0.7472379803657532,
            "answer": "national",
            "hit": false
          },
          {
            "score": 0.7404899597167969,
            "answer": "globe",
            "hit": false
          },
          {
            "score": 0.7247568368911743,
            "answer": "europe",
            "hit": false
          }
        ],
        "set_exclude": [
          "global"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8049120903015137,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to historical ",
        "b": "historical",
        "expected answer": [
          "historically"
        ],
        "predictions": [
          {
            "score": 0.8039812445640564,
            "answer": "historically",
            "hit": true
          },
          {
            "score": 0.789490282535553,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.782515287399292,
            "answer": "archaeological",
            "hit": false
          },
          {
            "score": 0.779524564743042,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.7707303166389465,
            "answer": "historic",
            "hit": false
          },
          {
            "score": 0.7649034261703491,
            "answer": "factual",
            "hit": false
          }
        ],
        "set_exclude": [
          "historical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.803981214761734,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to huge ",
        "b": "huge",
        "expected answer": [
          "hugely"
        ],
        "predictions": [
          {
            "score": 0.8054654598236084,
            "answer": "gigantic",
            "hit": false
          },
          {
            "score": 0.7869713306427002,
            "answer": "massive",
            "hit": false
          },
          {
            "score": 0.7861199975013733,
            "answer": "enormous",
            "hit": false
          },
          {
            "score": 0.7642043232917786,
            "answer": "immense",
            "hit": false
          },
          {
            "score": 0.7511398792266846,
            "answer": "lots",
            "hit": false
          },
          {
            "score": 0.7497742176055908,
            "answer": "tremendous",
            "hit": false
          }
        ],
        "set_exclude": [
          "huge"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7391422688961029,
        "b in neighbourhood of b_prime": 82,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to immediate ",
        "b": "immediate",
        "expected answer": [
          "immediately"
        ],
        "predictions": [
          {
            "score": 0.806105375289917,
            "answer": "immediately",
            "hit": true
          },
          {
            "score": 0.7586769461631775,
            "answer": "urgent",
            "hit": false
          },
          {
            "score": 0.7516365051269531,
            "answer": "imminent",
            "hit": false
          },
          {
            "score": 0.7505526542663574,
            "answer": "obvious",
            "hit": false
          },
          {
            "score": 0.7389456033706665,
            "answer": "instantly",
            "hit": false
          },
          {
            "score": 0.7345376014709473,
            "answer": "swift",
            "hit": false
          }
        ],
        "set_exclude": [
          "immediate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.806105375289917,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to important ",
        "b": "important",
        "expected answer": [
          "importantly"
        ],
        "predictions": [
          {
            "score": 0.8621231913566589,
            "answer": "crucial",
            "hit": false
          },
          {
            "score": 0.8209030628204346,
            "answer": "vital",
            "hit": false
          },
          {
            "score": 0.8057761788368225,
            "answer": "valuable",
            "hit": false
          },
          {
            "score": 0.7796115279197693,
            "answer": "influential",
            "hit": false
          },
          {
            "score": 0.7789888381958008,
            "answer": "importantly",
            "hit": true
          },
          {
            "score": 0.7773958444595337,
            "answer": "importance",
            "hit": false
          }
        ],
        "set_exclude": [
          "important"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7789888381958008,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to increasing ",
        "b": "increasing",
        "expected answer": [
          "increasingly"
        ],
        "predictions": [
          {
            "score": 0.8326659202575684,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.7945141792297363,
            "answer": "increasingly",
            "hit": true
          },
          {
            "score": 0.788402259349823,
            "answer": "increased",
            "hit": false
          },
          {
            "score": 0.7872037291526794,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7827983498573303,
            "answer": "decreases",
            "hit": false
          },
          {
            "score": 0.7806878685951233,
            "answer": "reducing",
            "hit": false
          }
        ],
        "set_exclude": [
          "increasing"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7945141792297363,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "internally"
        ],
        "predictions": [
          {
            "score": 0.7590417861938477,
            "answer": "internally",
            "hit": true
          },
          {
            "score": 0.7548767328262329,
            "answer": "external",
            "hit": false
          },
          {
            "score": 0.7527453303337097,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.7320874929428101,
            "answer": "intra",
            "hit": false
          },
          {
            "score": 0.708863377571106,
            "answer": "intrinsic",
            "hit": false
          },
          {
            "score": 0.7086846232414246,
            "answer": "inline",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7590417861938477,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to international ",
        "b": "international",
        "expected answer": [
          "internationally"
        ],
        "predictions": [
          {
            "score": 0.809816837310791,
            "answer": "internationally",
            "hit": true
          },
          {
            "score": 0.7766819000244141,
            "answer": "national",
            "hit": false
          },
          {
            "score": 0.7604889869689941,
            "answer": "global",
            "hit": false
          },
          {
            "score": 0.7587383389472961,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.7552767992019653,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7542499303817749,
            "answer": "overseas",
            "hit": false
          }
        ],
        "set_exclude": [
          "international"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8098168969154358,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to legal ",
        "b": "legal",
        "expected answer": [
          "legally"
        ],
        "predictions": [
          {
            "score": 0.7885478734970093,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.77083420753479,
            "answer": "litigation",
            "hit": false
          },
          {
            "score": 0.7708173990249634,
            "answer": "lawyer",
            "hit": false
          },
          {
            "score": 0.7672153115272522,
            "answer": "judicial",
            "hit": false
          },
          {
            "score": 0.7667676210403442,
            "answer": "legally",
            "hit": true
          },
          {
            "score": 0.7596744298934937,
            "answer": "attorneys",
            "hit": false
          }
        ],
        "set_exclude": [
          "legal"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.766767680644989,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to mental ",
        "b": "mental",
        "expected answer": [
          "mentally"
        ],
        "predictions": [
          {
            "score": 0.8211357593536377,
            "answer": "mentally",
            "hit": true
          },
          {
            "score": 0.7908750176429749,
            "answer": "cognitive",
            "hit": false
          },
          {
            "score": 0.7781955003738403,
            "answer": "neurological",
            "hit": false
          },
          {
            "score": 0.7710909247398376,
            "answer": "emotional",
            "hit": false
          },
          {
            "score": 0.7687848806381226,
            "answer": "psychic",
            "hit": false
          },
          {
            "score": 0.7654165625572205,
            "answer": "psychiatric",
            "hit": false
          }
        ],
        "set_exclude": [
          "mental"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8211357295513153,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to nice ",
        "b": "nice",
        "expected answer": [
          "nicely"
        ],
        "predictions": [
          {
            "score": 0.7355195879936218,
            "answer": "neat",
            "hit": false
          },
          {
            "score": 0.7325645685195923,
            "answer": "interesting",
            "hit": false
          },
          {
            "score": 0.7313840985298157,
            "answer": "nasty",
            "hit": false
          },
          {
            "score": 0.7305698394775391,
            "answer": "pleasant",
            "hit": false
          },
          {
            "score": 0.7302521467208862,
            "answer": "lots",
            "hit": false
          },
          {
            "score": 0.7248005867004395,
            "answer": "cute",
            "hit": false
          }
        ],
        "set_exclude": [
          "nice"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7142303586006165,
        "b in neighbourhood of b_prime": 73,
        "b_prime in neighbourhood of b": 18
      },
      {
        "question verbose": "What is to obvious ",
        "b": "obvious",
        "expected answer": [
          "obviously"
        ],
        "predictions": [
          {
            "score": 0.828014075756073,
            "answer": "apparent",
            "hit": false
          },
          {
            "score": 0.8054533004760742,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.7815006375312805,
            "answer": "glaring",
            "hit": false
          },
          {
            "score": 0.7737581729888916,
            "answer": "noticeable",
            "hit": false
          },
          {
            "score": 0.7594314813613892,
            "answer": "straightforward",
            "hit": false
          },
          {
            "score": 0.7550023794174194,
            "answer": "plainly",
            "hit": false
          }
        ],
        "set_exclude": [
          "obvious"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.748930498957634,
        "b in neighbourhood of b_prime": 118,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to physical ",
        "b": "physical",
        "expected answer": [
          "physically"
        ],
        "predictions": [
          {
            "score": 0.7827363014221191,
            "answer": "physically",
            "hit": true
          },
          {
            "score": 0.7482881546020508,
            "answer": "physiological",
            "hit": false
          },
          {
            "score": 0.7403417825698853,
            "answer": "psychological",
            "hit": false
          },
          {
            "score": 0.7371745109558105,
            "answer": "medical",
            "hit": false
          },
          {
            "score": 0.7317710518836975,
            "answer": "critical",
            "hit": false
          },
          {
            "score": 0.7294621467590332,
            "answer": "metaphysical",
            "hit": false
          }
        ],
        "set_exclude": [
          "physical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7827363014221191,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to political ",
        "b": "political",
        "expected answer": [
          "politically"
        ],
        "predictions": [
          {
            "score": 0.8023478388786316,
            "answer": "politically",
            "hit": true
          },
          {
            "score": 0.7885671854019165,
            "answer": "politics",
            "hit": false
          },
          {
            "score": 0.7834078669548035,
            "answer": "ideological",
            "hit": false
          },
          {
            "score": 0.7707711458206177,
            "answer": "electoral",
            "hit": false
          },
          {
            "score": 0.769158124923706,
            "answer": "parliamentary",
            "hit": false
          },
          {
            "score": 0.7620296478271484,
            "answer": "presidential",
            "hit": false
          }
        ],
        "set_exclude": [
          "political"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8023478388786316,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to practical ",
        "b": "practical",
        "expected answer": [
          "practically"
        ],
        "predictions": [
          {
            "score": 0.7730473875999451,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.7700470685958862,
            "answer": "realistic",
            "hit": false
          },
          {
            "score": 0.7694915533065796,
            "answer": "theoretical",
            "hit": false
          },
          {
            "score": 0.7666452527046204,
            "answer": "economical",
            "hit": false
          },
          {
            "score": 0.7529258728027344,
            "answer": "philosophical",
            "hit": false
          },
          {
            "score": 0.7490401864051819,
            "answer": "ethical",
            "hit": false
          }
        ],
        "set_exclude": [
          "practical"
        ],
        "rank": 47,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7142073065042496,
        "b in neighbourhood of b_prime": 101,
        "b_prime in neighbourhood of b": 48
      },
      {
        "question verbose": "What is to previous ",
        "b": "previous",
        "expected answer": [
          "previously"
        ],
        "predictions": [
          {
            "score": 0.7748084664344788,
            "answer": "current",
            "hit": false
          },
          {
            "score": 0.7636388540267944,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.7463717460632324,
            "answer": "although",
            "hit": false
          },
          {
            "score": 0.7342914938926697,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.7272542715072632,
            "answer": "next",
            "hit": false
          },
          {
            "score": 0.7267385721206665,
            "answer": "investigators",
            "hit": false
          }
        ],
        "set_exclude": [
          "previous"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7151278853416443,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 17
      },
      {
        "question verbose": "What is to rare ",
        "b": "rare",
        "expected answer": [
          "rarely"
        ],
        "predictions": [
          {
            "score": 0.8088733553886414,
            "answer": "common",
            "hit": false
          },
          {
            "score": 0.8016329407691956,
            "answer": "legendary",
            "hit": false
          },
          {
            "score": 0.7945601940155029,
            "answer": "uncommon",
            "hit": false
          },
          {
            "score": 0.7753616571426392,
            "answer": "very",
            "hit": false
          },
          {
            "score": 0.7638905644416809,
            "answer": "unique",
            "hit": false
          },
          {
            "score": 0.7606502771377563,
            "answer": "rarely",
            "hit": true
          }
        ],
        "set_exclude": [
          "rare"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7606503367424011,
        "b in neighbourhood of b_prime": 16,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriously"
        ],
        "predictions": [
          {
            "score": 0.7573761940002441,
            "answer": "seriously",
            "hit": true
          },
          {
            "score": 0.7493678331375122,
            "answer": "seriousness",
            "hit": false
          },
          {
            "score": 0.7327570915222168,
            "answer": "significant",
            "hit": false
          },
          {
            "score": 0.7244755029678345,
            "answer": "honest",
            "hit": false
          },
          {
            "score": 0.7195914387702942,
            "answer": "really",
            "hit": false
          },
          {
            "score": 0.714448094367981,
            "answer": "substantial",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7573761940002441,
        "b in neighbourhood of b_prime": 19,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to sexual ",
        "b": "sexual",
        "expected answer": [
          "sexually"
        ],
        "predictions": [
          {
            "score": 0.8360409140586853,
            "answer": "sexually",
            "hit": true
          },
          {
            "score": 0.8144656419754028,
            "answer": "sexuality",
            "hit": false
          },
          {
            "score": 0.7980505228042603,
            "answer": "homosexual",
            "hit": false
          },
          {
            "score": 0.7937425374984741,
            "answer": "rape",
            "hit": false
          },
          {
            "score": 0.7862055897712708,
            "answer": "raped",
            "hit": false
          },
          {
            "score": 0.7842187881469727,
            "answer": "homosexuality",
            "hit": false
          }
        ],
        "set_exclude": [
          "sexual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8360409140586853,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to significant ",
        "b": "significant",
        "expected answer": [
          "significantly"
        ],
        "predictions": [
          {
            "score": 0.8026626110076904,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.7786777019500732,
            "answer": "noteworthy",
            "hit": false
          },
          {
            "score": 0.7732187509536743,
            "answer": "meaningful",
            "hit": false
          },
          {
            "score": 0.7715576887130737,
            "answer": "significantly",
            "hit": true
          },
          {
            "score": 0.7701382637023926,
            "answer": "noticeable",
            "hit": false
          },
          {
            "score": 0.7683281302452087,
            "answer": "considerable",
            "hit": false
          }
        ],
        "set_exclude": [
          "significant"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7715576887130737,
        "b in neighbourhood of b_prime": 18,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to similar ",
        "b": "similar",
        "expected answer": [
          "similarly"
        ],
        "predictions": [
          {
            "score": 0.7919992208480835,
            "answer": "analogous",
            "hit": false
          },
          {
            "score": 0.7801883220672607,
            "answer": "comparable",
            "hit": false
          },
          {
            "score": 0.7783806920051575,
            "answer": "reminiscent",
            "hit": false
          },
          {
            "score": 0.768306314945221,
            "answer": "similarity",
            "hit": false
          },
          {
            "score": 0.7655872106552124,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.7595016360282898,
            "answer": "similarly",
            "hit": true
          }
        ],
        "set_exclude": [
          "similar"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7595016360282898,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongly"
        ],
        "predictions": [
          {
            "score": 0.7748849987983704,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.7661842107772827,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.7377214431762695,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.7354097962379456,
            "answer": "strength",
            "hit": false
          },
          {
            "score": 0.7247874140739441,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.719794750213623,
            "answer": "strongly",
            "hit": true
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7197947055101395,
        "b in neighbourhood of b_prime": 61,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to subsequent ",
        "b": "subsequent",
        "expected answer": [
          "subsequently"
        ],
        "predictions": [
          {
            "score": 0.8573818206787109,
            "answer": "ensuing",
            "hit": false
          },
          {
            "score": 0.8450069427490234,
            "answer": "subsequently",
            "hit": true
          },
          {
            "score": 0.7978384494781494,
            "answer": "resultant",
            "hit": false
          },
          {
            "score": 0.7964010238647461,
            "answer": "successive",
            "hit": false
          },
          {
            "score": 0.7883577346801758,
            "answer": "thereafter",
            "hit": false
          },
          {
            "score": 0.7682944536209106,
            "answer": "succeeding",
            "hit": false
          }
        ],
        "set_exclude": [
          "subsequent"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8450069427490234,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "successfully"
        ],
        "predictions": [
          {
            "score": 0.8469046950340271,
            "answer": "unsuccessful",
            "hit": false
          },
          {
            "score": 0.801691472530365,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.7886512279510498,
            "answer": "success",
            "hit": false
          },
          {
            "score": 0.7870626449584961,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.7648879885673523,
            "answer": "succeeds",
            "hit": false
          },
          {
            "score": 0.7639549970626831,
            "answer": "prosperous",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7542789578437805,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to traditional ",
        "b": "traditional",
        "expected answer": [
          "traditionally"
        ],
        "predictions": [
          {
            "score": 0.788313627243042,
            "answer": "modern",
            "hit": false
          },
          {
            "score": 0.7729639410972595,
            "answer": "traditionally",
            "hit": true
          },
          {
            "score": 0.7728236317634583,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.7700891494750977,
            "answer": "conventional",
            "hit": false
          },
          {
            "score": 0.7593220472335815,
            "answer": "contemporary",
            "hit": false
          },
          {
            "score": 0.7568700909614563,
            "answer": "alternative",
            "hit": false
          }
        ],
        "set_exclude": [
          "traditional"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7729639708995819,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to typical ",
        "b": "typical",
        "expected answer": [
          "typically"
        ],
        "predictions": [
          {
            "score": 0.7894495129585266,
            "answer": "generally",
            "hit": false
          },
          {
            "score": 0.7782167196273804,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.7681210041046143,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.7658867835998535,
            "answer": "depending",
            "hit": false
          },
          {
            "score": 0.7654257416725159,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.763823390007019,
            "answer": "example",
            "hit": false
          }
        ],
        "set_exclude": [
          "typical"
        ],
        "rank": 32,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7396782487630844,
        "b in neighbourhood of b_prime": 30,
        "b_prime in neighbourhood of b": 33
      },
      {
        "question verbose": "What is to unique ",
        "b": "unique",
        "expected answer": [
          "uniquely"
        ],
        "predictions": [
          {
            "score": 0.781670093536377,
            "answer": "distinctive",
            "hit": false
          },
          {
            "score": 0.771293044090271,
            "answer": "uniquely",
            "hit": true
          },
          {
            "score": 0.7638905644416809,
            "answer": "rare",
            "hit": false
          },
          {
            "score": 0.7591149806976318,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.7555686831474304,
            "answer": "specific",
            "hit": false
          },
          {
            "score": 0.7490248680114746,
            "answer": "exclusive",
            "hit": false
          }
        ],
        "set_exclude": [
          "unique"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.771293044090271,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to virtual ",
        "b": "virtual",
        "expected answer": [
          "virtually"
        ],
        "predictions": [
          {
            "score": 0.7759124636650085,
            "answer": "digital",
            "hit": false
          },
          {
            "score": 0.7442771792411804,
            "answer": "simulated",
            "hit": false
          },
          {
            "score": 0.7406371831893921,
            "answer": "augmented",
            "hit": false
          },
          {
            "score": 0.7254842519760132,
            "answer": "computational",
            "hit": false
          },
          {
            "score": 0.7223066091537476,
            "answer": "simulations",
            "hit": false
          },
          {
            "score": 0.7182832360267639,
            "answer": "imaginary",
            "hit": false
          }
        ],
        "set_exclude": [
          "virtual"
        ],
        "rank": 42,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6894518136978149,
        "b in neighbourhood of b_prime": 313,
        "b_prime in neighbourhood of b": 43
      },
      {
        "question verbose": "What is to visual ",
        "b": "visual",
        "expected answer": [
          "visually"
        ],
        "predictions": [
          {
            "score": 0.7755777835845947,
            "answer": "visually",
            "hit": true
          },
          {
            "score": 0.7418273687362671,
            "answer": "auditory",
            "hit": false
          },
          {
            "score": 0.7395367622375488,
            "answer": "sensory",
            "hit": false
          },
          {
            "score": 0.739081859588623,
            "answer": "graphical",
            "hit": false
          },
          {
            "score": 0.724773645401001,
            "answer": "seeing",
            "hit": false
          },
          {
            "score": 0.7237640619277954,
            "answer": "conceptual",
            "hit": false
          }
        ],
        "set_exclude": [
          "visual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7755778431892395,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 14,
      "cnt_questions_total": 44,
      "accuracy": 0.3181818181818182
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D03 [adj+ly_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "57e1d310-1d1d-4ccc-8f27-7677d4a0c36d",
      "timestamp": "2025-05-17T17:08:14.929750"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "awareness"
        ],
        "predictions": [
          {
            "score": 0.7342839241027832,
            "answer": "unaware",
            "hit": false
          },
          {
            "score": 0.7303744554519653,
            "answer": "conscious",
            "hit": false
          },
          {
            "score": 0.7103815078735352,
            "answer": "focused",
            "hit": false
          },
          {
            "score": 0.7088901996612549,
            "answer": "awareness",
            "hit": true
          },
          {
            "score": 0.7085369825363159,
            "answer": "ignorant",
            "hit": false
          },
          {
            "score": 0.7072590589523315,
            "answer": "considering",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7088902294635773,
        "b in neighbourhood of b_prime": 51,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "consciousness"
        ],
        "predictions": [
          {
            "score": 0.8330436944961548,
            "answer": "consciousness",
            "hit": true
          },
          {
            "score": 0.8281259536743164,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.777314305305481,
            "answer": "unconscious",
            "hit": false
          },
          {
            "score": 0.7649669647216797,
            "answer": "deliberate",
            "hit": false
          },
          {
            "score": 0.7503176927566528,
            "answer": "intentional",
            "hit": false
          },
          {
            "score": 0.7486288547515869,
            "answer": "awareness",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.83304363489151,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectiveness"
        ],
        "predictions": [
          {
            "score": 0.7568016648292542,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.7451818585395813,
            "answer": "efficient",
            "hit": false
          },
          {
            "score": 0.7431133985519409,
            "answer": "effectiveness",
            "hit": true
          },
          {
            "score": 0.7386809587478638,
            "answer": "specific",
            "hit": false
          },
          {
            "score": 0.7338383197784424,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.731692910194397,
            "answer": "whenever",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7431134283542633,
        "b in neighbourhood of b_prime": 15,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happiness"
        ],
        "predictions": [
          {
            "score": 0.7712745070457458,
            "answer": "happier",
            "hit": false
          },
          {
            "score": 0.7580035924911499,
            "answer": "happiness",
            "hit": true
          },
          {
            "score": 0.7530027031898499,
            "answer": "unhappy",
            "hit": false
          },
          {
            "score": 0.7511183023452759,
            "answer": "lucky",
            "hit": false
          },
          {
            "score": 0.7497065663337708,
            "answer": "cheerful",
            "hit": false
          },
          {
            "score": 0.7447563409805298,
            "answer": "enjoy",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7580035626888275,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to mad ",
        "b": "mad",
        "expected answer": [
          "madness"
        ],
        "predictions": [
          {
            "score": 0.7223823070526123,
            "answer": "want",
            "hit": false
          },
          {
            "score": 0.7145102620124817,
            "answer": "madrid",
            "hit": false
          },
          {
            "score": 0.7134618759155273,
            "answer": "madness",
            "hit": true
          },
          {
            "score": 0.7120980620384216,
            "answer": "bad",
            "hit": false
          },
          {
            "score": 0.7099010944366455,
            "answer": "dem",
            "hit": false
          },
          {
            "score": 0.7080973982810974,
            "answer": "mag",
            "hit": false
          }
        ],
        "set_exclude": [
          "mad"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7134618908166885,
        "b in neighbourhood of b_prime": 60,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to sad ",
        "b": "sad",
        "expected answer": [
          "sadness"
        ],
        "predictions": [
          {
            "score": 0.7612817287445068,
            "answer": "sadness",
            "hit": true
          },
          {
            "score": 0.7246761322021484,
            "answer": "happy",
            "hit": false
          },
          {
            "score": 0.7174845933914185,
            "answer": "sorrow",
            "hit": false
          },
          {
            "score": 0.7160099148750305,
            "answer": "anguish",
            "hit": false
          },
          {
            "score": 0.7154786586761475,
            "answer": "bad",
            "hit": false
          },
          {
            "score": 0.7123462557792664,
            "answer": "melancholy",
            "hit": false
          }
        ],
        "set_exclude": [
          "sad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7612816989421844,
        "b in neighbourhood of b_prime": 37,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriousness"
        ],
        "predictions": [
          {
            "score": 0.7573761940002441,
            "answer": "seriously",
            "hit": false
          },
          {
            "score": 0.7493678331375122,
            "answer": "seriousness",
            "hit": true
          },
          {
            "score": 0.7327570915222168,
            "answer": "significant",
            "hit": false
          },
          {
            "score": 0.7244755029678345,
            "answer": "honest",
            "hit": false
          },
          {
            "score": 0.7195914387702942,
            "answer": "really",
            "hit": false
          },
          {
            "score": 0.714448094367981,
            "answer": "substantial",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7493677884340286,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weakness"
        ],
        "predictions": [
          {
            "score": 0.7931559085845947,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.7796528935432434,
            "answer": "weakness",
            "hit": true
          },
          {
            "score": 0.762973427772522,
            "answer": "weaken",
            "hit": false
          },
          {
            "score": 0.7604753971099854,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.7537059783935547,
            "answer": "weaknesses",
            "hit": false
          },
          {
            "score": 0.7400948405265808,
            "answer": "weakened",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.779652863740921,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 2
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 8,
      "accuracy": 0.25
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D05 [adj+ness_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "cbcf5992-502b-43c6-bba4-cdb53ec96fc1",
      "timestamp": "2025-05-17T17:08:15.310275"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "acceptable"
        ],
        "predictions": [
          {
            "score": 0.881279468536377,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.8616923093795776,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.8471611142158508,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.8135776519775391,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.789398729801178,
            "answer": "reject",
            "hit": false
          },
          {
            "score": 0.7829883098602295,
            "answer": "acknowledge",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 58,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7148777544498444,
        "b in neighbourhood of b_prime": 55,
        "b_prime in neighbourhood of b": 59
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustable"
        ],
        "predictions": [
          {
            "score": 0.8381365537643433,
            "answer": "adjustment",
            "hit": false
          },
          {
            "score": 0.8325479626655579,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.8317915797233582,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.8124579191207886,
            "answer": "adjustable",
            "hit": true
          },
          {
            "score": 0.7603938579559326,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.7501000165939331,
            "answer": "align",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8124579191207886,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to afford ",
        "b": "afford",
        "expected answer": [
          "affordable"
        ],
        "predictions": [
          {
            "score": 0.8001750707626343,
            "answer": "afforded",
            "hit": false
          },
          {
            "score": 0.7441079020500183,
            "answer": "affordable",
            "hit": true
          },
          {
            "score": 0.7348110675811768,
            "answer": "sustain",
            "hit": false
          },
          {
            "score": 0.7337532043457031,
            "answer": "comfortably",
            "hit": false
          },
          {
            "score": 0.7317297458648682,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.7316004037857056,
            "answer": "tolerate",
            "hit": false
          }
        ],
        "set_exclude": [
          "afford"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7441079169511795,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considerable"
        ],
        "predictions": [
          {
            "score": 0.7909044623374939,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7676159143447876,
            "answer": "increasing",
            "hit": false
          },
          {
            "score": 0.7553883194923401,
            "answer": "considers",
            "hit": false
          },
          {
            "score": 0.7509335279464722,
            "answer": "reasonable",
            "hit": false
          },
          {
            "score": 0.7501152753829956,
            "answer": "consideration",
            "hit": false
          },
          {
            "score": 0.7478833794593811,
            "answer": "particularly",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7425186485052109,
        "b in neighbourhood of b_prime": 57,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyable"
        ],
        "predictions": [
          {
            "score": 0.8120999932289124,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7885305285453796,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.7876150608062744,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.7674121856689453,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.7522728443145752,
            "answer": "enjoyable",
            "hit": true
          },
          {
            "score": 0.7516811490058899,
            "answer": "feel",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7522728443145752,
        "b in neighbourhood of b_prime": 59,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifiable"
        ],
        "predictions": [
          {
            "score": 0.8861641883850098,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.8696592450141907,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7913675308227539,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7898815870285034,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.7776312828063965,
            "answer": "recognize",
            "hit": false
          },
          {
            "score": 0.7740652561187744,
            "answer": "describe",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7705175876617432,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to predict ",
        "b": "predict",
        "expected answer": [
          "predictable"
        ],
        "predictions": [
          {
            "score": 0.8594745397567749,
            "answer": "predicting",
            "hit": false
          },
          {
            "score": 0.8317493200302124,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.8102276921272278,
            "answer": "predictions",
            "hit": false
          },
          {
            "score": 0.7730000019073486,
            "answer": "forecast",
            "hit": false
          },
          {
            "score": 0.7512564063072205,
            "answer": "predictable",
            "hit": true
          },
          {
            "score": 0.7506452798843384,
            "answer": "calculate",
            "hit": false
          }
        ],
        "set_exclude": [
          "predict"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7512564659118652,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to rely ",
        "b": "rely",
        "expected answer": [
          "reliable"
        ],
        "predictions": [
          {
            "score": 0.8925193548202515,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.8872537016868591,
            "answer": "relied",
            "hit": false
          },
          {
            "score": 0.8710070848464966,
            "answer": "relying",
            "hit": false
          },
          {
            "score": 0.814583420753479,
            "answer": "depended",
            "hit": false
          },
          {
            "score": 0.8023049831390381,
            "answer": "reliance",
            "hit": false
          },
          {
            "score": 0.7996023893356323,
            "answer": "utilize",
            "hit": false
          }
        ],
        "set_exclude": [
          "rely"
        ],
        "rank": 46,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7253297865390778,
        "b in neighbourhood of b_prime": 54,
        "b_prime in neighbourhood of b": 47
      },
      {
        "question verbose": "What is to renew ",
        "b": "renew",
        "expected answer": [
          "renewable"
        ],
        "predictions": [
          {
            "score": 0.8685057759284973,
            "answer": "renewal",
            "hit": false
          },
          {
            "score": 0.8281707763671875,
            "answer": "renewed",
            "hit": false
          },
          {
            "score": 0.7409149408340454,
            "answer": "renewable",
            "hit": true
          },
          {
            "score": 0.7378356456756592,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.7259422540664673,
            "answer": "restoring",
            "hit": false
          },
          {
            "score": 0.7236157655715942,
            "answer": "strengthening",
            "hit": false
          }
        ],
        "set_exclude": [
          "renew"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.740914985537529,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to sustain ",
        "b": "sustain",
        "expected answer": [
          "sustainable"
        ],
        "predictions": [
          {
            "score": 0.8569005727767944,
            "answer": "sustaining",
            "hit": false
          },
          {
            "score": 0.789494514465332,
            "answer": "sustained",
            "hit": false
          },
          {
            "score": 0.7711179852485657,
            "answer": "maintain",
            "hit": false
          },
          {
            "score": 0.7559835910797119,
            "answer": "survive",
            "hit": false
          },
          {
            "score": 0.755619466304779,
            "answer": "sustainability",
            "hit": false
          },
          {
            "score": 0.7397894859313965,
            "answer": "withstand",
            "hit": false
          }
        ],
        "set_exclude": [
          "sustain"
        ],
        "rank": 115,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.687298446893692,
        "b in neighbourhood of b_prime": 888,
        "b_prime in neighbourhood of b": 116
      },
      {
        "question verbose": "What is to vary ",
        "b": "vary",
        "expected answer": [
          "variable"
        ],
        "predictions": [
          {
            "score": 0.8999819755554199,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.8648810982704163,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.823994517326355,
            "answer": "varied",
            "hit": false
          },
          {
            "score": 0.8084519505500793,
            "answer": "differs",
            "hit": false
          },
          {
            "score": 0.8078338503837585,
            "answer": "differed",
            "hit": false
          },
          {
            "score": 0.7951717972755432,
            "answer": "varying",
            "hit": false
          }
        ],
        "set_exclude": [
          "vary"
        ],
        "rank": 160,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7002110779285431,
        "b in neighbourhood of b_prime": 79,
        "b_prime in neighbourhood of b": 161
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 11,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D07 [verb+able_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "b5a76129-4ae2-44e6-baad-58f35175f640",
      "timestamp": "2025-05-17T17:08:15.380327"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believer"
        ],
        "predictions": [
          {
            "score": 0.78984534740448,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.7771393656730652,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7683236002922058,
            "answer": "honestly",
            "hit": false
          },
          {
            "score": 0.7655804753303528,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.763603687286377,
            "answer": "understand",
            "hit": false
          },
          {
            "score": 0.7557419538497925,
            "answer": "bel",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7324797809123993,
        "b in neighbourhood of b_prime": 24,
        "b_prime in neighbourhood of b": 21
      },
      {
        "question verbose": "What is to compose ",
        "b": "compose",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.8786642551422119,
            "answer": "composing",
            "hit": false
          },
          {
            "score": 0.812056303024292,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.7811499238014221,
            "answer": "comprise",
            "hit": false
          },
          {
            "score": 0.7678526639938354,
            "answer": "composition",
            "hit": false
          },
          {
            "score": 0.7551044225692749,
            "answer": "compositions",
            "hit": false
          },
          {
            "score": 0.7493126392364502,
            "answer": "constitute",
            "hit": false
          }
        ],
        "set_exclude": [
          "compose"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7466011643409729,
        "b in neighbourhood of b_prime": 25,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to consume ",
        "b": "consume",
        "expected answer": [
          "consumer"
        ],
        "predictions": [
          {
            "score": 0.8698296546936035,
            "answer": "consumed",
            "hit": false
          },
          {
            "score": 0.8208681344985962,
            "answer": "eat",
            "hit": false
          },
          {
            "score": 0.8068945407867432,
            "answer": "consumption",
            "hit": false
          },
          {
            "score": 0.7893542647361755,
            "answer": "eats",
            "hit": false
          },
          {
            "score": 0.7731465697288513,
            "answer": "drank",
            "hit": false
          },
          {
            "score": 0.7705980539321899,
            "answer": "eaten",
            "hit": false
          }
        ],
        "set_exclude": [
          "consume"
        ],
        "rank": 750,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6781369894742966,
        "b in neighbourhood of b_prime": 281,
        "b_prime in neighbourhood of b": 751
      },
      {
        "question verbose": "What is to contend ",
        "b": "contend",
        "expected answer": [
          "contender"
        ],
        "predictions": [
          {
            "score": 0.8033419251441956,
            "answer": "argue",
            "hit": false
          },
          {
            "score": 0.7678626775741577,
            "answer": "contention",
            "hit": false
          },
          {
            "score": 0.7653636336326599,
            "answer": "argues",
            "hit": false
          },
          {
            "score": 0.7646890878677368,
            "answer": "asserts",
            "hit": false
          },
          {
            "score": 0.7598645687103271,
            "answer": "compete",
            "hit": false
          },
          {
            "score": 0.7589812874794006,
            "answer": "argued",
            "hit": false
          }
        ],
        "set_exclude": [
          "contend"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7316668182611465,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 24
      },
      {
        "question verbose": "What is to defend ",
        "b": "defend",
        "expected answer": [
          "defender"
        ],
        "predictions": [
          {
            "score": 0.8650417923927307,
            "answer": "defended",
            "hit": false
          },
          {
            "score": 0.8554180860519409,
            "answer": "defending",
            "hit": false
          },
          {
            "score": 0.7763586044311523,
            "answer": "oppose",
            "hit": false
          },
          {
            "score": 0.7742695808410645,
            "answer": "defenses",
            "hit": false
          },
          {
            "score": 0.7730891704559326,
            "answer": "defenders",
            "hit": false
          },
          {
            "score": 0.7718838453292847,
            "answer": "defence",
            "hit": false
          }
        ],
        "set_exclude": [
          "defend"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7675340473651886,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developer"
        ],
        "predictions": [
          {
            "score": 0.8854014873504639,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.8651421070098877,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8541511297225952,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7938932776451111,
            "answer": "evolve",
            "hit": false
          },
          {
            "score": 0.7821511626243591,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.7779421210289001,
            "answer": "produce",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 61,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.723933070898056,
        "b in neighbourhood of b_prime": 27,
        "b_prime in neighbourhood of b": 62
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examiner"
        ],
        "predictions": [
          {
            "score": 0.876499354839325,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.8690241575241089,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.8639617562294006,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.8415148854255676,
            "answer": "analyze",
            "hit": false
          },
          {
            "score": 0.8383274078369141,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.8255355358123779,
            "answer": "evaluate",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 81,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7285217493772507,
        "b in neighbourhood of b_prime": 19,
        "b_prime in neighbourhood of b": 82
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.885469377040863,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.879253625869751,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.8693921566009521,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.8239961862564087,
            "answer": "examine",
            "hit": false
          },
          {
            "score": 0.8197250366210938,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.7934346795082092,
            "answer": "pursue",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 422,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6930802762508392,
        "b in neighbourhood of b_prime": 18,
        "b_prime in neighbourhood of b": 423
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follower"
        ],
        "predictions": [
          {
            "score": 0.8120335340499878,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.7988346219062805,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.7367404699325562,
            "answer": "adhere",
            "hit": false
          },
          {
            "score": 0.7360302209854126,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7356061935424805,
            "answer": "obey",
            "hit": false
          },
          {
            "score": 0.7283647656440735,
            "answer": "accompany",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6950639188289642,
        "b in neighbourhood of b_prime": 71,
        "b_prime in neighbourhood of b": 21
      },
      {
        "question verbose": "What is to interpret ",
        "b": "interpret",
        "expected answer": [
          "interpreter"
        ],
        "predictions": [
          {
            "score": 0.8091874718666077,
            "answer": "interpretations",
            "hit": false
          },
          {
            "score": 0.793857753276825,
            "answer": "interpreting",
            "hit": false
          },
          {
            "score": 0.7932953834533691,
            "answer": "interpretation",
            "hit": false
          },
          {
            "score": 0.7800886631011963,
            "answer": "interpreted",
            "hit": false
          },
          {
            "score": 0.7231144309043884,
            "answer": "conceptual",
            "hit": false
          },
          {
            "score": 0.7206107378005981,
            "answer": "issued",
            "hit": false
          }
        ],
        "set_exclude": [
          "interpret"
        ],
        "rank": 29,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7079212218523026,
        "b in neighbourhood of b_prime": 22,
        "b_prime in neighbourhood of b": 30
      },
      {
        "question verbose": "What is to listen ",
        "b": "listen",
        "expected answer": [
          "listener"
        ],
        "predictions": [
          {
            "score": 0.7885966300964355,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7861154079437256,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7669601440429688,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.7540489435195923,
            "answer": "listener",
            "hit": true
          },
          {
            "score": 0.746218740940094,
            "answer": "look",
            "hit": false
          },
          {
            "score": 0.7255991697311401,
            "answer": "hear",
            "hit": false
          }
        ],
        "set_exclude": [
          "listen"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7540489435195923,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "loser"
        ],
        "predictions": [
          {
            "score": 0.7982927560806274,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7737860679626465,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.759117066860199,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.7580106854438782,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.7436167001724243,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7336412668228149,
            "answer": "regain",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7257567048072815,
        "b in neighbourhood of b_prime": 17,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "manager"
        ],
        "predictions": [
          {
            "score": 0.8691065311431885,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7773045301437378,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7756030559539795,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.7727968692779541,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.7606368660926819,
            "answer": "manipulate",
            "hit": false
          },
          {
            "score": 0.7549307346343994,
            "answer": "administer",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 49,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7163756042718887,
        "b in neighbourhood of b_prime": 23,
        "b_prime in neighbourhood of b": 50
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observer"
        ],
        "predictions": [
          {
            "score": 0.8811935186386108,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.8771306872367859,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.8410970568656921,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.7922531962394714,
            "answer": "examine",
            "hit": false
          },
          {
            "score": 0.7851784825325012,
            "answer": "observations",
            "hit": false
          },
          {
            "score": 0.7838951945304871,
            "answer": "observation",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7749102711677551,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 9
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organizer"
        ],
        "predictions": [
          {
            "score": 0.8760344982147217,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.842402458190918,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.8142655491828918,
            "answer": "arrange",
            "hit": false
          },
          {
            "score": 0.8077436685562134,
            "answer": "organizer",
            "hit": true
          },
          {
            "score": 0.7952079176902771,
            "answer": "organizers",
            "hit": false
          },
          {
            "score": 0.782630443572998,
            "answer": "organizational",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8077436685562134,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performer"
        ],
        "predictions": [
          {
            "score": 0.9005298614501953,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.8682640790939331,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.7821890115737915,
            "answer": "execute",
            "hit": false
          },
          {
            "score": 0.7739981412887573,
            "answer": "performer",
            "hit": true
          },
          {
            "score": 0.7658475637435913,
            "answer": "participate",
            "hit": false
          },
          {
            "score": 0.7641125321388245,
            "answer": "performing",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7739981412887573,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to preach ",
        "b": "preach",
        "expected answer": [
          "preacher"
        ],
        "predictions": [
          {
            "score": 0.88349449634552,
            "answer": "preaching",
            "hit": false
          },
          {
            "score": 0.8023883104324341,
            "answer": "sermon",
            "hit": false
          },
          {
            "score": 0.7929595112800598,
            "answer": "preacher",
            "hit": true
          },
          {
            "score": 0.7828570008277893,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.7665120363235474,
            "answer": "theological",
            "hit": false
          },
          {
            "score": 0.7639660239219666,
            "answer": "teachings",
            "hit": false
          }
        ],
        "set_exclude": [
          "preach"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7929595112800598,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoter"
        ],
        "predictions": [
          {
            "score": 0.8944275975227356,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.8781294226646423,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.8345465660095215,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.833759069442749,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.8177255392074585,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.7867518663406372,
            "answer": "promotion",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 70,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7406169772148132,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 71
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provider"
        ],
        "predictions": [
          {
            "score": 0.8921548128128052,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.86236971616745,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.8529132008552551,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.8069967031478882,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.8006588220596313,
            "answer": "facilitate",
            "hit": false
          },
          {
            "score": 0.7988947629928589,
            "answer": "bring",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 313,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6981337666511536,
        "b in neighbourhood of b_prime": 79,
        "b_prime in neighbourhood of b": 314
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "publisher"
        ],
        "predictions": [
          {
            "score": 0.8743718862533569,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.8227976560592651,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7942847013473511,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.7913978695869446,
            "answer": "published",
            "hit": false
          },
          {
            "score": 0.7909828424453735,
            "answer": "publisher",
            "hit": true
          },
          {
            "score": 0.7680726647377014,
            "answer": "disclose",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7909828424453735,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiver"
        ],
        "predictions": [
          {
            "score": 0.8786818385124207,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8465611934661865,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.785489559173584,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.7792428731918335,
            "answer": "obtain",
            "hit": false
          },
          {
            "score": 0.7741402983665466,
            "answer": "participate",
            "hit": false
          },
          {
            "score": 0.7644912004470825,
            "answer": "provide",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 205,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6965592801570892,
        "b in neighbourhood of b_prime": 32,
        "b_prime in neighbourhood of b": 206
      },
      {
        "question verbose": "What is to speak ",
        "b": "speak",
        "expected answer": [
          "speaker"
        ],
        "predictions": [
          {
            "score": 0.7389788627624512,
            "answer": "speaks",
            "hit": false
          },
          {
            "score": 0.7352684736251831,
            "answer": "terminology",
            "hit": false
          },
          {
            "score": 0.7309379577636719,
            "answer": "speaking",
            "hit": false
          },
          {
            "score": 0.7294454574584961,
            "answer": "communicate",
            "hit": false
          },
          {
            "score": 0.7172686457633972,
            "answer": "discourse",
            "hit": false
          },
          {
            "score": 0.7163193225860596,
            "answer": "spoken",
            "hit": false
          }
        ],
        "set_exclude": [
          "speak"
        ],
        "rank": 1337,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6586373448371887,
        "b in neighbourhood of b_prime": 460,
        "b_prime in neighbourhood of b": 1338
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teacher"
        ],
        "predictions": [
          {
            "score": 0.889914333820343,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.8749581575393677,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.8298712968826294,
            "answer": "teaching",
            "hit": false
          },
          {
            "score": 0.8006123304367065,
            "answer": "educate",
            "hit": false
          },
          {
            "score": 0.7956241965293884,
            "answer": "learn",
            "hit": false
          },
          {
            "score": 0.7828569412231445,
            "answer": "preach",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7654690742492676,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 14
      },
      {
        "question verbose": "What is to write ",
        "b": "write",
        "expected answer": [
          "writer"
        ],
        "predictions": [
          {
            "score": 0.8553183078765869,
            "answer": "wrote",
            "hit": false
          },
          {
            "score": 0.8477038145065308,
            "answer": "writes",
            "hit": false
          },
          {
            "score": 0.7855252623558044,
            "answer": "writing",
            "hit": false
          },
          {
            "score": 0.756556510925293,
            "answer": "written",
            "hit": false
          },
          {
            "score": 0.7564987540245056,
            "answer": "writ",
            "hit": false
          },
          {
            "score": 0.7537500858306885,
            "answer": "publish",
            "hit": false
          }
        ],
        "set_exclude": [
          "write"
        ],
        "rank": 34,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7060136198997498,
        "b in neighbourhood of b_prime": 48,
        "b_prime in neighbourhood of b": 35
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 24,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D08 [verb+er_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "6397680e-5098-4300-acea-3af6170a5a1d",
      "timestamp": "2025-05-17T17:08:15.475233"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accuse ",
        "b": "accuse",
        "expected answer": [
          "accusation"
        ],
        "predictions": [
          {
            "score": 0.8784942626953125,
            "answer": "accusing",
            "hit": false
          },
          {
            "score": 0.8400518894195557,
            "answer": "accused",
            "hit": false
          },
          {
            "score": 0.8369953036308289,
            "answer": "accusation",
            "hit": true
          },
          {
            "score": 0.8270168304443359,
            "answer": "accusations",
            "hit": false
          },
          {
            "score": 0.7956346273422241,
            "answer": "alleging",
            "hit": false
          },
          {
            "score": 0.7925028204917908,
            "answer": "argue",
            "hit": false
          }
        ],
        "set_exclude": [
          "accuse"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8369952738285065,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to admire ",
        "b": "admire",
        "expected answer": [
          "admiration"
        ],
        "predictions": [
          {
            "score": 0.8413485288619995,
            "answer": "admired",
            "hit": false
          },
          {
            "score": 0.8253876566886902,
            "answer": "admiration",
            "hit": true
          },
          {
            "score": 0.7500342726707458,
            "answer": "appreciate",
            "hit": false
          },
          {
            "score": 0.7433459758758545,
            "answer": "devote",
            "hit": false
          },
          {
            "score": 0.7423945665359497,
            "answer": "enthusiasts",
            "hit": false
          },
          {
            "score": 0.742231011390686,
            "answer": "praise",
            "hit": false
          }
        ],
        "set_exclude": [
          "admire"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8253876268863678,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to compute ",
        "b": "compute",
        "expected answer": [
          "computation"
        ],
        "predictions": [
          {
            "score": 0.8217346668243408,
            "answer": "computation",
            "hit": true
          },
          {
            "score": 0.805178165435791,
            "answer": "calculate",
            "hit": false
          },
          {
            "score": 0.8043097853660583,
            "answer": "computational",
            "hit": false
          },
          {
            "score": 0.7980186939239502,
            "answer": "computed",
            "hit": false
          },
          {
            "score": 0.7730655670166016,
            "answer": "computing",
            "hit": false
          },
          {
            "score": 0.752685546875,
            "answer": "calculating",
            "hit": false
          }
        ],
        "set_exclude": [
          "compute"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8217347264289856,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuation"
        ],
        "predictions": [
          {
            "score": 0.7568832635879517,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.748924732208252,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.748767077922821,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.737725019454956,
            "answer": "proceed",
            "hit": false
          },
          {
            "score": 0.7294521331787109,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7238302230834961,
            "answer": "repeat",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7131004184484482,
        "b in neighbourhood of b_prime": 27,
        "b_prime in neighbourhood of b": 15
      },
      {
        "question verbose": "What is to declare ",
        "b": "declare",
        "expected answer": [
          "declaration"
        ],
        "predictions": [
          {
            "score": 0.8843992948532104,
            "answer": "declares",
            "hit": false
          },
          {
            "score": 0.8751409649848938,
            "answer": "declaring",
            "hit": false
          },
          {
            "score": 0.8707901835441589,
            "answer": "declared",
            "hit": false
          },
          {
            "score": 0.7684097290039062,
            "answer": "specify",
            "hit": false
          },
          {
            "score": 0.760991096496582,
            "answer": "designate",
            "hit": false
          },
          {
            "score": 0.7601119875907898,
            "answer": "announces",
            "hit": false
          }
        ],
        "set_exclude": [
          "declare"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7537760436534882,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to determine ",
        "b": "determine",
        "expected answer": [
          "determination"
        ],
        "predictions": [
          {
            "score": 0.8787156343460083,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.860167384147644,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.8572810292243958,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.8137173056602478,
            "answer": "evaluate",
            "hit": false
          },
          {
            "score": 0.8123443126678467,
            "answer": "calculate",
            "hit": false
          },
          {
            "score": 0.809664249420166,
            "answer": "determined",
            "hit": false
          }
        ],
        "set_exclude": [
          "determine"
        ],
        "rank": 68,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7354241907596588,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 69
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examination"
        ],
        "predictions": [
          {
            "score": 0.876499354839325,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.8690241575241089,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.8639617562294006,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.8415148854255676,
            "answer": "analyze",
            "hit": false
          },
          {
            "score": 0.8383274078369141,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.8255355358123779,
            "answer": "evaluate",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7771652340888977,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 14
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "exploration"
        ],
        "predictions": [
          {
            "score": 0.885469377040863,
            "answer": "exploring",
            "hit": false
          },
          {
            "score": 0.879253625869751,
            "answer": "explored",
            "hit": false
          },
          {
            "score": 0.8693921566009521,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.8239961862564087,
            "answer": "examine",
            "hit": false
          },
          {
            "score": 0.8197250366210938,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.7934346795082092,
            "answer": "pursue",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7685723900794983,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to imagine ",
        "b": "imagine",
        "expected answer": [
          "imagination"
        ],
        "predictions": [
          {
            "score": 0.7854723334312439,
            "answer": "maybe",
            "hit": false
          },
          {
            "score": 0.7835174798965454,
            "answer": "imagining",
            "hit": false
          },
          {
            "score": 0.778678297996521,
            "answer": "imagined",
            "hit": false
          },
          {
            "score": 0.7678658366203308,
            "answer": "why",
            "hit": false
          },
          {
            "score": 0.7664589881896973,
            "answer": "unlike",
            "hit": false
          },
          {
            "score": 0.7648496031761169,
            "answer": "almost",
            "hit": false
          }
        ],
        "set_exclude": [
          "imagine"
        ],
        "rank": 234,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7065394818782806,
        "b in neighbourhood of b_prime": 64,
        "b_prime in neighbourhood of b": 235
      },
      {
        "question verbose": "What is to inspire ",
        "b": "inspire",
        "expected answer": [
          "inspiration"
        ],
        "predictions": [
          {
            "score": 0.8513132333755493,
            "answer": "inspiring",
            "hit": false
          },
          {
            "score": 0.7924649715423584,
            "answer": "provoke",
            "hit": false
          },
          {
            "score": 0.791496753692627,
            "answer": "inspiration",
            "hit": true
          },
          {
            "score": 0.7911894917488098,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.7799137234687805,
            "answer": "inspired",
            "hit": false
          },
          {
            "score": 0.7687979340553284,
            "answer": "convince",
            "hit": false
          }
        ],
        "set_exclude": [
          "inspire"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7914967834949493,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observation"
        ],
        "predictions": [
          {
            "score": 0.8811935186386108,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.8771306872367859,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.8410970568656921,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.7922531962394714,
            "answer": "examine",
            "hit": false
          },
          {
            "score": 0.7851784825325012,
            "answer": "observations",
            "hit": false
          },
          {
            "score": 0.7838951945304871,
            "answer": "observation",
            "hit": true
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7838951647281647,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to occupy ",
        "b": "occupy",
        "expected answer": [
          "occupation"
        ],
        "predictions": [
          {
            "score": 0.8963196277618408,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.8585736751556396,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.7909263372421265,
            "answer": "inhabit",
            "hit": false
          },
          {
            "score": 0.7857980132102966,
            "answer": "occupied",
            "hit": false
          },
          {
            "score": 0.7825199365615845,
            "answer": "occupation",
            "hit": true
          },
          {
            "score": 0.7630990743637085,
            "answer": "reside",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupy"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7825199961662292,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organization"
        ],
        "predictions": [
          {
            "score": 0.8760344982147217,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.842402458190918,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.8142655491828918,
            "answer": "arrange",
            "hit": false
          },
          {
            "score": 0.8077436685562134,
            "answer": "organizer",
            "hit": false
          },
          {
            "score": 0.7952079176902771,
            "answer": "organizers",
            "hit": false
          },
          {
            "score": 0.782630443572998,
            "answer": "organizational",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7623420059680939,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to prepare ",
        "b": "prepare",
        "expected answer": [
          "preparation"
        ],
        "predictions": [
          {
            "score": 0.8695862889289856,
            "answer": "prepares",
            "hit": false
          },
          {
            "score": 0.8560477495193481,
            "answer": "preparing",
            "hit": false
          },
          {
            "score": 0.8280998468399048,
            "answer": "prepared",
            "hit": false
          },
          {
            "score": 0.8253277540206909,
            "answer": "preparation",
            "hit": true
          },
          {
            "score": 0.7832281589508057,
            "answer": "preparations",
            "hit": false
          },
          {
            "score": 0.7513641715049744,
            "answer": "assess",
            "hit": false
          }
        ],
        "set_exclude": [
          "prepare"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8253277540206909,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to restore ",
        "b": "restore",
        "expected answer": [
          "restoration"
        ],
        "predictions": [
          {
            "score": 0.903260350227356,
            "answer": "restoring",
            "hit": false
          },
          {
            "score": 0.858188807964325,
            "answer": "restored",
            "hit": false
          },
          {
            "score": 0.7893972992897034,
            "answer": "regain",
            "hit": false
          },
          {
            "score": 0.7839781641960144,
            "answer": "restoration",
            "hit": true
          },
          {
            "score": 0.7774649858474731,
            "answer": "preserve",
            "hit": false
          },
          {
            "score": 0.7773349285125732,
            "answer": "revive",
            "hit": false
          }
        ],
        "set_exclude": [
          "restore"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7839781641960144,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to stabilize ",
        "b": "stabilize",
        "expected answer": [
          "stabilization"
        ],
        "predictions": [
          {
            "score": 0.8842179179191589,
            "answer": "stabilized",
            "hit": false
          },
          {
            "score": 0.8531011939048767,
            "answer": "stabilization",
            "hit": true
          },
          {
            "score": 0.7904119491577148,
            "answer": "stability",
            "hit": false
          },
          {
            "score": 0.7780117392539978,
            "answer": "stable",
            "hit": false
          },
          {
            "score": 0.7650731205940247,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.7645223140716553,
            "answer": "alleviate",
            "hit": false
          }
        ],
        "set_exclude": [
          "stabilize"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8531012535095215,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 16,
      "accuracy": 0.0625
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D09 [verb+tion_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "5f2bd5a6-33e4-47a4-85e5-5e897918b828",
      "timestamp": "2025-05-17T17:08:15.683658"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accomplish ",
        "b": "accomplish",
        "expected answer": [
          "accomplishment"
        ],
        "predictions": [
          {
            "score": 0.8457323312759399,
            "answer": "accomplished",
            "hit": false
          },
          {
            "score": 0.7993879914283752,
            "answer": "fulfill",
            "hit": false
          },
          {
            "score": 0.7974237203598022,
            "answer": "accomplishment",
            "hit": true
          },
          {
            "score": 0.7972792387008667,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7924083471298218,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.7912845611572266,
            "answer": "achieved",
            "hit": false
          }
        ],
        "set_exclude": [
          "accomplish"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7974237203598022,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achievement"
        ],
        "predictions": [
          {
            "score": 0.7977390289306641,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7924083471298218,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7867431044578552,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.7702281475067139,
            "answer": "ensure",
            "hit": false
          },
          {
            "score": 0.7625571489334106,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.7618892192840576,
            "answer": "attain",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7366247475147247,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 24
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustment"
        ],
        "predictions": [
          {
            "score": 0.8381365537643433,
            "answer": "adjustment",
            "hit": true
          },
          {
            "score": 0.8325479626655579,
            "answer": "adjusting",
            "hit": false
          },
          {
            "score": 0.8317915797233582,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.8124579191207886,
            "answer": "adjustable",
            "hit": false
          },
          {
            "score": 0.7603938579559326,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.7501000165939331,
            "answer": "align",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8381365537643433,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreement"
        ],
        "predictions": [
          {
            "score": 0.8747720122337341,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.8463097810745239,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.837645411491394,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.8146491646766663,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.7868742942810059,
            "answer": "acknowledge",
            "hit": false
          },
          {
            "score": 0.7832205295562744,
            "answer": "disagreed",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7416486144065857,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 17
      },
      {
        "question verbose": "What is to align ",
        "b": "align",
        "expected answer": [
          "alignment"
        ],
        "predictions": [
          {
            "score": 0.7915264964103699,
            "answer": "aligned",
            "hit": false
          },
          {
            "score": 0.7668419480323792,
            "answer": "alignment",
            "hit": true
          },
          {
            "score": 0.7501000165939331,
            "answer": "adjust",
            "hit": false
          },
          {
            "score": 0.7233283519744873,
            "answer": "offset",
            "hit": false
          },
          {
            "score": 0.719071626663208,
            "answer": "reinforce",
            "hit": false
          },
          {
            "score": 0.717862606048584,
            "answer": "inline",
            "hit": false
          }
        ],
        "set_exclude": [
          "align"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7668419480323792,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to amend ",
        "b": "amend",
        "expected answer": [
          "amendment"
        ],
        "predictions": [
          {
            "score": 0.8212746977806091,
            "answer": "amended",
            "hit": false
          },
          {
            "score": 0.8035343885421753,
            "answer": "amendments",
            "hit": false
          },
          {
            "score": 0.7912939190864563,
            "answer": "modify",
            "hit": false
          },
          {
            "score": 0.7706038355827332,
            "answer": "clarify",
            "hit": false
          },
          {
            "score": 0.7573923468589783,
            "answer": "prohibit",
            "hit": false
          },
          {
            "score": 0.7546867728233337,
            "answer": "amendment",
            "hit": true
          }
        ],
        "set_exclude": [
          "amend"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7546868324279785,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announcement"
        ],
        "predictions": [
          {
            "score": 0.838386058807373,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.8196549415588379,
            "answer": "announcement",
            "hit": true
          },
          {
            "score": 0.7855234146118164,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.7711190581321716,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.7337414026260376,
            "answer": "announced",
            "hit": false
          },
          {
            "score": 0.7332971692085266,
            "answer": "notification",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8196549415588379,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to appoint ",
        "b": "appoint",
        "expected answer": [
          "appointment"
        ],
        "predictions": [
          {
            "score": 0.833682119846344,
            "answer": "appointed",
            "hit": false
          },
          {
            "score": 0.7922268509864807,
            "answer": "appointments",
            "hit": false
          },
          {
            "score": 0.7893871068954468,
            "answer": "appointment",
            "hit": true
          },
          {
            "score": 0.7579044103622437,
            "answer": "designate",
            "hit": false
          },
          {
            "score": 0.7530330419540405,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.7507039308547974,
            "answer": "assigns",
            "hit": false
          }
        ],
        "set_exclude": [
          "appoint"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7893871068954468,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to arrange ",
        "b": "arrange",
        "expected answer": [
          "arrangement"
        ],
        "predictions": [
          {
            "score": 0.8890964984893799,
            "answer": "arranging",
            "hit": false
          },
          {
            "score": 0.8551466464996338,
            "answer": "arranged",
            "hit": false
          },
          {
            "score": 0.8142655491828918,
            "answer": "organize",
            "hit": false
          },
          {
            "score": 0.7934204339981079,
            "answer": "arrangements",
            "hit": false
          },
          {
            "score": 0.7913532257080078,
            "answer": "arrangement",
            "hit": true
          },
          {
            "score": 0.7694071531295776,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "arrange"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7913532853126526,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to assess ",
        "b": "assess",
        "expected answer": [
          "assessment"
        ],
        "predictions": [
          {
            "score": 0.8609616160392761,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.8533445000648499,
            "answer": "assessed",
            "hit": false
          },
          {
            "score": 0.8495385646820068,
            "answer": "evaluate",
            "hit": false
          },
          {
            "score": 0.8352417349815369,
            "answer": "assessments",
            "hit": false
          },
          {
            "score": 0.8052704930305481,
            "answer": "examine",
            "hit": false
          },
          {
            "score": 0.7967540621757507,
            "answer": "assessment",
            "hit": true
          }
        ],
        "set_exclude": [
          "assess"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7967540621757507,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to assign ",
        "b": "assign",
        "expected answer": [
          "assignment"
        ],
        "predictions": [
          {
            "score": 0.8879124522209167,
            "answer": "assigns",
            "hit": false
          },
          {
            "score": 0.8427101373672485,
            "answer": "assigned",
            "hit": false
          },
          {
            "score": 0.7904406189918518,
            "answer": "assignments",
            "hit": false
          },
          {
            "score": 0.7790813446044922,
            "answer": "assignment",
            "hit": true
          },
          {
            "score": 0.7556412220001221,
            "answer": "evaluate",
            "hit": false
          },
          {
            "score": 0.7543503046035767,
            "answer": "designate",
            "hit": false
          }
        ],
        "set_exclude": [
          "assign"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7790813446044922,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to commit ",
        "b": "commit",
        "expected answer": [
          "commitment"
        ],
        "predictions": [
          {
            "score": 0.7922182083129883,
            "answer": "committing",
            "hit": false
          },
          {
            "score": 0.7882571220397949,
            "answer": "commitment",
            "hit": true
          },
          {
            "score": 0.7760931253433228,
            "answer": "commits",
            "hit": false
          },
          {
            "score": 0.7595872282981873,
            "answer": "commitments",
            "hit": false
          },
          {
            "score": 0.7581467032432556,
            "answer": "committed",
            "hit": false
          },
          {
            "score": 0.7252499461174011,
            "answer": "dedication",
            "hit": false
          }
        ],
        "set_exclude": [
          "commit"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7882571220397949,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "development"
        ],
        "predictions": [
          {
            "score": 0.8854014873504639,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.8651421070098877,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.8541511297225952,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7938932776451111,
            "answer": "evolve",
            "hit": false
          },
          {
            "score": 0.7821511626243591,
            "answer": "development",
            "hit": true
          },
          {
            "score": 0.7779421210289001,
            "answer": "produce",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7821511626243591,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to disagree ",
        "b": "disagree",
        "expected answer": [
          "disagreement"
        ],
        "predictions": [
          {
            "score": 0.8802672028541565,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.8146491646766663,
            "answer": "agree",
            "hit": false
          },
          {
            "score": 0.810258686542511,
            "answer": "disagreement",
            "hit": true
          },
          {
            "score": 0.7898778915405273,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.7702672481536865,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.761826753616333,
            "answer": "differing",
            "hit": false
          }
        ],
        "set_exclude": [
          "disagree"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.810258686542511,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouragement"
        ],
        "predictions": [
          {
            "score": 0.8907161355018616,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.8901094794273376,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.8493248820304871,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.8345465660095215,
            "answer": "promote",
            "hit": false
          },
          {
            "score": 0.8242634534835815,
            "answer": "encouraging",
            "hit": false
          },
          {
            "score": 0.8124820590019226,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7885138988494873,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to enforce ",
        "b": "enforce",
        "expected answer": [
          "enforcement"
        ],
        "predictions": [
          {
            "score": 0.8761070966720581,
            "answer": "enforcing",
            "hit": false
          },
          {
            "score": 0.8416193127632141,
            "answer": "enforced",
            "hit": false
          },
          {
            "score": 0.7777695059776306,
            "answer": "impose",
            "hit": false
          },
          {
            "score": 0.7708649039268494,
            "answer": "enforcement",
            "hit": true
          },
          {
            "score": 0.7617464065551758,
            "answer": "prohibit",
            "hit": false
          },
          {
            "score": 0.7611159682273865,
            "answer": "uphold",
            "hit": false
          }
        ],
        "set_exclude": [
          "enforce"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7708649039268494,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to engage ",
        "b": "engage",
        "expected answer": [
          "engagement"
        ],
        "predictions": [
          {
            "score": 0.9038443565368652,
            "answer": "engages",
            "hit": false
          },
          {
            "score": 0.8818995952606201,
            "answer": "engaging",
            "hit": false
          },
          {
            "score": 0.8631430268287659,
            "answer": "engaged",
            "hit": false
          },
          {
            "score": 0.7998576760292053,
            "answer": "engagement",
            "hit": true
          },
          {
            "score": 0.7967169284820557,
            "answer": "participate",
            "hit": false
          },
          {
            "score": 0.7751789093017578,
            "answer": "pursue",
            "hit": false
          }
        ],
        "set_exclude": [
          "engage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7998577356338501,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to enhance ",
        "b": "enhance",
        "expected answer": [
          "enhancement"
        ],
        "predictions": [
          {
            "score": 0.7860125303268433,
            "answer": "enhancement",
            "hit": true
          },
          {
            "score": 0.7856526374816895,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.7766793370246887,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.761343777179718,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7517064809799194,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.7509318590164185,
            "answer": "enhanced",
            "hit": false
          }
        ],
        "set_exclude": [
          "enhance"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7860125303268433,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyment"
        ],
        "predictions": [
          {
            "score": 0.8120999932289124,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.7885305285453796,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.7876150608062744,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.7674121856689453,
            "answer": "enjoyment",
            "hit": true
          },
          {
            "score": 0.7522728443145752,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.7516811490058899,
            "answer": "feel",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7674121558666229,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to entertain ",
        "b": "entertain",
        "expected answer": [
          "entertainment"
        ],
        "predictions": [
          {
            "score": 0.8317111134529114,
            "answer": "entertained",
            "hit": false
          },
          {
            "score": 0.810383677482605,
            "answer": "entertaining",
            "hit": false
          },
          {
            "score": 0.7972621917724609,
            "answer": "entertainment",
            "hit": true
          },
          {
            "score": 0.7554718255996704,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.7458520531654358,
            "answer": "musician",
            "hit": false
          },
          {
            "score": 0.739489734172821,
            "answer": "celebrities",
            "hit": false
          }
        ],
        "set_exclude": [
          "entertain"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7972621917724609,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishment"
        ],
        "predictions": [
          {
            "score": 0.8520770072937012,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.8274535536766052,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7631235122680664,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.7612297534942627,
            "answer": "initiating",
            "hit": false
          },
          {
            "score": 0.7596732378005981,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7570483684539795,
            "answer": "restoring",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 139,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7168536335229874,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 140
      },
      {
        "question verbose": "What is to fulfill ",
        "b": "fulfill",
        "expected answer": [
          "fulfillment"
        ],
        "predictions": [
          {
            "score": 0.8582807779312134,
            "answer": "fulfilled",
            "hit": false
          },
          {
            "score": 0.8563181161880493,
            "answer": "fulfilling",
            "hit": false
          },
          {
            "score": 0.8441270589828491,
            "answer": "satisfy",
            "hit": false
          },
          {
            "score": 0.8285223245620728,
            "answer": "fulfillment",
            "hit": true
          },
          {
            "score": 0.7993879318237305,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7751783132553101,
            "answer": "comply",
            "hit": false
          }
        ],
        "set_exclude": [
          "fulfill"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8285223543643951,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improvement"
        ],
        "predictions": [
          {
            "score": 0.8441023826599121,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.8371005058288574,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.810447096824646,
            "answer": "improvement",
            "hit": true
          },
          {
            "score": 0.8089033365249634,
            "answer": "improving",
            "hit": false
          },
          {
            "score": 0.8048802018165588,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7805802226066589,
            "answer": "alleviate",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8104471266269684,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to invest ",
        "b": "invest",
        "expected answer": [
          "investment"
        ],
        "predictions": [
          {
            "score": 0.7924058437347412,
            "answer": "investment",
            "hit": true
          },
          {
            "score": 0.7901512980461121,
            "answer": "investing",
            "hit": false
          },
          {
            "score": 0.7766919136047363,
            "answer": "investor",
            "hit": false
          },
          {
            "score": 0.7750998735427856,
            "answer": "investments",
            "hit": false
          },
          {
            "score": 0.7688864469528198,
            "answer": "invested",
            "hit": false
          },
          {
            "score": 0.7596666216850281,
            "answer": "investigate",
            "hit": false
          }
        ],
        "set_exclude": [
          "invest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7924058437347412,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involvement"
        ],
        "predictions": [
          {
            "score": 0.8940294981002808,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8378790616989136,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.8019938468933105,
            "answer": "require",
            "hit": false
          },
          {
            "score": 0.7944343090057373,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.7883403897285461,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7867710590362549,
            "answer": "incorporate",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7559574842453003,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 21
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "management"
        ],
        "predictions": [
          {
            "score": 0.8691065311431885,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7773045301437378,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7756030559539795,
            "answer": "managed",
            "hit": false
          },
          {
            "score": 0.7727968692779541,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.7606368660926819,
            "answer": "manipulate",
            "hit": false
          },
          {
            "score": 0.7549307346343994,
            "answer": "administer",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.740618109703064,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 11
      },
      {
        "question verbose": "What is to punish ",
        "b": "punish",
        "expected answer": [
          "punishment"
        ],
        "predictions": [
          {
            "score": 0.8858155012130737,
            "answer": "punished",
            "hit": false
          },
          {
            "score": 0.8383610844612122,
            "answer": "punishment",
            "hit": true
          },
          {
            "score": 0.7806678414344788,
            "answer": "impose",
            "hit": false
          },
          {
            "score": 0.770325779914856,
            "answer": "prohibit",
            "hit": false
          },
          {
            "score": 0.7683457732200623,
            "answer": "retaliation",
            "hit": false
          },
          {
            "score": 0.7671614289283752,
            "answer": "discourage",
            "hit": false
          }
        ],
        "set_exclude": [
          "punish"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8383610844612122,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to reinforce ",
        "b": "reinforce",
        "expected answer": [
          "reinforcement"
        ],
        "predictions": [
          {
            "score": 0.8639854788780212,
            "answer": "reinforced",
            "hit": false
          },
          {
            "score": 0.8408346176147461,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.8288209438323975,
            "answer": "reinforcement",
            "hit": true
          },
          {
            "score": 0.8111492991447449,
            "answer": "undermine",
            "hit": false
          },
          {
            "score": 0.7900388240814209,
            "answer": "emphasize",
            "hit": false
          },
          {
            "score": 0.7816622853279114,
            "answer": "strengthened",
            "hit": false
          }
        ],
        "set_exclude": [
          "reinforce"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8288210034370422,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replacement"
        ],
        "predictions": [
          {
            "score": 0.7788068056106567,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.7621755599975586,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.758103609085083,
            "answer": "replaced",
            "hit": false
          },
          {
            "score": 0.75592041015625,
            "answer": "split",
            "hit": false
          },
          {
            "score": 0.7505188584327698,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.7365209460258484,
            "answer": "replacement",
            "hit": true
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7365209609270096,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requirement"
        ],
        "predictions": [
          {
            "score": 0.839923083782196,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.8019938468933105,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.781915545463562,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.780232310295105,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.7796525955200195,
            "answer": "requirement",
            "hit": true
          },
          {
            "score": 0.7783592343330383,
            "answer": "prohibit",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7796525955200195,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 5
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 30,
      "accuracy": 0.1
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D10 [verb+ment_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "aca431b0-abad-42cd-b8ca-4feb8b4a9617",
      "timestamp": "2025-05-17T17:08:15.822893"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to athens ",
        "b": "athens",
        "expected answer": [
          "greece"
        ],
        "predictions": [
          {
            "score": 0.8584734797477722,
            "answer": "greece",
            "hit": true
          },
          {
            "score": 0.7984148263931274,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7937533259391785,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.7764204144477844,
            "answer": "istanbul",
            "hit": false
          },
          {
            "score": 0.7731401324272156,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.7707726955413818,
            "answer": "socrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "athens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8584735095500946,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to baghdad ",
        "b": "baghdad",
        "expected answer": [
          "iraq"
        ],
        "predictions": [
          {
            "score": 0.8495557904243469,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.8419049382209778,
            "answer": "iraq",
            "hit": true
          },
          {
            "score": 0.8350793123245239,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.8191362619400024,
            "answer": "damascus",
            "hit": false
          },
          {
            "score": 0.8068844079971313,
            "answer": "saddam",
            "hit": false
          },
          {
            "score": 0.7879759073257446,
            "answer": "cairo",
            "hit": false
          }
        ],
        "set_exclude": [
          "baghdad"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8419049382209778,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to bangkok ",
        "b": "bangkok",
        "expected answer": [
          "thailand"
        ],
        "predictions": [
          {
            "score": 0.8858237266540527,
            "answer": "thailand",
            "hit": true
          },
          {
            "score": 0.8421605825424194,
            "answer": "thai",
            "hit": false
          },
          {
            "score": 0.8061821460723877,
            "answer": "istanbul",
            "hit": false
          },
          {
            "score": 0.8053950071334839,
            "answer": "cambodia",
            "hit": false
          },
          {
            "score": 0.8018292784690857,
            "answer": "manila",
            "hit": false
          },
          {
            "score": 0.8011734485626221,
            "answer": "seoul",
            "hit": false
          }
        ],
        "set_exclude": [
          "bangkok"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8858236968517303,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to beijing ",
        "b": "beijing",
        "expected answer": [
          "china"
        ],
        "predictions": [
          {
            "score": 0.8551504611968994,
            "answer": "china",
            "hit": true
          },
          {
            "score": 0.8421714901924133,
            "answer": "shanghai",
            "hit": false
          },
          {
            "score": 0.8235241770744324,
            "answer": "seoul",
            "hit": false
          },
          {
            "score": 0.8232022523880005,
            "answer": "chinese",
            "hit": false
          },
          {
            "score": 0.8129591941833496,
            "answer": "tokyo",
            "hit": false
          },
          {
            "score": 0.7942241430282593,
            "answer": "bangkok",
            "hit": false
          }
        ],
        "set_exclude": [
          "beijing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8551504611968994,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to berlin ",
        "b": "berlin",
        "expected answer": [
          "germany"
        ],
        "predictions": [
          {
            "score": 0.8095274567604065,
            "answer": "germany",
            "hit": true
          },
          {
            "score": 0.7988272905349731,
            "answer": "hamburg",
            "hit": false
          },
          {
            "score": 0.7948089838027954,
            "answer": "munich",
            "hit": false
          },
          {
            "score": 0.7877275347709656,
            "answer": "frankfurt",
            "hit": false
          },
          {
            "score": 0.786768913269043,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7867202758789062,
            "answer": "vienna",
            "hit": false
          }
        ],
        "set_exclude": [
          "berlin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8095274567604065,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to bern ",
        "b": "bern",
        "expected answer": [
          "switzerland"
        ],
        "predictions": [
          {
            "score": 0.7056139707565308,
            "answer": "bernstein",
            "hit": false
          },
          {
            "score": 0.6991197466850281,
            "answer": "bernie",
            "hit": false
          },
          {
            "score": 0.6911472678184509,
            "answer": "becca",
            "hit": false
          },
          {
            "score": 0.6892246007919312,
            "answer": "sanders",
            "hit": false
          },
          {
            "score": 0.6872341632843018,
            "answer": "democratic",
            "hit": false
          },
          {
            "score": 0.6872068047523499,
            "answer": "fred",
            "hit": false
          }
        ],
        "set_exclude": [
          "bern"
        ],
        "rank": 1286,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6445838958024979,
        "b in neighbourhood of b_prime": 5193,
        "b_prime in neighbourhood of b": 1287
      },
      {
        "question verbose": "What is to brussels ",
        "b": "brussels",
        "expected answer": [
          "belgium"
        ],
        "predictions": [
          {
            "score": 0.8248552680015564,
            "answer": "belgium",
            "hit": true
          },
          {
            "score": 0.8096393346786499,
            "answer": "belgian",
            "hit": false
          },
          {
            "score": 0.7803038358688354,
            "answer": "berlin",
            "hit": false
          },
          {
            "score": 0.7750151753425598,
            "answer": "amsterdam",
            "hit": false
          },
          {
            "score": 0.7731133103370667,
            "answer": "paris",
            "hit": false
          },
          {
            "score": 0.7729319930076599,
            "answer": "lisbon",
            "hit": false
          }
        ],
        "set_exclude": [
          "brussels"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8248552680015564,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to budapest ",
        "b": "budapest",
        "expected answer": [
          "hungary"
        ],
        "predictions": [
          {
            "score": 0.8742265701293945,
            "answer": "hungary",
            "hit": true
          },
          {
            "score": 0.8646367788314819,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.8207138776779175,
            "answer": "prague",
            "hit": false
          },
          {
            "score": 0.8019543290138245,
            "answer": "vienna",
            "hit": false
          },
          {
            "score": 0.7990713715553284,
            "answer": "istanbul",
            "hit": false
          },
          {
            "score": 0.7852323651313782,
            "answer": "helsinki",
            "hit": false
          }
        ],
        "set_exclude": [
          "budapest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8742266297340393,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to cairo ",
        "b": "cairo",
        "expected answer": [
          "egypt"
        ],
        "predictions": [
          {
            "score": 0.8488540053367615,
            "answer": "egypt",
            "hit": true
          },
          {
            "score": 0.8253117203712463,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.7913385629653931,
            "answer": "istanbul",
            "hit": false
          },
          {
            "score": 0.7879759073257446,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.7830128073692322,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.7756123542785645,
            "answer": "damascus",
            "hit": false
          }
        ],
        "set_exclude": [
          "cairo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8488540351390839,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to copenhagen ",
        "b": "copenhagen",
        "expected answer": [
          "denmark"
        ],
        "predictions": [
          {
            "score": 0.8445398211479187,
            "answer": "denmark",
            "hit": true
          },
          {
            "score": 0.8358479738235474,
            "answer": "danish",
            "hit": false
          },
          {
            "score": 0.8129018545150757,
            "answer": "oslo",
            "hit": false
          },
          {
            "score": 0.8057295083999634,
            "answer": "stockholm",
            "hit": false
          },
          {
            "score": 0.7852497100830078,
            "answer": "paris",
            "hit": false
          },
          {
            "score": 0.7829865217208862,
            "answer": "kyoto",
            "hit": false
          }
        ],
        "set_exclude": [
          "copenhagen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8445398211479187,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to damascus ",
        "b": "damascus",
        "expected answer": [
          "syria"
        ],
        "predictions": [
          {
            "score": 0.8256634473800659,
            "answer": "syria",
            "hit": true
          },
          {
            "score": 0.8191363215446472,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.8121299743652344,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.8087645769119263,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.7790990471839905,
            "answer": "moscow",
            "hit": false
          },
          {
            "score": 0.7756123542785645,
            "answer": "cairo",
            "hit": false
          }
        ],
        "set_exclude": [
          "damascus"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8256634473800659,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to dublin ",
        "b": "dublin",
        "expected answer": [
          "ireland"
        ],
        "predictions": [
          {
            "score": 0.8284109830856323,
            "answer": "ireland",
            "hit": true
          },
          {
            "score": 0.8125098943710327,
            "answer": "belfast",
            "hit": false
          },
          {
            "score": 0.805228590965271,
            "answer": "cork",
            "hit": false
          },
          {
            "score": 0.8029683828353882,
            "answer": "irish",
            "hit": false
          },
          {
            "score": 0.7895737886428833,
            "answer": "edinburgh",
            "hit": false
          },
          {
            "score": 0.7853286266326904,
            "answer": "auckland",
            "hit": false
          }
        ],
        "set_exclude": [
          "dublin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8284109234809875,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to helsinki ",
        "b": "helsinki",
        "expected answer": [
          "finland"
        ],
        "predictions": [
          {
            "score": 0.8340702056884766,
            "answer": "finland",
            "hit": true
          },
          {
            "score": 0.8242729902267456,
            "answer": "finnish",
            "hit": false
          },
          {
            "score": 0.8128501772880554,
            "answer": "stockholm",
            "hit": false
          },
          {
            "score": 0.7977151274681091,
            "answer": "oslo",
            "hit": false
          },
          {
            "score": 0.7852323651313782,
            "answer": "budapest",
            "hit": false
          },
          {
            "score": 0.7739430069923401,
            "answer": "copenhagen",
            "hit": false
          }
        ],
        "set_exclude": [
          "helsinki"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8340702056884766,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to kingston ",
        "b": "kingston",
        "expected answer": [
          "jamaica"
        ],
        "predictions": [
          {
            "score": 0.7708017230033875,
            "answer": "jamaica",
            "hit": true
          },
          {
            "score": 0.7369507551193237,
            "answer": "johnston",
            "hit": false
          },
          {
            "score": 0.7331398129463196,
            "answer": "richmond",
            "hit": false
          },
          {
            "score": 0.7300922274589539,
            "answer": "toronto",
            "hit": false
          },
          {
            "score": 0.7275660037994385,
            "answer": "jacksonville",
            "hit": false
          },
          {
            "score": 0.7273170351982117,
            "answer": "ottawa",
            "hit": false
          }
        ],
        "set_exclude": [
          "kingston"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7708017230033875,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to lisbon ",
        "b": "lisbon",
        "expected answer": [
          "portugal"
        ],
        "predictions": [
          {
            "score": 0.8374372720718384,
            "answer": "portugal",
            "hit": true
          },
          {
            "score": 0.8061766028404236,
            "answer": "madrid",
            "hit": false
          },
          {
            "score": 0.8054313659667969,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7772881984710693,
            "answer": "amsterdam",
            "hit": false
          },
          {
            "score": 0.7759045362472534,
            "answer": "prague",
            "hit": false
          },
          {
            "score": 0.7746055126190186,
            "answer": "budapest",
            "hit": false
          }
        ],
        "set_exclude": [
          "lisbon"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8374372720718384,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to madrid ",
        "b": "madrid",
        "expected answer": [
          "spain"
        ],
        "predictions": [
          {
            "score": 0.8412976264953613,
            "answer": "barcelona",
            "hit": false
          },
          {
            "score": 0.8368453979492188,
            "answer": "spain",
            "hit": true
          },
          {
            "score": 0.8061766028404236,
            "answer": "lisbon",
            "hit": false
          },
          {
            "score": 0.7912978529930115,
            "answer": "valencia",
            "hit": false
          },
          {
            "score": 0.7872614860534668,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7753906846046448,
            "answer": "buenos",
            "hit": false
          }
        ],
        "set_exclude": [
          "madrid"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8368454575538635,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to manila ",
        "b": "manila",
        "expected answer": [
          "philippines"
        ],
        "predictions": [
          {
            "score": 0.8581740260124207,
            "answer": "philippine",
            "hit": false
          },
          {
            "score": 0.8369101881980896,
            "answer": "philippines",
            "hit": true
          },
          {
            "score": 0.8018292784690857,
            "answer": "bangkok",
            "hit": false
          },
          {
            "score": 0.78514164686203,
            "answer": "beijing",
            "hit": false
          },
          {
            "score": 0.7827473878860474,
            "answer": "tokyo",
            "hit": false
          },
          {
            "score": 0.7794260382652283,
            "answer": "seoul",
            "hit": false
          }
        ],
        "set_exclude": [
          "manila"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8369101881980896,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to moscow ",
        "b": "moscow",
        "expected answer": [
          "russia"
        ],
        "predictions": [
          {
            "score": 0.8857493996620178,
            "answer": "russia",
            "hit": true
          },
          {
            "score": 0.8195132613182068,
            "answer": "russians",
            "hit": false
          },
          {
            "score": 0.8192502856254578,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.811344563961029,
            "answer": "putin",
            "hit": false
          },
          {
            "score": 0.803593635559082,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.8034464120864868,
            "answer": "vladimir",
            "hit": false
          }
        ],
        "set_exclude": [
          "moscow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8857494592666626,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to oslo ",
        "b": "oslo",
        "expected answer": [
          "norway"
        ],
        "predictions": [
          {
            "score": 0.8389696478843689,
            "answer": "norway",
            "hit": true
          },
          {
            "score": 0.8199141621589661,
            "answer": "norwegian",
            "hit": false
          },
          {
            "score": 0.8129019141197205,
            "answer": "copenhagen",
            "hit": false
          },
          {
            "score": 0.8075271844863892,
            "answer": "stockholm",
            "hit": false
          },
          {
            "score": 0.7977151274681091,
            "answer": "helsinki",
            "hit": false
          },
          {
            "score": 0.7840392589569092,
            "answer": "amsterdam",
            "hit": false
          }
        ],
        "set_exclude": [
          "oslo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8389696478843689,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to ottawa ",
        "b": "ottawa",
        "expected answer": [
          "canada"
        ],
        "predictions": [
          {
            "score": 0.8441603183746338,
            "answer": "edmonton",
            "hit": false
          },
          {
            "score": 0.8394491672515869,
            "answer": "calgary",
            "hit": false
          },
          {
            "score": 0.831818699836731,
            "answer": "montreal",
            "hit": false
          },
          {
            "score": 0.8305858373641968,
            "answer": "winnipeg",
            "hit": false
          },
          {
            "score": 0.8233042359352112,
            "answer": "vancouver",
            "hit": false
          },
          {
            "score": 0.8224821090698242,
            "answer": "ontario",
            "hit": false
          }
        ],
        "set_exclude": [
          "ottawa"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8018941879272461,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 12
      },
      {
        "question verbose": "What is to paris ",
        "b": "paris",
        "expected answer": [
          "france"
        ],
        "predictions": [
          {
            "score": 0.7906097173690796,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.7856495380401611,
            "answer": "france",
            "hit": true
          },
          {
            "score": 0.7852497100830078,
            "answer": "copenhagen",
            "hit": false
          },
          {
            "score": 0.7731133103370667,
            "answer": "brussels",
            "hit": false
          },
          {
            "score": 0.7677663564682007,
            "answer": "london",
            "hit": false
          },
          {
            "score": 0.7668842077255249,
            "answer": "montreal",
            "hit": false
          }
        ],
        "set_exclude": [
          "paris"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7856495976448059,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to rome ",
        "b": "rome",
        "expected answer": [
          "italy"
        ],
        "predictions": [
          {
            "score": 0.7222837209701538,
            "answer": "roma",
            "hit": false
          },
          {
            "score": 0.6874594688415527,
            "answer": "chrome",
            "hit": false
          },
          {
            "score": 0.6823110580444336,
            "answer": "width",
            "hit": false
          },
          {
            "score": 0.6756867170333862,
            "answer": "monastery",
            "hit": false
          },
          {
            "score": 0.6742417812347412,
            "answer": "android",
            "hit": false
          },
          {
            "score": 0.6742112636566162,
            "answer": "romance",
            "hit": false
          }
        ],
        "set_exclude": [
          "rome"
        ],
        "rank": 55,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.661132350564003,
        "b in neighbourhood of b_prime": 5166,
        "b_prime in neighbourhood of b": 56
      },
      {
        "question verbose": "What is to santiago ",
        "b": "santiago",
        "expected answer": [
          "chile"
        ],
        "predictions": [
          {
            "score": 0.7886883020401001,
            "answer": "chile",
            "hit": true
          },
          {
            "score": 0.7573480606079102,
            "answer": "sanchez",
            "hit": false
          },
          {
            "score": 0.7570022344589233,
            "answer": "madrid",
            "hit": false
          },
          {
            "score": 0.7526906728744507,
            "answer": "francisco",
            "hit": false
          },
          {
            "score": 0.7495864033699036,
            "answer": "jorge",
            "hit": false
          },
          {
            "score": 0.7494515180587769,
            "answer": "buenos",
            "hit": false
          }
        ],
        "set_exclude": [
          "santiago"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7886882722377777,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to stockholm ",
        "b": "stockholm",
        "expected answer": [
          "sweden"
        ],
        "predictions": [
          {
            "score": 0.8470454216003418,
            "answer": "sweden",
            "hit": true
          },
          {
            "score": 0.8275089859962463,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.8128501772880554,
            "answer": "helsinki",
            "hit": false
          },
          {
            "score": 0.8075271844863892,
            "answer": "oslo",
            "hit": false
          },
          {
            "score": 0.8057295083999634,
            "answer": "copenhagen",
            "hit": false
          },
          {
            "score": 0.777802586555481,
            "answer": "norway",
            "hit": false
          }
        ],
        "set_exclude": [
          "stockholm"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8470454216003418,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to tehran ",
        "b": "tehran",
        "expected answer": [
          "iran"
        ],
        "predictions": [
          {
            "score": 0.8948147892951965,
            "answer": "iran",
            "hit": true
          },
          {
            "score": 0.8706576228141785,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.8350793719291687,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.8087645173072815,
            "answer": "damascus",
            "hit": false
          },
          {
            "score": 0.803593635559082,
            "answer": "moscow",
            "hit": false
          },
          {
            "score": 0.7909244894981384,
            "answer": "delhi",
            "hit": false
          }
        ],
        "set_exclude": [
          "tehran"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8948147594928741,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to tokyo ",
        "b": "tokyo",
        "expected answer": [
          "japan"
        ],
        "predictions": [
          {
            "score": 0.8566181659698486,
            "answer": "japan",
            "hit": true
          },
          {
            "score": 0.8268612623214722,
            "answer": "seoul",
            "hit": false
          },
          {
            "score": 0.8129591941833496,
            "answer": "beijing",
            "hit": false
          },
          {
            "score": 0.7907000780105591,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.7881655693054199,
            "answer": "shanghai",
            "hit": false
          },
          {
            "score": 0.7834348678588867,
            "answer": "kyoto",
            "hit": false
          }
        ],
        "set_exclude": [
          "tokyo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8566181659698486,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to vienna ",
        "b": "vienna",
        "expected answer": [
          "austria"
        ],
        "predictions": [
          {
            "score": 0.8293108940124512,
            "answer": "austria",
            "hit": true
          },
          {
            "score": 0.8042668104171753,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.8019543290138245,
            "answer": "budapest",
            "hit": false
          },
          {
            "score": 0.801624596118927,
            "answer": "prague",
            "hit": false
          },
          {
            "score": 0.8014997839927673,
            "answer": "munich",
            "hit": false
          },
          {
            "score": 0.7867202758789062,
            "answer": "berlin",
            "hit": false
          }
        ],
        "set_exclude": [
          "vienna"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8293108940124512,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to warsaw ",
        "b": "warsaw",
        "expected answer": [
          "poland"
        ],
        "predictions": [
          {
            "score": 0.8388829827308655,
            "answer": "poland",
            "hit": true
          },
          {
            "score": 0.8055715560913086,
            "answer": "polish",
            "hit": false
          },
          {
            "score": 0.8018101453781128,
            "answer": "prague",
            "hit": false
          },
          {
            "score": 0.7850003838539124,
            "answer": "budapest",
            "hit": false
          },
          {
            "score": 0.7824844717979431,
            "answer": "berlin",
            "hit": false
          },
          {
            "score": 0.7743977904319763,
            "answer": "poles",
            "hit": false
          }
        ],
        "set_exclude": [
          "warsaw"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8388830423355103,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 21,
      "cnt_questions_total": 28,
      "accuracy": 0.75
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E01 [country - capital].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "3cbd3139-3cfd-47cb-bbf5-d1d9aef795b9",
      "timestamp": "2025-05-17T17:08:16.077852"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to argentina ",
        "b": "argentina",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8836021423339844,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.8684957027435303,
            "answer": "buenos",
            "hit": false
          },
          {
            "score": 0.828382134437561,
            "answer": "chile",
            "hit": false
          },
          {
            "score": 0.8282555341720581,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.8126778602600098,
            "answer": "peru",
            "hit": false
          },
          {
            "score": 0.8010085225105286,
            "answer": "argent",
            "hit": false
          }
        ],
        "set_exclude": [
          "argentina"
        ],
        "rank": 76,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7248241305351257,
        "b in neighbourhood of b_prime": 56,
        "b_prime in neighbourhood of b": 77
      },
      {
        "question verbose": "What is to australia ",
        "b": "australia",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.8649015426635742,
            "answer": "australians",
            "hit": false
          },
          {
            "score": 0.8519105911254883,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.8296359181404114,
            "answer": "sydney",
            "hit": false
          },
          {
            "score": 0.8265113830566406,
            "answer": "melbourne",
            "hit": false
          },
          {
            "score": 0.8204261660575867,
            "answer": "queensland",
            "hit": false
          },
          {
            "score": 0.8159101009368896,
            "answer": "nsw",
            "hit": false
          }
        ],
        "set_exclude": [
          "australia"
        ],
        "rank": 676,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6561190485954285,
        "b in neighbourhood of b_prime": 243,
        "b_prime in neighbourhood of b": 677
      },
      {
        "question verbose": "What is to austria ",
        "b": "austria",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.8649814128875732,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.8499867916107178,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.8293108940124512,
            "answer": "vienna",
            "hit": false
          },
          {
            "score": 0.8205928802490234,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.8190088272094727,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.8166791796684265,
            "answer": "serbia",
            "hit": false
          }
        ],
        "set_exclude": [
          "austria"
        ],
        "rank": 37,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.75033038854599,
        "b in neighbourhood of b_prime": 52,
        "b_prime in neighbourhood of b": 38
      },
      {
        "question verbose": "What is to brazil ",
        "b": "brazil",
        "expected answer": [
          "portuguese"
        ],
        "predictions": [
          {
            "score": 0.8903593420982361,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.8079954385757446,
            "answer": "mexico",
            "hit": false
          },
          {
            "score": 0.7988041639328003,
            "answer": "portuguese",
            "hit": true
          },
          {
            "score": 0.79537433385849,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.7928314805030823,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.786772608757019,
            "answer": "argentina",
            "hit": false
          }
        ],
        "set_exclude": [
          "brazil"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7988041639328003,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to canada ",
        "b": "canada",
        "expected answer": [
          "english",
          "french"
        ],
        "predictions": [
          {
            "score": 0.8515093922615051,
            "answer": "canadian",
            "hit": false
          },
          {
            "score": 0.8441034555435181,
            "answer": "canadians",
            "hit": false
          },
          {
            "score": 0.8167847394943237,
            "answer": "toronto",
            "hit": false
          },
          {
            "score": 0.8108861446380615,
            "answer": "ontario",
            "hit": false
          },
          {
            "score": 0.8096955418586731,
            "answer": "alberta",
            "hit": false
          },
          {
            "score": 0.8019532561302185,
            "answer": "quebec",
            "hit": false
          }
        ],
        "set_exclude": [
          "canada"
        ],
        "rank": 600,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6393251568078995,
        "b in neighbourhood of b_prime": 761,
        "b_prime in neighbourhood of b": 601
      },
      {
        "question verbose": "What is to chile ",
        "b": "chile",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.828382134437561,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.8237299919128418,
            "answer": "peru",
            "hit": false
          },
          {
            "score": 0.8036881685256958,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.7963228821754456,
            "answer": "guatemala",
            "hit": false
          },
          {
            "score": 0.7918449640274048,
            "answer": "colombia",
            "hit": false
          },
          {
            "score": 0.7907297015190125,
            "answer": "spain",
            "hit": false
          }
        ],
        "set_exclude": [
          "chile"
        ],
        "rank": 54,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7307699173688889,
        "b in neighbourhood of b_prime": 47,
        "b_prime in neighbourhood of b": 55
      },
      {
        "question verbose": "What is to colombia ",
        "b": "colombia",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8208493590354919,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.8062700033187866,
            "answer": "peru",
            "hit": false
          },
          {
            "score": 0.8035953044891357,
            "answer": "ecuador",
            "hit": false
          },
          {
            "score": 0.7961509227752686,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.7950204610824585,
            "answer": "mexico",
            "hit": false
          },
          {
            "score": 0.7918449640274048,
            "answer": "chile",
            "hit": false
          }
        ],
        "set_exclude": [
          "colombia"
        ],
        "rank": 92,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7241895198822021,
        "b in neighbourhood of b_prime": 57,
        "b_prime in neighbourhood of b": 93
      },
      {
        "question verbose": "What is to cuba ",
        "b": "cuba",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8616656064987183,
            "answer": "cuban",
            "hit": false
          },
          {
            "score": 0.8329322934150696,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.7950956225395203,
            "answer": "castro",
            "hit": false
          },
          {
            "score": 0.7895448207855225,
            "answer": "haiti",
            "hit": false
          },
          {
            "score": 0.7887782454490662,
            "answer": "colombia",
            "hit": false
          },
          {
            "score": 0.7857930660247803,
            "answer": "jamaica",
            "hit": false
          }
        ],
        "set_exclude": [
          "cuba"
        ],
        "rank": 79,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7175671458244324,
        "b in neighbourhood of b_prime": 71,
        "b_prime in neighbourhood of b": 80
      },
      {
        "question verbose": "What is to cyprus ",
        "b": "cyprus",
        "expected answer": [
          "greek",
          "turkish"
        ],
        "predictions": [
          {
            "score": 0.8135225772857666,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.792755126953125,
            "answer": "bulgaria",
            "hit": false
          },
          {
            "score": 0.7730017900466919,
            "answer": "malta",
            "hit": false
          },
          {
            "score": 0.7729281187057495,
            "answer": "lebanon",
            "hit": false
          },
          {
            "score": 0.7721294164657593,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.7703844904899597,
            "answer": "romania",
            "hit": false
          }
        ],
        "set_exclude": [
          "cyprus"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.750245600938797,
        "b in neighbourhood of b_prime": 19,
        "b_prime in neighbourhood of b": 22
      },
      {
        "question verbose": "What is to egypt ",
        "b": "egypt",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8946446776390076,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.8488540053367615,
            "answer": "cairo",
            "hit": false
          },
          {
            "score": 0.8008842468261719,
            "answer": "libya",
            "hit": false
          },
          {
            "score": 0.7924222946166992,
            "answer": "ethiopia",
            "hit": false
          },
          {
            "score": 0.7877484560012817,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.7841147184371948,
            "answer": "morocco",
            "hit": false
          }
        ],
        "set_exclude": [
          "egypt"
        ],
        "rank": 45,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7435937076807022,
        "b in neighbourhood of b_prime": 41,
        "b_prime in neighbourhood of b": 46
      },
      {
        "question verbose": "What is to guatemala ",
        "b": "guatemala",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8010589480400085,
            "answer": "haiti",
            "hit": false
          },
          {
            "score": 0.7986703515052795,
            "answer": "peru",
            "hit": false
          },
          {
            "score": 0.797419011592865,
            "answer": "mexico",
            "hit": false
          },
          {
            "score": 0.7963228821754456,
            "answer": "chile",
            "hit": false
          },
          {
            "score": 0.7910367250442505,
            "answer": "colombia",
            "hit": false
          },
          {
            "score": 0.7904442548751831,
            "answer": "ecuador",
            "hit": false
          }
        ],
        "set_exclude": [
          "guatemala"
        ],
        "rank": 182,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7011443972587585,
        "b in neighbourhood of b_prime": 103,
        "b_prime in neighbourhood of b": 183
      },
      {
        "question verbose": "What is to iran ",
        "b": "iran",
        "expected answer": [
          "persian"
        ],
        "predictions": [
          {
            "score": 0.8993195295333862,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.8948147296905518,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.8122682571411133,
            "answer": "iraq",
            "hit": false
          },
          {
            "score": 0.793694019317627,
            "answer": "afghanistan",
            "hit": false
          },
          {
            "score": 0.7913100123405457,
            "answer": "pakistan",
            "hit": false
          },
          {
            "score": 0.7906846404075623,
            "answer": "saudi",
            "hit": false
          }
        ],
        "set_exclude": [
          "iran"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7735477089881897,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to iraq ",
        "b": "iraq",
        "expected answer": [
          "arabic",
          "kurdish"
        ],
        "predictions": [
          {
            "score": 0.8776708841323853,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.8487067818641663,
            "answer": "afghanistan",
            "hit": false
          },
          {
            "score": 0.8419049382209778,
            "answer": "baghdad",
            "hit": false
          },
          {
            "score": 0.823326826095581,
            "answer": "saddam",
            "hit": false
          },
          {
            "score": 0.8156936764717102,
            "answer": "libya",
            "hit": false
          },
          {
            "score": 0.8122682571411133,
            "answer": "iran",
            "hit": false
          }
        ],
        "set_exclude": [
          "iraq"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.73866206407547,
        "b in neighbourhood of b_prime": 49,
        "b_prime in neighbourhood of b": 25
      },
      {
        "question verbose": "What is to israel ",
        "b": "israel",
        "expected answer": [
          "hebrew",
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8635137677192688,
            "answer": "israeli",
            "hit": false
          },
          {
            "score": 0.8447834253311157,
            "answer": "israelis",
            "hit": false
          },
          {
            "score": 0.8066912889480591,
            "answer": "jerusalem",
            "hit": false
          },
          {
            "score": 0.8046115636825562,
            "answer": "palestinians",
            "hit": false
          },
          {
            "score": 0.801744282245636,
            "answer": "palestine",
            "hit": false
          },
          {
            "score": 0.7996411323547363,
            "answer": "hebrew",
            "hit": true
          }
        ],
        "set_exclude": [
          "israel"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7996411323547363,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to jordan ",
        "b": "jordan",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.7564245462417603,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.7526878118515015,
            "answer": "daniel",
            "hit": false
          },
          {
            "score": 0.7468676567077637,
            "answer": "christian",
            "hit": false
          },
          {
            "score": 0.7465187311172485,
            "answer": "palestinian",
            "hit": false
          },
          {
            "score": 0.7451624274253845,
            "answer": "aaron",
            "hit": false
          },
          {
            "score": 0.7444835901260376,
            "answer": "joshua",
            "hit": false
          }
        ],
        "set_exclude": [
          "jordan"
        ],
        "rank": 108,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7063494324684143,
        "b in neighbourhood of b_prime": 131,
        "b_prime in neighbourhood of b": 109
      },
      {
        "question verbose": "What is to kuwait ",
        "b": "kuwait",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8113976716995239,
            "answer": "qatar",
            "hit": false
          },
          {
            "score": 0.8100112676620483,
            "answer": "saudi",
            "hit": false
          },
          {
            "score": 0.7918459177017212,
            "answer": "dubai",
            "hit": false
          },
          {
            "score": 0.7868046760559082,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.7859611511230469,
            "answer": "uae",
            "hit": false
          },
          {
            "score": 0.7857213020324707,
            "answer": "lebanon",
            "hit": false
          }
        ],
        "set_exclude": [
          "kuwait"
        ],
        "rank": 35,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7410923838615417,
        "b in neighbourhood of b_prime": 43,
        "b_prime in neighbourhood of b": 36
      },
      {
        "question verbose": "What is to palestine ",
        "b": "palestine",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8476444482803345,
            "answer": "palestinian",
            "hit": false
          },
          {
            "score": 0.8464946746826172,
            "answer": "palestinians",
            "hit": false
          },
          {
            "score": 0.8169741034507751,
            "answer": "jerusalem",
            "hit": false
          },
          {
            "score": 0.801744282245636,
            "answer": "israel",
            "hit": false
          },
          {
            "score": 0.7905744910240173,
            "answer": "gaza",
            "hit": false
          },
          {
            "score": 0.7840405106544495,
            "answer": "lebanon",
            "hit": false
          }
        ],
        "set_exclude": [
          "palestine"
        ],
        "rank": 26,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7442068308591843,
        "b in neighbourhood of b_prime": 40,
        "b_prime in neighbourhood of b": 27
      },
      {
        "question verbose": "What is to peru ",
        "b": "peru",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8237299919128418,
            "answer": "chile",
            "hit": false
          },
          {
            "score": 0.8127356171607971,
            "answer": "ecuador",
            "hit": false
          },
          {
            "score": 0.812677800655365,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.8062700033187866,
            "answer": "colombia",
            "hit": false
          },
          {
            "score": 0.8040168881416321,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.7986703515052795,
            "answer": "guatemala",
            "hit": false
          }
        ],
        "set_exclude": [
          "peru"
        ],
        "rank": 75,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7236255407333374,
        "b in neighbourhood of b_prime": 58,
        "b_prime in neighbourhood of b": 76
      },
      {
        "question verbose": "What is to switzerland ",
        "b": "switzerland",
        "expected answer": [
          "german",
          "french",
          "italian"
        ],
        "predictions": [
          {
            "score": 0.861019492149353,
            "answer": "swiss",
            "hit": false
          },
          {
            "score": 0.8205928802490234,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.8152438402175903,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.8122565746307373,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.799558699131012,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.7988284230232239,
            "answer": "finland",
            "hit": false
          }
        ],
        "set_exclude": [
          "switzerland"
        ],
        "rank": 71,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7283170521259308,
        "b in neighbourhood of b_prime": 100,
        "b_prime in neighbourhood of b": 72
      },
      {
        "question verbose": "What is to syria ",
        "b": "syria",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8680657744407654,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.8256634473800659,
            "answer": "damascus",
            "hit": false
          },
          {
            "score": 0.8140543103218079,
            "answer": "libya",
            "hit": false
          },
          {
            "score": 0.8140271306037903,
            "answer": "russia",
            "hit": false
          },
          {
            "score": 0.7983345985412598,
            "answer": "iraq",
            "hit": false
          },
          {
            "score": 0.7932295799255371,
            "answer": "gaza",
            "hit": false
          }
        ],
        "set_exclude": [
          "syria"
        ],
        "rank": 86,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7394119501113892,
        "b in neighbourhood of b_prime": 46,
        "b_prime in neighbourhood of b": 87
      },
      {
        "question verbose": "What is to taiwan ",
        "b": "taiwan",
        "expected answer": [
          "chinese"
        ],
        "predictions": [
          {
            "score": 0.8752292394638062,
            "answer": "tai",
            "hit": false
          },
          {
            "score": 0.8032339811325073,
            "answer": "china",
            "hit": false
          },
          {
            "score": 0.7977540493011475,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.7929623126983643,
            "answer": "singapore",
            "hit": false
          },
          {
            "score": 0.7903413772583008,
            "answer": "japan",
            "hit": false
          },
          {
            "score": 0.7864993810653687,
            "answer": "korea",
            "hit": false
          }
        ],
        "set_exclude": [
          "taiwan"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7651342451572418,
        "b in neighbourhood of b_prime": 16,
        "b_prime in neighbourhood of b": 15
      },
      {
        "question verbose": "What is to usa ",
        "b": "usa",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.693998396396637,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.6876698732376099,
            "answer": "peru",
            "hit": false
          },
          {
            "score": 0.6875920295715332,
            "answer": "russia",
            "hit": false
          },
          {
            "score": 0.6837773323059082,
            "answer": "uno",
            "hit": false
          },
          {
            "score": 0.6822586059570312,
            "answer": "international",
            "hit": false
          },
          {
            "score": 0.6815795302391052,
            "answer": "reuters",
            "hit": false
          }
        ],
        "set_exclude": [
          "usa"
        ],
        "rank": 11781,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6034304276108742,
        "b in neighbourhood of b_prime": 7645,
        "b_prime in neighbourhood of b": 11782
      },
      {
        "question verbose": "What is to venezuela ",
        "b": "venezuela",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8329322338104248,
            "answer": "cuba",
            "hit": false
          },
          {
            "score": 0.8282554745674133,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.8208492994308472,
            "answer": "colombia",
            "hit": false
          },
          {
            "score": 0.8040168881416321,
            "answer": "peru",
            "hit": false
          },
          {
            "score": 0.8036881685256958,
            "answer": "chile",
            "hit": false
          },
          {
            "score": 0.7993825078010559,
            "answer": "ecuador",
            "hit": false
          }
        ],
        "set_exclude": [
          "venezuela"
        ],
        "rank": 108,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7205632030963898,
        "b in neighbourhood of b_prime": 66,
        "b_prime in neighbourhood of b": 109
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 23,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E02 [country - language].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "e961d333-dbd7-406e-8583-6c7ffad52f07",
      "timestamp": "2025-05-17T17:08:16.326402"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bath ",
        "b": "bath",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.8708980083465576,
            "answer": "baths",
            "hit": false
          },
          {
            "score": 0.7937822341918945,
            "answer": "bathing",
            "hit": false
          },
          {
            "score": 0.7871220707893372,
            "answer": "shower",
            "hit": false
          },
          {
            "score": 0.7842238545417786,
            "answer": "bathroom",
            "hit": false
          },
          {
            "score": 0.752851128578186,
            "answer": "bathrooms",
            "hit": false
          },
          {
            "score": 0.7385080456733704,
            "answer": "tub",
            "hit": false
          }
        ],
        "set_exclude": [
          "bath"
        ],
        "rank": 1725,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6511923372745514,
        "b in neighbourhood of b_prime": 4212,
        "b_prime in neighbourhood of b": 1726
      },
      {
        "question verbose": "What is to bradford ",
        "b": "bradford",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8058339953422546,
            "answer": "brad",
            "hit": false
          },
          {
            "score": 0.7786756753921509,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.765152096748352,
            "answer": "sheffield",
            "hit": false
          },
          {
            "score": 0.7493097186088562,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7475794553756714,
            "answer": "birmingham",
            "hit": false
          },
          {
            "score": 0.7417502403259277,
            "answer": "brighton",
            "hit": false
          }
        ],
        "set_exclude": [
          "bradford"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7493097335100174,
        "b in neighbourhood of b_prime": 22,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to brighton ",
        "b": "brighton",
        "expected answer": [
          "sussex"
        ],
        "predictions": [
          {
            "score": 0.7955336570739746,
            "answer": "sussex",
            "hit": true
          },
          {
            "score": 0.7821865081787109,
            "answer": "bristol",
            "hit": false
          },
          {
            "score": 0.7811605930328369,
            "answer": "liverpool",
            "hit": false
          },
          {
            "score": 0.7706457376480103,
            "answer": "leicester",
            "hit": false
          },
          {
            "score": 0.7656738758087158,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.76567143201828,
            "answer": "nottingham",
            "hit": false
          }
        ],
        "set_exclude": [
          "brighton"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7955335974693298,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to hull ",
        "b": "hull",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.7559658288955688,
            "answer": "chassis",
            "hit": false
          },
          {
            "score": 0.7453742623329163,
            "answer": "vessel",
            "hit": false
          },
          {
            "score": 0.7359437942504883,
            "answer": "ship",
            "hit": false
          },
          {
            "score": 0.7300958633422852,
            "answer": "boat",
            "hit": false
          },
          {
            "score": 0.7283998727798462,
            "answer": "cockpit",
            "hit": false
          },
          {
            "score": 0.7259086966514587,
            "answer": "yacht",
            "hit": false
          }
        ],
        "set_exclude": [
          "hull"
        ],
        "rank": 643,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6680411994457245,
        "b in neighbourhood of b_prime": 1407,
        "b_prime in neighbourhood of b": 644
      },
      {
        "question verbose": "What is to leeds ",
        "b": "leeds",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8202542066574097,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.8191214799880981,
            "answer": "sheffield",
            "hit": false
          },
          {
            "score": 0.809441328048706,
            "answer": "newcastle",
            "hit": false
          },
          {
            "score": 0.8055804371833801,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.8028348684310913,
            "answer": "liverpool",
            "hit": false
          },
          {
            "score": 0.784806489944458,
            "answer": "leicester",
            "hit": false
          }
        ],
        "set_exclude": [
          "leeds"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8202542066574097,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to plymouth ",
        "b": "plymouth",
        "expected answer": [
          "devon"
        ],
        "predictions": [
          {
            "score": 0.7681432366371155,
            "answer": "worcester",
            "hit": false
          },
          {
            "score": 0.7583126425743103,
            "answer": "bristol",
            "hit": false
          },
          {
            "score": 0.7578486800193787,
            "answer": "devon",
            "hit": true
          },
          {
            "score": 0.7528460621833801,
            "answer": "cornwall",
            "hit": false
          },
          {
            "score": 0.751687228679657,
            "answer": "cambridge",
            "hit": false
          },
          {
            "score": 0.748234748840332,
            "answer": "brighton",
            "hit": false
          }
        ],
        "set_exclude": [
          "plymouth"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7578486800193787,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to sheffield ",
        "b": "sheffield",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8235780596733093,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.8191214799880981,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.7863749861717224,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7786974906921387,
            "answer": "glasgow",
            "hit": false
          },
          {
            "score": 0.7780275344848633,
            "answer": "manchester",
            "hit": false
          },
          {
            "score": 0.7777374982833862,
            "answer": "birmingham",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheffield"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7863749861717224,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to wells ",
        "b": "wells",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.7743921875953674,
            "answer": "reservoirs",
            "hit": false
          },
          {
            "score": 0.7708516120910645,
            "answer": "groundwater",
            "hit": false
          },
          {
            "score": 0.7568420171737671,
            "answer": "drilling",
            "hit": false
          },
          {
            "score": 0.7454158067703247,
            "answer": "reactors",
            "hit": false
          },
          {
            "score": 0.7449507713317871,
            "answer": "earthquakes",
            "hit": false
          },
          {
            "score": 0.7419369220733643,
            "answer": "pumps",
            "hit": false
          }
        ],
        "set_exclude": [
          "wells"
        ],
        "rank": 3060,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6552236676216125,
        "b in neighbourhood of b_prime": 3289,
        "b_prime in neighbourhood of b": 3061
      },
      {
        "question verbose": "What is to york ",
        "b": "york",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.7849064469337463,
            "answer": "washington",
            "hit": false
          },
          {
            "score": 0.7713794708251953,
            "answer": "yorker",
            "hit": false
          },
          {
            "score": 0.7396482825279236,
            "answer": "toronto",
            "hit": false
          },
          {
            "score": 0.7392697930335999,
            "answer": "united",
            "hit": false
          },
          {
            "score": 0.7387502193450928,
            "answer": "orleans",
            "hit": false
          },
          {
            "score": 0.738221287727356,
            "answer": "yankees",
            "hit": false
          }
        ],
        "set_exclude": [
          "york"
        ],
        "rank": 66,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7046191245317459,
        "b in neighbourhood of b_prime": 147,
        "b_prime in neighbourhood of b": 67
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 9,
      "accuracy": 0.2222222222222222
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E03 [UK_city - county].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "889cb2fa-58bc-4ad1-8d8d-cf5fa88f88b3",
      "timestamp": "2025-05-17T17:08:16.537076"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.8385425806045532,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.8361717462539673,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.7894809246063232,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7805569171905518,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.770418643951416,
            "answer": "augustine",
            "hit": false
          },
          {
            "score": 0.770106315612793,
            "answer": "philosopher",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7353754043579102,
        "b in neighbourhood of b_prime": 30,
        "b_prime in neighbourhood of b": 26
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "roman"
        ],
        "predictions": [
          {
            "score": 0.7678673267364502,
            "answer": "augustus",
            "hit": false
          },
          {
            "score": 0.7322012782096863,
            "answer": "napoleon",
            "hit": false
          },
          {
            "score": 0.7261096239089966,
            "answer": "roman",
            "hit": true
          },
          {
            "score": 0.7243082523345947,
            "answer": "julius",
            "hit": false
          },
          {
            "score": 0.7160404920578003,
            "answer": "pasta",
            "hit": false
          },
          {
            "score": 0.7147572040557861,
            "answer": "romans",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.726109653711319,
        "b in neighbourhood of b_prime": 10,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to darwin ",
        "b": "darwin",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7928337454795837,
            "answer": "dar",
            "hit": false
          },
          {
            "score": 0.7690067887306213,
            "answer": "evolutionary",
            "hit": false
          },
          {
            "score": 0.7351329326629639,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7303743958473206,
            "answer": "biology",
            "hit": false
          },
          {
            "score": 0.7281696796417236,
            "answer": "biodiversity",
            "hit": false
          },
          {
            "score": 0.7269657850265503,
            "answer": "evolution",
            "hit": false
          }
        ],
        "set_exclude": [
          "darwin"
        ],
        "rank": 2161,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.5988448560237885,
        "b in neighbourhood of b_prime": 9086,
        "b_prime in neighbourhood of b": 2162
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7406965494155884,
            "answer": "einstein",
            "hit": false
          },
          {
            "score": 0.7156751155853271,
            "answer": "emerson",
            "hit": false
          },
          {
            "score": 0.7139480113983154,
            "answer": "jefferson",
            "hit": false
          },
          {
            "score": 0.7139298319816589,
            "answer": "ibm",
            "hit": false
          },
          {
            "score": 0.7126404047012329,
            "answer": "princeton",
            "hit": false
          },
          {
            "score": 0.7074158191680908,
            "answer": "tesla",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 442,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6642341911792755,
        "b in neighbourhood of b_prime": 1581,
        "b_prime in neighbourhood of b": 443
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "jewish",
          "german",
          "american"
        ],
        "predictions": [
          {
            "score": 0.7898781299591064,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7773139476776123,
            "answer": "relativity",
            "hit": false
          },
          {
            "score": 0.7659306526184082,
            "answer": "freud",
            "hit": false
          },
          {
            "score": 0.7604999542236328,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7574714422225952,
            "answer": "gravitational",
            "hit": false
          },
          {
            "score": 0.7569165825843811,
            "answer": "hitler",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 255,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6912362575531006,
        "b in neighbourhood of b_prime": 179,
        "b_prime in neighbourhood of b": 256
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "german",
          "austrian"
        ],
        "predictions": [
          {
            "score": 0.8786401152610779,
            "answer": "nazi",
            "hit": false
          },
          {
            "score": 0.8154264688491821,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7922099828720093,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.782085657119751,
            "answer": "holocaust",
            "hit": false
          },
          {
            "score": 0.7804054021835327,
            "answer": "putin",
            "hit": false
          },
          {
            "score": 0.7801454663276672,
            "answer": "saddam",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7623348832130432,
        "b in neighbourhood of b_prime": 38,
        "b_prime in neighbourhood of b": 12
      },
      {
        "question verbose": "What is to homer ",
        "b": "homer",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.7703739404678345,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.7598679065704346,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7502076625823975,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.7489496469497681,
            "answer": "lisa",
            "hit": false
          },
          {
            "score": 0.7479801177978516,
            "answer": "springfield",
            "hit": false
          },
          {
            "score": 0.7297146320343018,
            "answer": "troy",
            "hit": false
          }
        ],
        "set_exclude": [
          "homer"
        ],
        "rank": 35,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7088912129402161,
        "b in neighbourhood of b_prime": 75,
        "b_prime in neighbourhood of b": 36
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7560818791389465,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7515522241592407,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7486422061920166,
            "answer": "locke",
            "hit": false
          },
          {
            "score": 0.7425800561904907,
            "answer": "metaphysical",
            "hit": false
          },
          {
            "score": 0.7425243854522705,
            "answer": "kant",
            "hit": false
          },
          {
            "score": 0.7403820157051086,
            "answer": "socrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 800,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6606850028038025,
        "b in neighbourhood of b_prime": 984,
        "b_prime in neighbourhood of b": 801
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7539404630661011,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7530889511108398,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7486542463302612,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.7425243854522705,
            "answer": "hume",
            "hit": false
          },
          {
            "score": 0.7342600226402283,
            "answer": "freud",
            "hit": false
          },
          {
            "score": 0.7257555723190308,
            "answer": "metaphysical",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 262,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6727610379457474,
        "b in neighbourhood of b_prime": 1655,
        "b_prime in neighbourhood of b": 263
      },
      {
        "question verbose": "What is to kepler ",
        "b": "kepler",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7569212913513184,
            "answer": "maxwell",
            "hit": false
          },
          {
            "score": 0.7403169870376587,
            "answer": "telescopes",
            "hit": false
          },
          {
            "score": 0.7350208759307861,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7301878929138184,
            "answer": "astronomy",
            "hit": false
          },
          {
            "score": 0.7295377850532532,
            "answer": "jupiter",
            "hit": false
          },
          {
            "score": 0.7294486165046692,
            "answer": "planets",
            "hit": false
          }
        ],
        "set_exclude": [
          "kepler"
        ],
        "rank": 3175,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6501009464263916,
        "b in neighbourhood of b_prime": 6462,
        "b_prime in neighbourhood of b": 3176
      },
      {
        "question verbose": "What is to lenin ",
        "b": "lenin",
        "expected answer": [
          "soviet",
          "russian"
        ],
        "predictions": [
          {
            "score": 0.826948881149292,
            "answer": "marx",
            "hit": false
          },
          {
            "score": 0.7989715337753296,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7930930852890015,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.7764867544174194,
            "answer": "mao",
            "hit": false
          },
          {
            "score": 0.7626569867134094,
            "answer": "moscow",
            "hit": false
          },
          {
            "score": 0.7602167725563049,
            "answer": "communist",
            "hit": false
          }
        ],
        "set_exclude": [
          "lenin"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.756867915391922,
        "b in neighbourhood of b_prime": 15,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7725850939750671,
            "answer": "nebraska",
            "hit": false
          },
          {
            "score": 0.7484959363937378,
            "answer": "jefferson",
            "hit": false
          },
          {
            "score": 0.7464605569839478,
            "answer": "omaha",
            "hit": false
          },
          {
            "score": 0.7395708560943604,
            "answer": "nixon",
            "hit": false
          },
          {
            "score": 0.7365481853485107,
            "answer": "roosevelt",
            "hit": false
          },
          {
            "score": 0.7327057719230652,
            "answer": "springfield",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 280,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.674335777759552,
        "b in neighbourhood of b_prime": 813,
        "b_prime in neighbourhood of b": 281
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7486422061920166,
            "answer": "hume",
            "hit": false
          },
          {
            "score": 0.7314201593399048,
            "answer": "augustine",
            "hit": false
          },
          {
            "score": 0.7257108688354492,
            "answer": "newton",
            "hit": false
          },
          {
            "score": 0.7200766205787659,
            "answer": "neill",
            "hit": false
          },
          {
            "score": 0.71907639503479,
            "answer": "burke",
            "hit": false
          },
          {
            "score": 0.7173545360565186,
            "answer": "metaphysical",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 1342,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6183064579963684,
        "b in neighbourhood of b_prime": 3464,
        "b_prime in neighbourhood of b": 1343
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.8704439401626587,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.826948881149292,
            "answer": "lenin",
            "hit": false
          },
          {
            "score": 0.7991988062858582,
            "answer": "mao",
            "hit": false
          },
          {
            "score": 0.7853160500526428,
            "answer": "bourgeois",
            "hit": false
          },
          {
            "score": 0.7795201539993286,
            "answer": "communist",
            "hit": false
          },
          {
            "score": 0.7727787494659424,
            "answer": "capitalist",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 68,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7169898450374603,
        "b in neighbourhood of b_prime": 160,
        "b_prime in neighbourhood of b": 69
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7569212913513184,
            "answer": "kepler",
            "hit": false
          },
          {
            "score": 0.7180542945861816,
            "answer": "matthew",
            "hit": false
          },
          {
            "score": 0.7166764140129089,
            "answer": "richardson",
            "hit": false
          },
          {
            "score": 0.7166528701782227,
            "answer": "leonard",
            "hit": false
          },
          {
            "score": 0.7154921293258667,
            "answer": "jeffrey",
            "hit": false
          },
          {
            "score": 0.7101675271987915,
            "answer": "newton",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 8838,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.608859620988369,
        "b in neighbourhood of b_prime": 12031,
        "b_prime in neighbourhood of b": 8839
      },
      {
        "question verbose": "What is to newton ",
        "b": "newton",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7522493004798889,
            "answer": "einstein",
            "hit": false
          },
          {
            "score": 0.7257108688354492,
            "answer": "locke",
            "hit": false
          },
          {
            "score": 0.7208306789398193,
            "answer": "kepler",
            "hit": false
          },
          {
            "score": 0.7203186750411987,
            "answer": "newman",
            "hit": false
          },
          {
            "score": 0.7201589345932007,
            "answer": "panthers",
            "hit": false
          },
          {
            "score": 0.7170887589454651,
            "answer": "cambridge",
            "hit": false
          }
        ],
        "set_exclude": [
          "newton"
        ],
        "rank": 2783,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6173366233706474,
        "b in neighbourhood of b_prime": 3686,
        "b_prime in neighbourhood of b": 2784
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.8451951742172241,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.8385425806045532,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.781460165977478,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7760894298553467,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7706767320632935,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7703739404678345,
            "answer": "homer",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7280557453632355,
        "b in neighbourhood of b_prime": 41,
        "b_prime in neighbourhood of b": 20
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7875639200210571,
            "answer": "roosevelt",
            "hit": false
          },
          {
            "score": 0.7620968818664551,
            "answer": "reagan",
            "hit": false
          },
          {
            "score": 0.7616780996322632,
            "answer": "nixon",
            "hit": false
          },
          {
            "score": 0.759651243686676,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7518314719200134,
            "answer": "theodore",
            "hit": false
          },
          {
            "score": 0.7428805828094482,
            "answer": "churchill",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 488,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6756532788276672,
        "b in neighbourhood of b_prime": 753,
        "b_prime in neighbourhood of b": 489
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7394653558731079,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7351301908493042,
            "answer": "weber",
            "hit": false
          },
          {
            "score": 0.7320283055305481,
            "answer": "fischer",
            "hit": false
          },
          {
            "score": 0.7293971180915833,
            "answer": "schneider",
            "hit": false
          },
          {
            "score": 0.7245344519615173,
            "answer": "walsh",
            "hit": false
          },
          {
            "score": 0.7196964025497437,
            "answer": "fritz",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 73,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6889944672584534,
        "b in neighbourhood of b_prime": 546,
        "b_prime in neighbourhood of b": 74
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 19,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E04 [name - nationality].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "05893ef1-1214-4bdd-a41c-d55fdf3ff6db",
      "timestamp": "2025-05-17T17:08:16.624799"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8385425806045532,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.8361717462539673,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.7894809246063232,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7805569171905518,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.770418643951416,
            "answer": "augustine",
            "hit": false
          },
          {
            "score": 0.770106315612793,
            "answer": "philosopher",
            "hit": true
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7701063454151154,
        "b in neighbourhood of b_prime": 22,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "emperor",
          "commander",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.7678673267364502,
            "answer": "augustus",
            "hit": false
          },
          {
            "score": 0.7322012782096863,
            "answer": "napoleon",
            "hit": false
          },
          {
            "score": 0.7261096239089966,
            "answer": "roman",
            "hit": false
          },
          {
            "score": 0.7243082523345947,
            "answer": "julius",
            "hit": false
          },
          {
            "score": 0.7160404920578003,
            "answer": "pasta",
            "hit": false
          },
          {
            "score": 0.7147572040557861,
            "answer": "romans",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6987225711345673,
        "b in neighbourhood of b_prime": 43,
        "b_prime in neighbourhood of b": 22
      },
      {
        "question verbose": "What is to columbus ",
        "b": "columbus",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.7745965719223022,
            "answer": "cincinnati",
            "hit": false
          },
          {
            "score": 0.7711762189865112,
            "answer": "indianapolis",
            "hit": false
          },
          {
            "score": 0.7708423733711243,
            "answer": "cleveland",
            "hit": false
          },
          {
            "score": 0.7567208409309387,
            "answer": "nashville",
            "hit": false
          },
          {
            "score": 0.7518717050552368,
            "answer": "philadelphia",
            "hit": false
          },
          {
            "score": 0.751220166683197,
            "answer": "portland",
            "hit": false
          }
        ],
        "set_exclude": [
          "columbus"
        ],
        "rank": 2875,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.638878732919693,
        "b in neighbourhood of b_prime": 3845,
        "b_prime in neighbourhood of b": 2876
      },
      {
        "question verbose": "What is to dante ",
        "b": "dante",
        "expected answer": [
          "poet"
        ],
        "predictions": [
          {
            "score": 0.7405799031257629,
            "answer": "augustine",
            "hit": false
          },
          {
            "score": 0.73679119348526,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7365332841873169,
            "answer": "bruno",
            "hit": false
          },
          {
            "score": 0.7347142696380615,
            "answer": "giovanni",
            "hit": false
          },
          {
            "score": 0.7335848808288574,
            "answer": "theological",
            "hit": false
          },
          {
            "score": 0.733012855052948,
            "answer": "antonio",
            "hit": false
          }
        ],
        "set_exclude": [
          "dante"
        ],
        "rank": 44,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7101398259401321,
        "b in neighbourhood of b_prime": 201,
        "b_prime in neighbourhood of b": 45
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "inventor",
          "businessman"
        ],
        "predictions": [
          {
            "score": 0.7406965494155884,
            "answer": "einstein",
            "hit": false
          },
          {
            "score": 0.7156751155853271,
            "answer": "emerson",
            "hit": false
          },
          {
            "score": 0.7139480113983154,
            "answer": "jefferson",
            "hit": false
          },
          {
            "score": 0.7139298319816589,
            "answer": "ibm",
            "hit": false
          },
          {
            "score": 0.7126404047012329,
            "answer": "princeton",
            "hit": false
          },
          {
            "score": 0.7074158191680908,
            "answer": "tesla",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6996137350797653,
        "b in neighbourhood of b_prime": 153,
        "b_prime in neighbourhood of b": 14
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.7898781299591064,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.7773139476776123,
            "answer": "relativity",
            "hit": false
          },
          {
            "score": 0.7659306526184082,
            "answer": "freud",
            "hit": false
          },
          {
            "score": 0.7604999542236328,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7574714422225952,
            "answer": "gravitational",
            "hit": false
          },
          {
            "score": 0.7569165825843811,
            "answer": "hitler",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7898781299591064,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "dictator",
          "politician",
          "nazi"
        ],
        "predictions": [
          {
            "score": 0.8786401152610779,
            "answer": "nazi",
            "hit": true
          },
          {
            "score": 0.8154264688491821,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7922099828720093,
            "answer": "nazis",
            "hit": false
          },
          {
            "score": 0.782085657119751,
            "answer": "holocaust",
            "hit": false
          },
          {
            "score": 0.7804054021835327,
            "answer": "putin",
            "hit": false
          },
          {
            "score": 0.7801454663276672,
            "answer": "saddam",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7621779441833496,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "philosopher",
          "politician"
        ],
        "predictions": [
          {
            "score": 0.7560818791389465,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7515522241592407,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7486422061920166,
            "answer": "locke",
            "hit": false
          },
          {
            "score": 0.7425800561904907,
            "answer": "metaphysical",
            "hit": false
          },
          {
            "score": 0.7425243854522705,
            "answer": "kant",
            "hit": false
          },
          {
            "score": 0.7403820157051086,
            "answer": "socrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7168763875961304,
        "b in neighbourhood of b_prime": 194,
        "b_prime in neighbourhood of b": 15
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7539404630661011,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7530889511108398,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7486542463302612,
            "answer": "plato",
            "hit": false
          },
          {
            "score": 0.7425243854522705,
            "answer": "hume",
            "hit": false
          },
          {
            "score": 0.7342600226402283,
            "answer": "freud",
            "hit": false
          },
          {
            "score": 0.7257555723190308,
            "answer": "metaphysical",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 26,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7014982402324677,
        "b in neighbourhood of b_prime": 496,
        "b_prime in neighbourhood of b": 27
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.7725850939750671,
            "answer": "nebraska",
            "hit": false
          },
          {
            "score": 0.7484959363937378,
            "answer": "jefferson",
            "hit": false
          },
          {
            "score": 0.7464605569839478,
            "answer": "omaha",
            "hit": false
          },
          {
            "score": 0.7395708560943604,
            "answer": "nixon",
            "hit": false
          },
          {
            "score": 0.7365481853485107,
            "answer": "roosevelt",
            "hit": false
          },
          {
            "score": 0.7327057719230652,
            "answer": "springfield",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 363,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6708316802978516,
        "b in neighbourhood of b_prime": 313,
        "b_prime in neighbourhood of b": 364
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7486422061920166,
            "answer": "hume",
            "hit": false
          },
          {
            "score": 0.7314201593399048,
            "answer": "augustine",
            "hit": false
          },
          {
            "score": 0.7257108688354492,
            "answer": "newton",
            "hit": false
          },
          {
            "score": 0.7200766205787659,
            "answer": "neill",
            "hit": false
          },
          {
            "score": 0.71907639503479,
            "answer": "burke",
            "hit": false
          },
          {
            "score": 0.7173545360565186,
            "answer": "metaphysical",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 161,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6838835775852203,
        "b in neighbourhood of b_prime": 1462,
        "b_prime in neighbourhood of b": 162
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "philosopher",
          "communist"
        ],
        "predictions": [
          {
            "score": 0.8704439401626587,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.826948881149292,
            "answer": "lenin",
            "hit": false
          },
          {
            "score": 0.7991988062858582,
            "answer": "mao",
            "hit": false
          },
          {
            "score": 0.7853160500526428,
            "answer": "bourgeois",
            "hit": false
          },
          {
            "score": 0.7795201539993286,
            "answer": "communist",
            "hit": true
          },
          {
            "score": 0.7727787494659424,
            "answer": "capitalist",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.705318808555603,
        "b in neighbourhood of b_prime": 385,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.7569212913513184,
            "answer": "kepler",
            "hit": false
          },
          {
            "score": 0.7180542945861816,
            "answer": "matthew",
            "hit": false
          },
          {
            "score": 0.7166764140129089,
            "answer": "richardson",
            "hit": false
          },
          {
            "score": 0.7166528701782227,
            "answer": "leonard",
            "hit": false
          },
          {
            "score": 0.7154921293258667,
            "answer": "jeffrey",
            "hit": false
          },
          {
            "score": 0.7101675271987915,
            "answer": "newton",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 93,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6839728206396103,
        "b in neighbourhood of b_prime": 1419,
        "b_prime in neighbourhood of b": 94
      },
      {
        "question verbose": "What is to moses ",
        "b": "moses",
        "expected answer": [
          "prophet",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.7525017261505127,
            "answer": "jesus",
            "hit": false
          },
          {
            "score": 0.7524542212486267,
            "answer": "abraham",
            "hit": false
          },
          {
            "score": 0.7489686012268066,
            "answer": "noah",
            "hit": false
          },
          {
            "score": 0.7466239333152771,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.743487536907196,
            "answer": "rabbi",
            "hit": false
          },
          {
            "score": 0.7428362369537354,
            "answer": "isaiah",
            "hit": false
          }
        ],
        "set_exclude": [
          "moses"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7357734441757202,
        "b in neighbourhood of b_prime": 19,
        "b_prime in neighbourhood of b": 14
      },
      {
        "question verbose": "What is to napoleon ",
        "b": "napoleon",
        "expected answer": [
          "emperor",
          "leader",
          "politician",
          "commander"
        ],
        "predictions": [
          {
            "score": 0.7734971046447754,
            "answer": "hitler",
            "hit": false
          },
          {
            "score": 0.7499479651451111,
            "answer": "augustus",
            "hit": false
          },
          {
            "score": 0.7493312954902649,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7472968101501465,
            "answer": "emperor",
            "hit": true
          },
          {
            "score": 0.7434697151184082,
            "answer": "ottoman",
            "hit": false
          },
          {
            "score": 0.7397622466087341,
            "answer": "aristotle",
            "hit": false
          }
        ],
        "set_exclude": [
          "napoleon"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7472967654466629,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8451951742172241,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.8385425806045532,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.781460165977478,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7760894298553467,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7706767320632935,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7703739404678345,
            "answer": "homer",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7706767320632935,
        "b in neighbourhood of b_prime": 21,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.7875639200210571,
            "answer": "roosevelt",
            "hit": false
          },
          {
            "score": 0.7620968818664551,
            "answer": "reagan",
            "hit": false
          },
          {
            "score": 0.7616780996322632,
            "answer": "nixon",
            "hit": false
          },
          {
            "score": 0.759651243686676,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.7518314719200134,
            "answer": "theodore",
            "hit": false
          },
          {
            "score": 0.7428805828094482,
            "answer": "churchill",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 184,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6864784061908722,
        "b in neighbourhood of b_prime": 133,
        "b_prime in neighbourhood of b": 185
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.7394653558731079,
            "answer": "nietzsche",
            "hit": false
          },
          {
            "score": 0.7351301908493042,
            "answer": "weber",
            "hit": false
          },
          {
            "score": 0.7320283055305481,
            "answer": "fischer",
            "hit": false
          },
          {
            "score": 0.7293971180915833,
            "answer": "schneider",
            "hit": false
          },
          {
            "score": 0.7245344519615173,
            "answer": "walsh",
            "hit": false
          },
          {
            "score": 0.7196964025497437,
            "answer": "fritz",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7148966193199158,
        "b in neighbourhood of b_prime": 85,
        "b_prime in neighbourhood of b": 9
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 18,
      "accuracy": 0.1111111111111111
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E05 [name - occupation].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "d906e2c6-8bff-41de-9070-e11b3b0f94bc",
      "timestamp": "2025-05-17T17:08:16.820235"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "baby",
          "infant"
        ],
        "predictions": [
          {
            "score": 0.7726758718490601,
            "answer": "monkey",
            "hit": false
          },
          {
            "score": 0.7532568573951721,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7326546311378479,
            "answer": "animal",
            "hit": false
          },
          {
            "score": 0.7304034233093262,
            "answer": "negro",
            "hit": false
          },
          {
            "score": 0.7223746180534363,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.7212953567504883,
            "answer": "beasts",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 165,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6596762537956238,
        "b in neighbourhood of b_prime": 3200,
        "b_prime in neighbourhood of b": 166
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.7465057373046875,
            "answer": "borne",
            "hit": false
          },
          {
            "score": 0.7330659627914429,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.7189512848854065,
            "answer": "endure",
            "hit": false
          },
          {
            "score": 0.715822160243988,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.6983940601348877,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.6951324939727783,
            "answer": "suffer",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 2952,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6221700981259346,
        "b in neighbourhood of b_prime": 4782,
        "b_prime in neighbourhood of b": 2953
      },
      {
        "question verbose": "What is to buffalo ",
        "b": "buffalo",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7553845047950745,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7502496242523193,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.7499016523361206,
            "answer": "deer",
            "hit": false
          },
          {
            "score": 0.74576735496521,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7440637350082397,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7435911893844604,
            "answer": "tiger",
            "hit": false
          }
        ],
        "set_exclude": [
          "buffalo"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7234457731246948,
        "b in neighbourhood of b_prime": 15,
        "b_prime in neighbourhood of b": 21
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.8993592262268066,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7780378460884094,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.7580479979515076,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.7507907748222351,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.7356374263763428,
            "answer": "buffalo",
            "hit": false
          },
          {
            "score": 0.7307971715927124,
            "answer": "animal",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.724221259355545,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to goat ",
        "b": "goat",
        "expected answer": [
          "kid"
        ],
        "predictions": [
          {
            "score": 0.8245866298675537,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7255687713623047,
            "answer": "pumpkin",
            "hit": false
          },
          {
            "score": 0.723427414894104,
            "answer": "rabbit",
            "hit": false
          },
          {
            "score": 0.7167820930480957,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.7166337966918945,
            "answer": "buffalo",
            "hit": false
          },
          {
            "score": 0.7162014842033386,
            "answer": "cheese",
            "hit": false
          }
        ],
        "set_exclude": [
          "goat"
        ],
        "rank": 3579,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6461704671382904,
        "b in neighbourhood of b_prime": 961,
        "b_prime in neighbourhood of b": 3580
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.7829467058181763,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.7507907748222351,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.735672116279602,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.7301043272018433,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.726118266582489,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7217254638671875,
            "answer": "dragon",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 12040,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.606732040643692,
        "b in neighbourhood of b_prime": 9697,
        "b_prime in neighbourhood of b": 12041
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "infant"
        ],
        "predictions": [
          {
            "score": 0.8964869976043701,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7726758718490601,
            "answer": "ape",
            "hit": false
          },
          {
            "score": 0.7401586771011353,
            "answer": "banana",
            "hit": false
          },
          {
            "score": 0.7376115918159485,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.7346961498260498,
            "answer": "chicken",
            "hit": false
          },
          {
            "score": 0.7270472645759583,
            "answer": "animal",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 551,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6663698852062225,
        "b in neighbourhood of b_prime": 885,
        "b_prime in neighbourhood of b": 552
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "pup"
        ],
        "predictions": [
          {
            "score": 0.725480854511261,
            "answer": "marines",
            "hit": false
          },
          {
            "score": 0.7233673334121704,
            "answer": "sailors",
            "hit": false
          },
          {
            "score": 0.7214550971984863,
            "answer": "laden",
            "hit": false
          },
          {
            "score": 0.719910740852356,
            "answer": "taliban",
            "hit": false
          },
          {
            "score": 0.7175776362419128,
            "answer": "sailor",
            "hit": false
          },
          {
            "score": 0.7160569429397583,
            "answer": "seals",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 1074,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6627275794744492,
        "b in neighbourhood of b_prime": 988,
        "b_prime in neighbourhood of b": 1075
      },
      {
        "question verbose": "What is to shark ",
        "b": "shark",
        "expected answer": [
          "cub",
          "pup"
        ],
        "predictions": [
          {
            "score": 0.8075888156890869,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.7802578210830688,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.7679979801177979,
            "answer": "shrimp",
            "hit": false
          },
          {
            "score": 0.7635153532028198,
            "answer": "seafood",
            "hit": false
          },
          {
            "score": 0.7574595212936401,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7514886856079102,
            "answer": "whale",
            "hit": false
          }
        ],
        "set_exclude": [
          "shark"
        ],
        "rank": 348,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6023199260234833,
        "b in neighbourhood of b_prime": 10972,
        "b_prime in neighbourhood of b": 349
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.9022523760795593,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.7829467058181763,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.7802578210830688,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.7780378460884094,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.7604041695594788,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7485596537590027,
            "answer": "dragon",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 8450,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6320841312408447,
        "b in neighbourhood of b_prime": 2324,
        "b_prime in neighbourhood of b": 8451
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.8272629976272583,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7514886856079102,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.7299108505249023,
            "answer": "fish",
            "hit": false
          },
          {
            "score": 0.7222970128059387,
            "answer": "turtle",
            "hit": false
          },
          {
            "score": 0.7190298438072205,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.7153307795524597,
            "answer": "pirate",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 220,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6738413870334625,
        "b in neighbourhood of b_prime": 467,
        "b_prime in neighbourhood of b": 221
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 11,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E06 [animal - young].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "afce7217-40b7-428f-86d4-c0530bfa78ef",
      "timestamp": "2025-05-17T17:08:16.980200"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bee ",
        "b": "bee",
        "expected answer": [
          "buzz",
          "hum"
        ],
        "predictions": [
          {
            "score": 0.7700318098068237,
            "answer": "bees",
            "hit": false
          },
          {
            "score": 0.7261096239089966,
            "answer": "insect",
            "hit": false
          },
          {
            "score": 0.7138174176216125,
            "answer": "insects",
            "hit": false
          },
          {
            "score": 0.7099716663360596,
            "answer": "honey",
            "hit": false
          },
          {
            "score": 0.6997047066688538,
            "answer": "crab",
            "hit": false
          },
          {
            "score": 0.6995840668678284,
            "answer": "dee",
            "hit": false
          }
        ],
        "set_exclude": [
          "bee"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6905926167964935,
        "b in neighbourhood of b_prime": 32,
        "b_prime in neighbourhood of b": 17
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "buzz"
        ],
        "predictions": [
          {
            "score": 0.7652435302734375,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.7538789510726929,
            "answer": "flies",
            "hit": false
          },
          {
            "score": 0.7502869963645935,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.7473648190498352,
            "answer": "flying",
            "hit": false
          },
          {
            "score": 0.7226060628890991,
            "answer": "flight",
            "hit": false
          },
          {
            "score": 0.718571662902832,
            "answer": "stay",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 140,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6814801394939423,
        "b in neighbourhood of b_prime": 82,
        "b_prime in neighbourhood of b": 141
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "bark"
        ],
        "predictions": [
          {
            "score": 0.725480854511261,
            "answer": "marines",
            "hit": false
          },
          {
            "score": 0.7233673334121704,
            "answer": "sailors",
            "hit": false
          },
          {
            "score": 0.7214550971984863,
            "answer": "laden",
            "hit": false
          },
          {
            "score": 0.719910740852356,
            "answer": "taliban",
            "hit": false
          },
          {
            "score": 0.7175776362419128,
            "answer": "sailor",
            "hit": false
          },
          {
            "score": 0.7160569429397583,
            "answer": "seals",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 8688,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6285593211650848,
        "b in neighbourhood of b_prime": 5959,
        "b_prime in neighbourhood of b": 8689
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sing"
        ],
        "predictions": [
          {
            "score": 0.8272629976272583,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7514886856079102,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.7299108505249023,
            "answer": "fish",
            "hit": false
          },
          {
            "score": 0.7222970128059387,
            "answer": "turtle",
            "hit": false
          },
          {
            "score": 0.7190298438072205,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.7153307795524597,
            "answer": "pirate",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 14075,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.5834620967507362,
        "b in neighbourhood of b_prime": 13730,
        "b_prime in neighbourhood of b": 14076
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E07 [animal - sound].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "7df99096-1095-45d9-b9fe-b0316daab5e4",
      "timestamp": "2025-05-17T17:08:17.110388"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "grove",
          "tree",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7726758718490601,
            "answer": "monkey",
            "hit": false
          },
          {
            "score": 0.7532568573951721,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7326546311378479,
            "answer": "animal",
            "hit": false
          },
          {
            "score": 0.7304034233093262,
            "answer": "negro",
            "hit": false
          },
          {
            "score": 0.7223746180534363,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.7212953567504883,
            "answer": "beasts",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 1082,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6585615277290344,
        "b in neighbourhood of b_prime": 1035,
        "b_prime in neighbourhood of b": 1083
      },
      {
        "question verbose": "What is to bat ",
        "b": "bat",
        "expected answer": [
          "cave",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7727685570716858,
            "answer": "batman",
            "hit": false
          },
          {
            "score": 0.7526006698608398,
            "answer": "bats",
            "hit": false
          },
          {
            "score": 0.7266860008239746,
            "answer": "batting",
            "hit": false
          },
          {
            "score": 0.7250217199325562,
            "answer": "bathing",
            "hit": false
          },
          {
            "score": 0.7223675847053528,
            "answer": "bed",
            "hit": false
          },
          {
            "score": 0.7139731645584106,
            "answer": "saber",
            "hit": false
          }
        ],
        "set_exclude": [
          "bat"
        ],
        "rank": 2081,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6536440253257751,
        "b in neighbourhood of b_prime": 1319,
        "b_prime in neighbourhood of b": 2082
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7465057373046875,
            "answer": "borne",
            "hit": false
          },
          {
            "score": 0.7330659627914429,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.7189512848854065,
            "answer": "endure",
            "hit": false
          },
          {
            "score": 0.715822160243988,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.6983940601348877,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.6951324939727783,
            "answer": "suffer",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 4146,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.617374375462532,
        "b in neighbourhood of b_prime": 11473,
        "b_prime in neighbourhood of b": 4147
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "barn",
          "coral"
        ],
        "predictions": [
          {
            "score": 0.889541506767273,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.8544242978096008,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7979198694229126,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7964810132980347,
            "answer": "poultry",
            "hit": false
          },
          {
            "score": 0.7857985496520996,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.785063624382019,
            "answer": "goats",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 2080,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6585596352815628,
        "b in neighbourhood of b_prime": 1914,
        "b_prime in neighbourhood of b": 2081
      },
      {
        "question verbose": "What is to cricket ",
        "b": "cricket",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.8305240273475647,
            "answer": "rugby",
            "hit": false
          },
          {
            "score": 0.7924244403839111,
            "answer": "bowling",
            "hit": false
          },
          {
            "score": 0.7839726805686951,
            "answer": "soccer",
            "hit": false
          },
          {
            "score": 0.7798278331756592,
            "answer": "football",
            "hit": false
          },
          {
            "score": 0.7749895453453064,
            "answer": "baseball",
            "hit": false
          },
          {
            "score": 0.7714495658874512,
            "answer": "hockey",
            "hit": false
          }
        ],
        "set_exclude": [
          "cricket"
        ],
        "rank": 7058,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6336566209793091,
        "b in neighbourhood of b_prime": 2616,
        "b_prime in neighbourhood of b": 7059
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7227059006690979,
            "answer": "raven",
            "hit": false
          },
          {
            "score": 0.7126323580741882,
            "answer": "exclaimed",
            "hit": false
          },
          {
            "score": 0.7105799317359924,
            "answer": "turkey",
            "hit": false
          },
          {
            "score": 0.7093703746795654,
            "answer": "hawk",
            "hit": false
          },
          {
            "score": 0.7073087692260742,
            "answer": "chuckled",
            "hit": false
          },
          {
            "score": 0.7042579650878906,
            "answer": "lion",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 961,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6201778799295425,
        "b in neighbourhood of b_prime": 6169,
        "b_prime in neighbourhood of b": 962
      },
      {
        "question verbose": "What is to duck ",
        "b": "duck",
        "expected answer": [
          "pond",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.86279296875,
            "answer": "ducks",
            "hit": false
          },
          {
            "score": 0.7529721856117249,
            "answer": "chicken",
            "hit": false
          },
          {
            "score": 0.7463698387145996,
            "answer": "deer",
            "hit": false
          },
          {
            "score": 0.744488000869751,
            "answer": "goose",
            "hit": false
          },
          {
            "score": 0.7333725690841675,
            "answer": "poultry",
            "hit": false
          },
          {
            "score": 0.7315828800201416,
            "answer": "turkey",
            "hit": false
          }
        ],
        "set_exclude": [
          "duck"
        ],
        "rank": 124,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6778278648853302,
        "b in neighbourhood of b_prime": 150,
        "b_prime in neighbourhood of b": 125
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7652435302734375,
            "answer": "flew",
            "hit": false
          },
          {
            "score": 0.7538789510726929,
            "answer": "flies",
            "hit": false
          },
          {
            "score": 0.7502869963645935,
            "answer": "flown",
            "hit": false
          },
          {
            "score": 0.7473648190498352,
            "answer": "flying",
            "hit": false
          },
          {
            "score": 0.7226060628890991,
            "answer": "flight",
            "hit": false
          },
          {
            "score": 0.718571662902832,
            "answer": "stay",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 12687,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6082457304000854,
        "b in neighbourhood of b_prime": 9849,
        "b_prime in neighbourhood of b": 12688
      },
      {
        "question verbose": "What is to fox ",
        "b": "fox",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7935605049133301,
            "answer": "cbs",
            "hit": false
          },
          {
            "score": 0.7863292694091797,
            "answer": "nbc",
            "hit": false
          },
          {
            "score": 0.74052894115448,
            "answer": "abc",
            "hit": false
          },
          {
            "score": 0.7324898838996887,
            "answer": "espn",
            "hit": false
          },
          {
            "score": 0.7199497222900391,
            "answer": "hbo",
            "hit": false
          },
          {
            "score": 0.7125715017318726,
            "answer": "television",
            "hit": false
          }
        ],
        "set_exclude": [
          "fox"
        ],
        "rank": 448,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6305636316537857,
        "b in neighbourhood of b_prime": 8063,
        "b_prime in neighbourhood of b": 449
      },
      {
        "question verbose": "What is to insect ",
        "b": "insect",
        "expected answer": [
          "nest",
          "cage",
          "box"
        ],
        "predictions": [
          {
            "score": 0.8504816293716431,
            "answer": "insects",
            "hit": false
          },
          {
            "score": 0.7513754367828369,
            "answer": "mosquito",
            "hit": false
          },
          {
            "score": 0.7459956407546997,
            "answer": "larvae",
            "hit": false
          },
          {
            "score": 0.7424530386924744,
            "answer": "animal",
            "hit": false
          },
          {
            "score": 0.7402289509773254,
            "answer": "birds",
            "hit": false
          },
          {
            "score": 0.7382452487945557,
            "answer": "animals",
            "hit": false
          }
        ],
        "set_exclude": [
          "insect"
        ],
        "rank": 982,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6724139899015427,
        "b in neighbourhood of b_prime": 36,
        "b_prime in neighbourhood of b": 983
      },
      {
        "question verbose": "What is to mole ",
        "b": "mole",
        "expected answer": [
          "hole",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7374622225761414,
            "answer": "molecule",
            "hit": false
          },
          {
            "score": 0.7279834747314453,
            "answer": "molecules",
            "hit": false
          },
          {
            "score": 0.7037724852561951,
            "answer": "hole",
            "hit": true
          },
          {
            "score": 0.7016109228134155,
            "answer": "mouse",
            "hit": false
          },
          {
            "score": 0.6993085741996765,
            "answer": "monster",
            "hit": false
          },
          {
            "score": 0.6979081630706787,
            "answer": "mice",
            "hit": false
          }
        ],
        "set_exclude": [
          "mole"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7037724554538727,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "tree",
          "grove",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.8964869976043701,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7726758718490601,
            "answer": "ape",
            "hit": false
          },
          {
            "score": 0.7401586771011353,
            "answer": "banana",
            "hit": false
          },
          {
            "score": 0.7376115918159485,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.7346961498260498,
            "answer": "chicken",
            "hit": false
          },
          {
            "score": 0.7270472645759583,
            "answer": "animal",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 917,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6599088460206985,
        "b in neighbourhood of b_prime": 366,
        "b_prime in neighbourhood of b": 918
      },
      {
        "question verbose": "What is to mouse ",
        "b": "mouse",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7965774536132812,
            "answer": "mice",
            "hit": false
          },
          {
            "score": 0.7496100068092346,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.7245903015136719,
            "answer": "keyboard",
            "hit": false
          },
          {
            "score": 0.7244770526885986,
            "answer": "monkey",
            "hit": false
          },
          {
            "score": 0.7243074774742126,
            "answer": "mammalian",
            "hit": false
          },
          {
            "score": 0.7228610515594482,
            "answer": "menu",
            "hit": false
          }
        ],
        "set_exclude": [
          "mouse"
        ],
        "rank": 3141,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6241316869854927,
        "b in neighbourhood of b_prime": 4968,
        "b_prime in neighbourhood of b": 3142
      },
      {
        "question verbose": "What is to rat ",
        "b": "rat",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7487799525260925,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.7187705636024475,
            "answer": "monkey",
            "hit": false
          },
          {
            "score": 0.711052417755127,
            "answer": "rats",
            "hit": false
          },
          {
            "score": 0.7095587253570557,
            "answer": "spider",
            "hit": false
          },
          {
            "score": 0.7035640478134155,
            "answer": "mice",
            "hit": false
          },
          {
            "score": 0.7026278972625732,
            "answer": "mammalian",
            "hit": false
          }
        ],
        "set_exclude": [
          "rat"
        ],
        "rank": 143,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6106941401958466,
        "b in neighbourhood of b_prime": 9095,
        "b_prime in neighbourhood of b": 144
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.743301510810852,
            "answer": "starving",
            "hit": false
          },
          {
            "score": 0.7356643676757812,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.7321111559867859,
            "answer": "ravens",
            "hit": false
          },
          {
            "score": 0.727460503578186,
            "answer": "eagle",
            "hit": false
          },
          {
            "score": 0.7253165245056152,
            "answer": "thirst",
            "hit": false
          },
          {
            "score": 0.7227059006690979,
            "answer": "crow",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 1170,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6489938795566559,
        "b in neighbourhood of b_prime": 638,
        "b_prime in neighbourhood of b": 1171
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.9022523760795593,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.7829467058181763,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.7802578210830688,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.7780378460884094,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.7604041695594788,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7485596537590027,
            "answer": "dragon",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 299,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.5957705080509186,
        "b in neighbourhood of b_prime": 13889,
        "b_prime in neighbourhood of b": 300
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sea",
          "sanctuary"
        ],
        "predictions": [
          {
            "score": 0.8272629976272583,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7514886856079102,
            "answer": "shark",
            "hit": false
          },
          {
            "score": 0.7299108505249023,
            "answer": "fish",
            "hit": false
          },
          {
            "score": 0.7222970128059387,
            "answer": "turtle",
            "hit": false
          },
          {
            "score": 0.7190298438072205,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.7153307795524597,
            "answer": "pirate",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7138009071350098,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7867357730865479,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.7210699319839478,
            "answer": "vampire",
            "hit": false
          },
          {
            "score": 0.6951887011528015,
            "answer": "woods",
            "hit": false
          },
          {
            "score": 0.6947922110557556,
            "answer": "bird",
            "hit": false
          },
          {
            "score": 0.6947599649429321,
            "answer": "monster",
            "hit": false
          },
          {
            "score": 0.6939250826835632,
            "answer": "walker",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 2880,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6161114573478699,
        "b in neighbourhood of b_prime": 11730,
        "b_prime in neighbourhood of b": 2881
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 18,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E08 [animal - shelter].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "e86bc8d7-c9f7-4566-becb-7289fe92c356",
      "timestamp": "2025-05-17T17:08:17.169950"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ant ",
        "b": "ant",
        "expected answer": [
          "black",
          "brown",
          "red"
        ],
        "predictions": [
          {
            "score": 0.7834358215332031,
            "answer": "anton",
            "hit": false
          },
          {
            "score": 0.7617436647415161,
            "answer": "antonio",
            "hit": false
          },
          {
            "score": 0.7533203363418579,
            "answer": "anthony",
            "hit": false
          },
          {
            "score": 0.7272937297821045,
            "answer": "anti",
            "hit": false
          },
          {
            "score": 0.7203728556632996,
            "answer": "although",
            "hit": false
          },
          {
            "score": 0.7202305793762207,
            "answer": "antennas",
            "hit": false
          }
        ],
        "set_exclude": [
          "ant"
        ],
        "rank": 4947,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6390616148710251,
        "b in neighbourhood of b_prime": 5540,
        "b_prime in neighbourhood of b": 4948
      },
      {
        "question verbose": "What is to apple ",
        "b": "apple",
        "expected answer": [
          "red",
          "orange",
          "yellow",
          "golden"
        ],
        "predictions": [
          {
            "score": 0.8003710508346558,
            "answer": "iphone",
            "hit": false
          },
          {
            "score": 0.7908731698989868,
            "answer": "ios",
            "hit": false
          },
          {
            "score": 0.7816064357757568,
            "answer": "google",
            "hit": false
          },
          {
            "score": 0.7718772292137146,
            "answer": "nintendo",
            "hit": false
          },
          {
            "score": 0.7707198262214661,
            "answer": "android",
            "hit": false
          },
          {
            "score": 0.7702661752700806,
            "answer": "ipad",
            "hit": false
          }
        ],
        "set_exclude": [
          "apple"
        ],
        "rank": 81,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.5916342958807945,
        "b in neighbourhood of b_prime": 7700,
        "b_prime in neighbourhood of b": 82
      },
      {
        "question verbose": "What is to blood ",
        "b": "blood",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7337110638618469,
            "answer": "bloody",
            "hit": false
          },
          {
            "score": 0.7287135124206543,
            "answer": "bone",
            "hit": false
          },
          {
            "score": 0.7253063917160034,
            "answer": "bones",
            "hit": false
          },
          {
            "score": 0.7206177711486816,
            "answer": "death",
            "hit": false
          },
          {
            "score": 0.7202370166778564,
            "answer": "murder",
            "hit": false
          },
          {
            "score": 0.7199946641921997,
            "answer": "breath",
            "hit": false
          }
        ],
        "set_exclude": [
          "blood"
        ],
        "rank": 233,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6657226532697678,
        "b in neighbourhood of b_prime": 28,
        "b_prime in neighbourhood of b": 234
      },
      {
        "question verbose": "What is to cabbage ",
        "b": "cabbage",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.8085172176361084,
            "answer": "vegetables",
            "hit": false
          },
          {
            "score": 0.7805091142654419,
            "answer": "tomato",
            "hit": false
          },
          {
            "score": 0.7789964079856873,
            "answer": "potatoes",
            "hit": false
          },
          {
            "score": 0.7775919437408447,
            "answer": "onions",
            "hit": false
          },
          {
            "score": 0.775020182132721,
            "answer": "tomatoes",
            "hit": false
          },
          {
            "score": 0.7671898603439331,
            "answer": "vegetable",
            "hit": false
          }
        ],
        "set_exclude": [
          "cabbage"
        ],
        "rank": 3815,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6610901206731796,
        "b in neighbourhood of b_prime": 90,
        "b_prime in neighbourhood of b": 3816
      },
      {
        "question verbose": "What is to carrot ",
        "b": "carrot",
        "expected answer": [
          "orange",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7603182792663574,
            "answer": "cabbage",
            "hit": false
          },
          {
            "score": 0.7553480863571167,
            "answer": "vegetables",
            "hit": false
          },
          {
            "score": 0.7509984970092773,
            "answer": "tomato",
            "hit": false
          },
          {
            "score": 0.7341509461402893,
            "answer": "garlic",
            "hit": false
          },
          {
            "score": 0.7325330972671509,
            "answer": "vegetable",
            "hit": false
          },
          {
            "score": 0.7307724952697754,
            "answer": "fruits",
            "hit": false
          }
        ],
        "set_exclude": [
          "carrot"
        ],
        "rank": 948,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.648717999458313,
        "b in neighbourhood of b_prime": 503,
        "b_prime in neighbourhood of b": 949
      },
      {
        "question verbose": "What is to cherry ",
        "b": "cherry",
        "expected answer": [
          "red",
          "yellow",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7165516018867493,
            "answer": "coffee",
            "hit": false
          },
          {
            "score": 0.7146463394165039,
            "answer": "pine",
            "hit": false
          },
          {
            "score": 0.7129955291748047,
            "answer": "ginger",
            "hit": false
          },
          {
            "score": 0.7102334499359131,
            "answer": "maple",
            "hit": false
          },
          {
            "score": 0.7062885761260986,
            "answer": "holly",
            "hit": false
          },
          {
            "score": 0.7038595080375671,
            "answer": "lily",
            "hit": false
          }
        ],
        "set_exclude": [
          "cherry"
        ],
        "rank": 346,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6250630915164948,
        "b in neighbourhood of b_prime": 708,
        "b_prime in neighbourhood of b": 347
      },
      {
        "question verbose": "What is to chocolate ",
        "b": "chocolate",
        "expected answer": [
          "white",
          "brown",
          "black"
        ],
        "predictions": [
          {
            "score": 0.8491291403770447,
            "answer": "cocoa",
            "hit": false
          },
          {
            "score": 0.7874734401702881,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.7656735181808472,
            "answer": "coconut",
            "hit": false
          },
          {
            "score": 0.7649812698364258,
            "answer": "peanut",
            "hit": false
          },
          {
            "score": 0.7544922232627869,
            "answer": "butter",
            "hit": false
          },
          {
            "score": 0.751437783241272,
            "answer": "cinnamon",
            "hit": false
          }
        ],
        "set_exclude": [
          "chocolate"
        ],
        "rank": 79,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6512985527515411,
        "b in neighbourhood of b_prime": 2166,
        "b_prime in neighbourhood of b": 80
      },
      {
        "question verbose": "What is to cloud ",
        "b": "cloud",
        "expected answer": [
          "white",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7921517491340637,
            "answer": "clouds",
            "hit": false
          },
          {
            "score": 0.7203206419944763,
            "answer": "wind",
            "hit": false
          },
          {
            "score": 0.7191109657287598,
            "answer": "azure",
            "hit": false
          },
          {
            "score": 0.7155213356018066,
            "answer": "stream",
            "hit": false
          },
          {
            "score": 0.7098357677459717,
            "answer": "amazon",
            "hit": false
          },
          {
            "score": 0.7080855965614319,
            "answer": "thunder",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloud"
        ],
        "rank": 757,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6619472801685333,
        "b in neighbourhood of b_prime": 955,
        "b_prime in neighbourhood of b": 758
      },
      {
        "question verbose": "What is to coal ",
        "b": "coal",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7534583806991577,
            "answer": "fossil",
            "hit": false
          },
          {
            "score": 0.7458938956260681,
            "answer": "railway",
            "hit": false
          },
          {
            "score": 0.7430365085601807,
            "answer": "miners",
            "hit": false
          },
          {
            "score": 0.7389334440231323,
            "answer": "uranium",
            "hit": false
          },
          {
            "score": 0.7328072190284729,
            "answer": "petroleum",
            "hit": false
          },
          {
            "score": 0.7322090864181519,
            "answer": "copper",
            "hit": false
          }
        ],
        "set_exclude": [
          "coal"
        ],
        "rank": 1508,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.66276815533638,
        "b in neighbourhood of b_prime": 792,
        "b_prime in neighbourhood of b": 1509
      },
      {
        "question verbose": "What is to coffee ",
        "b": "coffee",
        "expected answer": [
          "black",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7719659805297852,
            "answer": "cafe",
            "hit": false
          },
          {
            "score": 0.768792986869812,
            "answer": "cocoa",
            "hit": false
          },
          {
            "score": 0.7673017978668213,
            "answer": "starbucks",
            "hit": false
          },
          {
            "score": 0.7469558715820312,
            "answer": "chocolate",
            "hit": false
          },
          {
            "score": 0.7434518337249756,
            "answer": "beans",
            "hit": false
          },
          {
            "score": 0.7334650754928589,
            "answer": "dairy",
            "hit": false
          }
        ],
        "set_exclude": [
          "coffee"
        ],
        "rank": 1196,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6393135786056519,
        "b in neighbourhood of b_prime": 5480,
        "b_prime in neighbourhood of b": 1197
      },
      {
        "question verbose": "What is to cream ",
        "b": "cream",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7656309008598328,
            "answer": "creamy",
            "hit": false
          },
          {
            "score": 0.7263212203979492,
            "answer": "cakes",
            "hit": false
          },
          {
            "score": 0.7221945524215698,
            "answer": "glared",
            "hit": false
          },
          {
            "score": 0.7207420468330383,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.7189803719520569,
            "answer": "sculptures",
            "hit": false
          },
          {
            "score": 0.7172898650169373,
            "answer": "dairy",
            "hit": false
          }
        ],
        "set_exclude": [
          "cream"
        ],
        "rank": 1822,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6648202240467072,
        "b in neighbourhood of b_prime": 745,
        "b_prime in neighbourhood of b": 1823
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7227059006690979,
            "answer": "raven",
            "hit": false
          },
          {
            "score": 0.7126323580741882,
            "answer": "exclaimed",
            "hit": false
          },
          {
            "score": 0.7105799317359924,
            "answer": "turkey",
            "hit": false
          },
          {
            "score": 0.7093703746795654,
            "answer": "hawk",
            "hit": false
          },
          {
            "score": 0.7073087692260742,
            "answer": "chuckled",
            "hit": false
          },
          {
            "score": 0.7042579650878906,
            "answer": "lion",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 972,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6528808027505875,
        "b in neighbourhood of b_prime": 2032,
        "b_prime in neighbourhood of b": 973
      },
      {
        "question verbose": "What is to fridge ",
        "b": "fridge",
        "expected answer": [
          "white",
          "silver",
          "black"
        ],
        "predictions": [
          {
            "score": 0.9334322810173035,
            "answer": "refrigerator",
            "hit": false
          },
          {
            "score": 0.7745559215545654,
            "answer": "supermarket",
            "hit": false
          },
          {
            "score": 0.7693190574645996,
            "answer": "oven",
            "hit": false
          },
          {
            "score": 0.7635464668273926,
            "answer": "microwave",
            "hit": false
          },
          {
            "score": 0.754210889339447,
            "answer": "grocery",
            "hit": false
          },
          {
            "score": 0.7512931823730469,
            "answer": "sofa",
            "hit": false
          }
        ],
        "set_exclude": [
          "fridge"
        ],
        "rank": 6632,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6287670433521271,
        "b in neighbourhood of b_prime": 8568,
        "b_prime in neighbourhood of b": 6633
      },
      {
        "question verbose": "What is to frog ",
        "b": "frog",
        "expected answer": [
          "green",
          "brown",
          "grey",
          "gray"
        ],
        "predictions": [
          {
            "score": 0.7191965579986572,
            "answer": "snake",
            "hit": false
          },
          {
            "score": 0.7173921465873718,
            "answer": "dogs",
            "hit": false
          },
          {
            "score": 0.7074477672576904,
            "answer": "shrimp",
            "hit": false
          },
          {
            "score": 0.7069997787475586,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7063186764717102,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.7055803537368774,
            "answer": "rodents",
            "hit": false
          }
        ],
        "set_exclude": [
          "frog"
        ],
        "rank": 9890,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6008419096469879,
        "b in neighbourhood of b_prime": 7663,
        "b_prime in neighbourhood of b": 9891
      },
      {
        "question verbose": "What is to grapes ",
        "b": "grapes",
        "expected answer": [
          "black",
          "red",
          "green",
          "purple"
        ],
        "predictions": [
          {
            "score": 0.8121320009231567,
            "answer": "wines",
            "hit": false
          },
          {
            "score": 0.7972611784934998,
            "answer": "tomatoes",
            "hit": false
          },
          {
            "score": 0.7949397563934326,
            "answer": "wine",
            "hit": false
          },
          {
            "score": 0.7883667945861816,
            "answer": "vine",
            "hit": false
          },
          {
            "score": 0.7682386040687561,
            "answer": "apples",
            "hit": false
          },
          {
            "score": 0.7678906917572021,
            "answer": "fruits",
            "hit": false
          }
        ],
        "set_exclude": [
          "grapes"
        ],
        "rank": 809,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6311472356319427,
        "b in neighbourhood of b_prime": 8076,
        "b_prime in neighbourhood of b": 810
      },
      {
        "question verbose": "What is to grass ",
        "b": "grass",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.7292869091033936,
            "answer": "vegetation",
            "hit": false
          },
          {
            "score": 0.7224338054656982,
            "answer": "grassroots",
            "hit": false
          },
          {
            "score": 0.7207105755805969,
            "answer": "pasture",
            "hit": false
          },
          {
            "score": 0.7106786966323853,
            "answer": "leaf",
            "hit": false
          },
          {
            "score": 0.7103922963142395,
            "answer": "herb",
            "hit": false
          },
          {
            "score": 0.7101389169692993,
            "answer": "dirt",
            "hit": false
          }
        ],
        "set_exclude": [
          "grass"
        ],
        "rank": 512,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6606661230325699,
        "b in neighbourhood of b_prime": 98,
        "b_prime in neighbourhood of b": 513
      },
      {
        "question verbose": "What is to leaves ",
        "b": "leaves",
        "expected answer": [
          "green",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7651973962783813,
            "answer": "leaf",
            "hit": false
          },
          {
            "score": 0.7522783279418945,
            "answer": "foliage",
            "hit": false
          },
          {
            "score": 0.7320870161056519,
            "answer": "leaving",
            "hit": false
          },
          {
            "score": 0.7270592451095581,
            "answer": "leave",
            "hit": false
          },
          {
            "score": 0.7263870239257812,
            "answer": "stems",
            "hit": false
          },
          {
            "score": 0.7261101007461548,
            "answer": "ends",
            "hit": false
          }
        ],
        "set_exclude": [
          "leaves"
        ],
        "rank": 750,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6348956525325775,
        "b in neighbourhood of b_prime": 713,
        "b_prime in neighbourhood of b": 751
      },
      {
        "question verbose": "What is to milk ",
        "b": "milk",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7660079598426819,
            "answer": "mil",
            "hit": false
          },
          {
            "score": 0.7579293251037598,
            "answer": "dairy",
            "hit": false
          },
          {
            "score": 0.7378122806549072,
            "answer": "butter",
            "hit": false
          },
          {
            "score": 0.7375267744064331,
            "answer": "creamy",
            "hit": false
          },
          {
            "score": 0.7277969121932983,
            "answer": "coffee",
            "hit": false
          },
          {
            "score": 0.722756028175354,
            "answer": "protein",
            "hit": false
          }
        ],
        "set_exclude": [
          "milk"
        ],
        "rank": 3081,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6445396542549133,
        "b in neighbourhood of b_prime": 3599,
        "b_prime in neighbourhood of b": 3082
      },
      {
        "question verbose": "What is to paper ",
        "b": "paper",
        "expected answer": [
          "white",
          "color"
        ],
        "predictions": [
          {
            "score": 0.8417016267776489,
            "answer": "papers",
            "hit": false
          },
          {
            "score": 0.7203567028045654,
            "answer": "parchment",
            "hit": false
          },
          {
            "score": 0.7083469033241272,
            "answer": "newspaper",
            "hit": false
          },
          {
            "score": 0.7048822045326233,
            "answer": "newspapers",
            "hit": false
          },
          {
            "score": 0.7008219957351685,
            "answer": "cardboard",
            "hit": false
          },
          {
            "score": 0.6984550952911377,
            "answer": "metal",
            "hit": false
          }
        ],
        "set_exclude": [
          "paper"
        ],
        "rank": 185,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6266319751739502,
        "b in neighbourhood of b_prime": 9297,
        "b_prime in neighbourhood of b": 186
      },
      {
        "question verbose": "What is to pepper ",
        "b": "pepper",
        "expected answer": [
          "black",
          "red",
          "green",
          "yellow",
          "orange"
        ],
        "predictions": [
          {
            "score": 0.7643885016441345,
            "answer": "peppers",
            "hit": false
          },
          {
            "score": 0.7155123949050903,
            "answer": "ginger",
            "hit": false
          },
          {
            "score": 0.7142209410667419,
            "answer": "chili",
            "hit": false
          },
          {
            "score": 0.7124965190887451,
            "answer": "peanut",
            "hit": false
          },
          {
            "score": 0.7107466459274292,
            "answer": "tomato",
            "hit": false
          },
          {
            "score": 0.7091284990310669,
            "answer": "clare",
            "hit": false
          }
        ],
        "set_exclude": [
          "pepper"
        ],
        "rank": 61,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.646951898932457,
        "b in neighbourhood of b_prime": 3226,
        "b_prime in neighbourhood of b": 62
      },
      {
        "question verbose": "What is to potato ",
        "b": "potato",
        "expected answer": [
          "brown"
        ],
        "predictions": [
          {
            "score": 0.8246753215789795,
            "answer": "potatoes",
            "hit": false
          },
          {
            "score": 0.7492411136627197,
            "answer": "tomato",
            "hit": false
          },
          {
            "score": 0.7463854551315308,
            "answer": "cheese",
            "hit": false
          },
          {
            "score": 0.741477370262146,
            "answer": "pumpkin",
            "hit": false
          },
          {
            "score": 0.7359276413917542,
            "answer": "vegetables",
            "hit": false
          },
          {
            "score": 0.7335588932037354,
            "answer": "banana",
            "hit": false
          }
        ],
        "set_exclude": [
          "potato"
        ],
        "rank": 5033,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6427932232618332,
        "b in neighbourhood of b_prime": 1899,
        "b_prime in neighbourhood of b": 5034
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.743301510810852,
            "answer": "starving",
            "hit": false
          },
          {
            "score": 0.7356643676757812,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.7321111559867859,
            "answer": "ravens",
            "hit": false
          },
          {
            "score": 0.727460503578186,
            "answer": "eagle",
            "hit": false
          },
          {
            "score": 0.7253165245056152,
            "answer": "thirst",
            "hit": false
          },
          {
            "score": 0.7227059006690979,
            "answer": "crow",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 1499,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6615881323814392,
        "b in neighbourhood of b_prime": 898,
        "b_prime in neighbourhood of b": 1500
      },
      {
        "question verbose": "What is to rose ",
        "b": "rose",
        "expected answer": [
          "red",
          "yellow",
          "pink",
          "white",
          "blue"
        ],
        "predictions": [
          {
            "score": 0.8070393204689026,
            "answer": "risen",
            "hit": false
          },
          {
            "score": 0.8032746911048889,
            "answer": "rises",
            "hit": false
          },
          {
            "score": 0.7733465433120728,
            "answer": "roses",
            "hit": false
          },
          {
            "score": 0.7685161828994751,
            "answer": "rising",
            "hit": false
          },
          {
            "score": 0.7684845924377441,
            "answer": "grew",
            "hit": false
          },
          {
            "score": 0.7683733701705933,
            "answer": "climbed",
            "hit": false
          }
        ],
        "set_exclude": [
          "rose"
        ],
        "rank": 592,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6489435285329819,
        "b in neighbourhood of b_prime": 97,
        "b_prime in neighbourhood of b": 593
      },
      {
        "question verbose": "What is to ruby ",
        "b": "ruby",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.771032452583313,
            "answer": "weiss",
            "hit": false
          },
          {
            "score": 0.7593883275985718,
            "answer": "yang",
            "hit": false
          },
          {
            "score": 0.7441791296005249,
            "answer": "blake",
            "hit": false
          },
          {
            "score": 0.7441207766532898,
            "answer": "python",
            "hit": false
          },
          {
            "score": 0.739316999912262,
            "answer": "scala",
            "hit": false
          },
          {
            "score": 0.7353821396827698,
            "answer": "php",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruby"
        ],
        "rank": 5509,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.625726580619812,
        "b in neighbourhood of b_prime": 661,
        "b_prime in neighbourhood of b": 5510
      },
      {
        "question verbose": "What is to salt ",
        "b": "salt",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.8047866821289062,
            "answer": "utah",
            "hit": false
          },
          {
            "score": 0.7453014850616455,
            "answer": "salts",
            "hit": false
          },
          {
            "score": 0.7339565753936768,
            "answer": "mormon",
            "hit": false
          },
          {
            "score": 0.7243319749832153,
            "answer": "sacramento",
            "hit": false
          },
          {
            "score": 0.7194007635116577,
            "answer": "latter",
            "hit": false
          },
          {
            "score": 0.7176796197891235,
            "answer": "sodium",
            "hit": false
          }
        ],
        "set_exclude": [
          "salt"
        ],
        "rank": 1859,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6384975463151932,
        "b in neighbourhood of b_prime": 5230,
        "b_prime in neighbourhood of b": 1860
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "blue",
          "green",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7914562225341797,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.7590340375900269,
            "answer": "ocean",
            "hit": false
          },
          {
            "score": 0.7389046549797058,
            "answer": "maritime",
            "hit": false
          },
          {
            "score": 0.7225472927093506,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7218091487884521,
            "answer": "naval",
            "hit": false
          },
          {
            "score": 0.7175421714782715,
            "answer": "coastal",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 66,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.679188996553421,
        "b in neighbourhood of b_prime": 206,
        "b_prime in neighbourhood of b": 67
      },
      {
        "question verbose": "What is to sky ",
        "b": "sky",
        "expected answer": [
          "blue",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7256544828414917,
            "answer": "skies",
            "hit": false
          },
          {
            "score": 0.7197157144546509,
            "answer": "thunder",
            "hit": false
          },
          {
            "score": 0.7147864699363708,
            "answer": "ski",
            "hit": false
          },
          {
            "score": 0.7129282355308533,
            "answer": "solar",
            "hit": false
          },
          {
            "score": 0.7106784582138062,
            "answer": "seven",
            "hit": false
          },
          {
            "score": 0.7051640748977661,
            "answer": "flying",
            "hit": false
          }
        ],
        "set_exclude": [
          "sky"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6991652250289917,
        "b in neighbourhood of b_prime": 31,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to snow ",
        "b": "snow",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7427623271942139,
            "answer": "winter",
            "hit": false
          },
          {
            "score": 0.738677978515625,
            "answer": "frost",
            "hit": false
          },
          {
            "score": 0.7311699986457825,
            "answer": "rain",
            "hit": false
          },
          {
            "score": 0.722046971321106,
            "answer": "sleeping",
            "hit": false
          },
          {
            "score": 0.7176843881607056,
            "answer": "skiing",
            "hit": false
          },
          {
            "score": 0.7157440781593323,
            "answer": "icy",
            "hit": false
          }
        ],
        "set_exclude": [
          "snow"
        ],
        "rank": 247,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6624578535556793,
        "b in neighbourhood of b_prime": 916,
        "b_prime in neighbourhood of b": 248
      },
      {
        "question verbose": "What is to soil ",
        "b": "soil",
        "expected answer": [
          "black",
          "brown",
          "dark"
        ],
        "predictions": [
          {
            "score": 0.8780450820922852,
            "answer": "soils",
            "hit": false
          },
          {
            "score": 0.7493658661842346,
            "answer": "terrain",
            "hit": false
          },
          {
            "score": 0.7482630014419556,
            "answer": "vegetation",
            "hit": false
          },
          {
            "score": 0.7475957870483398,
            "answer": "groundwater",
            "hit": false
          },
          {
            "score": 0.7466031312942505,
            "answer": "turf",
            "hit": false
          },
          {
            "score": 0.7413476705551147,
            "answer": "sediment",
            "hit": false
          }
        ],
        "set_exclude": [
          "soil"
        ],
        "rank": 2277,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6292776763439178,
        "b in neighbourhood of b_prime": 8686,
        "b_prime in neighbourhood of b": 2278
      },
      {
        "question verbose": "What is to sugar ",
        "b": "sugar",
        "expected answer": [
          "white",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7862030267715454,
            "answer": "glucose",
            "hit": false
          },
          {
            "score": 0.769922137260437,
            "answer": "syrup",
            "hit": false
          },
          {
            "score": 0.7618386745452881,
            "answer": "sweetness",
            "hit": false
          },
          {
            "score": 0.7506101131439209,
            "answer": "chocolate",
            "hit": false
          },
          {
            "score": 0.7489070296287537,
            "answer": "soda",
            "hit": false
          },
          {
            "score": 0.7435200810432434,
            "answer": "rice",
            "hit": false
          }
        ],
        "set_exclude": [
          "sugar"
        ],
        "rank": 1238,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6425965875387192,
        "b in neighbourhood of b_prime": 4082,
        "b_prime in neighbourhood of b": 1239
      },
      {
        "question verbose": "What is to sun ",
        "b": "sun",
        "expected answer": [
          "yellow",
          "gold"
        ],
        "predictions": [
          {
            "score": 0.7379845976829529,
            "answer": "sunset",
            "hit": false
          },
          {
            "score": 0.7371230125427246,
            "answer": "sunlight",
            "hit": false
          },
          {
            "score": 0.722923755645752,
            "answer": "solar",
            "hit": false
          },
          {
            "score": 0.7204639911651611,
            "answer": "dusk",
            "hit": false
          },
          {
            "score": 0.7204291224479675,
            "answer": "sunshine",
            "hit": false
          },
          {
            "score": 0.7140811085700989,
            "answer": "sunny",
            "hit": false
          }
        ],
        "set_exclude": [
          "sun"
        ],
        "rank": 191,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6670998930931091,
        "b in neighbourhood of b_prime": 1950,
        "b_prime in neighbourhood of b": 192
      },
      {
        "question verbose": "What is to swan ",
        "b": "swan",
        "expected answer": [
          "white",
          "black",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7034022808074951,
            "answer": "wan",
            "hit": false
          },
          {
            "score": 0.7028765082359314,
            "answer": "allan",
            "hit": false
          },
          {
            "score": 0.7027758359909058,
            "answer": "thames",
            "hit": false
          },
          {
            "score": 0.7022460699081421,
            "answer": "darling",
            "hit": false
          },
          {
            "score": 0.6974529027938843,
            "answer": "natalie",
            "hit": false
          },
          {
            "score": 0.6961678862571716,
            "answer": "sydney",
            "hit": false
          }
        ],
        "set_exclude": [
          "swan"
        ],
        "rank": 1080,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6538392901420593,
        "b in neighbourhood of b_prime": 1790,
        "b_prime in neighbourhood of b": 1081
      },
      {
        "question verbose": "What is to tea ",
        "b": "tea",
        "expected answer": [
          "black",
          "green",
          "white",
          "red",
          "brown",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7316455245018005,
            "answer": "coffee",
            "hit": false
          },
          {
            "score": 0.724403440952301,
            "answer": "beer",
            "hit": false
          },
          {
            "score": 0.7242165803909302,
            "answer": "drank",
            "hit": false
          },
          {
            "score": 0.7175171971321106,
            "answer": "romney",
            "hit": false
          },
          {
            "score": 0.7138091921806335,
            "answer": "tai",
            "hit": false
          },
          {
            "score": 0.713779091835022,
            "answer": "herbal",
            "hit": false
          }
        ],
        "set_exclude": [
          "tea"
        ],
        "rank": 83,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6307893097400665,
        "b in neighbourhood of b_prime": 8203,
        "b_prime in neighbourhood of b": 84
      },
      {
        "question verbose": "What is to tomato ",
        "b": "tomato",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.9140973687171936,
            "answer": "tomatoes",
            "hit": false
          },
          {
            "score": 0.7978475093841553,
            "answer": "vegetable",
            "hit": false
          },
          {
            "score": 0.7966240644454956,
            "answer": "vegetables",
            "hit": false
          },
          {
            "score": 0.7805091142654419,
            "answer": "cabbage",
            "hit": false
          },
          {
            "score": 0.7771070599555969,
            "answer": "garlic",
            "hit": false
          },
          {
            "score": 0.7764014005661011,
            "answer": "pasta",
            "hit": false
          }
        ],
        "set_exclude": [
          "tomato"
        ],
        "rank": 1502,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6697942018508911,
        "b in neighbourhood of b_prime": 25,
        "b_prime in neighbourhood of b": 1503
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 34,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E09 [things - color].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "130d5ef5-4de9-4422-b809-0026c19d7f2e",
      "timestamp": "2025-05-17T17:08:17.391099"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to actor ",
        "b": "actor",
        "expected answer": [
          "actress"
        ],
        "predictions": [
          {
            "score": 0.7292771339416504,
            "answer": "actress",
            "hit": true
          },
          {
            "score": 0.7239125967025757,
            "answer": "actors",
            "hit": false
          },
          {
            "score": 0.7211012840270996,
            "answer": "actions",
            "hit": false
          },
          {
            "score": 0.7007498741149902,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7006109356880188,
            "answer": "reactor",
            "hit": false
          },
          {
            "score": 0.6990481615066528,
            "answer": "actresses",
            "hit": false
          }
        ],
        "set_exclude": [
          "actor"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7292771637439728,
        "b in neighbourhood of b_prime": 47,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to boy ",
        "b": "boy",
        "expected answer": [
          "girl"
        ],
        "predictions": [
          {
            "score": 0.8008265495300293,
            "answer": "boys",
            "hit": false
          },
          {
            "score": 0.7395128011703491,
            "answer": "girl",
            "hit": true
          },
          {
            "score": 0.7212668657302856,
            "answer": "kid",
            "hit": false
          },
          {
            "score": 0.7157836556434631,
            "answer": "young",
            "hit": false
          },
          {
            "score": 0.7027356624603271,
            "answer": "boycott",
            "hit": false
          },
          {
            "score": 0.7012293338775635,
            "answer": "girls",
            "hit": false
          }
        ],
        "set_exclude": [
          "boy"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7395128011703491,
        "b in neighbourhood of b_prime": 18,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to brother ",
        "b": "brother",
        "expected answer": [
          "sister"
        ],
        "predictions": [
          {
            "score": 0.8259430527687073,
            "answer": "sibling",
            "hit": false
          },
          {
            "score": 0.816154956817627,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.8107480406761169,
            "answer": "father",
            "hit": false
          },
          {
            "score": 0.8067585229873657,
            "answer": "nephew",
            "hit": false
          },
          {
            "score": 0.7973389625549316,
            "answer": "siblings",
            "hit": false
          },
          {
            "score": 0.7924914956092834,
            "answer": "sisters",
            "hit": false
          }
        ],
        "set_exclude": [
          "brother"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7673939764499664,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 10
      },
      {
        "question verbose": "What is to buck ",
        "b": "buck",
        "expected answer": [
          "doe"
        ],
        "predictions": [
          {
            "score": 0.7449420690536499,
            "answer": "bucket",
            "hit": false
          },
          {
            "score": 0.7108566164970398,
            "answer": "bucks",
            "hit": false
          },
          {
            "score": 0.6855683326721191,
            "answer": "dick",
            "hit": false
          },
          {
            "score": 0.684253990650177,
            "answer": "retrieve",
            "hit": false
          },
          {
            "score": 0.683378279209137,
            "answer": "bolt",
            "hit": false
          },
          {
            "score": 0.6816734075546265,
            "answer": "burst",
            "hit": false
          }
        ],
        "set_exclude": [
          "buck"
        ],
        "rank": 1514,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6390469372272491,
        "b in neighbourhood of b_prime": 7425,
        "b_prime in neighbourhood of b": 1515
      },
      {
        "question verbose": "What is to bull ",
        "b": "bull",
        "expected answer": [
          "cow"
        ],
        "predictions": [
          {
            "score": 0.7832232713699341,
            "answer": "bulls",
            "hit": false
          },
          {
            "score": 0.7239207029342651,
            "answer": "bullying",
            "hit": false
          },
          {
            "score": 0.7079081535339355,
            "answer": "stud",
            "hit": false
          },
          {
            "score": 0.7052664756774902,
            "answer": "bully",
            "hit": false
          },
          {
            "score": 0.6981232166290283,
            "answer": "bullet",
            "hit": false
          },
          {
            "score": 0.6926991939544678,
            "answer": "bailey",
            "hit": false
          }
        ],
        "set_exclude": [
          "bull"
        ],
        "rank": 278,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6550697535276413,
        "b in neighbourhood of b_prime": 952,
        "b_prime in neighbourhood of b": 279
      },
      {
        "question verbose": "What is to dad ",
        "b": "dad",
        "expected answer": [
          "mom",
          "mum"
        ],
        "predictions": [
          {
            "score": 0.7399879693984985,
            "answer": "daddy",
            "hit": false
          },
          {
            "score": 0.7349447011947632,
            "answer": "mom",
            "hit": true
          },
          {
            "score": 0.7345281839370728,
            "answer": "kids",
            "hit": false
          },
          {
            "score": 0.7260644435882568,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.7240458726882935,
            "answer": "father",
            "hit": false
          },
          {
            "score": 0.7136013507843018,
            "answer": "husband",
            "hit": false
          }
        ],
        "set_exclude": [
          "dad"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7349447011947632,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to duke ",
        "b": "duke",
        "expected answer": [
          "duchess"
        ],
        "predictions": [
          {
            "score": 0.7657279968261719,
            "answer": "duchess",
            "hit": true
          },
          {
            "score": 0.7461159825325012,
            "answer": "durham",
            "hit": false
          },
          {
            "score": 0.7455282211303711,
            "answer": "earl",
            "hit": false
          },
          {
            "score": 0.7256499528884888,
            "answer": "virginia",
            "hit": false
          },
          {
            "score": 0.7249325513839722,
            "answer": "yale",
            "hit": false
          },
          {
            "score": 0.7163968682289124,
            "answer": "baron",
            "hit": false
          }
        ],
        "set_exclude": [
          "duke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7657280564308167,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "mother"
        ],
        "predictions": [
          {
            "score": 0.8505372405052185,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.8422760367393494,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.8112649321556091,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.8107479810714722,
            "answer": "brother",
            "hit": false
          },
          {
            "score": 0.7902212142944336,
            "answer": "mothers",
            "hit": false
          },
          {
            "score": 0.7883284091949463,
            "answer": "parent",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7434776276350021,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 20
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "goddess"
        ],
        "predictions": [
          {
            "score": 0.7506275177001953,
            "answer": "gods",
            "hit": false
          },
          {
            "score": 0.7503312230110168,
            "answer": "goddess",
            "hit": true
          },
          {
            "score": 0.7422109842300415,
            "answer": "divine",
            "hit": false
          },
          {
            "score": 0.7373530268669128,
            "answer": "holy",
            "hit": false
          },
          {
            "score": 0.7314649820327759,
            "answer": "righteous",
            "hit": false
          },
          {
            "score": 0.729637622833252,
            "answer": "jesus",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7503312826156616,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to grandfather ",
        "b": "grandfather",
        "expected answer": [
          "grandmother"
        ],
        "predictions": [
          {
            "score": 0.8838768005371094,
            "answer": "grandmother",
            "hit": true
          },
          {
            "score": 0.8698620796203613,
            "answer": "grandparents",
            "hit": false
          },
          {
            "score": 0.8422760367393494,
            "answer": "father",
            "hit": false
          },
          {
            "score": 0.8260492086410522,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.8055313229560852,
            "answer": "uncle",
            "hit": false
          },
          {
            "score": 0.7867141962051392,
            "answer": "grandchildren",
            "hit": false
          }
        ],
        "set_exclude": [
          "grandfather"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.883876770734787,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to groom ",
        "b": "groom",
        "expected answer": [
          "bride"
        ],
        "predictions": [
          {
            "score": 0.7240847945213318,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.7227185964584351,
            "answer": "marry",
            "hit": false
          },
          {
            "score": 0.7219199538230896,
            "answer": "bride",
            "hit": true
          },
          {
            "score": 0.7112686038017273,
            "answer": "mentor",
            "hit": false
          },
          {
            "score": 0.7082165479660034,
            "answer": "marrying",
            "hit": false
          },
          {
            "score": 0.7052292227745056,
            "answer": "shepherd",
            "hit": false
          }
        ],
        "set_exclude": [
          "groom"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7219199687242508,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to husband ",
        "b": "husband",
        "expected answer": [
          "wife"
        ],
        "predictions": [
          {
            "score": 0.8287346363067627,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.8018804788589478,
            "answer": "boyfriend",
            "hit": false
          },
          {
            "score": 0.7767384052276611,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.7754215002059937,
            "answer": "spouse",
            "hit": false
          },
          {
            "score": 0.7683006525039673,
            "answer": "wives",
            "hit": false
          },
          {
            "score": 0.7640138864517212,
            "answer": "daughter",
            "hit": false
          }
        ],
        "set_exclude": [
          "husband"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7569128572940826,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to king ",
        "b": "king",
        "expected answer": [
          "queen"
        ],
        "predictions": [
          {
            "score": 0.8416463136672974,
            "answer": "ked",
            "hit": false
          },
          {
            "score": 0.706896960735321,
            "answer": "ching",
            "hit": false
          },
          {
            "score": 0.6937026977539062,
            "answer": "kings",
            "hit": false
          },
          {
            "score": 0.6926721334457397,
            "answer": "ken",
            "hit": false
          },
          {
            "score": 0.689612865447998,
            "answer": "ping",
            "hit": false
          },
          {
            "score": 0.6843224763870239,
            "answer": "queen",
            "hit": true
          }
        ],
        "set_exclude": [
          "king"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6843224465847015,
        "b in neighbourhood of b_prime": 283,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to man ",
        "b": "man",
        "expected answer": [
          "woman"
        ],
        "predictions": [
          {
            "score": 0.7612902522087097,
            "answer": "men",
            "hit": false
          },
          {
            "score": 0.7438511848449707,
            "answer": "woman",
            "hit": true
          },
          {
            "score": 0.721167802810669,
            "answer": "how",
            "hit": false
          },
          {
            "score": 0.7202800512313843,
            "answer": "guy",
            "hit": false
          },
          {
            "score": 0.7166202068328857,
            "answer": "manning",
            "hit": false
          },
          {
            "score": 0.7157124280929565,
            "answer": "manager",
            "hit": false
          }
        ],
        "set_exclude": [
          "man"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7438511848449707,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to nephew ",
        "b": "nephew",
        "expected answer": [
          "niece"
        ],
        "predictions": [
          {
            "score": 0.8860370516777039,
            "answer": "niece",
            "hit": true
          },
          {
            "score": 0.8705646395683289,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.8205127716064453,
            "answer": "uncle",
            "hit": false
          },
          {
            "score": 0.8204543590545654,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.806758463382721,
            "answer": "brother",
            "hit": false
          },
          {
            "score": 0.793709397315979,
            "answer": "daughters",
            "hit": false
          }
        ],
        "set_exclude": [
          "nephew"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8860370516777039,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to prince ",
        "b": "prince",
        "expected answer": [
          "princess"
        ],
        "predictions": [
          {
            "score": 0.8785029053688049,
            "answer": "princes",
            "hit": false
          },
          {
            "score": 0.7596352696418762,
            "answer": "princess",
            "hit": true
          },
          {
            "score": 0.7568549513816833,
            "answer": "monarch",
            "hit": false
          },
          {
            "score": 0.7552096843719482,
            "answer": "ruler",
            "hit": false
          },
          {
            "score": 0.7431875467300415,
            "answer": "nobility",
            "hit": false
          },
          {
            "score": 0.7408976554870605,
            "answer": "sultan",
            "hit": false
          }
        ],
        "set_exclude": [
          "prince"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.759635329246521,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to son ",
        "b": "son",
        "expected answer": [
          "daughter"
        ],
        "predictions": [
          {
            "score": 0.7645333409309387,
            "answer": "daughter",
            "hit": true
          },
          {
            "score": 0.7017014622688293,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.6949357390403748,
            "answer": "father",
            "hit": false
          },
          {
            "score": 0.6896145343780518,
            "answer": "nephew",
            "hit": false
          },
          {
            "score": 0.6892282962799072,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.6889896988868713,
            "answer": "child",
            "hit": false
          }
        ],
        "set_exclude": [
          "son"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7645333409309387,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to uncle ",
        "b": "uncle",
        "expected answer": [
          "aunt"
        ],
        "predictions": [
          {
            "score": 0.8205127716064453,
            "answer": "nephew",
            "hit": false
          },
          {
            "score": 0.8055313229560852,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.7954452633857727,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.7894864082336426,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.7828199863433838,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.7811307907104492,
            "answer": "father",
            "hit": false
          }
        ],
        "set_exclude": [
          "uncle"
        ],
        "rank": 1303,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6543403565883636,
        "b in neighbourhood of b_prime": 515,
        "b_prime in neighbourhood of b": 1304
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 18,
      "accuracy": 0.2777777777777778
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E10 [male - female].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "42756b42-33c2-497f-ba70-cfe7c28449d2",
      "timestamp": "2025-05-17T17:08:17.774003"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to atmosphere ",
        "b": "atmosphere",
        "expected answer": [
          "gas",
          "oxygen",
          "hydrogen",
          "nitrogen",
          "ozone"
        ],
        "predictions": [
          {
            "score": 0.7545241713523865,
            "answer": "vibe",
            "hit": false
          },
          {
            "score": 0.7498308420181274,
            "answer": "attitude",
            "hit": false
          },
          {
            "score": 0.7454556226730347,
            "answer": "atmospheric",
            "hit": false
          },
          {
            "score": 0.7364468574523926,
            "answer": "environments",
            "hit": false
          },
          {
            "score": 0.7333379983901978,
            "answer": "surroundings",
            "hit": false
          },
          {
            "score": 0.7271878719329834,
            "answer": "spectacle",
            "hit": false
          }
        ],
        "set_exclude": [
          "atmosphere"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6402457654476166,
        "b in neighbourhood of b_prime": 5047,
        "b_prime in neighbourhood of b": 18
      },
      {
        "question verbose": "What is to bag ",
        "b": "bag",
        "expected answer": [
          "leather",
          "fabric",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.758056640625,
            "answer": "backpack",
            "hit": false
          },
          {
            "score": 0.7574893832206726,
            "answer": "bags",
            "hit": false
          },
          {
            "score": 0.7497392892837524,
            "answer": "suitcase",
            "hit": false
          },
          {
            "score": 0.7489023208618164,
            "answer": "pouch",
            "hit": false
          },
          {
            "score": 0.740752100944519,
            "answer": "luggage",
            "hit": false
          },
          {
            "score": 0.7273328304290771,
            "answer": "cup",
            "hit": false
          }
        ],
        "set_exclude": [
          "bag"
        ],
        "rank": 30,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6818124651908875,
        "b in neighbourhood of b_prime": 312,
        "b_prime in neighbourhood of b": 31
      },
      {
        "question verbose": "What is to beard ",
        "b": "beard",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.7142278552055359,
            "answer": "facial",
            "hit": false
          },
          {
            "score": 0.7056649923324585,
            "answer": "barbecue",
            "hit": false
          },
          {
            "score": 0.7056488394737244,
            "answer": "scars",
            "hit": false
          },
          {
            "score": 0.7048090696334839,
            "answer": "becker",
            "hit": false
          },
          {
            "score": 0.7030958533287048,
            "answer": "burger",
            "hit": false
          },
          {
            "score": 0.7025819420814514,
            "answer": "eyebrows",
            "hit": false
          }
        ],
        "set_exclude": [
          "beard"
        ],
        "rank": 52,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6893640756607056,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 53
      },
      {
        "question verbose": "What is to body ",
        "b": "body",
        "expected answer": [
          "flesh",
          "bones"
        ],
        "predictions": [
          {
            "score": 0.8565253019332886,
            "answer": "bodies",
            "hit": false
          },
          {
            "score": 0.7416090965270996,
            "answer": "torso",
            "hit": false
          },
          {
            "score": 0.7407339811325073,
            "answer": "corpse",
            "hit": false
          },
          {
            "score": 0.7191576957702637,
            "answer": "organs",
            "hit": false
          },
          {
            "score": 0.7188793420791626,
            "answer": "bodily",
            "hit": false
          },
          {
            "score": 0.7108966112136841,
            "answer": "limbs",
            "hit": false
          }
        ],
        "set_exclude": [
          "body"
        ],
        "rank": 121,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6493856757879257,
        "b in neighbourhood of b_prime": 2703,
        "b_prime in neighbourhood of b": 122
      },
      {
        "question verbose": "What is to boots ",
        "b": "boots",
        "expected answer": [
          "leather",
          "canvas"
        ],
        "predictions": [
          {
            "score": 0.7811807990074158,
            "answer": "socks",
            "hit": false
          },
          {
            "score": 0.7735551595687866,
            "answer": "trousers",
            "hit": false
          },
          {
            "score": 0.7734561562538147,
            "answer": "shoes",
            "hit": false
          },
          {
            "score": 0.7555001974105835,
            "answer": "gloves",
            "hit": false
          },
          {
            "score": 0.7490208745002747,
            "answer": "boot",
            "hit": false
          },
          {
            "score": 0.7456576824188232,
            "answer": "jeans",
            "hit": false
          }
        ],
        "set_exclude": [
          "boots"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7227783203125,
        "b in neighbourhood of b_prime": 21,
        "b_prime in neighbourhood of b": 16
      },
      {
        "question verbose": "What is to bottle ",
        "b": "bottle",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.8327356576919556,
            "answer": "bottles",
            "hit": false
          },
          {
            "score": 0.7563563585281372,
            "answer": "drink",
            "hit": false
          },
          {
            "score": 0.7480366826057434,
            "answer": "drank",
            "hit": false
          },
          {
            "score": 0.7454930543899536,
            "answer": "beer",
            "hit": false
          },
          {
            "score": 0.734207034111023,
            "answer": "cans",
            "hit": false
          },
          {
            "score": 0.7340385913848877,
            "answer": "brewery",
            "hit": false
          }
        ],
        "set_exclude": [
          "bottle"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7154126465320587,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 25
      },
      {
        "question verbose": "What is to bowl ",
        "b": "bowl",
        "expected answer": [
          "glass",
          "china",
          "aluminium",
          "wood",
          "steel",
          "plastic",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.8106671571731567,
            "answer": "bowls",
            "hit": false
          },
          {
            "score": 0.732684314250946,
            "answer": "cups",
            "hit": false
          },
          {
            "score": 0.7152793407440186,
            "answer": "stadium",
            "hit": false
          },
          {
            "score": 0.7150564193725586,
            "answer": "touchdowns",
            "hit": false
          },
          {
            "score": 0.7113991975784302,
            "answer": "nfl",
            "hit": false
          },
          {
            "score": 0.7113866806030273,
            "answer": "basin",
            "hit": false
          }
        ],
        "set_exclude": [
          "bowl"
        ],
        "rank": 330,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6397040337324142,
        "b in neighbourhood of b_prime": 1355,
        "b_prime in neighbourhood of b": 331
      },
      {
        "question verbose": "What is to cocktail ",
        "b": "cocktail",
        "expected answer": [
          "alcohol",
          "juice",
          "water"
        ],
        "predictions": [
          {
            "score": 0.7587794065475464,
            "answer": "vodka",
            "hit": false
          },
          {
            "score": 0.7547882795333862,
            "answer": "drinks",
            "hit": false
          },
          {
            "score": 0.7536070346832275,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.7535407543182373,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.743592381477356,
            "answer": "champagne",
            "hit": false
          },
          {
            "score": 0.7427239418029785,
            "answer": "salad",
            "hit": false
          }
        ],
        "set_exclude": [
          "cocktail"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6863913238048553,
        "b in neighbourhood of b_prime": 426,
        "b_prime in neighbourhood of b": 26
      },
      {
        "question verbose": "What is to desk ",
        "b": "desk",
        "expected answer": [
          "wood",
          "metal",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.712963342666626,
            "answer": "pocket",
            "hit": false
          },
          {
            "score": 0.7056127786636353,
            "answer": "dashboard",
            "hit": false
          },
          {
            "score": 0.7015256285667419,
            "answer": "office",
            "hit": false
          },
          {
            "score": 0.7004335522651672,
            "answer": "bed",
            "hit": false
          },
          {
            "score": 0.7003960609436035,
            "answer": "cabinets",
            "hit": false
          },
          {
            "score": 0.7002734541893005,
            "answer": "tracker",
            "hit": false
          }
        ],
        "set_exclude": [
          "desk"
        ],
        "rank": 5874,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.5986645147204399,
        "b in neighbourhood of b_prime": 11850,
        "b_prime in neighbourhood of b": 5875
      },
      {
        "question verbose": "What is to diamond ",
        "b": "diamond",
        "expected answer": [
          "carbon"
        ],
        "predictions": [
          {
            "score": 0.8869652152061462,
            "answer": "diamonds",
            "hit": false
          },
          {
            "score": 0.758202314376831,
            "answer": "jewels",
            "hit": false
          },
          {
            "score": 0.7578406929969788,
            "answer": "platinum",
            "hit": false
          },
          {
            "score": 0.7345139980316162,
            "answer": "pearl",
            "hit": false
          },
          {
            "score": 0.7338700294494629,
            "answer": "jewelry",
            "hit": false
          },
          {
            "score": 0.7276475429534912,
            "answer": "titanium",
            "hit": false
          }
        ],
        "set_exclude": [
          "diamond"
        ],
        "rank": 673,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6563347280025482,
        "b in neighbourhood of b_prime": 991,
        "b_prime in neighbourhood of b": 674
      },
      {
        "question verbose": "What is to flag ",
        "b": "flag",
        "expected answer": [
          "fabric",
          "paper"
        ],
        "predictions": [
          {
            "score": 0.7996644973754883,
            "answer": "flags",
            "hit": false
          },
          {
            "score": 0.7056719660758972,
            "answer": "supporters",
            "hit": false
          },
          {
            "score": 0.7047958374023438,
            "answer": "empty",
            "hit": false
          },
          {
            "score": 0.7038686871528625,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.7027156352996826,
            "answer": "banner",
            "hit": false
          },
          {
            "score": 0.7023153305053711,
            "answer": "patriot",
            "hit": false
          }
        ],
        "set_exclude": [
          "flag"
        ],
        "rank": 7789,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.632568284869194,
        "b in neighbourhood of b_prime": 5879,
        "b_prime in neighbourhood of b": 7790
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "bricks",
          "cement",
          "wood",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.8265252709388733,
            "answer": "senate",
            "hit": false
          },
          {
            "score": 0.7936402559280396,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.7575827240943909,
            "answer": "household",
            "hit": false
          },
          {
            "score": 0.7562566995620728,
            "answer": "sen",
            "hit": false
          },
          {
            "score": 0.7475826740264893,
            "answer": "households",
            "hit": false
          },
          {
            "score": 0.7421005964279175,
            "answer": "mansion",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 2750,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6544760465621948,
        "b in neighbourhood of b_prime": 2861,
        "b_prime in neighbourhood of b": 2751
      },
      {
        "question verbose": "What is to jam ",
        "b": "jam",
        "expected answer": [
          "fruit",
          "sugar",
          "berries"
        ],
        "predictions": [
          {
            "score": 0.7125738859176636,
            "answer": "jake",
            "hit": false
          },
          {
            "score": 0.7110568881034851,
            "answer": "rash",
            "hit": false
          },
          {
            "score": 0.7100505232810974,
            "answer": "isa",
            "hit": false
          },
          {
            "score": 0.7083199620246887,
            "answer": "jamie",
            "hit": false
          },
          {
            "score": 0.7082905769348145,
            "answer": "jordan",
            "hit": false
          },
          {
            "score": 0.707641065120697,
            "answer": "tam",
            "hit": false
          }
        ],
        "set_exclude": [
          "jam"
        ],
        "rank": 4317,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6320752799510956,
        "b in neighbourhood of b_prime": 6784,
        "b_prime in neighbourhood of b": 4318
      },
      {
        "question verbose": "What is to lawn ",
        "b": "lawn",
        "expected answer": [
          "grass"
        ],
        "predictions": [
          {
            "score": 0.7830647230148315,
            "answer": "porch",
            "hit": false
          },
          {
            "score": 0.7818795442581177,
            "answer": "garden",
            "hit": false
          },
          {
            "score": 0.7794586420059204,
            "answer": "patio",
            "hit": false
          },
          {
            "score": 0.7695419788360596,
            "answer": "driveway",
            "hit": false
          },
          {
            "score": 0.765494704246521,
            "answer": "sidewalk",
            "hit": false
          },
          {
            "score": 0.761940598487854,
            "answer": "backyard",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawn"
        ],
        "rank": 65,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7046903669834137,
        "b in neighbourhood of b_prime": 9,
        "b_prime in neighbourhood of b": 66
      },
      {
        "question verbose": "What is to lens ",
        "b": "lens",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.7909489870071411,
            "answer": "lenses",
            "hit": false
          },
          {
            "score": 0.7093750238418579,
            "answer": "glasses",
            "hit": false
          },
          {
            "score": 0.7092751264572144,
            "answer": "window",
            "hit": false
          },
          {
            "score": 0.7017943263053894,
            "answer": "prism",
            "hit": false
          },
          {
            "score": 0.7009835839271545,
            "answer": "gazed",
            "hit": false
          },
          {
            "score": 0.7004774212837219,
            "answer": "optics",
            "hit": false
          }
        ],
        "set_exclude": [
          "lens"
        ],
        "rank": 337,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6693586111068726,
        "b in neighbourhood of b_prime": 84,
        "b_prime in neighbourhood of b": 338
      },
      {
        "question verbose": "What is to mirror ",
        "b": "mirror",
        "expected answer": [
          "glass",
          "bronze"
        ],
        "predictions": [
          {
            "score": 0.7710030674934387,
            "answer": "mirrors",
            "hit": false
          },
          {
            "score": 0.7252235412597656,
            "answer": "mir",
            "hit": false
          },
          {
            "score": 0.7184861302375793,
            "answer": "telegraph",
            "hit": false
          },
          {
            "score": 0.7152982950210571,
            "answer": "reflect",
            "hit": false
          },
          {
            "score": 0.7094380259513855,
            "answer": "guardian",
            "hit": false
          },
          {
            "score": 0.7065926790237427,
            "answer": "portal",
            "hit": false
          }
        ],
        "set_exclude": [
          "mirror"
        ],
        "rank": 59,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6761023700237274,
        "b in neighbourhood of b_prime": 42,
        "b_prime in neighbourhood of b": 60
      },
      {
        "question verbose": "What is to money ",
        "b": "money",
        "expected answer": [
          "paper",
          "metal",
          "silver",
          "gold",
          "iron",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.8188983201980591,
            "answer": "funds",
            "hit": false
          },
          {
            "score": 0.7757987976074219,
            "answer": "funding",
            "hit": false
          },
          {
            "score": 0.7663938999176025,
            "answer": "monetary",
            "hit": false
          },
          {
            "score": 0.7615723013877869,
            "answer": "revenue",
            "hit": false
          },
          {
            "score": 0.7609302997589111,
            "answer": "finances",
            "hit": false
          },
          {
            "score": 0.7479380965232849,
            "answer": "dollars",
            "hit": false
          }
        ],
        "set_exclude": [
          "money"
        ],
        "rank": 412,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6338240504264832,
        "b in neighbourhood of b_prime": 3465,
        "b_prime in neighbourhood of b": 413
      },
      {
        "question verbose": "What is to ocean ",
        "b": "ocean",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.8793432712554932,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7705351710319519,
            "answer": "maritime",
            "hit": false
          },
          {
            "score": 0.7703254818916321,
            "answer": "aquatic",
            "hit": false
          },
          {
            "score": 0.7621923089027405,
            "answer": "underwater",
            "hit": false
          },
          {
            "score": 0.7600003480911255,
            "answer": "submarine",
            "hit": false
          },
          {
            "score": 0.7590340375900269,
            "answer": "sea",
            "hit": false
          }
        ],
        "set_exclude": [
          "ocean"
        ],
        "rank": 108,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7002686560153961,
        "b in neighbourhood of b_prime": 82,
        "b_prime in neighbourhood of b": 109
      },
      {
        "question verbose": "What is to pastry ",
        "b": "pastry",
        "expected answer": [
          "flour",
          "egg",
          "butter",
          "filling"
        ],
        "predictions": [
          {
            "score": 0.7935540676116943,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.7923569679260254,
            "answer": "culinary",
            "hit": false
          },
          {
            "score": 0.7797315120697021,
            "answer": "pasta",
            "hit": false
          },
          {
            "score": 0.7779372930526733,
            "answer": "dough",
            "hit": false
          },
          {
            "score": 0.7740349173545837,
            "answer": "chefs",
            "hit": false
          },
          {
            "score": 0.7596279978752136,
            "answer": "cuisine",
            "hit": false
          }
        ],
        "set_exclude": [
          "pastry"
        ],
        "rank": 33,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7289271950721741,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 34
      },
      {
        "question verbose": "What is to penny ",
        "b": "penny",
        "expected answer": [
          "metal",
          "alloy",
          "bronze",
          "nickel",
          "zinc",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.7582976818084717,
            "answer": "penn",
            "hit": false
          },
          {
            "score": 0.7421335577964783,
            "answer": "cents",
            "hit": false
          },
          {
            "score": 0.7420561909675598,
            "answer": "dollar",
            "hit": false
          },
          {
            "score": 0.7293004989624023,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.7242042422294617,
            "answer": "coins",
            "hit": false
          },
          {
            "score": 0.7229757308959961,
            "answer": "euro",
            "hit": false
          }
        ],
        "set_exclude": [
          "penny"
        ],
        "rank": 47,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6221445202827454,
        "b in neighbourhood of b_prime": 9504,
        "b_prime in neighbourhood of b": 48
      },
      {
        "question verbose": "What is to pill ",
        "b": "pill",
        "expected answer": [
          "medicine",
          "drug"
        ],
        "predictions": [
          {
            "score": 0.7752659916877747,
            "answer": "pills",
            "hit": false
          },
          {
            "score": 0.7391088008880615,
            "answer": "pillars",
            "hit": false
          },
          {
            "score": 0.7246991395950317,
            "answer": "pillow",
            "hit": false
          },
          {
            "score": 0.7051998972892761,
            "answer": "drug",
            "hit": true
          },
          {
            "score": 0.6976525783538818,
            "answer": "medications",
            "hit": false
          },
          {
            "score": 0.6941457390785217,
            "answer": "roses",
            "hit": false
          }
        ],
        "set_exclude": [
          "pill"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6619614362716675,
        "b in neighbourhood of b_prime": 1166,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to plastic ",
        "b": "plastic",
        "expected answer": [
          "polymer",
          "oil",
          "gas",
          "coal"
        ],
        "predictions": [
          {
            "score": 0.8388819694519043,
            "answer": "plastics",
            "hit": false
          },
          {
            "score": 0.7782377600669861,
            "answer": "cardboard",
            "hit": false
          },
          {
            "score": 0.7658219337463379,
            "answer": "ceramic",
            "hit": false
          },
          {
            "score": 0.7633543610572815,
            "answer": "nylon",
            "hit": false
          },
          {
            "score": 0.7593502998352051,
            "answer": "wooden",
            "hit": false
          },
          {
            "score": 0.7524255514144897,
            "answer": "vinyl",
            "hit": false
          }
        ],
        "set_exclude": [
          "plastic"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7474893927574158,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 7
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.7914562225341797,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.7590340375900269,
            "answer": "ocean",
            "hit": false
          },
          {
            "score": 0.7389046549797058,
            "answer": "maritime",
            "hit": false
          },
          {
            "score": 0.7225472927093506,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7218091487884521,
            "answer": "naval",
            "hit": false
          },
          {
            "score": 0.7175421714782715,
            "answer": "coastal",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 52,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6843328475952148,
        "b in neighbourhood of b_prime": 325,
        "b_prime in neighbourhood of b": 53
      },
      {
        "question verbose": "What is to spoon ",
        "b": "spoon",
        "expected answer": [
          "aluminium",
          "wood",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.7181575298309326,
            "answer": "bottle",
            "hit": false
          },
          {
            "score": 0.7157764434814453,
            "answer": "shovel",
            "hit": false
          },
          {
            "score": 0.7134344577789307,
            "answer": "simmons",
            "hit": false
          },
          {
            "score": 0.7053144574165344,
            "answer": "beans",
            "hit": false
          },
          {
            "score": 0.7038516998291016,
            "answer": "plum",
            "hit": false
          },
          {
            "score": 0.7023546695709229,
            "answer": "pour",
            "hit": false
          }
        ],
        "set_exclude": [
          "spoon"
        ],
        "rank": 2470,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6255740523338318,
        "b in neighbourhood of b_prime": 10863,
        "b_prime in neighbourhood of b": 2471
      },
      {
        "question verbose": "What is to table ",
        "b": "table",
        "expected answer": [
          "wood",
          "metal",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.796868085861206,
            "answer": "tables",
            "hit": false
          },
          {
            "score": 0.6978545784950256,
            "answer": "podium",
            "hit": false
          },
          {
            "score": 0.6959198713302612,
            "answer": "sheet",
            "hit": false
          },
          {
            "score": 0.6939067840576172,
            "answer": "dining",
            "hit": false
          },
          {
            "score": 0.6938408613204956,
            "answer": "charts",
            "hit": false
          },
          {
            "score": 0.6910022497177124,
            "answer": "chair",
            "hit": false
          }
        ],
        "set_exclude": [
          "table"
        ],
        "rank": 2910,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6151750683784485,
        "b in neighbourhood of b_prime": 7014,
        "b_prime in neighbourhood of b": 2911
      },
      {
        "question verbose": "What is to wig ",
        "b": "wig",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.7225519418716431,
            "answer": "ludwig",
            "hit": false
          },
          {
            "score": 0.6926730275154114,
            "answer": "haired",
            "hit": false
          },
          {
            "score": 0.69017493724823,
            "answer": "witch",
            "hit": false
          },
          {
            "score": 0.6890625953674316,
            "answer": "glared",
            "hit": false
          },
          {
            "score": 0.6857831478118896,
            "answer": "grinned",
            "hit": false
          },
          {
            "score": 0.6851149201393127,
            "answer": "sweater",
            "hit": false
          }
        ],
        "set_exclude": [
          "wig"
        ],
        "rank": 4838,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6292958408594131,
        "b in neighbourhood of b_prime": 5370,
        "b_prime in neighbourhood of b": 4839
      },
      {
        "question verbose": "What is to wine ",
        "b": "wine",
        "expected answer": [
          "grapes",
          "grape"
        ],
        "predictions": [
          {
            "score": 0.8963229656219482,
            "answer": "wines",
            "hit": false
          },
          {
            "score": 0.8113346099853516,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.7984058260917664,
            "answer": "liquor",
            "hit": false
          },
          {
            "score": 0.7967344522476196,
            "answer": "champagne",
            "hit": false
          },
          {
            "score": 0.7949397563934326,
            "answer": "grapes",
            "hit": true
          },
          {
            "score": 0.7764785289764404,
            "answer": "vodka",
            "hit": false
          }
        ],
        "set_exclude": [
          "wine"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.794939786195755,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to wire ",
        "b": "wire",
        "expected answer": [
          "metal"
        ],
        "predictions": [
          {
            "score": 0.7673543691635132,
            "answer": "wireless",
            "hit": false
          },
          {
            "score": 0.7632546424865723,
            "answer": "wires",
            "hit": false
          },
          {
            "score": 0.7347080111503601,
            "answer": "wiring",
            "hit": false
          },
          {
            "score": 0.7223826050758362,
            "answer": "wired",
            "hit": false
          },
          {
            "score": 0.7221792340278625,
            "answer": "gate",
            "hit": false
          },
          {
            "score": 0.7076359987258911,
            "answer": "ethernet",
            "hit": false
          }
        ],
        "set_exclude": [
          "wire"
        ],
        "rank": 2207,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6455896198749542,
        "b in neighbourhood of b_prime": 3122,
        "b_prime in neighbourhood of b": 2208
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 28,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L04 [meronyms - substance].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "f1e3b057-18f2-413c-ae21-ec235d47e926",
      "timestamp": "2025-05-17T17:08:17.933500"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bird ",
        "b": "bird",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.7601063251495361,
            "answer": "birds",
            "hit": false
          },
          {
            "score": 0.708508312702179,
            "answer": "hawk",
            "hit": false
          },
          {
            "score": 0.7070355415344238,
            "answer": "feathers",
            "hit": false
          },
          {
            "score": 0.7001973390579224,
            "answer": "frog",
            "hit": false
          },
          {
            "score": 0.698643147945404,
            "answer": "berries",
            "hit": false
          },
          {
            "score": 0.698403000831604,
            "answer": "chickens",
            "hit": false
          }
        ],
        "set_exclude": [
          "bird"
        ],
        "rank": 40,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6817476749420166,
        "b in neighbourhood of b_prime": 248,
        "b_prime in neighbourhood of b": 41
      },
      {
        "question verbose": "What is to calf ",
        "b": "calf",
        "expected answer": [
          "cattle",
          "herd"
        ],
        "predictions": [
          {
            "score": 0.874533474445343,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.8033495545387268,
            "answer": "thigh",
            "hit": false
          },
          {
            "score": 0.7711011171340942,
            "answer": "ankle",
            "hit": false
          },
          {
            "score": 0.7493276000022888,
            "answer": "forearm",
            "hit": false
          },
          {
            "score": 0.7485572695732117,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7338138818740845,
            "answer": "cattle",
            "hit": true
          }
        ],
        "set_exclude": [
          "calf"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7338138371706009,
        "b in neighbourhood of b_prime": 30,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "train",
          "procession"
        ],
        "predictions": [
          {
            "score": 0.7539123296737671,
            "answer": "carol",
            "hit": false
          },
          {
            "score": 0.743114709854126,
            "answer": "carbon",
            "hit": false
          },
          {
            "score": 0.7410986423492432,
            "answer": "carroll",
            "hit": false
          },
          {
            "score": 0.7396153211593628,
            "answer": "carrie",
            "hit": false
          },
          {
            "score": 0.7378537654876709,
            "answer": "caroline",
            "hit": false
          },
          {
            "score": 0.7370608448982239,
            "answer": "carolina",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 7228,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6243382170796394,
        "b in neighbourhood of b_prime": 5252,
        "b_prime in neighbourhood of b": 7229
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.889541506767273,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.8544242978096008,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7979198694229126,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7964810132980347,
            "answer": "poultry",
            "hit": false
          },
          {
            "score": 0.7857985496520996,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.785063624382019,
            "answer": "goats",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7495171129703522,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 15
      },
      {
        "question verbose": "What is to christian ",
        "b": "christian",
        "expected answer": [
          "congregation",
          "church",
          "parish"
        ],
        "predictions": [
          {
            "score": 0.8521656394004822,
            "answer": "christianity",
            "hit": false
          },
          {
            "score": 0.840271532535553,
            "answer": "christians",
            "hit": false
          },
          {
            "score": 0.8019970059394836,
            "answer": "catholic",
            "hit": false
          },
          {
            "score": 0.7952686548233032,
            "answer": "protestant",
            "hit": false
          },
          {
            "score": 0.7943001985549927,
            "answer": "pagan",
            "hit": false
          },
          {
            "score": 0.794206440448761,
            "answer": "theological",
            "hit": false
          }
        ],
        "set_exclude": [
          "christian"
        ],
        "rank": 40,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7108355462551117,
        "b in neighbourhood of b_prime": 174,
        "b_prime in neighbourhood of b": 41
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "university"
        ],
        "predictions": [
          {
            "score": 0.8130283951759338,
            "answer": "colleges",
            "hit": false
          },
          {
            "score": 0.759343683719635,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.7561167478561401,
            "answer": "student",
            "hit": false
          },
          {
            "score": 0.7542060613632202,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.750249981880188,
            "answer": "universities",
            "hit": false
          },
          {
            "score": 0.7487351894378662,
            "answer": "graduate",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 17,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7297011613845825,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 18
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "state",
          "country"
        ],
        "predictions": [
          {
            "score": 0.8201019763946533,
            "answer": "counties",
            "hit": false
          },
          {
            "score": 0.7804955244064331,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.7661525011062622,
            "answer": "sheriff",
            "hit": false
          },
          {
            "score": 0.7337665557861328,
            "answer": "parish",
            "hit": false
          },
          {
            "score": 0.7320931553840637,
            "answer": "province",
            "hit": false
          },
          {
            "score": 0.7297446727752686,
            "answer": "municipality",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7155953049659729,
        "b in neighbourhood of b_prime": 22,
        "b_prime in neighbourhood of b": 12
      },
      {
        "question verbose": "What is to cow ",
        "b": "cow",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.7520174384117126,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7271978259086609,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.7187251448631287,
            "answer": "coward",
            "hit": false
          },
          {
            "score": 0.7083468437194824,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.702919065952301,
            "answer": "buffalo",
            "hit": false
          },
          {
            "score": 0.701927661895752,
            "answer": "animal",
            "hit": false
          }
        ],
        "set_exclude": [
          "cow"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6891691386699677,
        "b in neighbourhood of b_prime": 82,
        "b_prime in neighbourhood of b": 24
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "murder"
        ],
        "predictions": [
          {
            "score": 0.7227059006690979,
            "answer": "raven",
            "hit": false
          },
          {
            "score": 0.7126323580741882,
            "answer": "exclaimed",
            "hit": false
          },
          {
            "score": 0.7105799317359924,
            "answer": "turkey",
            "hit": false
          },
          {
            "score": 0.7093703746795654,
            "answer": "hawk",
            "hit": false
          },
          {
            "score": 0.7073087692260742,
            "answer": "chuckled",
            "hit": false
          },
          {
            "score": 0.7042579650878906,
            "answer": "lion",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 2661,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6408639550209045,
        "b in neighbourhood of b_prime": 7215,
        "b_prime in neighbourhood of b": 2662
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8993592262268066,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7780378460884094,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.7580479979515076,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.7507907748222351,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.7356374263763428,
            "answer": "buffalo",
            "hit": false
          },
          {
            "score": 0.7307971715927124,
            "answer": "animal",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 68,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6984969228506088,
        "b in neighbourhood of b_prime": 41,
        "b_prime in neighbourhood of b": 69
      },
      {
        "question verbose": "What is to employee ",
        "b": "employee",
        "expected answer": [
          "staff",
          "company"
        ],
        "predictions": [
          {
            "score": 0.8088201880455017,
            "answer": "employees",
            "hit": false
          },
          {
            "score": 0.7966153025627136,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.7858006954193115,
            "answer": "employment",
            "hit": false
          },
          {
            "score": 0.7736939787864685,
            "answer": "worker",
            "hit": false
          },
          {
            "score": 0.7693206071853638,
            "answer": "employer",
            "hit": false
          },
          {
            "score": 0.7597478628158569,
            "answer": "corporate",
            "hit": false
          }
        ],
        "set_exclude": [
          "employee"
        ],
        "rank": 66,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7078916430473328,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 67
      },
      {
        "question verbose": "What is to fish ",
        "b": "fish",
        "expected answer": [
          "school"
        ],
        "predictions": [
          {
            "score": 0.771133542060852,
            "answer": "fishes",
            "hit": false
          },
          {
            "score": 0.7606175541877747,
            "answer": "seafood",
            "hit": false
          },
          {
            "score": 0.7599894404411316,
            "answer": "fishing",
            "hit": false
          },
          {
            "score": 0.7483283877372742,
            "answer": "salmon",
            "hit": false
          },
          {
            "score": 0.7406714558601379,
            "answer": "fishermen",
            "hit": false
          },
          {
            "score": 0.7332609295845032,
            "answer": "trout",
            "hit": false
          }
        ],
        "set_exclude": [
          "fish"
        ],
        "rank": 9674,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6142226308584213,
        "b in neighbourhood of b_prime": 12690,
        "b_prime in neighbourhood of b": 9675
      },
      {
        "question verbose": "What is to galaxy ",
        "b": "galaxy",
        "expected answer": [
          "universe"
        ],
        "predictions": [
          {
            "score": 0.8681043386459351,
            "answer": "galaxies",
            "hit": false
          },
          {
            "score": 0.8038704991340637,
            "answer": "milky",
            "hit": false
          },
          {
            "score": 0.7992663383483887,
            "answer": "galactic",
            "hit": false
          },
          {
            "score": 0.7799360156059265,
            "answer": "planet",
            "hit": false
          },
          {
            "score": 0.7702775001525879,
            "answer": "planets",
            "hit": false
          },
          {
            "score": 0.7683898210525513,
            "answer": "universe",
            "hit": true
          }
        ],
        "set_exclude": [
          "galaxy"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.768389880657196,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to letter ",
        "b": "letter",
        "expected answer": [
          "alphabet"
        ],
        "predictions": [
          {
            "score": 0.7428372502326965,
            "answer": "letters",
            "hit": false
          },
          {
            "score": 0.7246060371398926,
            "answer": "memorandum",
            "hit": false
          },
          {
            "score": 0.7199884653091431,
            "answer": "correspondence",
            "hit": false
          },
          {
            "score": 0.7170854806900024,
            "answer": "memo",
            "hit": false
          },
          {
            "score": 0.710412323474884,
            "answer": "essay",
            "hit": false
          },
          {
            "score": 0.7034865617752075,
            "answer": "poem",
            "hit": false
          }
        ],
        "set_exclude": [
          "letter"
        ],
        "rank": 80,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6764756143093109,
        "b in neighbourhood of b_prime": 95,
        "b_prime in neighbourhood of b": 81
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "pride"
        ],
        "predictions": [
          {
            "score": 0.7829467058181763,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.7507907748222351,
            "answer": "elephant",
            "hit": false
          },
          {
            "score": 0.735672116279602,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.7301043272018433,
            "answer": "lions",
            "hit": false
          },
          {
            "score": 0.726118266582489,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.7217254638671875,
            "answer": "dragon",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 821,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6574724763631821,
        "b in neighbourhood of b_prime": 1354,
        "b_prime in neighbourhood of b": 822
      },
      {
        "question verbose": "What is to listener ",
        "b": "listener",
        "expected answer": [
          "audience"
        ],
        "predictions": [
          {
            "score": 0.8923512697219849,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.8038448095321655,
            "answer": "viewer",
            "hit": false
          },
          {
            "score": 0.7867386341094971,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.756328284740448,
            "answer": "viewers",
            "hit": false
          },
          {
            "score": 0.7540489435195923,
            "answer": "listen",
            "hit": false
          },
          {
            "score": 0.7446850538253784,
            "answer": "listened",
            "hit": false
          }
        ],
        "set_exclude": [
          "listener"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7404283881187439,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "club",
          "team",
          "group",
          "band",
          "community"
        ],
        "predictions": [
          {
            "score": 0.7721220850944519,
            "answer": "members",
            "hit": false
          },
          {
            "score": 0.7577340602874756,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.7467868328094482,
            "answer": "chairman",
            "hit": false
          },
          {
            "score": 0.7212650775909424,
            "answer": "partner",
            "hit": false
          },
          {
            "score": 0.719831109046936,
            "answer": "supporter",
            "hit": false
          },
          {
            "score": 0.71694415807724,
            "answer": "representative",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 1384,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6421319246292114,
        "b in neighbourhood of b_prime": 919,
        "b_prime in neighbourhood of b": 1385
      },
      {
        "question verbose": "What is to musician ",
        "b": "musician",
        "expected answer": [
          "orchestra",
          "band"
        ],
        "predictions": [
          {
            "score": 0.8956692218780518,
            "answer": "musicians",
            "hit": false
          },
          {
            "score": 0.8535985946655273,
            "answer": "guitarist",
            "hit": false
          },
          {
            "score": 0.841291606426239,
            "answer": "rapper",
            "hit": false
          },
          {
            "score": 0.8376573324203491,
            "answer": "drummer",
            "hit": false
          },
          {
            "score": 0.8259215354919434,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.8225506544113159,
            "answer": "composer",
            "hit": false
          }
        ],
        "set_exclude": [
          "musician"
        ],
        "rank": 28,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7667799293994904,
        "b in neighbourhood of b_prime": 12,
        "b_prime in neighbourhood of b": 29
      },
      {
        "question verbose": "What is to person ",
        "b": "person",
        "expected answer": [
          "society",
          "company",
          "party",
          "world"
        ],
        "predictions": [
          {
            "score": 0.7598477602005005,
            "answer": "personal",
            "hit": false
          },
          {
            "score": 0.7409095168113708,
            "answer": "want",
            "hit": false
          },
          {
            "score": 0.7405575513839722,
            "answer": "someone",
            "hit": false
          },
          {
            "score": 0.7400200366973877,
            "answer": "personnel",
            "hit": false
          },
          {
            "score": 0.7398179173469543,
            "answer": "persons",
            "hit": false
          },
          {
            "score": 0.7341009974479675,
            "answer": "two",
            "hit": false
          }
        ],
        "set_exclude": [
          "person"
        ],
        "rank": 991,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6294749528169632,
        "b in neighbourhood of b_prime": 4356,
        "b_prime in neighbourhood of b": 992
      },
      {
        "question verbose": "What is to photo ",
        "b": "photo",
        "expected answer": [
          "album",
          "collection",
          "library"
        ],
        "predictions": [
          {
            "score": 0.8078331351280212,
            "answer": "photos",
            "hit": false
          },
          {
            "score": 0.7878230810165405,
            "answer": "picture",
            "hit": false
          },
          {
            "score": 0.7707920074462891,
            "answer": "photographed",
            "hit": false
          },
          {
            "score": 0.7679978013038635,
            "answer": "photograph",
            "hit": false
          },
          {
            "score": 0.7669122815132141,
            "answer": "photographs",
            "hit": false
          },
          {
            "score": 0.7607861161231995,
            "answer": "photography",
            "hit": false
          }
        ],
        "set_exclude": [
          "photo"
        ],
        "rank": 204,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.664933443069458,
        "b in neighbourhood of b_prime": 480,
        "b_prime in neighbourhood of b": 205
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "team",
          "group",
          "orchestra"
        ],
        "predictions": [
          {
            "score": 0.8904734253883362,
            "answer": "players",
            "hit": false
          },
          {
            "score": 0.7460964918136597,
            "answer": "footballer",
            "hit": false
          },
          {
            "score": 0.7446168661117554,
            "answer": "midfielder",
            "hit": false
          },
          {
            "score": 0.743523895740509,
            "answer": "defender",
            "hit": false
          },
          {
            "score": 0.7379502058029175,
            "answer": "user",
            "hit": false
          },
          {
            "score": 0.7316170334815979,
            "answer": "athlete",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 69,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6735675632953644,
        "b in neighbourhood of b_prime": 336,
        "b_prime in neighbourhood of b": 70
      },
      {
        "question verbose": "What is to policeman ",
        "b": "policeman",
        "expected answer": [
          "police"
        ],
        "predictions": [
          {
            "score": 0.8141381740570068,
            "answer": "police",
            "hit": true
          },
          {
            "score": 0.8140254020690918,
            "answer": "cops",
            "hit": false
          },
          {
            "score": 0.7772202491760254,
            "answer": "officers",
            "hit": false
          },
          {
            "score": 0.7703613042831421,
            "answer": "policing",
            "hit": false
          },
          {
            "score": 0.767123281955719,
            "answer": "businessman",
            "hit": false
          },
          {
            "score": 0.7670624852180481,
            "answer": "prosecutor",
            "hit": false
          }
        ],
        "set_exclude": [
          "policeman"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8141382336616516,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to secretary ",
        "b": "secretary",
        "expected answer": [
          "staff"
        ],
        "predictions": [
          {
            "score": 0.7883399724960327,
            "answer": "mayor",
            "hit": false
          },
          {
            "score": 0.7816746830940247,
            "answer": "minister",
            "hit": false
          },
          {
            "score": 0.779728889465332,
            "answer": "department",
            "hit": false
          },
          {
            "score": 0.7781148552894592,
            "answer": "director",
            "hit": false
          },
          {
            "score": 0.770287275314331,
            "answer": "clinton",
            "hit": false
          },
          {
            "score": 0.7700101137161255,
            "answer": "ambassador",
            "hit": false
          }
        ],
        "set_exclude": [
          "secretary"
        ],
        "rank": 4092,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6654912531375885,
        "b in neighbourhood of b_prime": 189,
        "b_prime in neighbourhood of b": 4093
      },
      {
        "question verbose": "What is to senator ",
        "b": "senator",
        "expected answer": [
          "senate",
          "house"
        ],
        "predictions": [
          {
            "score": 0.8846218585968018,
            "answer": "senators",
            "hit": false
          },
          {
            "score": 0.8645694255828857,
            "answer": "congressman",
            "hit": false
          },
          {
            "score": 0.8205169439315796,
            "answer": "politician",
            "hit": false
          },
          {
            "score": 0.8199389576911926,
            "answer": "sen",
            "hit": false
          },
          {
            "score": 0.8081085681915283,
            "answer": "senate",
            "hit": true
          },
          {
            "score": 0.7797813415527344,
            "answer": "legislators",
            "hit": false
          }
        ],
        "set_exclude": [
          "senator"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8081085085868835,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to sheep ",
        "b": "sheep",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.7975096106529236,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7857985496520996,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.7841618657112122,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.7798341512680054,
            "answer": "chickens",
            "hit": false
          },
          {
            "score": 0.7623336911201477,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7576043009757996,
            "answer": "rabbits",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheep"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7444807291030884,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to soldier ",
        "b": "soldier",
        "expected answer": [
          "army",
          "unit",
          "division",
          "troop"
        ],
        "predictions": [
          {
            "score": 0.7741568088531494,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.769872784614563,
            "answer": "sold",
            "hit": false
          },
          {
            "score": 0.732219934463501,
            "answer": "army",
            "hit": true
          },
          {
            "score": 0.7233134508132935,
            "answer": "warrior",
            "hit": false
          },
          {
            "score": 0.7226921319961548,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.7168595790863037,
            "answer": "regiment",
            "hit": false
          }
        ],
        "set_exclude": [
          "soldier"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.732219934463501,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to spouse ",
        "b": "spouse",
        "expected answer": [
          "couple",
          "relationship",
          "family"
        ],
        "predictions": [
          {
            "score": 0.797299325466156,
            "answer": "marital",
            "hit": false
          },
          {
            "score": 0.7918417453765869,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.7783046960830688,
            "answer": "wife",
            "hit": false
          },
          {
            "score": 0.7777180671691895,
            "answer": "married",
            "hit": false
          },
          {
            "score": 0.7754215002059937,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.7704504132270813,
            "answer": "boyfriend",
            "hit": false
          }
        ],
        "set_exclude": [
          "spouse"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6967961490154266,
        "b in neighbourhood of b_prime": 16,
        "b_prime in neighbourhood of b": 24
      },
      {
        "question verbose": "What is to state ",
        "b": "state",
        "expected answer": [
          "country",
          "province"
        ],
        "predictions": [
          {
            "score": 0.7499576807022095,
            "answer": "government",
            "hit": false
          },
          {
            "score": 0.7414724826812744,
            "answer": "senate",
            "hit": false
          },
          {
            "score": 0.7392612099647522,
            "answer": "statewide",
            "hit": false
          },
          {
            "score": 0.7391709089279175,
            "answer": "california",
            "hit": false
          },
          {
            "score": 0.7363561391830444,
            "answer": "gov",
            "hit": false
          },
          {
            "score": 0.736197829246521,
            "answer": "govern",
            "hit": false
          }
        ],
        "set_exclude": [
          "state"
        ],
        "rank": 91,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6815077364444733,
        "b in neighbourhood of b_prime": 78,
        "b_prime in neighbourhood of b": 92
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "class",
          "school"
        ],
        "predictions": [
          {
            "score": 0.8302891254425049,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.7793548107147217,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.7724264860153198,
            "answer": "pupil",
            "hit": false
          },
          {
            "score": 0.7706528306007385,
            "answer": "classroom",
            "hit": false
          },
          {
            "score": 0.7705467343330383,
            "answer": "school",
            "hit": true
          },
          {
            "score": 0.7687652111053467,
            "answer": "tuition",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6882646828889847,
        "b in neighbourhood of b_prime": 68,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to tree ",
        "b": "tree",
        "expected answer": [
          "forest",
          "wood",
          "grove"
        ],
        "predictions": [
          {
            "score": 0.8287115693092346,
            "answer": "trees",
            "hit": false
          },
          {
            "score": 0.7300183773040771,
            "answer": "forest",
            "hit": true
          },
          {
            "score": 0.7231786251068115,
            "answer": "leaf",
            "hit": false
          },
          {
            "score": 0.7145270705223083,
            "answer": "vegetation",
            "hit": false
          },
          {
            "score": 0.7098603248596191,
            "answer": "forests",
            "hit": false
          },
          {
            "score": 0.7083715200424194,
            "answer": "leaves",
            "hit": false
          }
        ],
        "set_exclude": [
          "tree"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7300184071063995,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "pack"
        ],
        "predictions": [
          {
            "score": 0.7867357730865479,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.7210699319839478,
            "answer": "vampire",
            "hit": false
          },
          {
            "score": 0.6951887011528015,
            "answer": "woods",
            "hit": false
          },
          {
            "score": 0.6947922110557556,
            "answer": "bird",
            "hit": false
          },
          {
            "score": 0.6947599649429321,
            "answer": "monster",
            "hit": false
          },
          {
            "score": 0.6939250826835632,
            "answer": "walker",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 1403,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6433722674846649,
        "b in neighbourhood of b_prime": 875,
        "b_prime in neighbourhood of b": 1404
      },
      {
        "question verbose": "What is to word ",
        "b": "word",
        "expected answer": [
          "paragraph",
          "sentence",
          "text"
        ],
        "predictions": [
          {
            "score": 0.7337354421615601,
            "answer": "words",
            "hit": false
          },
          {
            "score": 0.7190740704536438,
            "answer": "someone",
            "hit": false
          },
          {
            "score": 0.7181334495544434,
            "answer": "html",
            "hit": false
          },
          {
            "score": 0.7178678512573242,
            "answer": "text",
            "hit": true
          },
          {
            "score": 0.715348482131958,
            "answer": "vocabulary",
            "hit": false
          },
          {
            "score": 0.7136165499687195,
            "answer": "phrase",
            "hit": false
          }
        ],
        "set_exclude": [
          "word"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6661671102046967,
        "b in neighbourhood of b_prime": 1119,
        "b_prime in neighbourhood of b": 4
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 32,
      "accuracy": 0.03125
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L05 [meronyms - member].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "8421db77-a658-4e87-ba30-aa729292c4b6",
      "timestamp": "2025-05-17T17:08:18.232460"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bus ",
        "b": "bus",
        "expected answer": [
          "seats",
          "conductor",
          "window",
          "driver",
          "roof"
        ],
        "predictions": [
          {
            "score": 0.7675849199295044,
            "answer": "buses",
            "hit": false
          },
          {
            "score": 0.7095817923545837,
            "answer": "beer",
            "hit": false
          },
          {
            "score": 0.7095338702201843,
            "answer": "ford",
            "hit": false
          },
          {
            "score": 0.7059971690177917,
            "answer": "bush",
            "hit": false
          },
          {
            "score": 0.70108962059021,
            "answer": "taxi",
            "hit": false
          },
          {
            "score": 0.6999204158782959,
            "answer": "trucks",
            "hit": false
          }
        ],
        "set_exclude": [
          "bus"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6353269517421722,
        "b in neighbourhood of b_prime": 4417,
        "b_prime in neighbourhood of b": 25
      },
      {
        "question verbose": "What is to byte ",
        "b": "byte",
        "expected answer": [
          "bit"
        ],
        "predictions": [
          {
            "score": 0.7934213876724243,
            "answer": "bytes",
            "hit": false
          },
          {
            "score": 0.7188728451728821,
            "answer": "integer",
            "hit": false
          },
          {
            "score": 0.715887188911438,
            "answer": "pixel",
            "hit": false
          },
          {
            "score": 0.7059919238090515,
            "answer": "cpu",
            "hit": false
          },
          {
            "score": 0.7037510871887207,
            "answer": "seconds",
            "hit": false
          },
          {
            "score": 0.703408420085907,
            "answer": "unicode",
            "hit": false
          }
        ],
        "set_exclude": [
          "byte"
        ],
        "rank": 104,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6815984696149826,
        "b in neighbourhood of b_prime": 103,
        "b_prime in neighbourhood of b": 105
      },
      {
        "question verbose": "What is to comb ",
        "b": "comb",
        "expected answer": [
          "teeth",
          "shaft",
          "grip",
          "tooth",
          "handle"
        ],
        "predictions": [
          {
            "score": 0.7033475637435913,
            "answer": "confront",
            "hit": false
          },
          {
            "score": 0.6987029314041138,
            "answer": "brushes",
            "hit": false
          },
          {
            "score": 0.6922715902328491,
            "answer": "brushing",
            "hit": false
          },
          {
            "score": 0.6911767721176147,
            "answer": "brushed",
            "hit": false
          },
          {
            "score": 0.6900638341903687,
            "answer": "battling",
            "hit": false
          },
          {
            "score": 0.6899415254592896,
            "answer": "combining",
            "hit": false
          }
        ],
        "set_exclude": [
          "comb"
        ],
        "rank": 2198,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6295885145664215,
        "b in neighbourhood of b_prime": 4898,
        "b_prime in neighbourhood of b": 2199
      },
      {
        "question verbose": "What is to dollar ",
        "b": "dollar",
        "expected answer": [
          "cent"
        ],
        "predictions": [
          {
            "score": 0.8283206224441528,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.7463005185127258,
            "answer": "usd",
            "hit": false
          },
          {
            "score": 0.7420561909675598,
            "answer": "penny",
            "hit": false
          },
          {
            "score": 0.7403696775436401,
            "answer": "gallon",
            "hit": false
          },
          {
            "score": 0.7248629927635193,
            "answer": "monetary",
            "hit": false
          },
          {
            "score": 0.7243200540542603,
            "answer": "bucks",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollar"
        ],
        "rank": 1997,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6530249714851379,
        "b in neighbourhood of b_prime": 64,
        "b_prime in neighbourhood of b": 1998
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L06 [meronyms - part].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "a6239f3f-3cb1-44a6-8eb4-e6dda596ec8b",
      "timestamp": "2025-05-17T17:08:18.542651"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to excited ",
        "b": "excited",
        "expected answer": [
          "agitated",
          "nervous"
        ],
        "predictions": [
          {
            "score": 0.8480502367019653,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.8279940485954285,
            "answer": "delighted",
            "hit": false
          },
          {
            "score": 0.8212262392044067,
            "answer": "excitement",
            "hit": false
          },
          {
            "score": 0.8168735504150391,
            "answer": "intrigued",
            "hit": false
          },
          {
            "score": 0.8143928050994873,
            "answer": "enthusiastic",
            "hit": false
          },
          {
            "score": 0.7978745102882385,
            "answer": "anxious",
            "hit": false
          }
        ],
        "set_exclude": [
          "excited"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7817206382751465,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "palace",
          "castle"
        ],
        "predictions": [
          {
            "score": 0.8265252709388733,
            "answer": "senate",
            "hit": false
          },
          {
            "score": 0.7936402559280396,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.7575827240943909,
            "answer": "household",
            "hit": false
          },
          {
            "score": 0.7562566995620728,
            "answer": "sen",
            "hit": false
          },
          {
            "score": 0.7475826740264893,
            "answer": "households",
            "hit": false
          },
          {
            "score": 0.7421005964279175,
            "answer": "mansion",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 26,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7148531228303909,
        "b in neighbourhood of b_prime": 42,
        "b_prime in neighbourhood of b": 27
      },
      {
        "question verbose": "What is to lake ",
        "b": "lake",
        "expected answer": [
          "sea",
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.7065092325210571,
            "answer": "creek",
            "hit": false
          },
          {
            "score": 0.6965467929840088,
            "answer": "lakes",
            "hit": false
          },
          {
            "score": 0.6939375996589661,
            "answer": "bourne",
            "hit": false
          },
          {
            "score": 0.6933223009109497,
            "answer": "brook",
            "hit": false
          },
          {
            "score": 0.6896564960479736,
            "answer": "kernel",
            "hit": false
          },
          {
            "score": 0.6892619729042053,
            "answer": "concert",
            "hit": false
          }
        ],
        "set_exclude": [
          "lake"
        ],
        "rank": 192,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6535638868808746,
        "b in neighbourhood of b_prime": 313,
        "b_prime in neighbourhood of b": 193
      },
      {
        "question verbose": "What is to pain ",
        "b": "pain",
        "expected answer": [
          "torment",
          "torture",
          "agony"
        ],
        "predictions": [
          {
            "score": 0.768395721912384,
            "answer": "painting",
            "hit": false
          },
          {
            "score": 0.754926323890686,
            "answer": "painter",
            "hit": false
          },
          {
            "score": 0.7523438930511475,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.7467150092124939,
            "answer": "painful",
            "hit": false
          },
          {
            "score": 0.739874005317688,
            "answer": "agony",
            "hit": true
          },
          {
            "score": 0.738562822341919,
            "answer": "anguish",
            "hit": false
          }
        ],
        "set_exclude": [
          "pain"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6952947676181793,
        "b in neighbourhood of b_prime": 278,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to pony ",
        "b": "pony",
        "expected answer": [
          "horse"
        ],
        "predictions": [
          {
            "score": 0.7201780080795288,
            "answer": "pig",
            "hit": false
          },
          {
            "score": 0.7125168442726135,
            "answer": "horses",
            "hit": false
          },
          {
            "score": 0.7081174254417419,
            "answer": "pokemon",
            "hit": false
          },
          {
            "score": 0.7070966958999634,
            "answer": "horse",
            "hit": true
          },
          {
            "score": 0.7063242197036743,
            "answer": "wagon",
            "hit": false
          },
          {
            "score": 0.7059627175331116,
            "answer": "ranger",
            "hit": false
          }
        ],
        "set_exclude": [
          "pony"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7070966809988022,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.7914562225341797,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.7590340375900269,
            "answer": "ocean",
            "hit": true
          },
          {
            "score": 0.7389046549797058,
            "answer": "maritime",
            "hit": false
          },
          {
            "score": 0.7225472927093506,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.7218091487884521,
            "answer": "naval",
            "hit": false
          },
          {
            "score": 0.7175421714782715,
            "answer": "coastal",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7590340375900269,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to snack ",
        "b": "snack",
        "expected answer": [
          "meal",
          "eat"
        ],
        "predictions": [
          {
            "score": 0.907848060131073,
            "answer": "snacks",
            "hit": false
          },
          {
            "score": 0.7918291687965393,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.7876758575439453,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.785266637802124,
            "answer": "eat",
            "hit": true
          },
          {
            "score": 0.7823759913444519,
            "answer": "breakfast",
            "hit": false
          },
          {
            "score": 0.7700236439704895,
            "answer": "beverages",
            "hit": false
          }
        ],
        "set_exclude": [
          "snack"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6714281737804413,
        "b in neighbourhood of b_prime": 81,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to tired ",
        "b": "tired",
        "expected answer": [
          "exhausted",
          "drained"
        ],
        "predictions": [
          {
            "score": 0.832733690738678,
            "answer": "weary",
            "hit": false
          },
          {
            "score": 0.8210963010787964,
            "answer": "bored",
            "hit": false
          },
          {
            "score": 0.8031882643699646,
            "answer": "exhausted",
            "hit": true
          },
          {
            "score": 0.7889015078544617,
            "answer": "frustrated",
            "hit": false
          },
          {
            "score": 0.7811776399612427,
            "answer": "annoyed",
            "hit": false
          },
          {
            "score": 0.7683073878288269,
            "answer": "fatigue",
            "hit": false
          }
        ],
        "set_exclude": [
          "tired"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8031882345676422,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 3
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 8,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L07 [synonyms - intensity].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "32b1ca33-e25a-41d1-ac8f-f41f677b160d",
      "timestamp": "2025-05-17T17:08:18.586684"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bicycle ",
        "b": "bicycle",
        "expected answer": [
          "bike",
          "wheel",
          "cycle"
        ],
        "predictions": [
          {
            "score": 0.8258532285690308,
            "answer": "bike",
            "hit": true
          },
          {
            "score": 0.7954497337341309,
            "answer": "bikes",
            "hit": false
          },
          {
            "score": 0.7936644554138184,
            "answer": "cyclists",
            "hit": false
          },
          {
            "score": 0.7875185012817383,
            "answer": "motorcycle",
            "hit": false
          },
          {
            "score": 0.7867890000343323,
            "answer": "cycling",
            "hit": false
          },
          {
            "score": 0.7556706666946411,
            "answer": "automobile",
            "hit": false
          }
        ],
        "set_exclude": [
          "bicycle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8258532285690308,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to cloth ",
        "b": "cloth",
        "expected answer": [
          "fabric",
          "material",
          "textile"
        ],
        "predictions": [
          {
            "score": 0.7267029285430908,
            "answer": "robe",
            "hit": false
          },
          {
            "score": 0.7143064737319946,
            "answer": "linen",
            "hit": false
          },
          {
            "score": 0.7139183878898621,
            "answer": "fabrics",
            "hit": false
          },
          {
            "score": 0.713034987449646,
            "answer": "garments",
            "hit": false
          },
          {
            "score": 0.7101308703422546,
            "answer": "towel",
            "hit": false
          },
          {
            "score": 0.7062265276908875,
            "answer": "textile",
            "hit": true
          }
        ],
        "set_exclude": [
          "cloth"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6554517894983292,
        "b in neighbourhood of b_prime": 1146,
        "b_prime in neighbourhood of b": 6
      },
      {
        "question verbose": "What is to dollars ",
        "b": "dollars",
        "expected answer": [
          "bucks"
        ],
        "predictions": [
          {
            "score": 0.8283206224441528,
            "answer": "dollar",
            "hit": false
          },
          {
            "score": 0.7611649036407471,
            "answer": "bucks",
            "hit": true
          },
          {
            "score": 0.7573332190513611,
            "answer": "usd",
            "hit": false
          },
          {
            "score": 0.7487223148345947,
            "answer": "cents",
            "hit": false
          },
          {
            "score": 0.7479380965232849,
            "answer": "money",
            "hit": false
          },
          {
            "score": 0.7383027076721191,
            "answer": "gallons",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollars"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7611649632453918,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "dad",
          "daddy"
        ],
        "predictions": [
          {
            "score": 0.8505372405052185,
            "answer": "fathers",
            "hit": false
          },
          {
            "score": 0.8422760367393494,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.8112649321556091,
            "answer": "grandmother",
            "hit": false
          },
          {
            "score": 0.8107479810714722,
            "answer": "brother",
            "hit": false
          },
          {
            "score": 0.7902212142944336,
            "answer": "mothers",
            "hit": false
          },
          {
            "score": 0.7883284091949463,
            "answer": "parent",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 34,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7240459024906158,
        "b in neighbourhood of b_prime": 5,
        "b_prime in neighbourhood of b": 35
      },
      {
        "question verbose": "What is to help ",
        "b": "help",
        "expected answer": [
          "aid",
          "assist"
        ],
        "predictions": [
          {
            "score": 0.7441402077674866,
            "answer": "helped",
            "hit": false
          },
          {
            "score": 0.735984742641449,
            "answer": "helping",
            "hit": false
          },
          {
            "score": 0.7350046038627625,
            "answer": "assistance",
            "hit": false
          },
          {
            "score": 0.7330321073532104,
            "answer": "services",
            "hit": false
          },
          {
            "score": 0.7288329601287842,
            "answer": "say",
            "hit": false
          },
          {
            "score": 0.7266474366188049,
            "answer": "make",
            "hit": false
          }
        ],
        "set_exclude": [
          "help"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7022502273321152,
        "b in neighbourhood of b_prime": 14,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to intelligent ",
        "b": "intelligent",
        "expected answer": [
          "clever",
          "smart"
        ],
        "predictions": [
          {
            "score": 0.7965371012687683,
            "answer": "smarter",
            "hit": false
          },
          {
            "score": 0.7775969505310059,
            "answer": "thoughtful",
            "hit": false
          },
          {
            "score": 0.7646173238754272,
            "answer": "intellect",
            "hit": false
          },
          {
            "score": 0.7629923820495605,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.7610825300216675,
            "answer": "sophisticated",
            "hit": false
          },
          {
            "score": 0.7586660981178284,
            "answer": "intelligence",
            "hit": false
          }
        ],
        "set_exclude": [
          "intelligent"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7059318721294403,
        "b in neighbourhood of b_prime": 25,
        "b_prime in neighbourhood of b": 16
      },
      {
        "question verbose": "What is to jewel ",
        "b": "jewel",
        "expected answer": [
          "gem",
          "stone"
        ],
        "predictions": [
          {
            "score": 0.8174874782562256,
            "answer": "jewelry",
            "hit": false
          },
          {
            "score": 0.7811189889907837,
            "answer": "jewels",
            "hit": false
          },
          {
            "score": 0.7471248507499695,
            "answer": "jew",
            "hit": false
          },
          {
            "score": 0.7330617308616638,
            "answer": "necklace",
            "hit": false
          },
          {
            "score": 0.7261911630630493,
            "answer": "shoes",
            "hit": false
          },
          {
            "score": 0.7241193652153015,
            "answer": "gems",
            "hit": false
          }
        ],
        "set_exclude": [
          "jewel"
        ],
        "rank": 626,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6637599021196365,
        "b in neighbourhood of b_prime": 29,
        "b_prime in neighbourhood of b": 627
      },
      {
        "question verbose": "What is to monument ",
        "b": "monument",
        "expected answer": [
          "memorial"
        ],
        "predictions": [
          {
            "score": 0.822628915309906,
            "answer": "monuments",
            "hit": false
          },
          {
            "score": 0.7510740160942078,
            "answer": "memorial",
            "hit": true
          },
          {
            "score": 0.7324711084365845,
            "answer": "sculpture",
            "hit": false
          },
          {
            "score": 0.732010006904602,
            "answer": "erected",
            "hit": false
          },
          {
            "score": 0.7315853834152222,
            "answer": "statue",
            "hit": false
          },
          {
            "score": 0.7287330627441406,
            "answer": "statues",
            "hit": false
          }
        ],
        "set_exclude": [
          "monument"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7510740160942078,
        "b in neighbourhood of b_prime": 7,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to new ",
        "b": "new",
        "expected answer": [
          "modern",
          "recent"
        ],
        "predictions": [
          {
            "score": 0.7545740008354187,
            "answer": "los",
            "hit": false
          },
          {
            "score": 0.7397761344909668,
            "answer": "nyc",
            "hit": false
          },
          {
            "score": 0.7356518507003784,
            "answer": "manhattan",
            "hit": false
          },
          {
            "score": 0.7244053483009338,
            "answer": "brooklyn",
            "hit": false
          },
          {
            "score": 0.7168188691139221,
            "answer": "philadelphia",
            "hit": false
          },
          {
            "score": 0.7131794095039368,
            "answer": "massachusetts",
            "hit": false
          }
        ],
        "set_exclude": [
          "new"
        ],
        "rank": 604,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6257157325744629,
        "b in neighbourhood of b_prime": 12797,
        "b_prime in neighbourhood of b": 605
      },
      {
        "question verbose": "What is to package ",
        "b": "package",
        "expected answer": [
          "parcel",
          "pack",
          "packet",
          "bundle"
        ],
        "predictions": [
          {
            "score": 0.8011442422866821,
            "answer": "packages",
            "hit": false
          },
          {
            "score": 0.7428668141365051,
            "answer": "import",
            "hit": false
          },
          {
            "score": 0.7357577085494995,
            "answer": "packaging",
            "hit": false
          },
          {
            "score": 0.7350630164146423,
            "answer": "modules",
            "hit": false
          },
          {
            "score": 0.7232794761657715,
            "answer": "install",
            "hit": false
          },
          {
            "score": 0.7221075296401978,
            "answer": "module",
            "hit": false
          }
        ],
        "set_exclude": [
          "package"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7020606100559235,
        "b in neighbourhood of b_prime": 23,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to railway ",
        "b": "railway",
        "expected answer": [
          "railroad"
        ],
        "predictions": [
          {
            "score": 0.8180150389671326,
            "answer": "railroad",
            "hit": true
          },
          {
            "score": 0.748706579208374,
            "answer": "transportation",
            "hit": false
          },
          {
            "score": 0.7458938956260681,
            "answer": "coal",
            "hit": false
          },
          {
            "score": 0.7410305738449097,
            "answer": "trains",
            "hit": false
          },
          {
            "score": 0.7376185655593872,
            "answer": "rail",
            "hit": false
          },
          {
            "score": 0.7321639657020569,
            "answer": "rural",
            "hit": false
          }
        ],
        "set_exclude": [
          "railway"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8180150389671326,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to rational ",
        "b": "rational",
        "expected answer": [
          "logical",
          "coherent",
          "reasonable",
          "sane"
        ],
        "predictions": [
          {
            "score": 0.7899134159088135,
            "answer": "irrational",
            "hit": false
          },
          {
            "score": 0.7285270690917969,
            "answer": "reasonable",
            "hit": true
          },
          {
            "score": 0.7238805294036865,
            "answer": "reasoning",
            "hit": false
          },
          {
            "score": 0.7232022285461426,
            "answer": "sane",
            "hit": true
          },
          {
            "score": 0.7219232320785522,
            "answer": "liberal",
            "hit": false
          },
          {
            "score": 0.7212858200073242,
            "answer": "reasoned",
            "hit": false
          }
        ],
        "set_exclude": [
          "rational"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.721171036362648,
        "b in neighbourhood of b_prime": 26,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "sensible"
        ],
        "predictions": [
          {
            "score": 0.819106936454773,
            "answer": "unreasonable",
            "hit": false
          },
          {
            "score": 0.795109748840332,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.7881217002868652,
            "answer": "reason",
            "hit": false
          },
          {
            "score": 0.7865856885910034,
            "answer": "necessary",
            "hit": false
          },
          {
            "score": 0.780083179473877,
            "answer": "acceptable",
            "hit": false
          },
          {
            "score": 0.778426468372345,
            "answer": "plausible",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7702670395374298,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 8
      },
      {
        "question verbose": "What is to rock ",
        "b": "rock",
        "expected answer": [
          "stone"
        ],
        "predictions": [
          {
            "score": 0.7245430946350098,
            "answer": "rocks",
            "hit": false
          },
          {
            "score": 0.717459499835968,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.7063187956809998,
            "answer": "brock",
            "hit": false
          },
          {
            "score": 0.7047439813613892,
            "answer": "rocking",
            "hit": false
          },
          {
            "score": 0.6923350691795349,
            "answer": "punk",
            "hit": false
          },
          {
            "score": 0.6860796213150024,
            "answer": "rocky",
            "hit": false
          }
        ],
        "set_exclude": [
          "rock"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6795859038829803,
        "b in neighbourhood of b_prime": 11,
        "b_prime in neighbourhood of b": 12
      },
      {
        "question verbose": "What is to sofa ",
        "b": "sofa",
        "expected answer": [
          "couch",
          "lounge"
        ],
        "predictions": [
          {
            "score": 0.7852665185928345,
            "answer": "mattress",
            "hit": false
          },
          {
            "score": 0.774307131767273,
            "answer": "furniture",
            "hit": false
          },
          {
            "score": 0.7713730335235596,
            "answer": "patio",
            "hit": false
          },
          {
            "score": 0.7671065926551819,
            "answer": "balcony",
            "hit": false
          },
          {
            "score": 0.7640054225921631,
            "answer": "fireplace",
            "hit": false
          },
          {
            "score": 0.7605348825454712,
            "answer": "pillow",
            "hit": false
          }
        ],
        "set_exclude": [
          "sofa"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7387082129716873,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 14
      },
      {
        "question verbose": "What is to style ",
        "b": "style",
        "expected answer": [
          "manner",
          "mode",
          "fashion",
          "way"
        ],
        "predictions": [
          {
            "score": 0.7725133895874023,
            "answer": "styled",
            "hit": false
          },
          {
            "score": 0.7563791871070862,
            "answer": "fashion",
            "hit": true
          },
          {
            "score": 0.7560834884643555,
            "answer": "styling",
            "hit": false
          },
          {
            "score": 0.7391926050186157,
            "answer": "styles",
            "hit": false
          },
          {
            "score": 0.7290711402893066,
            "answer": "manner",
            "hit": true
          },
          {
            "score": 0.7221737504005432,
            "answer": "aesthetics",
            "hit": false
          }
        ],
        "set_exclude": [
          "style"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7290711402893066,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 2
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 16,
      "accuracy": 0.125
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L08 [synonyms - exact].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "bbff47dd-537e-47f8-aec7-fbc04ed22739",
      "timestamp": "2025-05-17T17:08:18.657796"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to after ",
        "b": "after",
        "expected answer": [
          "before",
          "earlier",
          "previously"
        ],
        "predictions": [
          {
            "score": 0.8344910740852356,
            "answer": "while",
            "hit": false
          },
          {
            "score": 0.8328020572662354,
            "answer": "since",
            "hit": false
          },
          {
            "score": 0.8095125555992126,
            "answer": "when",
            "hit": false
          },
          {
            "score": 0.7947130799293518,
            "answer": "upon",
            "hit": false
          },
          {
            "score": 0.7934501767158508,
            "answer": "however",
            "hit": false
          },
          {
            "score": 0.7861015796661377,
            "answer": "they",
            "hit": false
          }
        ],
        "set_exclude": [
          "after"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.732951283454895,
        "b in neighbourhood of b_prime": 13,
        "b_prime in neighbourhood of b": 16
      },
      {
        "question verbose": "What is to ahead ",
        "b": "ahead",
        "expected answer": [
          "behind",
          "rear",
          "after",
          "tail",
          "beforehand"
        ],
        "predictions": [
          {
            "score": 0.7406705021858215,
            "answer": "beforehand",
            "hit": true
          },
          {
            "score": 0.7160763740539551,
            "answer": "alongside",
            "hit": false
          },
          {
            "score": 0.7144765853881836,
            "answer": "behind",
            "hit": true
          },
          {
            "score": 0.7130588293075562,
            "answer": "amid",
            "hit": false
          },
          {
            "score": 0.7076834440231323,
            "answer": "advance",
            "hit": false
          },
          {
            "score": 0.6993728876113892,
            "answer": "beyond",
            "hit": false
          }
        ],
        "set_exclude": [
          "ahead"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7144765853881836,
        "b in neighbourhood of b_prime": 4,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to anterior ",
        "b": "anterior",
        "expected answer": [
          "posterior"
        ],
        "predictions": [
          {
            "score": 0.8775193691253662,
            "answer": "posterior",
            "hit": true
          },
          {
            "score": 0.8350508809089661,
            "answer": "medial",
            "hit": false
          },
          {
            "score": 0.80866539478302,
            "answer": "dorsal",
            "hit": false
          },
          {
            "score": 0.7981699705123901,
            "answer": "lateral",
            "hit": false
          },
          {
            "score": 0.7691362500190735,
            "answer": "abdominal",
            "hit": false
          },
          {
            "score": 0.7680255174636841,
            "answer": "abdomen",
            "hit": false
          }
        ],
        "set_exclude": [
          "anterior"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8775193691253662,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to before ",
        "b": "before",
        "expected answer": [
          "after",
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "ahead"
        ],
        "predictions": [
          {
            "score": 0.7844216227531433,
            "answer": "beforehand",
            "hit": false
          },
          {
            "score": 0.7794702053070068,
            "answer": "without",
            "hit": false
          },
          {
            "score": 0.7721475958824158,
            "answer": "this",
            "hit": false
          },
          {
            "score": 0.7646408677101135,
            "answer": "only",
            "hit": false
          },
          {
            "score": 0.7511526346206665,
            "answer": "for",
            "hit": false
          },
          {
            "score": 0.7497133016586304,
            "answer": "all",
            "hit": false
          }
        ],
        "set_exclude": [
          "before"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.732951283454895,
        "b in neighbourhood of b_prime": 39,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to beginning ",
        "b": "beginning",
        "expected answer": [
          "end",
          "terminal",
          "ending",
          "last",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.7635038495063782,
            "answer": "begun",
            "hit": false
          },
          {
            "score": 0.7594355344772339,
            "answer": "begins",
            "hit": false
          },
          {
            "score": 0.7542003393173218,
            "answer": "beginnings",
            "hit": false
          },
          {
            "score": 0.7538847923278809,
            "answer": "begin",
            "hit": false
          },
          {
            "score": 0.7415270209312439,
            "answer": "began",
            "hit": false
          },
          {
            "score": 0.7372545599937439,
            "answer": "continuing",
            "hit": false
          }
        ],
        "set_exclude": [
          "beginning"
        ],
        "rank": 33,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6992111057043076,
        "b in neighbourhood of b_prime": 38,
        "b_prime in neighbourhood of b": 34
      },
      {
        "question verbose": "What is to dead ",
        "b": "dead",
        "expected answer": [
          "alive",
          "living",
          "live"
        ],
        "predictions": [
          {
            "score": 0.7699320316314697,
            "answer": "death",
            "hit": false
          },
          {
            "score": 0.7644783854484558,
            "answer": "deadline",
            "hit": false
          },
          {
            "score": 0.7453668117523193,
            "answer": "corpse",
            "hit": false
          },
          {
            "score": 0.74323970079422,
            "answer": "deceased",
            "hit": false
          },
          {
            "score": 0.736128568649292,
            "answer": "dying",
            "hit": false
          },
          {
            "score": 0.7312710285186768,
            "answer": "lifeless",
            "hit": false
          }
        ],
        "set_exclude": [
          "dead"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7127331048250198,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 12
      },
      {
        "question verbose": "What is to dive ",
        "b": "dive",
        "expected answer": [
          "emerge"
        ],
        "predictions": [
          {
            "score": 0.8686380386352539,
            "answer": "diving",
            "hit": false
          },
          {
            "score": 0.7629752159118652,
            "answer": "dove",
            "hit": false
          },
          {
            "score": 0.7566824555397034,
            "answer": "plunge",
            "hit": false
          },
          {
            "score": 0.7266428470611572,
            "answer": "explore",
            "hit": false
          },
          {
            "score": 0.7232474088668823,
            "answer": "divers",
            "hit": false
          },
          {
            "score": 0.721318781375885,
            "answer": "climb",
            "hit": false
          }
        ],
        "set_exclude": [
          "dive"
        ],
        "rank": 4828,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6311912387609482,
        "b in neighbourhood of b_prime": 8466,
        "b_prime in neighbourhood of b": 4829
      },
      {
        "question verbose": "What is to fall ",
        "b": "fall",
        "expected answer": [
          "rise",
          "upward",
          "climb"
        ],
        "predictions": [
          {
            "score": 0.7618017196655273,
            "answer": "autumn",
            "hit": false
          },
          {
            "score": 0.7526799440383911,
            "answer": "winter",
            "hit": false
          },
          {
            "score": 0.7516887187957764,
            "answer": "spring",
            "hit": false
          },
          {
            "score": 0.7435896396636963,
            "answer": "falling",
            "hit": false
          },
          {
            "score": 0.7385855913162231,
            "answer": "fallen",
            "hit": false
          },
          {
            "score": 0.7338680624961853,
            "answer": "fell",
            "hit": false
          }
        ],
        "set_exclude": [
          "fall"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6936035305261612,
        "b in neighbourhood of b_prime": 22,
        "b_prime in neighbourhood of b": 13
      },
      {
        "question verbose": "What is to first ",
        "b": "first",
        "expected answer": [
          "last",
          "end",
          "terminal",
          "ending",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.7805159091949463,
            "answer": "firstly",
            "hit": false
          },
          {
            "score": 0.7277237176895142,
            "answer": "sixth",
            "hit": false
          },
          {
            "score": 0.7178702354431152,
            "answer": "after",
            "hit": false
          },
          {
            "score": 0.7130731344223022,
            "answer": "initially",
            "hit": false
          },
          {
            "score": 0.7038865089416504,
            "answer": "while",
            "hit": false
          },
          {
            "score": 0.699222207069397,
            "answer": "since",
            "hit": false
          }
        ],
        "set_exclude": [
          "first"
        ],
        "rank": 105,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6525433659553528,
        "b in neighbourhood of b_prime": 58,
        "b_prime in neighbourhood of b": 106
      },
      {
        "question verbose": "What is to input ",
        "b": "input",
        "expected answer": [
          "output"
        ],
        "predictions": [
          {
            "score": 0.8295089602470398,
            "answer": "inputs",
            "hit": false
          },
          {
            "score": 0.7712364792823792,
            "answer": "outputs",
            "hit": false
          },
          {
            "score": 0.7463971972465515,
            "answer": "output",
            "hit": true
          },
          {
            "score": 0.7397421598434448,
            "answer": "feedback",
            "hit": false
          },
          {
            "score": 0.7360479831695557,
            "answer": "parameters",
            "hit": false
          },
          {
            "score": 0.7283461093902588,
            "answer": "process",
            "hit": false
          }
        ],
        "set_exclude": [
          "input"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7463972270488739,
        "b in neighbourhood of b_prime": 6,
        "b_prime in neighbourhood of b": 3
      },
      {
        "question verbose": "What is to inside ",
        "b": "inside",
        "expected answer": [
          "outside",
          "exterior",
          "out"
        ],
        "predictions": [
          {
            "score": 0.7908953428268433,
            "answer": "outside",
            "hit": true
          },
          {
            "score": 0.7664007544517517,
            "answer": "within",
            "hit": false
          },
          {
            "score": 0.7450770139694214,
            "answer": "underneath",
            "hit": false
          },
          {
            "score": 0.7289532423019409,
            "answer": "around",
            "hit": false
          },
          {
            "score": 0.7234913110733032,
            "answer": "every",
            "hit": false
          },
          {
            "score": 0.7204797863960266,
            "answer": "across",
            "hit": false
          }
        ],
        "set_exclude": [
          "inside"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7908953428268433,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "external",
          "outer",
          "outside"
        ],
        "predictions": [
          {
            "score": 0.7590417861938477,
            "answer": "internally",
            "hit": false
          },
          {
            "score": 0.7548767328262329,
            "answer": "external",
            "hit": true
          },
          {
            "score": 0.7527453303337097,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.7320874929428101,
            "answer": "intra",
            "hit": false
          },
          {
            "score": 0.708863377571106,
            "answer": "intrinsic",
            "hit": false
          },
          {
            "score": 0.7086846232414246,
            "answer": "inline",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7548767626285553,
        "b in neighbourhood of b_prime": 2,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to mortal ",
        "b": "mortal",
        "expected answer": [
          "immortal"
        ],
        "predictions": [
          {
            "score": 0.7463563084602356,
            "answer": "mortality",
            "hit": false
          },
          {
            "score": 0.7430475950241089,
            "answer": "immortal",
            "hit": true
          },
          {
            "score": 0.7325197458267212,
            "answer": "divine",
            "hit": false
          },
          {
            "score": 0.7218664884567261,
            "answer": "miserable",
            "hit": false
          },
          {
            "score": 0.7193577289581299,
            "answer": "fatal",
            "hit": false
          },
          {
            "score": 0.7175197601318359,
            "answer": "deadly",
            "hit": false
          }
        ],
        "set_exclude": [
          "mortal"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7430476099252701,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 2
      },
      {
        "question verbose": "What is to occupied ",
        "b": "occupied",
        "expected answer": [
          "vacant",
          "free"
        ],
        "predictions": [
          {
            "score": 0.7857979536056519,
            "answer": "occupy",
            "hit": false
          },
          {
            "score": 0.7793488502502441,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.774517834186554,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.7482889890670776,
            "answer": "inhabited",
            "hit": false
          },
          {
            "score": 0.7355141639709473,
            "answer": "vacant",
            "hit": true
          },
          {
            "score": 0.7330098152160645,
            "answer": "controlled",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupied"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7355141341686249,
        "b in neighbourhood of b_prime": 8,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to over ",
        "b": "over",
        "expected answer": [
          "under",
          "below",
          "beneath"
        ],
        "predictions": [
          {
            "score": 0.7959210276603699,
            "answer": "under",
            "hit": true
          },
          {
            "score": 0.7641260623931885,
            "answer": "for",
            "hit": false
          },
          {
            "score": 0.7535172700881958,
            "answer": "this",
            "hit": false
          },
          {
            "score": 0.7504315376281738,
            "answer": "into",
            "hit": false
          },
          {
            "score": 0.7429484128952026,
            "answer": "all",
            "hit": false
          },
          {
            "score": 0.7392876148223877,
            "answer": "need",
            "hit": false
          }
        ],
        "set_exclude": [
          "over"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7959210276603699,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to previously ",
        "b": "previously",
        "expected answer": [
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "after",
          "subsequent"
        ],
        "predictions": [
          {
            "score": 0.8119500279426575,
            "answer": "originally",
            "hit": false
          },
          {
            "score": 0.7953854203224182,
            "answer": "recently",
            "hit": false
          },
          {
            "score": 0.7477707266807556,
            "answer": "traditionally",
            "hit": false
          },
          {
            "score": 0.7451382875442505,
            "answer": "subsequently",
            "hit": true
          },
          {
            "score": 0.735701322555542,
            "answer": "formerly",
            "hit": false
          },
          {
            "score": 0.7341271042823792,
            "answer": "historically",
            "hit": false
          }
        ],
        "set_exclude": [
          "previously"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7451382726430893,
        "b in neighbourhood of b_prime": 27,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to proceed ",
        "b": "proceed",
        "expected answer": [
          "retreat",
          "return"
        ],
        "predictions": [
          {
            "score": 0.8321086168289185,
            "answer": "proceeds",
            "hit": false
          },
          {
            "score": 0.7797377109527588,
            "answer": "proceeded",
            "hit": false
          },
          {
            "score": 0.760145366191864,
            "answer": "proceeding",
            "hit": false
          },
          {
            "score": 0.737725019454956,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.7279181480407715,
            "answer": "progresses",
            "hit": false
          },
          {
            "score": 0.7154841423034668,
            "answer": "attempt",
            "hit": false
          }
        ],
        "set_exclude": [
          "proceed"
        ],
        "rank": 4190,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6461924016475677,
        "b in neighbourhood of b_prime": 1914,
        "b_prime in neighbourhood of b": 4191
      },
      {
        "question verbose": "What is to rise ",
        "b": "rise",
        "expected answer": [
          "sink",
          "drop",
          "fall"
        ],
        "predictions": [
          {
            "score": 0.7477796077728271,
            "answer": "rises",
            "hit": false
          },
          {
            "score": 0.741030216217041,
            "answer": "risen",
            "hit": false
          },
          {
            "score": 0.7348938584327698,
            "answer": "rising",
            "hit": false
          },
          {
            "score": 0.7346554398536682,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7123216390609741,
            "answer": "emergence",
            "hit": false
          },
          {
            "score": 0.7101125717163086,
            "answer": "surge",
            "hit": false
          }
        ],
        "set_exclude": [
          "rise"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.6112690716981888,
        "b in neighbourhood of b_prime": 9667,
        "b_prime in neighbourhood of b": 22
      },
      {
        "question verbose": "What is to south ",
        "b": "south",
        "expected answer": [
          "north"
        ],
        "predictions": [
          {
            "score": 0.8756882548332214,
            "answer": "southeast",
            "hit": false
          },
          {
            "score": 0.8718616962432861,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.8677592277526855,
            "answer": "northeast",
            "hit": false
          },
          {
            "score": 0.7840673923492432,
            "answer": "north",
            "hit": true
          },
          {
            "score": 0.7662864923477173,
            "answer": "southwest",
            "hit": false
          },
          {
            "score": 0.7583781480789185,
            "answer": "inland",
            "hit": false
          }
        ],
        "set_exclude": [
          "south"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7840674519538879,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 4
      },
      {
        "question verbose": "What is to southeast ",
        "b": "southeast",
        "expected answer": [
          "southwest",
          "northeast"
        ],
        "predictions": [
          {
            "score": 0.9360181093215942,
            "answer": "northeast",
            "hit": true
          },
          {
            "score": 0.9329519867897034,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.8756881952285767,
            "answer": "south",
            "hit": false
          },
          {
            "score": 0.7986043691635132,
            "answer": "southwest",
            "hit": true
          },
          {
            "score": 0.7741439342498779,
            "answer": "inland",
            "hit": false
          },
          {
            "score": 0.7721889019012451,
            "answer": "east",
            "hit": false
          }
        ],
        "set_exclude": [
          "southeast"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.7986043989658356,
        "b in neighbourhood of b_prime": 3,
        "b_prime in neighbourhood of b": 1
      },
      {
        "question verbose": "What is to toward ",
        "b": "toward",
        "expected answer": [
          "away",
          "off",
          "forth",
          "aside"
        ],
        "predictions": [
          {
            "score": 0.8051232695579529,
            "answer": "towards",
            "hit": false
          },
          {
            "score": 0.7217258214950562,
            "answer": "upward",
            "hit": false
          },
          {
            "score": 0.7191611528396606,
            "answer": "leans",
            "hit": false
          },
          {
            "score": 0.7184658050537109,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.7157259583473206,
            "answer": "downward",
            "hit": false
          },
          {
            "score": 0.7130775451660156,
            "answer": "farther",
            "hit": false
          }
        ],
        "set_exclude": [
          "toward"
        ],
        "rank": 146,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.674093633890152,
        "b in neighbourhood of b_prime": 209,
        "b_prime in neighbourhood of b": 147
      },
      {
        "question verbose": "What is to true ",
        "b": "true",
        "expected answer": [
          "false",
          "incorrect",
          "wrong",
          "mistaken"
        ],
        "predictions": [
          {
            "score": 0.7532253265380859,
            "answer": "real",
            "hit": false
          },
          {
            "score": 0.743850588798523,
            "answer": "genuine",
            "hit": false
          },
          {
            "score": 0.7370749115943909,
            "answer": "accurate",
            "hit": false
          },
          {
            "score": 0.7254170775413513,
            "answer": "actual",
            "hit": false
          },
          {
            "score": 0.720624566078186,
            "answer": "false",
            "hit": true
          },
          {
            "score": 0.7159615755081177,
            "answer": "authentic",
            "hit": false
          }
        ],
        "set_exclude": [
          "true"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.720624566078186,
        "b in neighbourhood of b_prime": 31,
        "b_prime in neighbourhood of b": 5
      },
      {
        "question verbose": "What is to west ",
        "b": "west",
        "expected answer": [
          "east"
        ],
        "predictions": [
          {
            "score": 0.8388415575027466,
            "answer": "east",
            "hit": true
          },
          {
            "score": 0.7705299854278564,
            "answer": "north",
            "hit": false
          },
          {
            "score": 0.7699540853500366,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.7541176676750183,
            "answer": "northeast",
            "hit": false
          },
          {
            "score": 0.7518805861473083,
            "answer": "southeast",
            "hit": false
          },
          {
            "score": 0.7470065951347351,
            "answer": "south",
            "hit": false
          }
        ],
        "set_exclude": [
          "west"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "similarity to correct cosine": 0.8388416171073914,
        "b in neighbourhood of b_prime": 1,
        "b_prime in neighbourhood of b": 1
      }
    ],
    "result": {
      "cnt_questions_correct": 6,
      "cnt_questions_total": 23,
      "accuracy": 0.2608695652173913
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L10 [antonyms - binary].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "SimilarToB",
      "uuid": "e5473d3a-1188-402b-b054-8247c916fa8d",
      "timestamp": "2025-05-17T17:08:18.803230"
    }
  }
]