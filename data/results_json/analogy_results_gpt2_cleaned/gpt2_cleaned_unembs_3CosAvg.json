[
  {
    "details": [
      {
        "question verbose": "What is to album ",
        "b": "album",
        "expected answer": [
          "albums"
        ],
        "predictions": [
          {
            "score": 0.7527621984481812,
            "answer": "albums",
            "hit": true
          },
          {
            "score": 0.6743009686470032,
            "answer": "songs",
            "hit": false
          },
          {
            "score": 0.6357935667037964,
            "answer": "concerts",
            "hit": false
          },
          {
            "score": 0.6234121322631836,
            "answer": "items",
            "hit": false
          },
          {
            "score": 0.6230646371841431,
            "answer": "cds",
            "hit": false
          },
          {
            "score": 0.6206205487251282,
            "answer": "poems",
            "hit": false
          }
        ],
        "set_exclude": [
          "album"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7527622878551483
      },
      {
        "question verbose": "What is to application ",
        "b": "application",
        "expected answer": [
          "applications"
        ],
        "predictions": [
          {
            "score": 0.8427371978759766,
            "answer": "applications",
            "hit": true
          },
          {
            "score": 0.6838073134422302,
            "answer": "forms",
            "hit": false
          },
          {
            "score": 0.6805193424224854,
            "answer": "authentication",
            "hit": false
          },
          {
            "score": 0.6759852170944214,
            "answer": "activities",
            "hit": false
          },
          {
            "score": 0.6722307801246643,
            "answer": "applicant",
            "hit": false
          },
          {
            "score": 0.6707596778869629,
            "answer": "areas",
            "hit": false
          }
        ],
        "set_exclude": [
          "application"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8427371382713318
      },
      {
        "question verbose": "What is to area ",
        "b": "area",
        "expected answer": [
          "areas"
        ],
        "predictions": [
          {
            "score": 0.7767976522445679,
            "answer": "region",
            "hit": false
          },
          {
            "score": 0.7463686466217041,
            "answer": "regions",
            "hit": false
          },
          {
            "score": 0.7388719916343689,
            "answer": "areas",
            "hit": true
          },
          {
            "score": 0.7373909950256348,
            "answer": "vicinity",
            "hit": false
          },
          {
            "score": 0.7261013388633728,
            "answer": "locations",
            "hit": false
          },
          {
            "score": 0.7050617933273315,
            "answer": "location",
            "hit": false
          }
        ],
        "set_exclude": [
          "area"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7388720214366913
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "cars"
        ],
        "predictions": [
          {
            "score": 0.7820907831192017,
            "answer": "automobile",
            "hit": false
          },
          {
            "score": 0.7783080339431763,
            "answer": "vehicles",
            "hit": false
          },
          {
            "score": 0.7589744329452515,
            "answer": "automobiles",
            "hit": false
          },
          {
            "score": 0.7364982962608337,
            "answer": "truck",
            "hit": false
          },
          {
            "score": 0.7241238355636597,
            "answer": "motor",
            "hit": false
          },
          {
            "score": 0.7195805311203003,
            "answer": "automotive",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6765867620706558
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "colleges"
        ],
        "predictions": [
          {
            "score": 0.7503335475921631,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.7502431273460388,
            "answer": "colleges",
            "hit": true
          },
          {
            "score": 0.6831142902374268,
            "answer": "schools",
            "hit": false
          },
          {
            "score": 0.6604059934616089,
            "answer": "young",
            "hit": false
          },
          {
            "score": 0.6595372557640076,
            "answer": "universities",
            "hit": false
          },
          {
            "score": 0.6548370122909546,
            "answer": "faculty",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7502431273460388
      },
      {
        "question verbose": "What is to council ",
        "b": "council",
        "expected answer": [
          "councils"
        ],
        "predictions": [
          {
            "score": 0.7216906547546387,
            "answer": "councils",
            "hit": true
          },
          {
            "score": 0.7038605809211731,
            "answer": "officers",
            "hit": false
          },
          {
            "score": 0.6869469881057739,
            "answer": "members",
            "hit": false
          },
          {
            "score": 0.6683313846588135,
            "answer": "officials",
            "hit": false
          },
          {
            "score": 0.6594911813735962,
            "answer": "government",
            "hit": false
          },
          {
            "score": 0.6567716598510742,
            "answer": "authorities",
            "hit": false
          }
        ],
        "set_exclude": [
          "council"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7216906249523163
      },
      {
        "question verbose": "What is to customer ",
        "b": "customer",
        "expected answer": [
          "customers"
        ],
        "predictions": [
          {
            "score": 0.8169939517974854,
            "answer": "customers",
            "hit": true
          },
          {
            "score": 0.7035990357398987,
            "answer": "sales",
            "hit": false
          },
          {
            "score": 0.6948522329330444,
            "answer": "user",
            "hit": false
          },
          {
            "score": 0.6809491515159607,
            "answer": "client",
            "hit": false
          },
          {
            "score": 0.677111029624939,
            "answer": "pricing",
            "hit": false
          },
          {
            "score": 0.6672571897506714,
            "answer": "shopping",
            "hit": false
          }
        ],
        "set_exclude": [
          "customer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8169939815998077
      },
      {
        "question verbose": "What is to day ",
        "b": "day",
        "expected answer": [
          "days"
        ],
        "predictions": [
          {
            "score": 0.6982749700546265,
            "answer": "week",
            "hit": false
          },
          {
            "score": 0.671196460723877,
            "answer": "days",
            "hit": true
          },
          {
            "score": 0.6640399694442749,
            "answer": "nights",
            "hit": false
          },
          {
            "score": 0.6481281518936157,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.638917088508606,
            "answer": "mornings",
            "hit": false
          },
          {
            "score": 0.6352032423019409,
            "answer": "look",
            "hit": false
          }
        ],
        "set_exclude": [
          "day"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6711964905261993
      },
      {
        "question verbose": "What is to death ",
        "b": "death",
        "expected answer": [
          "deaths"
        ],
        "predictions": [
          {
            "score": 0.7364795207977295,
            "answer": "deaths",
            "hit": true
          },
          {
            "score": 0.675997257232666,
            "answer": "dying",
            "hit": false
          },
          {
            "score": 0.6745282411575317,
            "answer": "killing",
            "hit": false
          },
          {
            "score": 0.6725265383720398,
            "answer": "kill",
            "hit": false
          },
          {
            "score": 0.6648142337799072,
            "answer": "battle",
            "hit": false
          },
          {
            "score": 0.6618251800537109,
            "answer": "fatal",
            "hit": false
          }
        ],
        "set_exclude": [
          "death"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7364794760942459
      },
      {
        "question verbose": "What is to department ",
        "b": "department",
        "expected answer": [
          "departments"
        ],
        "predictions": [
          {
            "score": 0.8921481370925903,
            "answer": "departments",
            "hit": true
          },
          {
            "score": 0.7125793099403381,
            "answer": "agencies",
            "hit": false
          },
          {
            "score": 0.6993035078048706,
            "answer": "dept",
            "hit": false
          },
          {
            "score": 0.6714755296707153,
            "answer": "offices",
            "hit": false
          },
          {
            "score": 0.661133348941803,
            "answer": "committee",
            "hit": false
          },
          {
            "score": 0.661069929599762,
            "answer": "supervisors",
            "hit": false
          }
        ],
        "set_exclude": [
          "department"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8921481966972351
      },
      {
        "question verbose": "What is to development ",
        "b": "development",
        "expected answer": [
          "developments"
        ],
        "predictions": [
          {
            "score": 0.6860055923461914,
            "answer": "projects",
            "hit": false
          },
          {
            "score": 0.6838260889053345,
            "answer": "develop",
            "hit": false
          },
          {
            "score": 0.6658558249473572,
            "answer": "developments",
            "hit": true
          },
          {
            "score": 0.6567317843437195,
            "answer": "environment",
            "hit": false
          },
          {
            "score": 0.6533475518226624,
            "answer": "developmental",
            "hit": false
          },
          {
            "score": 0.6358986496925354,
            "answer": "developing",
            "hit": false
          }
        ],
        "set_exclude": [
          "development"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6658558249473572
      },
      {
        "question verbose": "What is to difference ",
        "b": "difference",
        "expected answer": [
          "differences"
        ],
        "predictions": [
          {
            "score": 0.7282862067222595,
            "answer": "distinction",
            "hit": false
          },
          {
            "score": 0.7148942947387695,
            "answer": "distinctions",
            "hit": false
          },
          {
            "score": 0.7088810205459595,
            "answer": "similarity",
            "hit": false
          },
          {
            "score": 0.6985647678375244,
            "answer": "similarities",
            "hit": false
          },
          {
            "score": 0.6970648765563965,
            "answer": "differences",
            "hit": true
          },
          {
            "score": 0.6918606162071228,
            "answer": "advantages",
            "hit": false
          }
        ],
        "set_exclude": [
          "difference"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6970648914575577
      },
      {
        "question verbose": "What is to director ",
        "b": "director",
        "expected answer": [
          "directors"
        ],
        "predictions": [
          {
            "score": 0.7385150790214539,
            "answer": "coordinator",
            "hit": false
          },
          {
            "score": 0.7296876311302185,
            "answer": "filmmaker",
            "hit": false
          },
          {
            "score": 0.7231303453445435,
            "answer": "directors",
            "hit": true
          },
          {
            "score": 0.700752317905426,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.6911495327949524,
            "answer": "executive",
            "hit": false
          },
          {
            "score": 0.6898824572563171,
            "answer": "assistant",
            "hit": false
          }
        ],
        "set_exclude": [
          "director"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7231303602457047
      },
      {
        "question verbose": "What is to event ",
        "b": "event",
        "expected answer": [
          "events"
        ],
        "predictions": [
          {
            "score": 0.7099237442016602,
            "answer": "events",
            "hit": true
          },
          {
            "score": 0.6624417304992676,
            "answer": "action",
            "hit": false
          },
          {
            "score": 0.6498308181762695,
            "answer": "services",
            "hit": false
          },
          {
            "score": 0.6428501009941101,
            "answer": "have",
            "hit": false
          },
          {
            "score": 0.6303372979164124,
            "answer": "participants",
            "hit": false
          },
          {
            "score": 0.6289505958557129,
            "answer": "run",
            "hit": false
          }
        ],
        "set_exclude": [
          "event"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7099236994981766
      },
      {
        "question verbose": "What is to example ",
        "b": "example",
        "expected answer": [
          "examples"
        ],
        "predictions": [
          {
            "score": 0.8308234214782715,
            "answer": "examples",
            "hit": true
          },
          {
            "score": 0.6640506386756897,
            "answer": "comparison",
            "hit": false
          },
          {
            "score": 0.6576753854751587,
            "answer": "cases",
            "hit": false
          },
          {
            "score": 0.6473928689956665,
            "answer": "overview",
            "hit": false
          },
          {
            "score": 0.6418200135231018,
            "answer": "applications",
            "hit": false
          },
          {
            "score": 0.6406630277633667,
            "answer": "suppose",
            "hit": false
          }
        ],
        "set_exclude": [
          "example"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8308234512805939
      },
      {
        "question verbose": "What is to fact ",
        "b": "fact",
        "expected answer": [
          "facts"
        ],
        "predictions": [
          {
            "score": 0.663408637046814,
            "answer": "truth",
            "hit": false
          },
          {
            "score": 0.6428260803222656,
            "answer": "principles",
            "hit": false
          },
          {
            "score": 0.6421273946762085,
            "answer": "myth",
            "hit": false
          },
          {
            "score": 0.637278139591217,
            "answer": "forms",
            "hit": false
          },
          {
            "score": 0.6353362798690796,
            "answer": "evidence",
            "hit": false
          },
          {
            "score": 0.6343019008636475,
            "answer": "facts",
            "hit": true
          }
        ],
        "set_exclude": [
          "fact"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6343019008636475
      },
      {
        "question verbose": "What is to friend ",
        "b": "friend",
        "expected answer": [
          "friends"
        ],
        "predictions": [
          {
            "score": 0.7553903460502625,
            "answer": "colleague",
            "hit": false
          },
          {
            "score": 0.7197268605232239,
            "answer": "brother",
            "hit": false
          },
          {
            "score": 0.7169857621192932,
            "answer": "friendships",
            "hit": false
          },
          {
            "score": 0.7137240171432495,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.7091805338859558,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.7081297039985657,
            "answer": "neighbor",
            "hit": false
          }
        ],
        "set_exclude": [
          "friend"
        ],
        "rank": 29,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6625734120607376
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "gods"
        ],
        "predictions": [
          {
            "score": 0.6839803457260132,
            "answer": "gods",
            "hit": true
          },
          {
            "score": 0.6695831418037415,
            "answer": "allah",
            "hit": false
          },
          {
            "score": 0.6585680842399597,
            "answer": "lord",
            "hit": false
          },
          {
            "score": 0.6441067457199097,
            "answer": "satan",
            "hit": false
          },
          {
            "score": 0.6335951089859009,
            "answer": "him",
            "hit": false
          },
          {
            "score": 0.6326040029525757,
            "answer": "christians",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.683980330824852
      },
      {
        "question verbose": "What is to government ",
        "b": "government",
        "expected answer": [
          "governments"
        ],
        "predictions": [
          {
            "score": 0.7400240302085876,
            "answer": "governments",
            "hit": true
          },
          {
            "score": 0.7256745100021362,
            "answer": "authorities",
            "hit": false
          },
          {
            "score": 0.7116250991821289,
            "answer": "officials",
            "hit": false
          },
          {
            "score": 0.7052783966064453,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.6899746656417847,
            "answer": "congress",
            "hit": false
          },
          {
            "score": 0.6833101511001587,
            "answer": "financial",
            "hit": false
          }
        ],
        "set_exclude": [
          "government"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7400240004062653
      },
      {
        "question verbose": "What is to hour ",
        "b": "hour",
        "expected answer": [
          "hours"
        ],
        "predictions": [
          {
            "score": 0.6546867489814758,
            "answer": "minute",
            "hit": false
          },
          {
            "score": 0.6356209516525269,
            "answer": "hours",
            "hit": true
          },
          {
            "score": 0.6354784369468689,
            "answer": "weeks",
            "hit": false
          },
          {
            "score": 0.6291443705558777,
            "answer": "hands",
            "hit": false
          },
          {
            "score": 0.6264463067054749,
            "answer": "moments",
            "hit": false
          },
          {
            "score": 0.6261528134346008,
            "answer": "age",
            "hit": false
          }
        ],
        "set_exclude": [
          "hour"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6356209814548492
      },
      {
        "question verbose": "What is to idea ",
        "b": "idea",
        "expected answer": [
          "ideas"
        ],
        "predictions": [
          {
            "score": 0.7378528118133545,
            "answer": "ideas",
            "hit": true
          },
          {
            "score": 0.6742256879806519,
            "answer": "concept",
            "hit": false
          },
          {
            "score": 0.661851167678833,
            "answer": "concepts",
            "hit": false
          },
          {
            "score": 0.6535467505455017,
            "answer": "plans",
            "hit": false
          },
          {
            "score": 0.6520516276359558,
            "answer": "notions",
            "hit": false
          },
          {
            "score": 0.6415901184082031,
            "answer": "theory",
            "hit": false
          }
        ],
        "set_exclude": [
          "idea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7378528714179993
      },
      {
        "question verbose": "What is to language ",
        "b": "language",
        "expected answer": [
          "languages"
        ],
        "predictions": [
          {
            "score": 0.7333133816719055,
            "answer": "languages",
            "hit": true
          },
          {
            "score": 0.6548022031784058,
            "answer": "translation",
            "hit": false
          },
          {
            "score": 0.6523001790046692,
            "answer": "words",
            "hit": false
          },
          {
            "score": 0.6396485567092896,
            "answer": "names",
            "hit": false
          },
          {
            "score": 0.6354991793632507,
            "answer": "linguistic",
            "hit": false
          },
          {
            "score": 0.6349687576293945,
            "answer": "translations",
            "hit": false
          }
        ],
        "set_exclude": [
          "language"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7333133965730667
      },
      {
        "question verbose": "What is to law ",
        "b": "law",
        "expected answer": [
          "laws"
        ],
        "predictions": [
          {
            "score": 0.6869161128997803,
            "answer": "courts",
            "hit": false
          },
          {
            "score": 0.67877197265625,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.6703891754150391,
            "answer": "legislation",
            "hit": false
          },
          {
            "score": 0.6675589084625244,
            "answer": "attorney",
            "hit": false
          },
          {
            "score": 0.6626174449920654,
            "answer": "rights",
            "hit": false
          },
          {
            "score": 0.6622743010520935,
            "answer": "police",
            "hit": false
          }
        ],
        "set_exclude": [
          "law"
        ],
        "rank": 37,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6231271326541901
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "members"
        ],
        "predictions": [
          {
            "score": 0.6839777231216431,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.6727817058563232,
            "answer": "chairman",
            "hit": false
          },
          {
            "score": 0.663279116153717,
            "answer": "members",
            "hit": true
          },
          {
            "score": 0.6602246761322021,
            "answer": "governments",
            "hit": false
          },
          {
            "score": 0.6527812480926514,
            "answer": "leader",
            "hit": false
          },
          {
            "score": 0.6503243446350098,
            "answer": "mps",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6632791459560394
      },
      {
        "question verbose": "What is to month ",
        "b": "month",
        "expected answer": [
          "months"
        ],
        "predictions": [
          {
            "score": 0.8217160105705261,
            "answer": "months",
            "hit": true
          },
          {
            "score": 0.8213511109352112,
            "answer": "year",
            "hit": false
          },
          {
            "score": 0.7325422167778015,
            "answer": "monthly",
            "hit": false
          },
          {
            "score": 0.7211117148399353,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.7147568464279175,
            "answer": "weekend",
            "hit": false
          },
          {
            "score": 0.7001076340675354,
            "answer": "semester",
            "hit": false
          }
        ],
        "set_exclude": [
          "month"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8217160105705261
      },
      {
        "question verbose": "What is to night ",
        "b": "night",
        "expected answer": [
          "nights"
        ],
        "predictions": [
          {
            "score": 0.7007739543914795,
            "answer": "nights",
            "hit": true
          },
          {
            "score": 0.6888970136642456,
            "answer": "days",
            "hit": false
          },
          {
            "score": 0.6727151274681091,
            "answer": "shadow",
            "hit": false
          },
          {
            "score": 0.6726194024085999,
            "answer": "hours",
            "hit": false
          },
          {
            "score": 0.6683202981948853,
            "answer": "tomorrow",
            "hit": false
          },
          {
            "score": 0.6673024892807007,
            "answer": "moon",
            "hit": false
          }
        ],
        "set_exclude": [
          "night"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7007739990949631
      },
      {
        "question verbose": "What is to office ",
        "b": "office",
        "expected answer": [
          "offices"
        ],
        "predictions": [
          {
            "score": 0.7473539113998413,
            "answer": "offices",
            "hit": true
          },
          {
            "score": 0.6359626054763794,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.6322912573814392,
            "answer": "agents",
            "hit": false
          },
          {
            "score": 0.623356819152832,
            "answer": "chairs",
            "hit": false
          },
          {
            "score": 0.6200065016746521,
            "answer": "quarters",
            "hit": false
          },
          {
            "score": 0.6190074682235718,
            "answer": "views",
            "hit": false
          }
        ],
        "set_exclude": [
          "office"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7473539263010025
      },
      {
        "question verbose": "What is to period ",
        "b": "period",
        "expected answer": [
          "periods"
        ],
        "predictions": [
          {
            "score": 0.8848952054977417,
            "answer": "periods",
            "hit": true
          },
          {
            "score": 0.7213917970657349,
            "answer": "era",
            "hit": false
          },
          {
            "score": 0.7044030427932739,
            "answer": "eras",
            "hit": false
          },
          {
            "score": 0.6888710260391235,
            "answer": "phases",
            "hit": false
          },
          {
            "score": 0.6883790493011475,
            "answer": "interval",
            "hit": false
          },
          {
            "score": 0.6819906234741211,
            "answer": "duration",
            "hit": false
          }
        ],
        "set_exclude": [
          "period"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8848952054977417
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "players"
        ],
        "predictions": [
          {
            "score": 0.7175420522689819,
            "answer": "players",
            "hit": true
          },
          {
            "score": 0.6678940057754517,
            "answer": "manager",
            "hit": false
          },
          {
            "score": 0.667715311050415,
            "answer": "games",
            "hit": false
          },
          {
            "score": 0.6479427814483643,
            "answer": "users",
            "hit": false
          },
          {
            "score": 0.6467956900596619,
            "answer": "characters",
            "hit": false
          },
          {
            "score": 0.6459837555885315,
            "answer": "button",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7175419926643372
      },
      {
        "question verbose": "What is to population ",
        "b": "population",
        "expected answer": [
          "populations"
        ],
        "predictions": [
          {
            "score": 0.7151358723640442,
            "answer": "populations",
            "hit": true
          },
          {
            "score": 0.6499090194702148,
            "answer": "breeding",
            "hit": false
          },
          {
            "score": 0.6477975845336914,
            "answer": "demographics",
            "hit": false
          },
          {
            "score": 0.644679069519043,
            "answer": "species",
            "hit": false
          },
          {
            "score": 0.6341142654418945,
            "answer": "organisms",
            "hit": false
          },
          {
            "score": 0.6310570240020752,
            "answer": "demographic",
            "hit": false
          }
        ],
        "set_exclude": [
          "population"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7151359021663666
      },
      {
        "question verbose": "What is to problem ",
        "b": "problem",
        "expected answer": [
          "problems"
        ],
        "predictions": [
          {
            "score": 0.7322239875793457,
            "answer": "solution",
            "hit": false
          },
          {
            "score": 0.6870975494384766,
            "answer": "problems",
            "hit": true
          },
          {
            "score": 0.660038948059082,
            "answer": "issue",
            "hit": false
          },
          {
            "score": 0.6589236855506897,
            "answer": "questions",
            "hit": false
          },
          {
            "score": 0.651470422744751,
            "answer": "factor",
            "hit": false
          },
          {
            "score": 0.6479048728942871,
            "answer": "imagine",
            "hit": false
          }
        ],
        "set_exclude": [
          "problem"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6870975196361542
      },
      {
        "question verbose": "What is to product ",
        "b": "product",
        "expected answer": [
          "products"
        ],
        "predictions": [
          {
            "score": 0.66203373670578,
            "answer": "services",
            "hit": false
          },
          {
            "score": 0.6554493308067322,
            "answer": "productions",
            "hit": false
          },
          {
            "score": 0.6475185751914978,
            "answer": "products",
            "hit": true
          },
          {
            "score": 0.6472591161727905,
            "answer": "work",
            "hit": false
          },
          {
            "score": 0.6448538899421692,
            "answer": "service",
            "hit": false
          },
          {
            "score": 0.641088604927063,
            "answer": "customers",
            "hit": false
          }
        ],
        "set_exclude": [
          "product"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.647518590092659
      },
      {
        "question verbose": "What is to resource ",
        "b": "resource",
        "expected answer": [
          "resources"
        ],
        "predictions": [
          {
            "score": 0.6536595821380615,
            "answer": "resources",
            "hit": true
          },
          {
            "score": 0.6477689743041992,
            "answer": "items",
            "hit": false
          },
          {
            "score": 0.6393843293190002,
            "answer": "assets",
            "hit": false
          },
          {
            "score": 0.6379655599594116,
            "answer": "properties",
            "hit": false
          },
          {
            "score": 0.6377174258232117,
            "answer": "property",
            "hit": false
          },
          {
            "score": 0.6309484839439392,
            "answer": "income",
            "hit": false
          }
        ],
        "set_exclude": [
          "resource"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6536596119403839
      },
      {
        "question verbose": "What is to river ",
        "b": "river",
        "expected answer": [
          "rivers"
        ],
        "predictions": [
          {
            "score": 0.7544560432434082,
            "answer": "lakes",
            "hit": false
          },
          {
            "score": 0.7256648540496826,
            "answer": "water",
            "hit": false
          },
          {
            "score": 0.7074238061904907,
            "answer": "hills",
            "hit": false
          },
          {
            "score": 0.7000755071640015,
            "answer": "boats",
            "hit": false
          },
          {
            "score": 0.696927011013031,
            "answer": "streams",
            "hit": false
          },
          {
            "score": 0.6954834461212158,
            "answer": "forests",
            "hit": false
          }
        ],
        "set_exclude": [
          "river"
        ],
        "rank": 30,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6628156900405884
      },
      {
        "question verbose": "What is to road ",
        "b": "road",
        "expected answer": [
          "roads"
        ],
        "predictions": [
          {
            "score": 0.6670303344726562,
            "answer": "days",
            "hit": false
          },
          {
            "score": 0.6535366177558899,
            "answer": "path",
            "hit": false
          },
          {
            "score": 0.6474587321281433,
            "answer": "rail",
            "hit": false
          },
          {
            "score": 0.6467577219009399,
            "answer": "speed",
            "hit": false
          },
          {
            "score": 0.643582820892334,
            "answer": "highway",
            "hit": false
          },
          {
            "score": 0.6427187323570251,
            "answer": "wheel",
            "hit": false
          }
        ],
        "set_exclude": [
          "road"
        ],
        "rank": 69,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6159376502037048
      },
      {
        "question verbose": "What is to role ",
        "b": "role",
        "expected answer": [
          "roles"
        ],
        "predictions": [
          {
            "score": 0.6960719227790833,
            "answer": "roles",
            "hit": true
          },
          {
            "score": 0.6614153385162354,
            "answer": "members",
            "hit": false
          },
          {
            "score": 0.6427822709083557,
            "answer": "types",
            "hit": false
          },
          {
            "score": 0.6392171382904053,
            "answer": "theme",
            "hit": false
          },
          {
            "score": 0.6391106247901917,
            "answer": "years",
            "hit": false
          },
          {
            "score": 0.6317654252052307,
            "answer": "questions",
            "hit": false
          }
        ],
        "set_exclude": [
          "role"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6960719376802444
      },
      {
        "question verbose": "What is to science ",
        "b": "science",
        "expected answer": [
          "sciences"
        ],
        "predictions": [
          {
            "score": 0.7127301692962646,
            "answer": "scientists",
            "hit": false
          },
          {
            "score": 0.671947717666626,
            "answer": "natural",
            "hit": false
          },
          {
            "score": 0.671628475189209,
            "answer": "sciences",
            "hit": true
          },
          {
            "score": 0.6663514375686646,
            "answer": "life",
            "hit": false
          },
          {
            "score": 0.6655927896499634,
            "answer": "scientific",
            "hit": false
          },
          {
            "score": 0.6644049286842346,
            "answer": "experts",
            "hit": false
          }
        ],
        "set_exclude": [
          "science"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6716284602880478
      },
      {
        "question verbose": "What is to solution ",
        "b": "solution",
        "expected answer": [
          "solutions"
        ],
        "predictions": [
          {
            "score": 0.7349405884742737,
            "answer": "solutions",
            "hit": true
          },
          {
            "score": 0.7132618427276611,
            "answer": "problem",
            "hit": false
          },
          {
            "score": 0.7014274001121521,
            "answer": "answer",
            "hit": false
          },
          {
            "score": 0.651991605758667,
            "answer": "products",
            "hit": false
          },
          {
            "score": 0.6448385715484619,
            "answer": "types",
            "hit": false
          },
          {
            "score": 0.6342580318450928,
            "answer": "experts",
            "hit": false
          }
        ],
        "set_exclude": [
          "solution"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7349405884742737
      },
      {
        "question verbose": "What is to song ",
        "b": "song",
        "expected answer": [
          "songs"
        ],
        "predictions": [
          {
            "score": 0.9026772975921631,
            "answer": "songs",
            "hit": true
          },
          {
            "score": 0.7806254029273987,
            "answer": "lyrics",
            "hit": false
          },
          {
            "score": 0.764585554599762,
            "answer": "melody",
            "hit": false
          },
          {
            "score": 0.7599477171897888,
            "answer": "singing",
            "hit": false
          },
          {
            "score": 0.7538210153579712,
            "answer": "singers",
            "hit": false
          },
          {
            "score": 0.7359585165977478,
            "answer": "tunes",
            "hit": false
          }
        ],
        "set_exclude": [
          "song"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9026772677898407
      },
      {
        "question verbose": "What is to street ",
        "b": "street",
        "expected answer": [
          "streets"
        ],
        "predictions": [
          {
            "score": 0.6963723301887512,
            "answer": "streets",
            "hit": true
          },
          {
            "score": 0.6260663270950317,
            "answer": "stairs",
            "hit": false
          },
          {
            "score": 0.6152088642120361,
            "answer": "sur",
            "hit": false
          },
          {
            "score": 0.6130306124687195,
            "answer": "stone",
            "hit": false
          },
          {
            "score": 0.6116713285446167,
            "answer": "shots",
            "hit": false
          },
          {
            "score": 0.6085143089294434,
            "answer": "skirts",
            "hit": false
          }
        ],
        "set_exclude": [
          "street"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6963723301887512
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "students"
        ],
        "predictions": [
          {
            "score": 0.7645047903060913,
            "answer": "students",
            "hit": true
          },
          {
            "score": 0.7113840579986572,
            "answer": "campus",
            "hit": false
          },
          {
            "score": 0.6970582604408264,
            "answer": "education",
            "hit": false
          },
          {
            "score": 0.6661865711212158,
            "answer": "graduate",
            "hit": false
          },
          {
            "score": 0.6588824987411499,
            "answer": "kids",
            "hit": false
          },
          {
            "score": 0.6562674045562744,
            "answer": "campuses",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7645047903060913
      },
      {
        "question verbose": "What is to system ",
        "b": "system",
        "expected answer": [
          "systems"
        ],
        "predictions": [
          {
            "score": 0.7036160230636597,
            "answer": "processes",
            "hit": false
          },
          {
            "score": 0.7028323411941528,
            "answer": "mechanisms",
            "hit": false
          },
          {
            "score": 0.702024519443512,
            "answer": "systems",
            "hit": true
          },
          {
            "score": 0.6996015310287476,
            "answer": "mechanism",
            "hit": false
          },
          {
            "score": 0.69669109582901,
            "answer": "process",
            "hit": false
          },
          {
            "score": 0.6865345239639282,
            "answer": "scheme",
            "hit": false
          }
        ],
        "set_exclude": [
          "system"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.702024519443512
      },
      {
        "question verbose": "What is to thing ",
        "b": "thing",
        "expected answer": [
          "things"
        ],
        "predictions": [
          {
            "score": 0.6587258577346802,
            "answer": "things",
            "hit": true
          },
          {
            "score": 0.6548759937286377,
            "answer": "everything",
            "hit": false
          },
          {
            "score": 0.6342959403991699,
            "answer": "what",
            "hit": false
          },
          {
            "score": 0.632780909538269,
            "answer": "ness",
            "hit": false
          },
          {
            "score": 0.6273921728134155,
            "answer": "anything",
            "hit": false
          },
          {
            "score": 0.6265160441398621,
            "answer": "ways",
            "hit": false
          }
        ],
        "set_exclude": [
          "thing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6587258130311966
      },
      {
        "question verbose": "What is to town ",
        "b": "town",
        "expected answer": [
          "towns"
        ],
        "predictions": [
          {
            "score": 0.7824826240539551,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.7703195810317993,
            "answer": "village",
            "hit": false
          },
          {
            "score": 0.755485475063324,
            "answer": "villages",
            "hit": false
          },
          {
            "score": 0.7491458058357239,
            "answer": "cities",
            "hit": false
          },
          {
            "score": 0.7102385759353638,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.6970266699790955,
            "answer": "communities",
            "hit": false
          }
        ],
        "set_exclude": [
          "town"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6572533547878265
      },
      {
        "question verbose": "What is to user ",
        "b": "user",
        "expected answer": [
          "users"
        ],
        "predictions": [
          {
            "score": 0.7011510133743286,
            "answer": "customer",
            "hit": false
          },
          {
            "score": 0.6901340484619141,
            "answer": "users",
            "hit": true
          },
          {
            "score": 0.6808524131774902,
            "answer": "applications",
            "hit": false
          },
          {
            "score": 0.6748221516609192,
            "answer": "customers",
            "hit": false
          },
          {
            "score": 0.6705362796783447,
            "answer": "usage",
            "hit": false
          },
          {
            "score": 0.6649686098098755,
            "answer": "application",
            "hit": false
          }
        ],
        "set_exclude": [
          "user"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6901341080665588
      },
      {
        "question verbose": "What is to version ",
        "b": "version",
        "expected answer": [
          "versions"
        ],
        "predictions": [
          {
            "score": 0.7170961499214172,
            "answer": "variants",
            "hit": false
          },
          {
            "score": 0.7165750861167908,
            "answer": "editions",
            "hit": false
          },
          {
            "score": 0.7002973556518555,
            "answer": "iteration",
            "hit": false
          },
          {
            "score": 0.6817659735679626,
            "answer": "copies",
            "hit": false
          },
          {
            "score": 0.6713042855262756,
            "answer": "counterpart",
            "hit": false
          },
          {
            "score": 0.670826256275177,
            "answer": "counterparts",
            "hit": false
          }
        ],
        "set_exclude": [
          "version"
        ],
        "rank": 67,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6142653599381447
      },
      {
        "question verbose": "What is to village ",
        "b": "village",
        "expected answer": [
          "villages"
        ],
        "predictions": [
          {
            "score": 0.8885287642478943,
            "answer": "villages",
            "hit": true
          },
          {
            "score": 0.7943762540817261,
            "answer": "villagers",
            "hit": false
          },
          {
            "score": 0.7642720341682434,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.724959135055542,
            "answer": "city",
            "hit": false
          },
          {
            "score": 0.7014966011047363,
            "answer": "cities",
            "hit": false
          },
          {
            "score": 0.6990612745285034,
            "answer": "neighborhoods",
            "hit": false
          }
        ],
        "set_exclude": [
          "village"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8885287046432495
      },
      {
        "question verbose": "What is to website ",
        "b": "website",
        "expected answer": [
          "websites"
        ],
        "predictions": [
          {
            "score": 0.6951473355293274,
            "answer": "websites",
            "hit": true
          },
          {
            "score": 0.668877124786377,
            "answer": "hours",
            "hit": false
          },
          {
            "score": 0.6637466549873352,
            "answer": "images",
            "hit": false
          },
          {
            "score": 0.6622600555419922,
            "answer": "comments",
            "hit": false
          },
          {
            "score": 0.6554222702980042,
            "answer": "products",
            "hit": false
          },
          {
            "score": 0.6521035432815552,
            "answer": "download",
            "hit": false
          }
        ],
        "set_exclude": [
          "website"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6951473355293274
      },
      {
        "question verbose": "What is to week ",
        "b": "week",
        "expected answer": [
          "weeks"
        ],
        "predictions": [
          {
            "score": 0.7172955870628357,
            "answer": "day",
            "hit": false
          },
          {
            "score": 0.6726559400558472,
            "answer": "weekly",
            "hit": false
          },
          {
            "score": 0.666799008846283,
            "answer": "weeks",
            "hit": true
          },
          {
            "score": 0.6583365797996521,
            "answer": "world",
            "hit": false
          },
          {
            "score": 0.655266284942627,
            "answer": "weekend",
            "hit": false
          },
          {
            "score": 0.6423747539520264,
            "answer": "work",
            "hit": false
          }
        ],
        "set_exclude": [
          "week"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.666799008846283
      },
      {
        "question verbose": "What is to year ",
        "b": "year",
        "expected answer": [
          "years"
        ],
        "predictions": [
          {
            "score": 0.8225963115692139,
            "answer": "month",
            "hit": false
          },
          {
            "score": 0.7875884175300598,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.7557607293128967,
            "answer": "months",
            "hit": false
          },
          {
            "score": 0.7375009059906006,
            "answer": "seasons",
            "hit": false
          },
          {
            "score": 0.7019731998443604,
            "answer": "semester",
            "hit": false
          },
          {
            "score": 0.7006196975708008,
            "answer": "yearly",
            "hit": false
          }
        ],
        "set_exclude": [
          "year"
        ],
        "rank": 44,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6140476167201996
      }
    ],
    "result": {
      "cnt_questions_correct": 27,
      "cnt_questions_total": 50,
      "accuracy": 0.54
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I01 [noun - plural_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "3a3a9baf-0c99-4c11-9227-6b2389e3f3d7",
      "timestamp": "2025-05-17T17:15:32.502442"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ability ",
        "b": "ability",
        "expected answer": [
          "abilities"
        ],
        "predictions": [
          {
            "score": 0.6374202370643616,
            "answer": "abilities",
            "hit": true
          },
          {
            "score": 0.6295211315155029,
            "answer": "attributes",
            "hit": false
          },
          {
            "score": 0.6287224292755127,
            "answer": "types",
            "hit": false
          },
          {
            "score": 0.6244992017745972,
            "answer": "excellent",
            "hit": false
          },
          {
            "score": 0.6222597360610962,
            "answer": "capabilities",
            "hit": false
          },
          {
            "score": 0.6217972636222839,
            "answer": "increases",
            "hit": false
          }
        ],
        "set_exclude": [
          "ability"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6374202370643616
      },
      {
        "question verbose": "What is to activity ",
        "b": "activity",
        "expected answer": [
          "activities"
        ],
        "predictions": [
          {
            "score": 0.6847901940345764,
            "answer": "activities",
            "hit": true
          },
          {
            "score": 0.6392368674278259,
            "answer": "apps",
            "hit": false
          },
          {
            "score": 0.6357241868972778,
            "answer": "behaviors",
            "hit": false
          },
          {
            "score": 0.6319823265075684,
            "answer": "actions",
            "hit": false
          },
          {
            "score": 0.625785231590271,
            "answer": "view",
            "hit": false
          },
          {
            "score": 0.6233140230178833,
            "answer": "companies",
            "hit": false
          }
        ],
        "set_exclude": [
          "activity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6847902089357376
      },
      {
        "question verbose": "What is to agency ",
        "b": "agency",
        "expected answer": [
          "agencies"
        ],
        "predictions": [
          {
            "score": 0.7550463676452637,
            "answer": "agencies",
            "hit": true
          },
          {
            "score": 0.6793056130409241,
            "answer": "administration",
            "hit": false
          },
          {
            "score": 0.6544111967086792,
            "answer": "authority",
            "hit": false
          },
          {
            "score": 0.6523846983909607,
            "answer": "bureau",
            "hit": false
          },
          {
            "score": 0.640708863735199,
            "answer": "cia",
            "hit": false
          },
          {
            "score": 0.6391765475273132,
            "answer": "departments",
            "hit": false
          }
        ],
        "set_exclude": [
          "agency"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7550463080406189
      },
      {
        "question verbose": "What is to analysis ",
        "b": "analysis",
        "expected answer": [
          "analyses"
        ],
        "predictions": [
          {
            "score": 0.7609058618545532,
            "answer": "analyses",
            "hit": true
          },
          {
            "score": 0.7071322798728943,
            "answer": "analyst",
            "hit": false
          },
          {
            "score": 0.6974291801452637,
            "answer": "studies",
            "hit": false
          },
          {
            "score": 0.6836894750595093,
            "answer": "overview",
            "hit": false
          },
          {
            "score": 0.6766362190246582,
            "answer": "analysts",
            "hit": false
          },
          {
            "score": 0.6738036870956421,
            "answer": "comparison",
            "hit": false
          }
        ],
        "set_exclude": [
          "analysis"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.760905921459198
      },
      {
        "question verbose": "What is to army ",
        "b": "army",
        "expected answer": [
          "armies"
        ],
        "predictions": [
          {
            "score": 0.7478444576263428,
            "answer": "armies",
            "hit": true
          },
          {
            "score": 0.7378371953964233,
            "answer": "military",
            "hit": false
          },
          {
            "score": 0.7215402126312256,
            "answer": "troops",
            "hit": false
          },
          {
            "score": 0.7065722942352295,
            "answer": "air",
            "hit": false
          },
          {
            "score": 0.7023933529853821,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.6961492300033569,
            "answer": "infantry",
            "hit": false
          }
        ],
        "set_exclude": [
          "army"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.747844472527504
      },
      {
        "question verbose": "What is to authority ",
        "b": "authority",
        "expected answer": [
          "authorities"
        ],
        "predictions": [
          {
            "score": 0.6668518781661987,
            "answer": "agency",
            "hit": false
          },
          {
            "score": 0.6459527611732483,
            "answer": "administration",
            "hit": false
          },
          {
            "score": 0.6407326459884644,
            "answer": "commissioner",
            "hit": false
          },
          {
            "score": 0.639860987663269,
            "answer": "organizations",
            "hit": false
          },
          {
            "score": 0.6387497186660767,
            "answer": "ministry",
            "hit": false
          },
          {
            "score": 0.6382339000701904,
            "answer": "agencies",
            "hit": false
          }
        ],
        "set_exclude": [
          "authority"
        ],
        "rank": 522,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5720670819282532
      },
      {
        "question verbose": "What is to basis ",
        "b": "basis",
        "expected answer": [
          "bases"
        ],
        "predictions": [
          {
            "score": 0.7180145382881165,
            "answer": "bases",
            "hit": true
          },
          {
            "score": 0.691552996635437,
            "answer": "foundations",
            "hit": false
          },
          {
            "score": 0.6831963062286377,
            "answer": "backbone",
            "hit": false
          },
          {
            "score": 0.6772142052650452,
            "answer": "premise",
            "hit": false
          },
          {
            "score": 0.6749252080917358,
            "answer": "justification",
            "hit": false
          },
          {
            "score": 0.6723743677139282,
            "answer": "base",
            "hit": false
          }
        ],
        "set_exclude": [
          "basis"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7180145382881165
      },
      {
        "question verbose": "What is to business ",
        "b": "business",
        "expected answer": [
          "businesses"
        ],
        "predictions": [
          {
            "score": 0.7886201739311218,
            "answer": "businesses",
            "hit": true
          },
          {
            "score": 0.7025750279426575,
            "answer": "corporate",
            "hit": false
          },
          {
            "score": 0.6835371255874634,
            "answer": "industries",
            "hit": false
          },
          {
            "score": 0.6727128028869629,
            "answer": "entrepreneurs",
            "hit": false
          },
          {
            "score": 0.6673222780227661,
            "answer": "corporations",
            "hit": false
          },
          {
            "score": 0.6624292135238647,
            "answer": "industry",
            "hit": false
          }
        ],
        "set_exclude": [
          "business"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.788620114326477
      },
      {
        "question verbose": "What is to category ",
        "b": "category",
        "expected answer": [
          "categories"
        ],
        "predictions": [
          {
            "score": 0.6434376239776611,
            "answer": "categories",
            "hit": true
          },
          {
            "score": 0.6379765272140503,
            "answer": "items",
            "hit": false
          },
          {
            "score": 0.6362045407295227,
            "answer": "genres",
            "hit": false
          },
          {
            "score": 0.6359421014785767,
            "answer": "genre",
            "hit": false
          },
          {
            "score": 0.6313778162002563,
            "answer": "species",
            "hit": false
          },
          {
            "score": 0.6232588887214661,
            "answer": "component",
            "hit": false
          }
        ],
        "set_exclude": [
          "category"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6434376239776611
      },
      {
        "question verbose": "What is to century ",
        "b": "century",
        "expected answer": [
          "centuries"
        ],
        "predictions": [
          {
            "score": 0.6956804394721985,
            "answer": "centuries",
            "hit": true
          },
          {
            "score": 0.6596765518188477,
            "answer": "millennium",
            "hit": false
          },
          {
            "score": 0.6546574831008911,
            "answer": "decade",
            "hit": false
          },
          {
            "score": 0.6453160047531128,
            "answer": "decades",
            "hit": false
          },
          {
            "score": 0.6406946182250977,
            "answer": "generation",
            "hit": false
          },
          {
            "score": 0.6172267198562622,
            "answer": "eras",
            "hit": false
          }
        ],
        "set_exclude": [
          "century"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6956804394721985
      },
      {
        "question verbose": "What is to child ",
        "b": "child",
        "expected answer": [
          "children"
        ],
        "predictions": [
          {
            "score": 0.7072393894195557,
            "answer": "parent",
            "hit": false
          },
          {
            "score": 0.6897508502006531,
            "answer": "adult",
            "hit": false
          },
          {
            "score": 0.6812030673027039,
            "answer": "children",
            "hit": true
          },
          {
            "score": 0.6526983976364136,
            "answer": "young",
            "hit": false
          },
          {
            "score": 0.6488478183746338,
            "answer": "infants",
            "hit": false
          },
          {
            "score": 0.6437824368476868,
            "answer": "students",
            "hit": false
          }
        ],
        "set_exclude": [
          "child"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6812030673027039
      },
      {
        "question verbose": "What is to city ",
        "b": "city",
        "expected answer": [
          "cities"
        ],
        "predictions": [
          {
            "score": 0.8858802914619446,
            "answer": "cities",
            "hit": true
          },
          {
            "score": 0.7832979559898376,
            "answer": "town",
            "hit": false
          },
          {
            "score": 0.7597672343254089,
            "answer": "municipal",
            "hit": false
          },
          {
            "score": 0.7586346864700317,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.7547839283943176,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.7391746640205383,
            "answer": "streets",
            "hit": false
          }
        ],
        "set_exclude": [
          "city"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8858802914619446
      },
      {
        "question verbose": "What is to community ",
        "b": "community",
        "expected answer": [
          "communities"
        ],
        "predictions": [
          {
            "score": 0.6989185810089111,
            "answer": "communities",
            "hit": true
          },
          {
            "score": 0.6357524394989014,
            "answer": "breaking",
            "hit": false
          },
          {
            "score": 0.6353892087936401,
            "answer": "hundreds",
            "hit": false
          },
          {
            "score": 0.6340932846069336,
            "answer": "members",
            "hit": false
          },
          {
            "score": 0.6306268572807312,
            "answer": "commercial",
            "hit": false
          },
          {
            "score": 0.6284053921699524,
            "answer": "authorities",
            "hit": false
          }
        ],
        "set_exclude": [
          "community"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6989185363054276
      },
      {
        "question verbose": "What is to country ",
        "b": "country",
        "expected answer": [
          "countries"
        ],
        "predictions": [
          {
            "score": 0.7279222011566162,
            "answer": "countries",
            "hit": true
          },
          {
            "score": 0.677195131778717,
            "answer": "nations",
            "hit": false
          },
          {
            "score": 0.6666755080223083,
            "answer": "counties",
            "hit": false
          },
          {
            "score": 0.6611374616622925,
            "answer": "county",
            "hit": false
          },
          {
            "score": 0.6449154019355774,
            "answer": "regional",
            "hit": false
          },
          {
            "score": 0.6363939642906189,
            "answer": "places",
            "hit": false
          }
        ],
        "set_exclude": [
          "country"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.727922186255455
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "counties"
        ],
        "predictions": [
          {
            "score": 0.8127037882804871,
            "answer": "counties",
            "hit": true
          },
          {
            "score": 0.7147032618522644,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.6695559620857239,
            "answer": "neighborhoods",
            "hit": false
          },
          {
            "score": 0.6661033630371094,
            "answer": "municipalities",
            "hit": false
          },
          {
            "score": 0.6643475294113159,
            "answer": "parish",
            "hit": false
          },
          {
            "score": 0.6555967330932617,
            "answer": "regional",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8127037882804871
      },
      {
        "question verbose": "What is to duty ",
        "b": "duty",
        "expected answer": [
          "duties"
        ],
        "predictions": [
          {
            "score": 0.7150576114654541,
            "answer": "duties",
            "hit": true
          },
          {
            "score": 0.6529760956764221,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.6419098377227783,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.6401033401489258,
            "answer": "responsibilities",
            "hit": false
          },
          {
            "score": 0.6237912178039551,
            "answer": "tasks",
            "hit": false
          },
          {
            "score": 0.6236145496368408,
            "answer": "combat",
            "hit": false
          }
        ],
        "set_exclude": [
          "duty"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7150576114654541
      },
      {
        "question verbose": "What is to economy ",
        "b": "economy",
        "expected answer": [
          "economies"
        ],
        "predictions": [
          {
            "score": 0.7452216148376465,
            "answer": "economies",
            "hit": true
          },
          {
            "score": 0.6664810180664062,
            "answer": "industries",
            "hit": false
          },
          {
            "score": 0.6590714454650879,
            "answer": "economists",
            "hit": false
          },
          {
            "score": 0.6550136804580688,
            "answer": "agriculture",
            "hit": false
          },
          {
            "score": 0.6535426378250122,
            "answer": "economics",
            "hit": false
          },
          {
            "score": 0.6457117795944214,
            "answer": "industry",
            "hit": false
          }
        ],
        "set_exclude": [
          "economy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7452216595411301
      },
      {
        "question verbose": "What is to energy ",
        "b": "energy",
        "expected answer": [
          "energies"
        ],
        "predictions": [
          {
            "score": 0.7134537696838379,
            "answer": "energies",
            "hit": true
          },
          {
            "score": 0.6923341751098633,
            "answer": "electricity",
            "hit": false
          },
          {
            "score": 0.682639479637146,
            "answer": "oil",
            "hit": false
          },
          {
            "score": 0.677250862121582,
            "answer": "environmental",
            "hit": false
          },
          {
            "score": 0.6760431528091431,
            "answer": "solar",
            "hit": false
          },
          {
            "score": 0.6702960133552551,
            "answer": "agriculture",
            "hit": false
          }
        ],
        "set_exclude": [
          "energy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7134537696838379
      },
      {
        "question verbose": "What is to entry ",
        "b": "entry",
        "expected answer": [
          "entries"
        ],
        "predictions": [
          {
            "score": 0.7212584018707275,
            "answer": "entries",
            "hit": true
          },
          {
            "score": 0.6187063455581665,
            "answer": "comments",
            "hit": false
          },
          {
            "score": 0.6171638369560242,
            "answer": "members",
            "hit": false
          },
          {
            "score": 0.6153371334075928,
            "answer": "from",
            "hit": false
          },
          {
            "score": 0.6141690015792847,
            "answer": "types",
            "hit": false
          },
          {
            "score": 0.6136109232902527,
            "answer": "opening",
            "hit": false
          }
        ],
        "set_exclude": [
          "entry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7212584316730499
      },
      {
        "question verbose": "What is to facility ",
        "b": "facility",
        "expected answer": [
          "facilities"
        ],
        "predictions": [
          {
            "score": 0.7144840955734253,
            "answer": "capabilities",
            "hit": false
          },
          {
            "score": 0.712177038192749,
            "answer": "infrastructure",
            "hit": false
          },
          {
            "score": 0.7084245681762695,
            "answer": "locations",
            "hit": false
          },
          {
            "score": 0.7007842063903809,
            "answer": "capability",
            "hit": false
          },
          {
            "score": 0.6981493234634399,
            "answer": "venue",
            "hit": false
          },
          {
            "score": 0.695580244064331,
            "answer": "location",
            "hit": false
          }
        ],
        "set_exclude": [
          "facility"
        ],
        "rank": 28,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6760246604681015
      },
      {
        "question verbose": "What is to family ",
        "b": "family",
        "expected answer": [
          "families"
        ],
        "predictions": [
          {
            "score": 0.8028660416603088,
            "answer": "relatives",
            "hit": false
          },
          {
            "score": 0.7498847246170044,
            "answer": "parents",
            "hit": false
          },
          {
            "score": 0.7477061748504639,
            "answer": "siblings",
            "hit": false
          },
          {
            "score": 0.7187050580978394,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.7182707786560059,
            "answer": "brothers",
            "hit": false
          },
          {
            "score": 0.7090839147567749,
            "answer": "grandparents",
            "hit": false
          }
        ],
        "set_exclude": [
          "family"
        ],
        "rank": 31,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6656681448221207
      },
      {
        "question verbose": "What is to history ",
        "b": "history",
        "expected answer": [
          "histories"
        ],
        "predictions": [
          {
            "score": 0.8042788505554199,
            "answer": "histories",
            "hit": true
          },
          {
            "score": 0.7248921394348145,
            "answer": "historical",
            "hit": false
          },
          {
            "score": 0.714572012424469,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.6845517158508301,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.6671506762504578,
            "answer": "studies",
            "hit": false
          },
          {
            "score": 0.6578909158706665,
            "answer": "timeline",
            "hit": false
          }
        ],
        "set_exclude": [
          "history"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8042788803577423
      },
      {
        "question verbose": "What is to industry ",
        "b": "industry",
        "expected answer": [
          "industries"
        ],
        "predictions": [
          {
            "score": 0.7924847602844238,
            "answer": "industries",
            "hit": true
          },
          {
            "score": 0.6969218850135803,
            "answer": "industrial",
            "hit": false
          },
          {
            "score": 0.6825636625289917,
            "answer": "businesses",
            "hit": false
          },
          {
            "score": 0.6703056693077087,
            "answer": "organizations",
            "hit": false
          },
          {
            "score": 0.6697192192077637,
            "answer": "manufacturers",
            "hit": false
          },
          {
            "score": 0.6665517091751099,
            "answer": "technology",
            "hit": false
          }
        ],
        "set_exclude": [
          "industry"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7924847602844238
      },
      {
        "question verbose": "What is to library ",
        "b": "library",
        "expected answer": [
          "libraries"
        ],
        "predictions": [
          {
            "score": 0.7285589575767517,
            "answer": "libraries",
            "hit": true
          },
          {
            "score": 0.7258901596069336,
            "answer": "collections",
            "hit": false
          },
          {
            "score": 0.7043101787567139,
            "answer": "archives",
            "hit": false
          },
          {
            "score": 0.7028911113739014,
            "answer": "databases",
            "hit": false
          },
          {
            "score": 0.6917281150817871,
            "answer": "catalog",
            "hit": false
          },
          {
            "score": 0.6916313171386719,
            "answer": "museum",
            "hit": false
          }
        ],
        "set_exclude": [
          "library"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7285589575767517
      },
      {
        "question verbose": "What is to life ",
        "b": "life",
        "expected answer": [
          "lives"
        ],
        "predictions": [
          {
            "score": 0.6518704891204834,
            "answer": "lives",
            "hit": true
          },
          {
            "score": 0.6515258550643921,
            "answer": "science",
            "hit": false
          },
          {
            "score": 0.6513634324073792,
            "answer": "everything",
            "hit": false
          },
          {
            "score": 0.6484025120735168,
            "answer": "years",
            "hit": false
          },
          {
            "score": 0.6464366912841797,
            "answer": "days",
            "hit": false
          },
          {
            "score": 0.6454089879989624,
            "answer": "live",
            "hit": false
          }
        ],
        "set_exclude": [
          "life"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6518704891204834
      },
      {
        "question verbose": "What is to loss ",
        "b": "loss",
        "expected answer": [
          "losses"
        ],
        "predictions": [
          {
            "score": 0.7422738671302795,
            "answer": "losses",
            "hit": true
          },
          {
            "score": 0.6547223329544067,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.6428290605545044,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.6253288388252258,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.6241949796676636,
            "answer": "gains",
            "hit": false
          },
          {
            "score": 0.6228690147399902,
            "answer": "reductions",
            "hit": false
          }
        ],
        "set_exclude": [
          "loss"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7422738969326019
      },
      {
        "question verbose": "What is to memory ",
        "b": "memory",
        "expected answer": [
          "memories"
        ],
        "predictions": [
          {
            "score": 0.6540014743804932,
            "answer": "storage",
            "hit": false
          },
          {
            "score": 0.6420130729675293,
            "answer": "memories",
            "hit": true
          },
          {
            "score": 0.6380207538604736,
            "answer": "images",
            "hit": false
          },
          {
            "score": 0.6362712979316711,
            "answer": "textures",
            "hit": false
          },
          {
            "score": 0.6362079381942749,
            "answer": "ancient",
            "hit": false
          },
          {
            "score": 0.6359081864356995,
            "answer": "remember",
            "hit": false
          }
        ],
        "set_exclude": [
          "memory"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6420131325721741
      },
      {
        "question verbose": "What is to opportunity ",
        "b": "opportunity",
        "expected answer": [
          "opportunities"
        ],
        "predictions": [
          {
            "score": 0.8901326060295105,
            "answer": "opportunities",
            "hit": true
          },
          {
            "score": 0.723089337348938,
            "answer": "possibility",
            "hit": false
          },
          {
            "score": 0.7214845418930054,
            "answer": "possibilities",
            "hit": false
          },
          {
            "score": 0.7000640630722046,
            "answer": "chances",
            "hit": false
          },
          {
            "score": 0.6984425783157349,
            "answer": "advantages",
            "hit": false
          },
          {
            "score": 0.6886886358261108,
            "answer": "prospects",
            "hit": false
          }
        ],
        "set_exclude": [
          "opportunity"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8901325464248657
      },
      {
        "question verbose": "What is to policy ",
        "b": "policy",
        "expected answer": [
          "policies"
        ],
        "predictions": [
          {
            "score": 0.7965700626373291,
            "answer": "policies",
            "hit": true
          },
          {
            "score": 0.6815625429153442,
            "answer": "programs",
            "hit": false
          },
          {
            "score": 0.6671651601791382,
            "answer": "strategy",
            "hit": false
          },
          {
            "score": 0.6649616956710815,
            "answer": "plans",
            "hit": false
          },
          {
            "score": 0.6646754741668701,
            "answer": "guidelines",
            "hit": false
          },
          {
            "score": 0.6573434472084045,
            "answer": "agenda",
            "hit": false
          }
        ],
        "set_exclude": [
          "policy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7965700030326843
      },
      {
        "question verbose": "What is to property ",
        "b": "property",
        "expected answer": [
          "properties"
        ],
        "predictions": [
          {
            "score": 0.7431631088256836,
            "answer": "properties",
            "hit": true
          },
          {
            "score": 0.6676501035690308,
            "answer": "objects",
            "hit": false
          },
          {
            "score": 0.6449347734451294,
            "answer": "items",
            "hit": false
          },
          {
            "score": 0.6388688087463379,
            "answer": "assets",
            "hit": false
          },
          {
            "score": 0.6378483176231384,
            "answer": "estates",
            "hit": false
          },
          {
            "score": 0.6325250267982483,
            "answer": "tenants",
            "hit": false
          }
        ],
        "set_exclude": [
          "property"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7431631088256836
      },
      {
        "question verbose": "What is to responsibility ",
        "b": "responsibility",
        "expected answer": [
          "responsibilities"
        ],
        "predictions": [
          {
            "score": 0.8551307916641235,
            "answer": "responsibilities",
            "hit": true
          },
          {
            "score": 0.7619812488555908,
            "answer": "obligations",
            "hit": false
          },
          {
            "score": 0.7561657428741455,
            "answer": "obligation",
            "hit": false
          },
          {
            "score": 0.7463133335113525,
            "answer": "duties",
            "hit": false
          },
          {
            "score": 0.7334051132202148,
            "answer": "accountability",
            "hit": false
          },
          {
            "score": 0.7183055281639099,
            "answer": "roles",
            "hit": false
          }
        ],
        "set_exclude": [
          "responsibility"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8551307916641235
      },
      {
        "question verbose": "What is to security ",
        "b": "security",
        "expected answer": [
          "securities"
        ],
        "predictions": [
          {
            "score": 0.7095229625701904,
            "answer": "protections",
            "hit": false
          },
          {
            "score": 0.7052804827690125,
            "answer": "encryption",
            "hit": false
          },
          {
            "score": 0.7034966945648193,
            "answer": "stability",
            "hit": false
          },
          {
            "score": 0.6948093175888062,
            "answer": "securing",
            "hit": false
          },
          {
            "score": 0.694484293460846,
            "answer": "policies",
            "hit": false
          },
          {
            "score": 0.693098783493042,
            "answer": "terrorists",
            "hit": false
          }
        ],
        "set_exclude": [
          "security"
        ],
        "rank": 53,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6571022719144821
      },
      {
        "question verbose": "What is to series ",
        "b": "series",
        "expected answer": [
          "series"
        ],
        "predictions": [
          {
            "score": 0.6290460228919983,
            "answer": "episodes",
            "hit": false
          },
          {
            "score": 0.6285866498947144,
            "answer": "trilogy",
            "hit": false
          },
          {
            "score": 0.6230446696281433,
            "answer": "seasons",
            "hit": false
          },
          {
            "score": 0.6176084280014038,
            "answer": "groups",
            "hit": false
          },
          {
            "score": 0.6174823641777039,
            "answer": "model",
            "hit": false
          },
          {
            "score": 0.6161932349205017,
            "answer": "formats",
            "hit": false
          }
        ],
        "set_exclude": [
          "series"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9614349603652954
      },
      {
        "question verbose": "What is to society ",
        "b": "society",
        "expected answer": [
          "societies"
        ],
        "predictions": [
          {
            "score": 0.8724108934402466,
            "answer": "societies",
            "hit": true
          },
          {
            "score": 0.7754231691360474,
            "answer": "societal",
            "hit": false
          },
          {
            "score": 0.7489053606987,
            "answer": "civilization",
            "hit": false
          },
          {
            "score": 0.7380079627037048,
            "answer": "communities",
            "hit": false
          },
          {
            "score": 0.7166837453842163,
            "answer": "institutions",
            "hit": false
          },
          {
            "score": 0.7122722864151001,
            "answer": "nations",
            "hit": false
          }
        ],
        "set_exclude": [
          "society"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.872410923242569
      },
      {
        "question verbose": "What is to species ",
        "b": "species",
        "expected answer": [
          "species"
        ],
        "predictions": [
          {
            "score": 0.6741875410079956,
            "answer": "organisms",
            "hit": false
          },
          {
            "score": 0.6671875715255737,
            "answer": "varieties",
            "hit": false
          },
          {
            "score": 0.6555431485176086,
            "answer": "creatures",
            "hit": false
          },
          {
            "score": 0.6538137197494507,
            "answer": "populations",
            "hit": false
          },
          {
            "score": 0.6519463062286377,
            "answer": "habitats",
            "hit": false
          },
          {
            "score": 0.6453266739845276,
            "answer": "breeding",
            "hit": false
          }
        ],
        "set_exclude": [
          "species"
        ],
        "rank": 14180,
        "landing_b": true,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9631744027137756
      },
      {
        "question verbose": "What is to story ",
        "b": "story",
        "expected answer": [
          "stories"
        ],
        "predictions": [
          {
            "score": 0.6623305678367615,
            "answer": "stories",
            "hit": true
          },
          {
            "score": 0.6388199925422668,
            "answer": "narratives",
            "hit": false
          },
          {
            "score": 0.6358172297477722,
            "answer": "characters",
            "hit": false
          },
          {
            "score": 0.6315565705299377,
            "answer": "newsletter",
            "hit": false
          },
          {
            "score": 0.6281106472015381,
            "answer": "tales",
            "hit": false
          },
          {
            "score": 0.6185169816017151,
            "answer": "plot",
            "hit": false
          }
        ],
        "set_exclude": [
          "story"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6623305678367615
      },
      {
        "question verbose": "What is to strategy ",
        "b": "strategy",
        "expected answer": [
          "strategies"
        ],
        "predictions": [
          {
            "score": 0.7668573260307312,
            "answer": "strategies",
            "hit": true
          },
          {
            "score": 0.7013897895812988,
            "answer": "tactics",
            "hit": false
          },
          {
            "score": 0.6845264434814453,
            "answer": "strategic",
            "hit": false
          },
          {
            "score": 0.6668682098388672,
            "answer": "campaign",
            "hit": false
          },
          {
            "score": 0.6661120653152466,
            "answer": "policy",
            "hit": false
          },
          {
            "score": 0.6634683609008789,
            "answer": "plans",
            "hit": false
          }
        ],
        "set_exclude": [
          "strategy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7668573260307312
      },
      {
        "question verbose": "What is to success ",
        "b": "success",
        "expected answer": [
          "successes"
        ],
        "predictions": [
          {
            "score": 0.7529203295707703,
            "answer": "successes",
            "hit": true
          },
          {
            "score": 0.6765871047973633,
            "answer": "results",
            "hit": false
          },
          {
            "score": 0.675529420375824,
            "answer": "successful",
            "hit": false
          },
          {
            "score": 0.6687353849411011,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.6673948168754578,
            "answer": "victories",
            "hit": false
          },
          {
            "score": 0.6569489240646362,
            "answer": "accomplishments",
            "hit": false
          }
        ],
        "set_exclude": [
          "success"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7529203593730927
      },
      {
        "question verbose": "What is to technology ",
        "b": "technology",
        "expected answer": [
          "technologies"
        ],
        "predictions": [
          {
            "score": 0.7840311527252197,
            "answer": "technologies",
            "hit": true
          },
          {
            "score": 0.7146453857421875,
            "answer": "technological",
            "hit": false
          },
          {
            "score": 0.7135953307151794,
            "answer": "tech",
            "hit": false
          },
          {
            "score": 0.7063062787055969,
            "answer": "innovation",
            "hit": false
          },
          {
            "score": 0.6929323673248291,
            "answer": "engineering",
            "hit": false
          },
          {
            "score": 0.6865764856338501,
            "answer": "systems",
            "hit": false
          }
        ],
        "set_exclude": [
          "technology"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7840311229228973
      },
      {
        "question verbose": "What is to theory ",
        "b": "theory",
        "expected answer": [
          "theories"
        ],
        "predictions": [
          {
            "score": 0.7911670207977295,
            "answer": "theories",
            "hit": true
          },
          {
            "score": 0.6798393726348877,
            "answer": "hypothesis",
            "hit": false
          },
          {
            "score": 0.6709824204444885,
            "answer": "concepts",
            "hit": false
          },
          {
            "score": 0.6612261533737183,
            "answer": "studies",
            "hit": false
          },
          {
            "score": 0.6591636538505554,
            "answer": "principles",
            "hit": false
          },
          {
            "score": 0.6552083492279053,
            "answer": "interpretations",
            "hit": false
          }
        ],
        "set_exclude": [
          "theory"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7911670207977295
      },
      {
        "question verbose": "What is to university ",
        "b": "university",
        "expected answer": [
          "universities"
        ],
        "predictions": [
          {
            "score": 0.881027102470398,
            "answer": "universities",
            "hit": true
          },
          {
            "score": 0.7912728786468506,
            "answer": "school",
            "hit": false
          },
          {
            "score": 0.7557565569877625,
            "answer": "campuses",
            "hit": false
          },
          {
            "score": 0.7556240558624268,
            "answer": "undergraduate",
            "hit": false
          },
          {
            "score": 0.7552065253257751,
            "answer": "academics",
            "hit": false
          },
          {
            "score": 0.7501218914985657,
            "answer": "professors",
            "hit": false
          }
        ],
        "set_exclude": [
          "university"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.881027102470398
      },
      {
        "question verbose": "What is to variety ",
        "b": "variety",
        "expected answer": [
          "varieties"
        ],
        "predictions": [
          {
            "score": 0.6539648771286011,
            "answer": "varieties",
            "hit": true
          },
          {
            "score": 0.6505893468856812,
            "answer": "diversity",
            "hit": false
          },
          {
            "score": 0.6460046768188477,
            "answer": "vanity",
            "hit": false
          },
          {
            "score": 0.6420288681983948,
            "answer": "paramount",
            "hit": false
          },
          {
            "score": 0.6352812647819519,
            "answer": "genres",
            "hit": false
          },
          {
            "score": 0.6344839334487915,
            "answer": "productions",
            "hit": false
          }
        ],
        "set_exclude": [
          "variety"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6539648771286011
      },
      {
        "question verbose": "What is to wife ",
        "b": "wife",
        "expected answer": [
          "wives"
        ],
        "predictions": [
          {
            "score": 0.8548433780670166,
            "answer": "wives",
            "hit": true
          },
          {
            "score": 0.7283604145050049,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.6493498086929321,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.6478849053382874,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.6456742286682129,
            "answer": "daughters",
            "hit": false
          },
          {
            "score": 0.6369567513465881,
            "answer": "widow",
            "hit": false
          }
        ],
        "set_exclude": [
          "wife"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8548433780670166
      },
      {
        "question verbose": "What is to woman ",
        "b": "woman",
        "expected answer": [
          "women"
        ],
        "predictions": [
          {
            "score": 0.6969184875488281,
            "answer": "female",
            "hit": false
          },
          {
            "score": 0.6920498609542847,
            "answer": "lady",
            "hit": false
          },
          {
            "score": 0.67814040184021,
            "answer": "women",
            "hit": true
          },
          {
            "score": 0.6552904844284058,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.6548291444778442,
            "answer": "sex",
            "hit": false
          },
          {
            "score": 0.654239296913147,
            "answer": "male",
            "hit": false
          }
        ],
        "set_exclude": [
          "woman"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6781403720378876
      }
    ],
    "result": {
      "cnt_questions_correct": 35,
      "cnt_questions_total": 44,
      "accuracy": 0.7954545454545454
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I02 [noun - plural_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "f52c8ee5-e77c-47a4-8948-a069d47dbb18",
      "timestamp": "2025-05-17T17:15:32.695946"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to cheap ",
        "b": "cheap",
        "expected answer": [
          "cheaper"
        ],
        "predictions": [
          {
            "score": 0.786341667175293,
            "answer": "cheaper",
            "hit": true
          },
          {
            "score": 0.6900314092636108,
            "answer": "poorer",
            "hit": false
          },
          {
            "score": 0.686379075050354,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.6814994812011719,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.6796848773956299,
            "answer": "bigger",
            "hit": false
          },
          {
            "score": 0.678347110748291,
            "answer": "happier",
            "hit": false
          }
        ],
        "set_exclude": [
          "cheap"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7863416373729706
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happier"
        ],
        "predictions": [
          {
            "score": 0.7330859899520874,
            "answer": "happier",
            "hit": true
          },
          {
            "score": 0.713545560836792,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.6954480409622192,
            "answer": "easier",
            "hit": false
          },
          {
            "score": 0.6931561231613159,
            "answer": "cheaper",
            "hit": false
          },
          {
            "score": 0.6803994178771973,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.6789705753326416,
            "answer": "simpler",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7330860048532486
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "stronger"
        ],
        "predictions": [
          {
            "score": 0.8256644606590271,
            "answer": "stronger",
            "hit": true
          },
          {
            "score": 0.7882320284843445,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.7158548831939697,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.6882099509239197,
            "answer": "softer",
            "hit": false
          },
          {
            "score": 0.6866977214813232,
            "answer": "strengthened",
            "hit": false
          },
          {
            "score": 0.6814560890197754,
            "answer": "heavier",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8256645202636719
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weaker"
        ],
        "predictions": [
          {
            "score": 0.7981542348861694,
            "answer": "weaker",
            "hit": true
          },
          {
            "score": 0.7902883887290955,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.6954516172409058,
            "answer": "weakening",
            "hit": false
          },
          {
            "score": 0.6935020685195923,
            "answer": "weakness",
            "hit": false
          },
          {
            "score": 0.687401294708252,
            "answer": "slower",
            "hit": false
          },
          {
            "score": 0.6867631077766418,
            "answer": "weakened",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7981542646884918
      }
    ],
    "result": {
      "cnt_questions_correct": 4,
      "cnt_questions_total": 4,
      "accuracy": 1.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I03 [adj - comparative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "58b70622-e4fe-4bbd-b787-945eacc40671",
      "timestamp": "2025-05-17T17:15:32.875399"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to hot ",
        "b": "hot",
        "expected answer": [
          "hottest"
        ],
        "predictions": [
          {
            "score": 0.7263718843460083,
            "answer": "strongest",
            "hit": false
          },
          {
            "score": 0.697663426399231,
            "answer": "biggest",
            "hit": false
          },
          {
            "score": 0.6883596777915955,
            "answer": "hottest",
            "hit": true
          },
          {
            "score": 0.6875612139701843,
            "answer": "most",
            "hit": false
          },
          {
            "score": 0.6671314835548401,
            "answer": "easiest",
            "hit": false
          },
          {
            "score": 0.651557445526123,
            "answer": "closest",
            "hit": false
          }
        ],
        "set_exclude": [
          "hot"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6883596777915955
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongest"
        ],
        "predictions": [
          {
            "score": 0.7506993412971497,
            "answer": "hottest",
            "hit": false
          },
          {
            "score": 0.7143815755844116,
            "answer": "strongest",
            "hit": true
          },
          {
            "score": 0.6560449600219727,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.638260006904602,
            "answer": "fastest",
            "hit": false
          },
          {
            "score": 0.6357342004776001,
            "answer": "lowest",
            "hit": false
          },
          {
            "score": 0.6306140422821045,
            "answer": "brightest",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7143815755844116
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 2,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I04 [adj - superlative].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "bbeb28c1-bc23-4463-9851-320ac5745350",
      "timestamp": "2025-05-17T17:15:32.889568"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepts"
        ],
        "predictions": [
          {
            "score": 0.9113885164260864,
            "answer": "accepts",
            "hit": true
          },
          {
            "score": 0.7868978977203369,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.7853009700775146,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.7486538290977478,
            "answer": "acknowledges",
            "hit": false
          },
          {
            "score": 0.7477984428405762,
            "answer": "rejects",
            "hit": false
          },
          {
            "score": 0.744587242603302,
            "answer": "agrees",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9113885760307312
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.7167763710021973,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.6983124017715454,
            "answer": "brings",
            "hit": false
          },
          {
            "score": 0.6969542503356934,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.6904590129852295,
            "answer": "makes",
            "hit": false
          },
          {
            "score": 0.681525707244873,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.6793655753135681,
            "answer": "puts",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 320,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5950390249490738
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agrees"
        ],
        "predictions": [
          {
            "score": 0.7347375154495239,
            "answer": "agrees",
            "hit": true
          },
          {
            "score": 0.6746489405632019,
            "answer": "prefers",
            "hit": false
          },
          {
            "score": 0.6724584698677063,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.6719465255737305,
            "answer": "argues",
            "hit": false
          },
          {
            "score": 0.6696518063545227,
            "answer": "suggests",
            "hit": false
          },
          {
            "score": 0.6693239212036133,
            "answer": "acknowledges",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7347374856472015
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.6986163854598999,
            "answer": "allows",
            "hit": true
          },
          {
            "score": 0.6948409080505371,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.6933605670928955,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.6905013918876648,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.6874336004257202,
            "answer": "removes",
            "hit": false
          },
          {
            "score": 0.6856683492660522,
            "answer": "encourages",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6986163854598999
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.8479583263397217,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.8257983922958374,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7973556518554688,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7594233751296997,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7572720646858215,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7440874576568604,
            "answer": "becomes",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 516,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6161733791232109
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.7610183358192444,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.6711721420288086,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.6703154444694519,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.6695933938026428,
            "answer": "removes",
            "hit": false
          },
          {
            "score": 0.6686367392539978,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.6684023141860962,
            "answer": "applying",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7610183358192444
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.7517579793930054,
            "answer": "asks",
            "hit": true
          },
          {
            "score": 0.6803040504455566,
            "answer": "questions",
            "hit": false
          },
          {
            "score": 0.6734082698822021,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.6696618795394897,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.6691516637802124,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.6625444889068604,
            "answer": "considers",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7517579793930054
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoids"
        ],
        "predictions": [
          {
            "score": 0.7789711952209473,
            "answer": "avoids",
            "hit": true
          },
          {
            "score": 0.7012611627578735,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.6984314918518066,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.6874828338623047,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.6857408285140991,
            "answer": "ignores",
            "hit": false
          },
          {
            "score": 0.6851440668106079,
            "answer": "encourages",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7789711952209473
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.7378081679344177,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.6881618499755859,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.6802477836608887,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.6799695491790771,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.6792694330215454,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.6761319041252136,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7378082126379013
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.7795132398605347,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.7007870078086853,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.678044319152832,
            "answer": "insists",
            "hit": false
          },
          {
            "score": 0.6776890158653259,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.6755848526954651,
            "answer": "says",
            "hit": false
          },
          {
            "score": 0.6711004376411438,
            "answer": "knows",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7795132696628571
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.7272294163703918,
            "answer": "considers",
            "hit": true
          },
          {
            "score": 0.6731681823730469,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.6633793115615845,
            "answer": "suggests",
            "hit": false
          },
          {
            "score": 0.6589577794075012,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.6577503681182861,
            "answer": "doesn",
            "hit": false
          },
          {
            "score": 0.6547645330429077,
            "answer": "discusses",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7272293865680695
      },
      {
        "question verbose": "What is to consist ",
        "b": "consist",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.9199057817459106,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.8511122465133667,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.8007400631904602,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7818660140037537,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.771278977394104,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7650975584983826,
            "answer": "contains",
            "hit": false
          }
        ],
        "set_exclude": [
          "consist"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9199057817459106
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.9204986095428467,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.7777615785598755,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.7652446031570435,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.7592865228652954,
            "answer": "possesses",
            "hit": false
          },
          {
            "score": 0.7589905261993408,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7521770000457764,
            "answer": "involves",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9204986095428467
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.9236992597579956,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.7842002511024475,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.7562172412872314,
            "answer": "keeps",
            "hit": false
          },
          {
            "score": 0.7552006244659424,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7436122298240662,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.7369141578674316,
            "answer": "remains",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9236993193626404
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.9350988268852234,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.8070994019508362,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.7839346528053284,
            "answer": "makes",
            "hit": false
          },
          {
            "score": 0.7796975374221802,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.7735118865966797,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7710161209106445,
            "answer": "generate",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9350987672805786
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.9181753396987915,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.7810755968093872,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7762494087219238,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.7756213545799255,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.7706270217895508,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7679840326309204,
            "answer": "defines",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9181753098964691
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.7487598061561584,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.6997014284133911,
            "answer": "developer",
            "hit": false
          },
          {
            "score": 0.6632755994796753,
            "answer": "design",
            "hit": false
          },
          {
            "score": 0.6617889404296875,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6549266576766968,
            "answer": "testing",
            "hit": false
          },
          {
            "score": 0.6534923315048218,
            "answer": "developed",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7487598061561584
      },
      {
        "question verbose": "What is to enable ",
        "b": "enable",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.7271183729171753,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.6783531904220581,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.6709367036819458,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.6680983304977417,
            "answer": "allow",
            "hit": false
          },
          {
            "score": 0.6622188091278076,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.6577396392822266,
            "answer": "creates",
            "hit": false
          }
        ],
        "set_exclude": [
          "enable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7271183729171753
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoys"
        ],
        "predictions": [
          {
            "score": 0.7686371207237244,
            "answer": "enjoys",
            "hit": true
          },
          {
            "score": 0.6955850124359131,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.6941820383071899,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.6910715103149414,
            "answer": "makes",
            "hit": false
          },
          {
            "score": 0.6902312636375427,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.6868408918380737,
            "answer": "celebrates",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7686371505260468
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensures"
        ],
        "predictions": [
          {
            "score": 0.9173664450645447,
            "answer": "ensures",
            "hit": true
          },
          {
            "score": 0.8005033731460571,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7970597743988037,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.7911732792854309,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7902548313140869,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.7633469700813293,
            "answer": "protects",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9173665046691895
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.9312629699707031,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.8617377281188965,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.7350993156433105,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7343814373016357,
            "answer": "arises",
            "hit": false
          },
          {
            "score": 0.7300149202346802,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.724860429763794,
            "answer": "survives",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9312629699707031
      },
      {
        "question verbose": "What is to explain ",
        "b": "explain",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.7705397605895996,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.7340825796127319,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7329776287078857,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.710435152053833,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.6969236135482788,
            "answer": "argues",
            "hit": false
          },
          {
            "score": 0.695642352104187,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "explain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7705398201942444
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.7653713822364807,
            "answer": "follows",
            "hit": true
          },
          {
            "score": 0.7158381938934326,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.66316819190979,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.659529447555542,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.6580151915550232,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.6574000716209412,
            "answer": "corresponds",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7653713524341583
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.9004271030426025,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.8353791832923889,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.8060511350631714,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7812103033065796,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7735996246337891,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.7370178699493408,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9004271626472473
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.8365188837051392,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.8073371648788452,
            "answer": "heard",
            "hit": false
          },
          {
            "score": 0.7508524656295776,
            "answer": "sees",
            "hit": false
          },
          {
            "score": 0.7206323146820068,
            "answer": "listen",
            "hit": false
          },
          {
            "score": 0.7183109521865845,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.70964515209198,
            "answer": "learns",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8365189135074615
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifies"
        ],
        "predictions": [
          {
            "score": 0.9064120054244995,
            "answer": "identifies",
            "hit": true
          },
          {
            "score": 0.8108305931091309,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.8059672713279724,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7482888698577881,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7360830307006836,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.7359529137611389,
            "answer": "recognizes",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9064119458198547
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.8129066228866577,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.7320802211761475,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7296582460403442,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.7195914387702942,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.7119121551513672,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.7099676132202148,
            "answer": "promotes",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8129066526889801
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.7962530851364136,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7958155870437622,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.7942736148834229,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.7862889170646667,
            "answer": "encompasses",
            "hit": false
          },
          {
            "score": 0.7806028127670288,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.7800363898277283,
            "answer": "contains",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 78,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6948122084140778
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.9240785837173462,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.7646387815475464,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.7627972364425659,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.7611773014068604,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7557995319366455,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.7442691326141357,
            "answer": "occurs",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9240785837173462
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.7395994067192078,
            "answer": "learns",
            "hit": true
          },
          {
            "score": 0.7123755812644958,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.6846245527267456,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.6804608106613159,
            "answer": "brings",
            "hit": false
          },
          {
            "score": 0.6786434650421143,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.6764862537384033,
            "answer": "find",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7395993769168854
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintains"
        ],
        "predictions": [
          {
            "score": 0.8909478187561035,
            "answer": "maintains",
            "hit": true
          },
          {
            "score": 0.8188890218734741,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.7905836701393127,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7673133611679077,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.7654662728309631,
            "answer": "keeps",
            "hit": false
          },
          {
            "score": 0.7422509789466858,
            "answer": "ensures",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8909478187561035
      },
      {
        "question verbose": "What is to occur ",
        "b": "occur",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.934302031993866,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.8375504612922668,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.8119924068450928,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.7822607755661011,
            "answer": "arises",
            "hit": false
          },
          {
            "score": 0.7816482782363892,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7676655054092407,
            "answer": "happen",
            "hit": false
          }
        ],
        "set_exclude": [
          "occur"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.934302031993866
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.9291657209396362,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.7643654346466064,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.7520531415939331,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.7507231831550598,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.7463141083717346,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7435488700866699,
            "answer": "regulates",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9291657209396362
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "prevents"
        ],
        "predictions": [
          {
            "score": 0.8952068090438843,
            "answer": "prevents",
            "hit": true
          },
          {
            "score": 0.8090284466743469,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.793765664100647,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.7864355444908142,
            "answer": "protects",
            "hit": false
          },
          {
            "score": 0.7841660976409912,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.768079400062561,
            "answer": "prohibits",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8952068090438843
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.9245287775993347,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8004907369613647,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.7833950519561768,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.7692925930023193,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7615959048271179,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.74735426902771,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9245287775993347
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protects"
        ],
        "predictions": [
          {
            "score": 0.756289005279541,
            "answer": "protects",
            "hit": true
          },
          {
            "score": 0.6800875663757324,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.6794641017913818,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.6730121970176697,
            "answer": "removes",
            "hit": false
          },
          {
            "score": 0.6693807244300842,
            "answer": "safe",
            "hit": false
          },
          {
            "score": 0.66172856092453,
            "answer": "creates",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7562890648841858
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.8321553468704224,
            "answer": "provides",
            "hit": true
          },
          {
            "score": 0.7481734752655029,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.7373460531234741,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7312451601028442,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.724177360534668,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7213457226753235,
            "answer": "promotes",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8321554064750671
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.9226603507995605,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.783618688583374,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.7729254961013794,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.7522883415222168,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.7487316131591797,
            "answer": "delivers",
            "hit": false
          },
          {
            "score": 0.746977686882019,
            "answer": "gives",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9226602911949158
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.8254220485687256,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.7297032475471497,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7255859375,
            "answer": "removes",
            "hit": false
          },
          {
            "score": 0.7250430583953857,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7243354320526123,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.7200348377227783,
            "answer": "lowers",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8254221081733704
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.7566567063331604,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.6927879452705383,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.6842986345291138,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.682902455329895,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.6781772375106812,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.6731659173965454,
            "answer": "receives",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7566567361354828
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.7128369808197021,
            "answer": "leave",
            "hit": false
          },
          {
            "score": 0.6826146841049194,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.6675477623939514,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.658683180809021,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.6506609916687012,
            "answer": "stays",
            "hit": false
          },
          {
            "score": 0.6446479558944702,
            "answer": "continues",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6826146841049194
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembers"
        ],
        "predictions": [
          {
            "score": 0.7375956773757935,
            "answer": "remembers",
            "hit": true
          },
          {
            "score": 0.7083032727241516,
            "answer": "the",
            "hit": false
          },
          {
            "score": 0.7057870626449585,
            "answer": "note",
            "hit": false
          },
          {
            "score": 0.7016671895980835,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.6957613825798035,
            "answer": "despite",
            "hit": false
          },
          {
            "score": 0.6946989297866821,
            "answer": "those",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7375956922769547
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.7678937911987305,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.7148442268371582,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.703144907951355,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.6974478960037231,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.6795823574066162,
            "answer": "constitutes",
            "hit": false
          },
          {
            "score": 0.6718964576721191,
            "answer": "representation",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7678937911987305
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.7029601335525513,
            "answer": "prohibits",
            "hit": false
          },
          {
            "score": 0.6918153166770935,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.6875951290130615,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.68574059009552,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.6774276494979858,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.6765735149383545,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 53,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6435812711715698
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.9325706958770752,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.8570355176925659,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7736819982528687,
            "answer": "tends",
            "hit": false
          },
          {
            "score": 0.7727440595626831,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.760002851486206,
            "answer": "makes",
            "hit": false
          },
          {
            "score": 0.7511035799980164,
            "answer": "suggests",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9325706958770752
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sends"
        ],
        "predictions": [
          {
            "score": 0.9164103269577026,
            "answer": "sends",
            "hit": true
          },
          {
            "score": 0.7511443495750427,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7506784796714783,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7346122860908508,
            "answer": "puts",
            "hit": false
          },
          {
            "score": 0.732032060623169,
            "answer": "makes",
            "hit": false
          },
          {
            "score": 0.7280184030532837,
            "answer": "gets",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9164103269577026
      },
      {
        "question verbose": "What is to suggest ",
        "b": "suggest",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.7886159420013428,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.7281528115272522,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.7119259834289551,
            "answer": "implies",
            "hit": false
          },
          {
            "score": 0.7089782357215881,
            "answer": "suggested",
            "hit": false
          },
          {
            "score": 0.6984409093856812,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.6888622045516968,
            "answer": "confirms",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7886159121990204
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.7853111028671265,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.7020190954208374,
            "answer": "says",
            "hit": false
          },
          {
            "score": 0.7020151615142822,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.6910762786865234,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.6898829936981201,
            "answer": "reveals",
            "hit": false
          },
          {
            "score": 0.6891942620277405,
            "answer": "describes",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7853111028671265
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.8861480951309204,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.7960520386695862,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.7705144882202148,
            "answer": "knows",
            "hit": false
          },
          {
            "score": 0.7688394784927368,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.75382399559021,
            "answer": "realizes",
            "hit": false
          },
          {
            "score": 0.7474439144134521,
            "answer": "believes",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8861480355262756
      }
    ],
    "result": {
      "cnt_questions_correct": 44,
      "cnt_questions_total": 49,
      "accuracy": 0.8979591836734694
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I05 [verb_inf - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "b21fe37b-dcc9-4015-814b-653bfb295e3d",
      "timestamp": "2025-05-17T17:15:32.897257"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieving"
        ],
        "predictions": [
          {
            "score": 0.9037365317344666,
            "answer": "achieving",
            "hit": true
          },
          {
            "score": 0.8039087057113647,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.8003997206687927,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.7595903277397156,
            "answer": "attain",
            "hit": false
          },
          {
            "score": 0.7404240369796753,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7403563261032104,
            "answer": "obtaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9037364721298218
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "adding"
        ],
        "predictions": [
          {
            "score": 0.7317963242530823,
            "answer": "adding",
            "hit": true
          },
          {
            "score": 0.6807190179824829,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.6689332723617554,
            "answer": "addition",
            "hit": false
          },
          {
            "score": 0.6581673622131348,
            "answer": "addressing",
            "hit": false
          },
          {
            "score": 0.6562752723693848,
            "answer": "removing",
            "hit": false
          },
          {
            "score": 0.6512079238891602,
            "answer": "providing",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7317963391542435
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowing"
        ],
        "predictions": [
          {
            "score": 0.7008432149887085,
            "answer": "allowing",
            "hit": true
          },
          {
            "score": 0.6765149235725403,
            "answer": "setting",
            "hit": false
          },
          {
            "score": 0.6757017374038696,
            "answer": "using",
            "hit": false
          },
          {
            "score": 0.667290449142456,
            "answer": "letting",
            "hit": false
          },
          {
            "score": 0.6638062596321106,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.6566376686096191,
            "answer": "granting",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7008432000875473
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appearing"
        ],
        "predictions": [
          {
            "score": 0.8571213483810425,
            "answer": "appearing",
            "hit": true
          },
          {
            "score": 0.8036437034606934,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.7787715196609497,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7281620502471924,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.708059549331665,
            "answer": "exhibiting",
            "hit": false
          },
          {
            "score": 0.7066030502319336,
            "answer": "displaying",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8571213185787201
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applying"
        ],
        "predictions": [
          {
            "score": 0.7789903879165649,
            "answer": "applying",
            "hit": true
          },
          {
            "score": 0.6859312057495117,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.6447190046310425,
            "answer": "evaluating",
            "hit": false
          },
          {
            "score": 0.6357846856117249,
            "answer": "transferring",
            "hit": false
          },
          {
            "score": 0.6341168880462646,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.6320123076438904,
            "answer": "assessing",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7789903879165649
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asking"
        ],
        "predictions": [
          {
            "score": 0.673547089099884,
            "answer": "questions",
            "hit": false
          },
          {
            "score": 0.6507872343063354,
            "answer": "who",
            "hit": false
          },
          {
            "score": 0.6482318639755249,
            "answer": "going",
            "hit": false
          },
          {
            "score": 0.6482292413711548,
            "answer": "using",
            "hit": false
          },
          {
            "score": 0.644944429397583,
            "answer": "which",
            "hit": false
          },
          {
            "score": 0.6426347494125366,
            "answer": "asking",
            "hit": true
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6426347345113754
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attending"
        ],
        "predictions": [
          {
            "score": 0.8862386345863342,
            "answer": "attending",
            "hit": true
          },
          {
            "score": 0.7910269498825073,
            "answer": "attended",
            "hit": false
          },
          {
            "score": 0.75181645154953,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.7256590127944946,
            "answer": "participating",
            "hit": false
          },
          {
            "score": 0.7239471077919006,
            "answer": "visiting",
            "hit": false
          },
          {
            "score": 0.7019936442375183,
            "answer": "attendees",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.886238694190979
      },
      {
        "question verbose": "What is to avoid ",
        "b": "avoid",
        "expected answer": [
          "avoiding"
        ],
        "predictions": [
          {
            "score": 0.7915754318237305,
            "answer": "avoiding",
            "hit": true
          },
          {
            "score": 0.7105419039726257,
            "answer": "avoidance",
            "hit": false
          },
          {
            "score": 0.6943469047546387,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.6776185035705566,
            "answer": "ignoring",
            "hit": false
          },
          {
            "score": 0.6768137216567993,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.6765217781066895,
            "answer": "avoided",
            "hit": false
          }
        ],
        "set_exclude": [
          "avoid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7915754616260529
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "becoming"
        ],
        "predictions": [
          {
            "score": 0.724762499332428,
            "answer": "becoming",
            "hit": true
          },
          {
            "score": 0.6539984345436096,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.6326414942741394,
            "answer": "joining",
            "hit": false
          },
          {
            "score": 0.6312772035598755,
            "answer": "acquiring",
            "hit": false
          },
          {
            "score": 0.6310094594955444,
            "answer": "making",
            "hit": false
          },
          {
            "score": 0.6279800534248352,
            "answer": "adopting",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.724762499332428
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believing"
        ],
        "predictions": [
          {
            "score": 0.7284436821937561,
            "answer": "believing",
            "hit": true
          },
          {
            "score": 0.6656852960586548,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.6583425998687744,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.6572479009628296,
            "answer": "making",
            "hit": false
          },
          {
            "score": 0.6547346711158752,
            "answer": "saying",
            "hit": false
          },
          {
            "score": 0.6481596231460571,
            "answer": "doing",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7284436374902725
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considering"
        ],
        "predictions": [
          {
            "score": 0.6815271377563477,
            "answer": "increasing",
            "hit": false
          },
          {
            "score": 0.6808452010154724,
            "answer": "thinking",
            "hit": false
          },
          {
            "score": 0.6610425710678101,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.658259391784668,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.657778263092041,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.6562054753303528,
            "answer": "considering",
            "hit": true
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6562054753303528
      },
      {
        "question verbose": "What is to contain ",
        "b": "contain",
        "expected answer": [
          "containing"
        ],
        "predictions": [
          {
            "score": 0.8180014491081238,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.7188934087753296,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.7137770056724548,
            "answer": "incorporating",
            "hit": false
          },
          {
            "score": 0.7060651779174805,
            "answer": "possessing",
            "hit": false
          },
          {
            "score": 0.7044625282287598,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.7016817331314087,
            "answer": "displaying",
            "hit": false
          }
        ],
        "set_exclude": [
          "contain"
        ],
        "rank": 334,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6270660012960434
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuing"
        ],
        "predictions": [
          {
            "score": 0.8656477928161621,
            "answer": "continuing",
            "hit": true
          },
          {
            "score": 0.818545937538147,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8166001439094543,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.7320834398269653,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.717750072479248,
            "answer": "continually",
            "hit": false
          },
          {
            "score": 0.7173668742179871,
            "answer": "taking",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8656478524208069
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "creating"
        ],
        "predictions": [
          {
            "score": 0.8065648078918457,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.763404905796051,
            "answer": "generate",
            "hit": false
          },
          {
            "score": 0.7632655501365662,
            "answer": "generating",
            "hit": false
          },
          {
            "score": 0.7461078763008118,
            "answer": "providing",
            "hit": false
          },
          {
            "score": 0.7383905649185181,
            "answer": "constructing",
            "hit": false
          },
          {
            "score": 0.7299435138702393,
            "answer": "establishing",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 59,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6812670677900314
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developing"
        ],
        "predictions": [
          {
            "score": 0.7235673666000366,
            "answer": "developing",
            "hit": true
          },
          {
            "score": 0.6842517852783203,
            "answer": "developer",
            "hit": false
          },
          {
            "score": 0.6750081777572632,
            "answer": "testing",
            "hit": false
          },
          {
            "score": 0.6714404821395874,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6641412973403931,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.6620129942893982,
            "answer": "using",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.723567396402359
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouraging"
        ],
        "predictions": [
          {
            "score": 0.8167867064476013,
            "answer": "encouraging",
            "hit": true
          },
          {
            "score": 0.8114372491836548,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.801571249961853,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.7975139617919922,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.762305498123169,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.7444781064987183,
            "answer": "facilitating",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8167867064476013
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoying"
        ],
        "predictions": [
          {
            "score": 0.7773973941802979,
            "answer": "enjoying",
            "hit": true
          },
          {
            "score": 0.6691053509712219,
            "answer": "celebrating",
            "hit": false
          },
          {
            "score": 0.6635129451751709,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.6573134660720825,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.6515125632286072,
            "answer": "experiencing",
            "hit": false
          },
          {
            "score": 0.6469739675521851,
            "answer": "enjoyment",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7773973941802979
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensuring"
        ],
        "predictions": [
          {
            "score": 0.9134024977684021,
            "answer": "ensuring",
            "hit": true
          },
          {
            "score": 0.8023936152458191,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7800612449645996,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.7649019360542297,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7637309432029724,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.7615530490875244,
            "answer": "securing",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9134024381637573
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishing"
        ],
        "predictions": [
          {
            "score": 0.7981475591659546,
            "answer": "establishing",
            "hit": true
          },
          {
            "score": 0.731103777885437,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.7199649810791016,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.708726704120636,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.6891109943389893,
            "answer": "initiating",
            "hit": false
          },
          {
            "score": 0.6890937089920044,
            "answer": "restoring",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7981475591659546
      },
      {
        "question verbose": "What is to exist ",
        "b": "exist",
        "expected answer": [
          "existing"
        ],
        "predictions": [
          {
            "score": 0.8244667649269104,
            "answer": "exists",
            "hit": false
          },
          {
            "score": 0.8134193420410156,
            "answer": "existed",
            "hit": false
          },
          {
            "score": 0.705548107624054,
            "answer": "being",
            "hit": false
          },
          {
            "score": 0.6932746171951294,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.6932547092437744,
            "answer": "existing",
            "hit": true
          },
          {
            "score": 0.6918633580207825,
            "answer": "forming",
            "hit": false
          }
        ],
        "set_exclude": [
          "exist"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6932547092437744
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expecting"
        ],
        "predictions": [
          {
            "score": 0.7216178178787231,
            "answer": "expecting",
            "hit": true
          },
          {
            "score": 0.7128889560699463,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.6808320879936218,
            "answer": "expectation",
            "hit": false
          },
          {
            "score": 0.6701265573501587,
            "answer": "expected",
            "hit": false
          },
          {
            "score": 0.6641048192977905,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.6596325635910034,
            "answer": "trying",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7216177880764008
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "following"
        ],
        "predictions": [
          {
            "score": 0.6860892176628113,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.6826871633529663,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.6498862504959106,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.6497353315353394,
            "answer": "following",
            "hit": true
          },
          {
            "score": 0.6373722553253174,
            "answer": "joining",
            "hit": false
          },
          {
            "score": 0.636124849319458,
            "answer": "pursuing",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6497353613376617
      },
      {
        "question verbose": "What is to happen ",
        "b": "happen",
        "expected answer": [
          "happening"
        ],
        "predictions": [
          {
            "score": 0.8367835283279419,
            "answer": "happening",
            "hit": true
          },
          {
            "score": 0.7809298038482666,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.7758475542068481,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.7658397555351257,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7544072270393372,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7031732797622681,
            "answer": "taking",
            "hit": false
          }
        ],
        "set_exclude": [
          "happen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8367834985256195
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifying"
        ],
        "predictions": [
          {
            "score": 0.911040186882019,
            "answer": "identifying",
            "hit": true
          },
          {
            "score": 0.8235249519348145,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.788546085357666,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7733050584793091,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.7428079843521118,
            "answer": "locating",
            "hit": false
          },
          {
            "score": 0.7410047650337219,
            "answer": "distinguishing",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9110401272773743
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improving"
        ],
        "predictions": [
          {
            "score": 0.7701165080070496,
            "answer": "improving",
            "hit": true
          },
          {
            "score": 0.7255460023880005,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.7008914351463318,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.699500560760498,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.6909536123275757,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.6809908151626587,
            "answer": "reducing",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7701165080070496
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "including"
        ],
        "predictions": [
          {
            "score": 0.8095400333404541,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.7370673418045044,
            "answer": "incorporating",
            "hit": false
          },
          {
            "score": 0.7271232604980469,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7213962078094482,
            "answer": "incorporate",
            "hit": false
          },
          {
            "score": 0.7199879884719849,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7092629075050354,
            "answer": "providing",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 382,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.617763876914978
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involving"
        ],
        "predictions": [
          {
            "score": 0.8146398067474365,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.8051236271858215,
            "answer": "involving",
            "hit": true
          },
          {
            "score": 0.7202990055084229,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.7175611853599548,
            "answer": "incorporating",
            "hit": false
          },
          {
            "score": 0.713607668876648,
            "answer": "employing",
            "hit": false
          },
          {
            "score": 0.7121584415435791,
            "answer": "relying",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8051235973834991
      },
      {
        "question verbose": "What is to learn ",
        "b": "learn",
        "expected answer": [
          "learning"
        ],
        "predictions": [
          {
            "score": 0.6841464042663574,
            "answer": "learning",
            "hit": true
          },
          {
            "score": 0.6687085628509521,
            "answer": "using",
            "hit": false
          },
          {
            "score": 0.6514550447463989,
            "answer": "find",
            "hit": false
          },
          {
            "score": 0.6461886763572693,
            "answer": "see",
            "hit": false
          },
          {
            "score": 0.6421269178390503,
            "answer": "discover",
            "hit": false
          },
          {
            "score": 0.6417626142501831,
            "answer": "studying",
            "hit": false
          }
        ],
        "set_exclude": [
          "learn"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6841463893651962
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "losing"
        ],
        "predictions": [
          {
            "score": 0.7621562480926514,
            "answer": "losing",
            "hit": true
          },
          {
            "score": 0.6796020269393921,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.6771063804626465,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.660571813583374,
            "answer": "winning",
            "hit": false
          },
          {
            "score": 0.6431652307510376,
            "answer": "having",
            "hit": false
          },
          {
            "score": 0.6412467956542969,
            "answer": "gain",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7621562778949738
      },
      {
        "question verbose": "What is to maintain ",
        "b": "maintain",
        "expected answer": [
          "maintaining"
        ],
        "predictions": [
          {
            "score": 0.9037166833877563,
            "answer": "maintaining",
            "hit": true
          },
          {
            "score": 0.80845707654953,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.7709560394287109,
            "answer": "keeping",
            "hit": false
          },
          {
            "score": 0.7680484652519226,
            "answer": "preserving",
            "hit": false
          },
          {
            "score": 0.7595953345298767,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.7451061010360718,
            "answer": "retaining",
            "hit": false
          }
        ],
        "set_exclude": [
          "maintain"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9037166833877563
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managing"
        ],
        "predictions": [
          {
            "score": 0.8603823781013489,
            "answer": "managing",
            "hit": true
          },
          {
            "score": 0.7943086624145508,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.7499629259109497,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7219705581665039,
            "answer": "controlling",
            "hit": false
          },
          {
            "score": 0.7166569828987122,
            "answer": "securing",
            "hit": false
          },
          {
            "score": 0.7150051593780518,
            "answer": "achieving",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8603823781013489
      },
      {
        "question verbose": "What is to operate ",
        "b": "operate",
        "expected answer": [
          "operating"
        ],
        "predictions": [
          {
            "score": 0.8133770227432251,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.734264612197876,
            "answer": "operational",
            "hit": false
          },
          {
            "score": 0.731879711151123,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.7227226495742798,
            "answer": "conducting",
            "hit": false
          },
          {
            "score": 0.7177608013153076,
            "answer": "employing",
            "hit": false
          },
          {
            "score": 0.7112544178962708,
            "answer": "executing",
            "hit": false
          }
        ],
        "set_exclude": [
          "operate"
        ],
        "rank": 410,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6310767233371735
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performing"
        ],
        "predictions": [
          {
            "score": 0.7490878701210022,
            "answer": "performing",
            "hit": true
          },
          {
            "score": 0.6862912178039551,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.6778846979141235,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.673117458820343,
            "answer": "performances",
            "hit": false
          },
          {
            "score": 0.6613320112228394,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.6604198217391968,
            "answer": "doing",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7490878850221634
      },
      {
        "question verbose": "What is to prevent ",
        "b": "prevent",
        "expected answer": [
          "preventing"
        ],
        "predictions": [
          {
            "score": 0.891906201839447,
            "answer": "preventing",
            "hit": true
          },
          {
            "score": 0.7859065532684326,
            "answer": "prevented",
            "hit": false
          },
          {
            "score": 0.7836702466011047,
            "answer": "protecting",
            "hit": false
          },
          {
            "score": 0.7782437205314636,
            "answer": "reducing",
            "hit": false
          },
          {
            "score": 0.7721083760261536,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7651371955871582,
            "answer": "prevents",
            "hit": false
          }
        ],
        "set_exclude": [
          "prevent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.891906201839447
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoting"
        ],
        "predictions": [
          {
            "score": 0.905947208404541,
            "answer": "promoting",
            "hit": true
          },
          {
            "score": 0.8089806437492371,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.775789201259613,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7452602982521057,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.7434051036834717,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.735606849193573,
            "answer": "advocating",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.905947208404541
      },
      {
        "question verbose": "What is to protect ",
        "b": "protect",
        "expected answer": [
          "protecting"
        ],
        "predictions": [
          {
            "score": 0.7435583472251892,
            "answer": "protecting",
            "hit": true
          },
          {
            "score": 0.6591546535491943,
            "answer": "preventing",
            "hit": false
          },
          {
            "score": 0.6557742953300476,
            "answer": "safe",
            "hit": false
          },
          {
            "score": 0.6553537249565125,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.6532760262489319,
            "answer": "safety",
            "hit": false
          },
          {
            "score": 0.6530452966690063,
            "answer": "protection",
            "hit": false
          }
        ],
        "set_exclude": [
          "protect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7435583472251892
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "providing"
        ],
        "predictions": [
          {
            "score": 0.7912497520446777,
            "answer": "providing",
            "hit": true
          },
          {
            "score": 0.758830189704895,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7034338712692261,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.6969980597496033,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.6898444294929504,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.6790401339530945,
            "answer": "ensuring",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7912497520446777
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiving"
        ],
        "predictions": [
          {
            "score": 0.8835816383361816,
            "answer": "receiving",
            "hit": true
          },
          {
            "score": 0.8041701316833496,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7387473583221436,
            "answer": "obtaining",
            "hit": false
          },
          {
            "score": 0.7302756309509277,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.7287331819534302,
            "answer": "experiencing",
            "hit": false
          },
          {
            "score": 0.7229064702987671,
            "answer": "providing",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8835816979408264
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reducing"
        ],
        "predictions": [
          {
            "score": 0.7851142883300781,
            "answer": "reducing",
            "hit": true
          },
          {
            "score": 0.7258999347686768,
            "answer": "reduced",
            "hit": false
          },
          {
            "score": 0.7132095694541931,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.708297610282898,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.7069076895713806,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.7020993828773499,
            "answer": "increased",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7851142883300781
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referring"
        ],
        "predictions": [
          {
            "score": 0.7412552833557129,
            "answer": "referring",
            "hit": true
          },
          {
            "score": 0.6807819604873657,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.6686760783195496,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.6645651459693909,
            "answer": "referred",
            "hit": false
          },
          {
            "score": 0.6606531143188477,
            "answer": "mentioning",
            "hit": false
          },
          {
            "score": 0.6559924483299255,
            "answer": "requesting",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7412552982568741
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remaining"
        ],
        "predictions": [
          {
            "score": 0.7133662104606628,
            "answer": "leave",
            "hit": false
          },
          {
            "score": 0.6721606254577637,
            "answer": "staying",
            "hit": false
          },
          {
            "score": 0.6577980518341064,
            "answer": "leaving",
            "hit": false
          },
          {
            "score": 0.6530750393867493,
            "answer": "maintaining",
            "hit": false
          },
          {
            "score": 0.6495232582092285,
            "answer": "expressing",
            "hit": false
          },
          {
            "score": 0.6456544995307922,
            "answer": "keeping",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6394100934267044
      },
      {
        "question verbose": "What is to remember ",
        "b": "remember",
        "expected answer": [
          "remembering"
        ],
        "predictions": [
          {
            "score": 0.7099657654762268,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.7015800476074219,
            "answer": "remembering",
            "hit": true
          },
          {
            "score": 0.699305534362793,
            "answer": "going",
            "hit": false
          },
          {
            "score": 0.6968095302581787,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.6964780688285828,
            "answer": "the",
            "hit": false
          },
          {
            "score": 0.6911147832870483,
            "answer": "using",
            "hit": false
          }
        ],
        "set_exclude": [
          "remember"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7015800774097443
      },
      {
        "question verbose": "What is to represent ",
        "b": "represent",
        "expected answer": [
          "representing"
        ],
        "predictions": [
          {
            "score": 0.76766037940979,
            "answer": "representing",
            "hit": true
          },
          {
            "score": 0.6992676258087158,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.6954248547554016,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.6641571521759033,
            "answer": "presenting",
            "hit": false
          },
          {
            "score": 0.6630945801734924,
            "answer": "reporting",
            "hit": false
          },
          {
            "score": 0.6474474668502808,
            "answer": "representations",
            "hit": false
          }
        ],
        "set_exclude": [
          "represent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7676603198051453
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requiring"
        ],
        "predictions": [
          {
            "score": 0.7232356667518616,
            "answer": "requiring",
            "hit": true
          },
          {
            "score": 0.6657875776290894,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.6608759760856628,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.6607472896575928,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.6592164039611816,
            "answer": "restricting",
            "hit": false
          },
          {
            "score": 0.6499148011207581,
            "answer": "declaring",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.723235696554184
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seeming"
        ],
        "predictions": [
          {
            "score": 0.8314526677131653,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.8172799348831177,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7826244831085205,
            "answer": "seeming",
            "hit": true
          },
          {
            "score": 0.7750469446182251,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7441587448120117,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.7259973883628845,
            "answer": "appearing",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7826244533061981
      },
      {
        "question verbose": "What is to sit ",
        "b": "sit",
        "expected answer": [
          "sitting"
        ],
        "predictions": [
          {
            "score": 0.6783409714698792,
            "answer": "sitting",
            "hit": true
          },
          {
            "score": 0.6408414840698242,
            "answer": "having",
            "hit": false
          },
          {
            "score": 0.6365799307823181,
            "answer": "taking",
            "hit": false
          },
          {
            "score": 0.6350942254066467,
            "answer": "placing",
            "hit": false
          },
          {
            "score": 0.6342437267303467,
            "answer": "presenting",
            "hit": false
          },
          {
            "score": 0.6341663599014282,
            "answer": "stand",
            "hit": false
          }
        ],
        "set_exclude": [
          "sit"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6783409714698792
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spending"
        ],
        "predictions": [
          {
            "score": 0.7328433394432068,
            "answer": "spending",
            "hit": true
          },
          {
            "score": 0.6907222270965576,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.6834572553634644,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.6549229621887207,
            "answer": "doing",
            "hit": false
          },
          {
            "score": 0.6498135328292847,
            "answer": "trying",
            "hit": false
          },
          {
            "score": 0.6454010605812073,
            "answer": "putting",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7328433394432068
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teaching"
        ],
        "predictions": [
          {
            "score": 0.8912988901138306,
            "answer": "teaching",
            "hit": true
          },
          {
            "score": 0.8142970204353333,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.7973341345787048,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7226352095603943,
            "answer": "studying",
            "hit": false
          },
          {
            "score": 0.7193625569343567,
            "answer": "classroom",
            "hit": false
          },
          {
            "score": 0.7115611433982849,
            "answer": "practicing",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8912989795207977
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "telling"
        ],
        "predictions": [
          {
            "score": 0.7444454431533813,
            "answer": "telling",
            "hit": true
          },
          {
            "score": 0.6648192405700684,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.6641288995742798,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.6533476710319519,
            "answer": "talking",
            "hit": false
          },
          {
            "score": 0.646101713180542,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.6456940174102783,
            "answer": "reminding",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7444453835487366
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understanding"
        ],
        "predictions": [
          {
            "score": 0.7847468256950378,
            "answer": "understood",
            "hit": false
          },
          {
            "score": 0.7756985425949097,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7704258561134338,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7288854718208313,
            "answer": "know",
            "hit": false
          },
          {
            "score": 0.7270853519439697,
            "answer": "grasping",
            "hit": false
          },
          {
            "score": 0.7251307368278503,
            "answer": "figuring",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 264,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6390435844659805
      }
    ],
    "result": {
      "cnt_questions_correct": 37,
      "cnt_questions_total": 50,
      "accuracy": 0.74
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I06 [verb_inf - Ving].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "d725e647-481b-46d6-9165-0834d568e3e8",
      "timestamp": "2025-05-17T17:15:33.082783"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "accepted"
        ],
        "predictions": [
          {
            "score": 0.8677842020988464,
            "answer": "accepted",
            "hit": true
          },
          {
            "score": 0.8221727609634399,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.802176833152771,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.7531999945640564,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.7308222651481628,
            "answer": "agreed",
            "hit": false
          },
          {
            "score": 0.7281802892684937,
            "answer": "rejected",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.867784172296524
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achieved"
        ],
        "predictions": [
          {
            "score": 0.8823728561401367,
            "answer": "achieved",
            "hit": true
          },
          {
            "score": 0.8163490295410156,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.8079913854598999,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7778113484382629,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.7570180892944336,
            "answer": "attain",
            "hit": false
          },
          {
            "score": 0.7457280158996582,
            "answer": "accomplished",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8823728263378143
      },
      {
        "question verbose": "What is to add ",
        "b": "add",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.7234253883361816,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.7141244411468506,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.6327455043792725,
            "answer": "price",
            "hit": false
          },
          {
            "score": 0.632227897644043,
            "answer": "optional",
            "hit": false
          },
          {
            "score": 0.6320539116859436,
            "answer": "combined",
            "hit": false
          },
          {
            "score": 0.6319416165351868,
            "answer": "update",
            "hit": false
          }
        ],
        "set_exclude": [
          "add"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7234253734350204
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.6840668320655823,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.6721094846725464,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.6570290327072144,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.6435697078704834,
            "answer": "received",
            "hit": false
          },
          {
            "score": 0.6415067911148071,
            "answer": "appointed",
            "hit": false
          },
          {
            "score": 0.6412255764007568,
            "answer": "disagree",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6721094995737076
      },
      {
        "question verbose": "What is to allow ",
        "b": "allow",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.6863700747489929,
            "answer": "enable",
            "hit": false
          },
          {
            "score": 0.6724644303321838,
            "answer": "adjust",
            "hit": false
          },
          {
            "score": 0.6625096797943115,
            "answer": "some",
            "hit": false
          },
          {
            "score": 0.6581532955169678,
            "answer": "option",
            "hit": false
          },
          {
            "score": 0.6573432683944702,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.6563493013381958,
            "answer": "using",
            "hit": false
          }
        ],
        "set_exclude": [
          "allow"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.650674432516098
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8036160469055176,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.7992914319038391,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.7819328308105469,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.7421678304672241,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.7383302450180054,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.7158757448196411,
            "answer": "declared",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6849408149719238
      },
      {
        "question verbose": "What is to appear ",
        "b": "appear",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8788979649543762,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.7951813340187073,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7862946391105652,
            "answer": "appearing",
            "hit": false
          },
          {
            "score": 0.7730346918106079,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7364835143089294,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7183828353881836,
            "answer": "displayed",
            "hit": false
          }
        ],
        "set_exclude": [
          "appear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8788979351520538
      },
      {
        "question verbose": "What is to apply ",
        "b": "apply",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.7090073227882385,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.6692360639572144,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.6564871668815613,
            "answer": "used",
            "hit": false
          },
          {
            "score": 0.651699960231781,
            "answer": "specified",
            "hit": false
          },
          {
            "score": 0.6468341946601868,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.6403262615203857,
            "answer": "received",
            "hit": false
          }
        ],
        "set_exclude": [
          "apply"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7090073376893997
      },
      {
        "question verbose": "What is to ask ",
        "b": "ask",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.6972521543502808,
            "answer": "questions",
            "hit": false
          },
          {
            "score": 0.6659160852432251,
            "answer": "who",
            "hit": false
          },
          {
            "score": 0.6615428328514099,
            "answer": "the",
            "hit": false
          },
          {
            "score": 0.6610109806060791,
            "answer": "talk",
            "hit": false
          },
          {
            "score": 0.6563817858695984,
            "answer": "very",
            "hit": false
          },
          {
            "score": 0.6551990509033203,
            "answer": "nobody",
            "hit": false
          }
        ],
        "set_exclude": [
          "ask"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6505191028118134
      },
      {
        "question verbose": "What is to attend ",
        "b": "attend",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.8641796112060547,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.8254372477531433,
            "answer": "attending",
            "hit": false
          },
          {
            "score": 0.741094708442688,
            "answer": "attendance",
            "hit": false
          },
          {
            "score": 0.7280958890914917,
            "answer": "participated",
            "hit": false
          },
          {
            "score": 0.7138007879257202,
            "answer": "visited",
            "hit": false
          },
          {
            "score": 0.7083641290664673,
            "answer": "attendees",
            "hit": false
          }
        ],
        "set_exclude": [
          "attend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8641796112060547
      },
      {
        "question verbose": "What is to become ",
        "b": "become",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.6585050821304321,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.6460951566696167,
            "answer": "reached",
            "hit": false
          },
          {
            "score": 0.6280899047851562,
            "answer": "learned",
            "hit": false
          },
          {
            "score": 0.6266202330589294,
            "answer": "already",
            "hit": false
          },
          {
            "score": 0.6265481114387512,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.6238164305686951,
            "answer": "increased",
            "hit": false
          }
        ],
        "set_exclude": [
          "become"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6585050821304321
      },
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.7168325185775757,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.6832401752471924,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.6440950036048889,
            "answer": "almost",
            "hit": false
          },
          {
            "score": 0.643538236618042,
            "answer": "absolutely",
            "hit": false
          },
          {
            "score": 0.6398873329162598,
            "answer": "actually",
            "hit": false
          },
          {
            "score": 0.635807991027832,
            "answer": "believing",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7168325185775757
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.6732088327407837,
            "answer": "increasing",
            "hit": false
          },
          {
            "score": 0.667194664478302,
            "answer": "given",
            "hit": false
          },
          {
            "score": 0.6605510115623474,
            "answer": "particularly",
            "hit": false
          },
          {
            "score": 0.6579272747039795,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.6564217805862427,
            "answer": "thinking",
            "hit": false
          },
          {
            "score": 0.6500051617622375,
            "answer": "since",
            "hit": false
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6372817754745483
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.8554602265357971,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.8513434529304504,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7940058708190918,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7729507684707642,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7273648977279663,
            "answer": "began",
            "hit": false
          },
          {
            "score": 0.7273070812225342,
            "answer": "resumed",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8554602265357971
      },
      {
        "question verbose": "What is to create ",
        "b": "create",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.8380523920059204,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7636058330535889,
            "answer": "generate",
            "hit": false
          },
          {
            "score": 0.7525350451469421,
            "answer": "generated",
            "hit": false
          },
          {
            "score": 0.7279130220413208,
            "answer": "produced",
            "hit": false
          },
          {
            "score": 0.7248926162719727,
            "answer": "made",
            "hit": false
          },
          {
            "score": 0.7174290418624878,
            "answer": "make",
            "hit": false
          }
        ],
        "set_exclude": [
          "create"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7037520259618759
      },
      {
        "question verbose": "What is to decide ",
        "b": "decide",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8733025789260864,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8459360003471375,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.7660701274871826,
            "answer": "determine",
            "hit": false
          },
          {
            "score": 0.7531911134719849,
            "answer": "chose",
            "hit": false
          },
          {
            "score": 0.748279333114624,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.7398242950439453,
            "answer": "choose",
            "hit": false
          }
        ],
        "set_exclude": [
          "decide"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8733025789260864
      },
      {
        "question verbose": "What is to describe ",
        "b": "describe",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8406791090965271,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.837510347366333,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.7982200384140015,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.7323634624481201,
            "answer": "characterized",
            "hit": false
          },
          {
            "score": 0.7209766507148743,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.7098656296730042,
            "answer": "referred",
            "hit": false
          }
        ],
        "set_exclude": [
          "describe"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8375104069709778
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.7114658355712891,
            "answer": "developer",
            "hit": false
          },
          {
            "score": 0.6940428614616394,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.6771288514137268,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6715777516365051,
            "answer": "testing",
            "hit": false
          },
          {
            "score": 0.6665148735046387,
            "answer": "design",
            "hit": false
          },
          {
            "score": 0.6570362448692322,
            "answer": "the",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.694042831659317
      },
      {
        "question verbose": "What is to discover ",
        "b": "discover",
        "expected answer": [
          "discovered"
        ],
        "predictions": [
          {
            "score": 0.6666382551193237,
            "answer": "find",
            "hit": false
          },
          {
            "score": 0.652525782585144,
            "answer": "learn",
            "hit": false
          },
          {
            "score": 0.6470914483070374,
            "answer": "despite",
            "hit": false
          },
          {
            "score": 0.6414732933044434,
            "answer": "amazing",
            "hit": false
          },
          {
            "score": 0.6409944295883179,
            "answer": "classic",
            "hit": false
          },
          {
            "score": 0.6401172280311584,
            "answer": "located",
            "hit": false
          }
        ],
        "set_exclude": [
          "discover"
        ],
        "rank": 40,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6171750724315643
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyed"
        ],
        "predictions": [
          {
            "score": 0.7265012264251709,
            "answer": "enjoyed",
            "hit": true
          },
          {
            "score": 0.697890043258667,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.6748299598693848,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.6518095135688782,
            "answer": "thanks",
            "hit": false
          },
          {
            "score": 0.6344877481460571,
            "answer": "liked",
            "hit": false
          },
          {
            "score": 0.6311991214752197,
            "answer": "featuring",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7265012115240097
      },
      {
        "question verbose": "What is to ensure ",
        "b": "ensure",
        "expected answer": [
          "ensured"
        ],
        "predictions": [
          {
            "score": 0.8509841561317444,
            "answer": "ensured",
            "hit": true
          },
          {
            "score": 0.8288685083389282,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.8221535682678223,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7523840665817261,
            "answer": "assure",
            "hit": false
          },
          {
            "score": 0.7343707084655762,
            "answer": "prevent",
            "hit": false
          },
          {
            "score": 0.7112348675727844,
            "answer": "guarantee",
            "hit": false
          }
        ],
        "set_exclude": [
          "ensure"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.850984126329422
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.7963083982467651,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.733344554901123,
            "answer": "establishment",
            "hit": false
          },
          {
            "score": 0.7034918069839478,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.6606209874153137,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.6600261926651001,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.657325029373169,
            "answer": "opened",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7963083982467651
      },
      {
        "question verbose": "What is to expect ",
        "b": "expect",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.6908879280090332,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.6870682239532471,
            "answer": "expectations",
            "hit": false
          },
          {
            "score": 0.6789695024490356,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.6571006774902344,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.6525894403457642,
            "answer": "hopefully",
            "hit": false
          },
          {
            "score": 0.6517229080200195,
            "answer": "expectation",
            "hit": false
          }
        ],
        "set_exclude": [
          "expect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.690887913107872
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.7234737873077393,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.689887523651123,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.6490715146064758,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6424423456192017,
            "answer": "reported",
            "hit": false
          },
          {
            "score": 0.6421744227409363,
            "answer": "announced",
            "hit": false
          },
          {
            "score": 0.6406161785125732,
            "answer": "given",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7234737575054169
      },
      {
        "question verbose": "What is to hear ",
        "b": "hear",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.8620596528053284,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.7933168411254883,
            "answer": "hears",
            "hit": false
          },
          {
            "score": 0.7261000871658325,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.699184775352478,
            "answer": "listen",
            "hit": false
          },
          {
            "score": 0.6927400827407837,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.6841701865196228,
            "answer": "seen",
            "hit": false
          }
        ],
        "set_exclude": [
          "hear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.862059623003006
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identified"
        ],
        "predictions": [
          {
            "score": 0.8884451985359192,
            "answer": "identified",
            "hit": true
          },
          {
            "score": 0.835483729839325,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8215267658233643,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7538955211639404,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.7453580498695374,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.7113491296768188,
            "answer": "recognized",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.888445258140564
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.7543591856956482,
            "answer": "improved",
            "hit": true
          },
          {
            "score": 0.7145968079566956,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.6964398622512817,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.6860107183456421,
            "answer": "increased",
            "hit": false
          },
          {
            "score": 0.6837102174758911,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.6720196008682251,
            "answer": "reduced",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7543591856956482
      },
      {
        "question verbose": "What is to include ",
        "b": "include",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.8691155910491943,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.7372132539749146,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.7167943716049194,
            "answer": "encompass",
            "hit": false
          },
          {
            "score": 0.7076772451400757,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7007240653038025,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.6999921202659607,
            "answer": "incorporate",
            "hit": false
          }
        ],
        "set_exclude": [
          "include"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.869115561246872
      },
      {
        "question verbose": "What is to introduce ",
        "b": "introduce",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8885274529457092,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8311388492584229,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.8282092809677124,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.7204433679580688,
            "answer": "brought",
            "hit": false
          },
          {
            "score": 0.7010477781295776,
            "answer": "implemented",
            "hit": false
          },
          {
            "score": 0.6967210173606873,
            "answer": "unveiled",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8885274529457092
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8390452861785889,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.780190110206604,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.737488329410553,
            "answer": "resulted",
            "hit": false
          },
          {
            "score": 0.72869473695755,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.7129656672477722,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.7056236267089844,
            "answer": "included",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 149,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.644646942615509
      },
      {
        "question verbose": "What is to locate ",
        "b": "locate",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.820552408695221,
            "answer": "locating",
            "hit": false
          },
          {
            "score": 0.7257821559906006,
            "answer": "relocated",
            "hit": false
          },
          {
            "score": 0.7174739241600037,
            "answer": "found",
            "hit": false
          },
          {
            "score": 0.716793417930603,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.7107145190238953,
            "answer": "discovered",
            "hit": false
          },
          {
            "score": 0.7063062191009521,
            "answer": "location",
            "hit": false
          }
        ],
        "set_exclude": [
          "locate"
        ],
        "rank": 1395,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5818274021148682
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.688856840133667,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.6766947507858276,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.6556400060653687,
            "answer": "gained",
            "hit": false
          },
          {
            "score": 0.642199695110321,
            "answer": "died",
            "hit": false
          },
          {
            "score": 0.6342767477035522,
            "answer": "gain",
            "hit": false
          },
          {
            "score": 0.6342003345489502,
            "answer": "winning",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6103665679693222
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8215828537940979,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.784823477268219,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7116538286209106,
            "answer": "handled",
            "hit": false
          },
          {
            "score": 0.7009589672088623,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.6916384696960449,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.6877678632736206,
            "answer": "succeeded",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6874955594539642
      },
      {
        "question verbose": "What is to marry ",
        "b": "marry",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.8278806209564209,
            "answer": "marrying",
            "hit": false
          },
          {
            "score": 0.7136713266372681,
            "answer": "kissed",
            "hit": false
          },
          {
            "score": 0.7050027847290039,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.692558765411377,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.6885892152786255,
            "answer": "wedding",
            "hit": false
          },
          {
            "score": 0.6873704791069031,
            "answer": "divorced",
            "hit": false
          }
        ],
        "set_exclude": [
          "marry"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.692558765411377
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.7040690779685974,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.674782395362854,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.6686384081840515,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.6646158695220947,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.658330500125885,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.6494195461273193,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7040691077709198
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.7734284400939941,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7191189527511597,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.6783893704414368,
            "answer": "supplied",
            "hit": false
          },
          {
            "score": 0.6769323945045471,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.6704553365707397,
            "answer": "offered",
            "hit": false
          },
          {
            "score": 0.6644888520240784,
            "answer": "providing",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7191189825534821
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.8191157579421997,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.756540060043335,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7042367458343506,
            "answer": "printed",
            "hit": false
          },
          {
            "score": 0.7001442313194275,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.6996637582778931,
            "answer": "authored",
            "hit": false
          },
          {
            "score": 0.6928658485412598,
            "answer": "released",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6649169325828552
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8333402872085571,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.8098767995834351,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.7090071439743042,
            "answer": "obtain",
            "hit": false
          },
          {
            "score": 0.7015372514724731,
            "answer": "obtained",
            "hit": false
          },
          {
            "score": 0.6963821053504944,
            "answer": "delivered",
            "hit": false
          },
          {
            "score": 0.695580244064331,
            "answer": "gained",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6817365884780884
      },
      {
        "question verbose": "What is to reduce ",
        "b": "reduce",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.7595119476318359,
            "answer": "reduced",
            "hit": true
          },
          {
            "score": 0.7356595993041992,
            "answer": "increased",
            "hit": false
          },
          {
            "score": 0.7187782526016235,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.7150609493255615,
            "answer": "reduction",
            "hit": false
          },
          {
            "score": 0.6883203983306885,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.6818657517433167,
            "answer": "improved",
            "hit": false
          }
        ],
        "set_exclude": [
          "reduce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7595120072364807
      },
      {
        "question verbose": "What is to refer ",
        "b": "refer",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.7131507396697998,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.6759806275367737,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.6595218777656555,
            "answer": "referenced",
            "hit": false
          },
          {
            "score": 0.6588625907897949,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.6587956547737122,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.6576614379882812,
            "answer": "reference",
            "hit": false
          }
        ],
        "set_exclude": [
          "refer"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.713150754570961
      },
      {
        "question verbose": "What is to relate ",
        "b": "relate",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8329764604568481,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7507098913192749,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7192878723144531,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.699210524559021,
            "answer": "arose",
            "hit": false
          },
          {
            "score": 0.6980896592140198,
            "answer": "progressed",
            "hit": false
          },
          {
            "score": 0.6936060190200806,
            "answer": "described",
            "hit": false
          }
        ],
        "set_exclude": [
          "relate"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7192878723144531
      },
      {
        "question verbose": "What is to remain ",
        "b": "remain",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.71626877784729,
            "answer": "leave",
            "hit": false
          },
          {
            "score": 0.6771014928817749,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.6370283365249634,
            "answer": "left",
            "hit": false
          },
          {
            "score": 0.6318780779838562,
            "answer": "stayed",
            "hit": false
          },
          {
            "score": 0.6309857368469238,
            "answer": "returned",
            "hit": false
          },
          {
            "score": 0.6241841912269592,
            "answer": "theresa",
            "hit": false
          }
        ],
        "set_exclude": [
          "remain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6771014928817749
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.6821045875549316,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.6419969201087952,
            "answer": "finished",
            "hit": false
          },
          {
            "score": 0.639360785484314,
            "answer": "matched",
            "hit": false
          },
          {
            "score": 0.6388657689094543,
            "answer": "repair",
            "hit": false
          },
          {
            "score": 0.6385783553123474,
            "answer": "picked",
            "hit": false
          },
          {
            "score": 0.6363997459411621,
            "answer": "contained",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6821045726537704
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.7024229764938354,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.6536849141120911,
            "answer": "necessary",
            "hit": false
          },
          {
            "score": 0.6502914428710938,
            "answer": "demanded",
            "hit": false
          },
          {
            "score": 0.6419786810874939,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.63912034034729,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.6347224116325378,
            "answer": "created",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7024230062961578
      },
      {
        "question verbose": "What is to seem ",
        "b": "seem",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.8821122050285339,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.8592155575752258,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7852064371109009,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7547361850738525,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.7188268899917603,
            "answer": "looked",
            "hit": false
          },
          {
            "score": 0.7165176868438721,
            "answer": "seemingly",
            "hit": false
          }
        ],
        "set_exclude": [
          "seem"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8821122348308563
      },
      {
        "question verbose": "What is to send ",
        "b": "send",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8227158784866333,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.6982900500297546,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.6944292783737183,
            "answer": "delivered",
            "hit": false
          },
          {
            "score": 0.6933348178863525,
            "answer": "brought",
            "hit": false
          },
          {
            "score": 0.6890493631362915,
            "answer": "shipped",
            "hit": false
          },
          {
            "score": 0.6884338855743408,
            "answer": "transmitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "send"
        ],
        "rank": 208,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.624213233590126
      },
      {
        "question verbose": "What is to spend ",
        "b": "spend",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.7311663031578064,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.6997533440589905,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.6651244163513184,
            "answer": "paid",
            "hit": false
          },
          {
            "score": 0.6609673500061035,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.6541956663131714,
            "answer": "bought",
            "hit": false
          },
          {
            "score": 0.6393613815307617,
            "answer": "cost",
            "hit": false
          }
        ],
        "set_exclude": [
          "spend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7311662882566452
      },
      {
        "question verbose": "What is to tell ",
        "b": "tell",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.6848012208938599,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.6519628167152405,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.6400256752967834,
            "answer": "explain",
            "hit": false
          },
          {
            "score": 0.6344485878944397,
            "answer": "can",
            "hit": false
          },
          {
            "score": 0.6332591772079468,
            "answer": "you",
            "hit": false
          },
          {
            "score": 0.6328081488609314,
            "answer": "will",
            "hit": false
          }
        ],
        "set_exclude": [
          "tell"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6284759938716888
      },
      {
        "question verbose": "What is to understand ",
        "b": "understand",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.8532248139381409,
            "answer": "understood",
            "hit": true
          },
          {
            "score": 0.8068845272064209,
            "answer": "understands",
            "hit": false
          },
          {
            "score": 0.7642970085144043,
            "answer": "comprehend",
            "hit": false
          },
          {
            "score": 0.7325308918952942,
            "answer": "know",
            "hit": false
          },
          {
            "score": 0.7156152725219727,
            "answer": "knew",
            "hit": false
          },
          {
            "score": 0.7140220999717712,
            "answer": "grasped",
            "hit": false
          }
        ],
        "set_exclude": [
          "understand"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8532248437404633
      },
      {
        "question verbose": "What is to unite ",
        "b": "unite",
        "expected answer": [
          "united"
        ],
        "predictions": [
          {
            "score": 0.6942029595375061,
            "answer": "fused",
            "hit": false
          },
          {
            "score": 0.686093807220459,
            "answer": "embraced",
            "hit": false
          },
          {
            "score": 0.6826642155647278,
            "answer": "denounced",
            "hit": false
          },
          {
            "score": 0.6790258884429932,
            "answer": "joined",
            "hit": false
          },
          {
            "score": 0.6723220944404602,
            "answer": "vowed",
            "hit": false
          },
          {
            "score": 0.668362021446228,
            "answer": "gathered",
            "hit": false
          }
        ],
        "set_exclude": [
          "unite"
        ],
        "rank": 6501,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.522642232477665
      }
    ],
    "result": {
      "cnt_questions_correct": 28,
      "cnt_questions_total": 50,
      "accuracy": 0.56
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I07 [verb_inf - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "cfd1dd28-deda-4155-967d-19edd3077439",
      "timestamp": "2025-05-17T17:15:33.273476"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "adds"
        ],
        "predictions": [
          {
            "score": 0.7166273593902588,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.7129939794540405,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7097678780555725,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7094473838806152,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.6975629329681396,
            "answer": "brings",
            "hit": false
          },
          {
            "score": 0.6965323686599731,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 137,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6394718885421753
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allows"
        ],
        "predictions": [
          {
            "score": 0.8255195617675781,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.792059063911438,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7880246043205261,
            "answer": "lets",
            "hit": false
          },
          {
            "score": 0.7742016315460205,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.7680749297142029,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7627533674240112,
            "answer": "facilitates",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7164876759052277
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appears"
        ],
        "predictions": [
          {
            "score": 0.8093652725219727,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.783808708190918,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7536060810089111,
            "answer": "seems",
            "hit": false
          },
          {
            "score": 0.7374424338340759,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.734264612197876,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7331588864326477,
            "answer": "disappears",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 244,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6365001201629639
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applies"
        ],
        "predictions": [
          {
            "score": 0.8653262257575989,
            "answer": "applies",
            "hit": true
          },
          {
            "score": 0.8099435567855835,
            "answer": "applied",
            "hit": false
          },
          {
            "score": 0.721394956111908,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7212289571762085,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.7211438417434692,
            "answer": "removes",
            "hit": false
          },
          {
            "score": 0.7191505432128906,
            "answer": "employs",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8653262853622437
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asks"
        ],
        "predictions": [
          {
            "score": 0.6931396722793579,
            "answer": "asks",
            "hit": true
          },
          {
            "score": 0.6604640483856201,
            "answer": "seeks",
            "hit": false
          },
          {
            "score": 0.6517996788024902,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.6499859094619751,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.6493375301361084,
            "answer": "doesn",
            "hit": false
          },
          {
            "score": 0.6487147808074951,
            "answer": "decides",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6931396424770355
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "becomes"
        ],
        "predictions": [
          {
            "score": 0.8584886789321899,
            "answer": "becomes",
            "hit": true
          },
          {
            "score": 0.803398847579956,
            "answer": "became",
            "hit": false
          },
          {
            "score": 0.7513635158538818,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.726772665977478,
            "answer": "grows",
            "hit": false
          },
          {
            "score": 0.724965512752533,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7236847877502441,
            "answer": "makes",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8584886789321899
      },
      {
        "question verbose": "What is to believing ",
        "b": "believing",
        "expected answer": [
          "believes"
        ],
        "predictions": [
          {
            "score": 0.8435875177383423,
            "answer": "believes",
            "hit": true
          },
          {
            "score": 0.7673829197883606,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.734857439994812,
            "answer": "believed",
            "hit": false
          },
          {
            "score": 0.7214906215667725,
            "answer": "insists",
            "hit": false
          },
          {
            "score": 0.7211313247680664,
            "answer": "realizes",
            "hit": false
          },
          {
            "score": 0.7173090577125549,
            "answer": "considers",
            "hit": false
          }
        ],
        "set_exclude": [
          "believing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8435875177383423
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considers"
        ],
        "predictions": [
          {
            "score": 0.7782015800476074,
            "answer": "despite",
            "hit": false
          },
          {
            "score": 0.7613715529441833,
            "answer": "compared",
            "hit": false
          },
          {
            "score": 0.7567875385284424,
            "answer": "perhaps",
            "hit": false
          },
          {
            "score": 0.7463518977165222,
            "answer": "according",
            "hit": false
          },
          {
            "score": 0.744805634021759,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.7438684105873108,
            "answer": "apparently",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7051510959863663
      },
      {
        "question verbose": "What is to consisting ",
        "b": "consisting",
        "expected answer": [
          "consists"
        ],
        "predictions": [
          {
            "score": 0.8894208669662476,
            "answer": "consists",
            "hit": true
          },
          {
            "score": 0.815924882888794,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.8120356202125549,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.7879816889762878,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.7849695086479187,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.7841106653213501,
            "answer": "comprising",
            "hit": false
          }
        ],
        "set_exclude": [
          "consisting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8894208073616028
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contains"
        ],
        "predictions": [
          {
            "score": 0.736126184463501,
            "answer": "contains",
            "hit": true
          },
          {
            "score": 0.6971602439880371,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.6723685264587402,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.6660685539245605,
            "answer": "derived",
            "hit": false
          },
          {
            "score": 0.6638786792755127,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.6624723076820374,
            "answer": "specifies",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.736126184463501
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continues"
        ],
        "predictions": [
          {
            "score": 0.8638067841529846,
            "answer": "continues",
            "hit": true
          },
          {
            "score": 0.797991156578064,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.79249107837677,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.7335201501846313,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.7226806282997131,
            "answer": "keeps",
            "hit": false
          },
          {
            "score": 0.7200236916542053,
            "answer": "continuation",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8638067543506622
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "creates"
        ],
        "predictions": [
          {
            "score": 0.7693978548049927,
            "answer": "creates",
            "hit": true
          },
          {
            "score": 0.7299361228942871,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.7151035070419312,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.69728022813797,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.691981315612793,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.6874634027481079,
            "answer": "defines",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7693978548049927
      },
      {
        "question verbose": "What is to depending ",
        "b": "depending",
        "expected answer": [
          "depends"
        ],
        "predictions": [
          {
            "score": 0.7962685823440552,
            "answer": "depends",
            "hit": true
          },
          {
            "score": 0.769767165184021,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.7368824481964111,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.7352595925331116,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.72227942943573,
            "answer": "assumes",
            "hit": false
          },
          {
            "score": 0.7184064388275146,
            "answer": "decides",
            "hit": false
          }
        ],
        "set_exclude": [
          "depending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7962686419487
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "describes"
        ],
        "predictions": [
          {
            "score": 0.8937726020812988,
            "answer": "describes",
            "hit": true
          },
          {
            "score": 0.8096076846122742,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.7688353061676025,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.7686315178871155,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.7625559568405151,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7601966857910156,
            "answer": "depicts",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8937726020812988
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "develops"
        ],
        "predictions": [
          {
            "score": 0.8669676780700684,
            "answer": "develops",
            "hit": true
          },
          {
            "score": 0.78070467710495,
            "answer": "developed",
            "hit": false
          },
          {
            "score": 0.7363577485084534,
            "answer": "produces",
            "hit": false
          },
          {
            "score": 0.7291373610496521,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7083871960639954,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7028095722198486,
            "answer": "generates",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8669676780700684
      },
      {
        "question verbose": "What is to discovering ",
        "b": "discovering",
        "expected answer": [
          "discovers"
        ],
        "predictions": [
          {
            "score": 0.8685028553009033,
            "answer": "discovers",
            "hit": true
          },
          {
            "score": 0.7928857207298279,
            "answer": "learns",
            "hit": false
          },
          {
            "score": 0.7666566371917725,
            "answer": "discovered",
            "hit": false
          },
          {
            "score": 0.7631127238273621,
            "answer": "finds",
            "hit": false
          },
          {
            "score": 0.7402670383453369,
            "answer": "realizes",
            "hit": false
          },
          {
            "score": 0.7385389804840088,
            "answer": "discoveries",
            "hit": false
          }
        ],
        "set_exclude": [
          "discovering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8685029149055481
      },
      {
        "question verbose": "What is to enabling ",
        "b": "enabling",
        "expected answer": [
          "enables"
        ],
        "predictions": [
          {
            "score": 0.8904737830162048,
            "answer": "enables",
            "hit": true
          },
          {
            "score": 0.7765181064605713,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7624370455741882,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.742804765701294,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7389854192733765,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7374862432479858,
            "answer": "prevents",
            "hit": false
          }
        ],
        "set_exclude": [
          "enabling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8904737830162048
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "exists"
        ],
        "predictions": [
          {
            "score": 0.727558970451355,
            "answer": "exists",
            "hit": true
          },
          {
            "score": 0.7078782916069031,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.6919070482254028,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.687597930431366,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.6861797571182251,
            "answer": "incorporates",
            "hit": false
          },
          {
            "score": 0.6828101277351379,
            "answer": "establishes",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.727558970451355
      },
      {
        "question verbose": "What is to explaining ",
        "b": "explaining",
        "expected answer": [
          "explains"
        ],
        "predictions": [
          {
            "score": 0.855113685131073,
            "answer": "explains",
            "hit": true
          },
          {
            "score": 0.7818921804428101,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7658557891845703,
            "answer": "discusses",
            "hit": false
          },
          {
            "score": 0.7656135559082031,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.7625313401222229,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.7448838353157043,
            "answer": "informs",
            "hit": false
          }
        ],
        "set_exclude": [
          "explaining"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.855113685131073
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "follows"
        ],
        "predictions": [
          {
            "score": 0.7887027859687805,
            "answer": "after",
            "hit": false
          },
          {
            "score": 0.7753641605377197,
            "answer": "during",
            "hit": false
          },
          {
            "score": 0.7481655478477478,
            "answer": "while",
            "hit": false
          },
          {
            "score": 0.7254909873008728,
            "answer": "several",
            "hit": false
          },
          {
            "score": 0.7112697958946228,
            "answer": "along",
            "hit": false
          },
          {
            "score": 0.7050631046295166,
            "answer": "follows",
            "hit": true
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7050631046295166
      },
      {
        "question verbose": "What is to happening ",
        "b": "happening",
        "expected answer": [
          "happens"
        ],
        "predictions": [
          {
            "score": 0.8560940623283386,
            "answer": "happens",
            "hit": true
          },
          {
            "score": 0.8140889406204224,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.7962440252304077,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7732052206993103,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7688418626785278,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.7296268939971924,
            "answer": "occurred",
            "hit": false
          }
        ],
        "set_exclude": [
          "happening"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8560940623283386
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "hears"
        ],
        "predictions": [
          {
            "score": 0.6722137331962585,
            "answer": "speaks",
            "hit": false
          },
          {
            "score": 0.6676255464553833,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6651890277862549,
            "answer": "hears",
            "hit": true
          },
          {
            "score": 0.6562207937240601,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.6556374430656433,
            "answer": "speech",
            "hit": false
          },
          {
            "score": 0.6496713161468506,
            "answer": "gives",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6651890873908997
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improves"
        ],
        "predictions": [
          {
            "score": 0.8855592012405396,
            "answer": "improves",
            "hit": true
          },
          {
            "score": 0.7680494785308838,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7527501583099365,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.7375242114067078,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7318129539489746,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.7218794822692871,
            "answer": "promotes",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8855592012405396
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "includes"
        ],
        "predictions": [
          {
            "score": 0.7313616275787354,
            "answer": "excluding",
            "hit": false
          },
          {
            "score": 0.7205316424369812,
            "answer": "especially",
            "hit": false
          },
          {
            "score": 0.7077655792236328,
            "answer": "includes",
            "hit": true
          },
          {
            "score": 0.6991474628448486,
            "answer": "particularly",
            "hit": false
          },
          {
            "score": 0.6906291246414185,
            "answer": "both",
            "hit": false
          },
          {
            "score": 0.6897453665733337,
            "answer": "comprises",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7077655494213104
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involves"
        ],
        "predictions": [
          {
            "score": 0.8541831374168396,
            "answer": "involves",
            "hit": true
          },
          {
            "score": 0.7565162181854248,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7520472407341003,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7325618267059326,
            "answer": "contains",
            "hit": false
          },
          {
            "score": 0.7307182550430298,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7297641038894653,
            "answer": "consists",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8541831374168396
      },
      {
        "question verbose": "What is to learning ",
        "b": "learning",
        "expected answer": [
          "learns"
        ],
        "predictions": [
          {
            "score": 0.7469744682312012,
            "answer": "learns",
            "hit": true
          },
          {
            "score": 0.6961414813995361,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.6757081747055054,
            "answer": "learn",
            "hit": false
          },
          {
            "score": 0.6744645237922668,
            "answer": "education",
            "hit": false
          },
          {
            "score": 0.6576899886131287,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.6539387702941895,
            "answer": "discovers",
            "hit": false
          }
        ],
        "set_exclude": [
          "learning"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.74697445333004
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "loses"
        ],
        "predictions": [
          {
            "score": 0.8794664740562439,
            "answer": "loses",
            "hit": true
          },
          {
            "score": 0.7413436770439148,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.7395279407501221,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7274909615516663,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7247306108474731,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.7199038863182068,
            "answer": "suffers",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8794665336608887
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "manages"
        ],
        "predictions": [
          {
            "score": 0.8354892134666443,
            "answer": "manages",
            "hit": true
          },
          {
            "score": 0.7911285161972046,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.7351735830307007,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.724718451499939,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.7130427956581116,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.7128082513809204,
            "answer": "understands",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8354892730712891
      },
      {
        "question verbose": "What is to occurring ",
        "b": "occurring",
        "expected answer": [
          "occurs"
        ],
        "predictions": [
          {
            "score": 0.8800755143165588,
            "answer": "occurs",
            "hit": true
          },
          {
            "score": 0.7899484634399414,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.7888715267181396,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.7879390716552734,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.7684738636016846,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.7504285573959351,
            "answer": "arises",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8800755739212036
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operates"
        ],
        "predictions": [
          {
            "score": 0.744472861289978,
            "answer": "operates",
            "hit": true
          },
          {
            "score": 0.6859818696975708,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.6761103868484497,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.6613923907279968,
            "answer": "employs",
            "hit": false
          },
          {
            "score": 0.6553713083267212,
            "answer": "maintains",
            "hit": false
          },
          {
            "score": 0.6523786783218384,
            "answer": "performs",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7444728910923004
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performs"
        ],
        "predictions": [
          {
            "score": 0.9087285399436951,
            "answer": "performs",
            "hit": true
          },
          {
            "score": 0.8034652471542358,
            "answer": "performed",
            "hit": false
          },
          {
            "score": 0.721599817276001,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.7213600277900696,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.720502495765686,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7176568508148193,
            "answer": "performers",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9087285995483398
      },
      {
        "question verbose": "What is to promoting ",
        "b": "promoting",
        "expected answer": [
          "promotes"
        ],
        "predictions": [
          {
            "score": 0.9003384709358215,
            "answer": "promotes",
            "hit": true
          },
          {
            "score": 0.8263174295425415,
            "answer": "promote",
            "hit": false
          },
          {
            "score": 0.7742106318473816,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.7486890554428101,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7396706342697144,
            "answer": "facilitates",
            "hit": false
          },
          {
            "score": 0.7192419171333313,
            "answer": "creates",
            "hit": false
          }
        ],
        "set_exclude": [
          "promoting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9003384411334991
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provides"
        ],
        "predictions": [
          {
            "score": 0.7960148453712463,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7724517583847046,
            "answer": "ensures",
            "hit": false
          },
          {
            "score": 0.7721644639968872,
            "answer": "enables",
            "hit": false
          },
          {
            "score": 0.7703526616096497,
            "answer": "delivers",
            "hit": false
          },
          {
            "score": 0.7658987045288086,
            "answer": "creates",
            "hit": false
          },
          {
            "score": 0.7582248449325562,
            "answer": "serves",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7296276390552521
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "receives"
        ],
        "predictions": [
          {
            "score": 0.8799044489860535,
            "answer": "receives",
            "hit": true
          },
          {
            "score": 0.8103987574577332,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.7444941401481628,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.7224211096763611,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.712082028388977,
            "answer": "delivers",
            "hit": false
          },
          {
            "score": 0.7083266973495483,
            "answer": "loses",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8799044489860535
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduces"
        ],
        "predictions": [
          {
            "score": 0.905556857585907,
            "answer": "reduces",
            "hit": true
          },
          {
            "score": 0.7894390821456909,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.7815209627151489,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7809180021286011,
            "answer": "decreases",
            "hit": false
          },
          {
            "score": 0.7720077037811279,
            "answer": "lowers",
            "hit": false
          },
          {
            "score": 0.7680138349533081,
            "answer": "removes",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 0,
        "landing_b": false,
        "landing_b_prime": true,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.905556857585907
      },
      {
        "question verbose": "What is to referring ",
        "b": "referring",
        "expected answer": [
          "refers"
        ],
        "predictions": [
          {
            "score": 0.8590844869613647,
            "answer": "refers",
            "hit": true
          },
          {
            "score": 0.7631382346153259,
            "answer": "referencing",
            "hit": false
          },
          {
            "score": 0.7620606422424316,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7403782606124878,
            "answer": "implies",
            "hit": false
          },
          {
            "score": 0.7397900819778442,
            "answer": "specifies",
            "hit": false
          },
          {
            "score": 0.7363610863685608,
            "answer": "relates",
            "hit": false
          }
        ],
        "set_exclude": [
          "referring"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8590844869613647
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "relates"
        ],
        "predictions": [
          {
            "score": 0.8404763340950012,
            "answer": "relates",
            "hit": true
          },
          {
            "score": 0.7889624834060669,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.7533379793167114,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7476200461387634,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7446077466011047,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7431226968765259,
            "answer": "involves",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8404763042926788
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remains"
        ],
        "predictions": [
          {
            "score": 0.7581591010093689,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.747124195098877,
            "answer": "remains",
            "hit": true
          },
          {
            "score": 0.729387640953064,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7208563089370728,
            "answer": "retains",
            "hit": false
          },
          {
            "score": 0.7202731370925903,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7029290199279785,
            "answer": "survives",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7471241652965546
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represents"
        ],
        "predictions": [
          {
            "score": 0.8827611207962036,
            "answer": "represents",
            "hit": true
          },
          {
            "score": 0.7720142602920532,
            "answer": "represented",
            "hit": false
          },
          {
            "score": 0.739425778388977,
            "answer": "reflects",
            "hit": false
          },
          {
            "score": 0.7357727289199829,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.7337794303894043,
            "answer": "depicts",
            "hit": false
          },
          {
            "score": 0.7317636013031006,
            "answer": "serves",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.882761150598526
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "requires"
        ],
        "predictions": [
          {
            "score": 0.7691964507102966,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7631691694259644,
            "answer": "prohibits",
            "hit": false
          },
          {
            "score": 0.7566344738006592,
            "answer": "prevents",
            "hit": false
          },
          {
            "score": 0.7563006281852722,
            "answer": "relies",
            "hit": false
          },
          {
            "score": 0.7419925928115845,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.7378447651863098,
            "answer": "enables",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7082463502883911
      },
      {
        "question verbose": "What is to seeming ",
        "b": "seeming",
        "expected answer": [
          "seems"
        ],
        "predictions": [
          {
            "score": 0.810600757598877,
            "answer": "seems",
            "hit": true
          },
          {
            "score": 0.7651259899139404,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.7434641718864441,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.7370680570602417,
            "answer": "tends",
            "hit": false
          },
          {
            "score": 0.733873724937439,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7161935567855835,
            "answer": "becomes",
            "hit": false
          }
        ],
        "set_exclude": [
          "seeming"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8106006979942322
      },
      {
        "question verbose": "What is to sitting ",
        "b": "sitting",
        "expected answer": [
          "sits"
        ],
        "predictions": [
          {
            "score": 0.8438940048217773,
            "answer": "sits",
            "hit": true
          },
          {
            "score": 0.7067071795463562,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.7047531604766846,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.7029178738594055,
            "answer": "seated",
            "hit": false
          },
          {
            "score": 0.7017433643341064,
            "answer": "holds",
            "hit": false
          },
          {
            "score": 0.6997941136360168,
            "answer": "puts",
            "hit": false
          }
        ],
        "set_exclude": [
          "sitting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8438939452171326
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spends"
        ],
        "predictions": [
          {
            "score": 0.8348931074142456,
            "answer": "spends",
            "hit": true
          },
          {
            "score": 0.7643382549285889,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7359404563903809,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.7172884345054626,
            "answer": "spent",
            "hit": false
          },
          {
            "score": 0.7043032646179199,
            "answer": "gets",
            "hit": false
          },
          {
            "score": 0.7008920907974243,
            "answer": "pays",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8348931074142456
      },
      {
        "question verbose": "What is to suggesting ",
        "b": "suggesting",
        "expected answer": [
          "suggests"
        ],
        "predictions": [
          {
            "score": 0.8836743831634521,
            "answer": "suggests",
            "hit": true
          },
          {
            "score": 0.8057550191879272,
            "answer": "implying",
            "hit": false
          },
          {
            "score": 0.7965434193611145,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.793500542640686,
            "answer": "implies",
            "hit": false
          },
          {
            "score": 0.7852411270141602,
            "answer": "indicating",
            "hit": false
          },
          {
            "score": 0.7498053312301636,
            "answer": "proposes",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggesting"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8836744427680969
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "teaches"
        ],
        "predictions": [
          {
            "score": 0.868156909942627,
            "answer": "teaches",
            "hit": true
          },
          {
            "score": 0.8199701905250549,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.7752249240875244,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.7396063804626465,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.7106638550758362,
            "answer": "classroom",
            "hit": false
          },
          {
            "score": 0.7083205580711365,
            "answer": "learns",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8681569695472717
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "tells"
        ],
        "predictions": [
          {
            "score": 0.8512146472930908,
            "answer": "tells",
            "hit": true
          },
          {
            "score": 0.7412633895874023,
            "answer": "asks",
            "hit": false
          },
          {
            "score": 0.7390971183776855,
            "answer": "informs",
            "hit": false
          },
          {
            "score": 0.7361379861831665,
            "answer": "says",
            "hit": false
          },
          {
            "score": 0.7289013862609863,
            "answer": "gives",
            "hit": false
          },
          {
            "score": 0.7206265330314636,
            "answer": "thinks",
            "hit": false
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8512146174907684
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understands"
        ],
        "predictions": [
          {
            "score": 0.7104374170303345,
            "answer": "understands",
            "hit": true
          },
          {
            "score": 0.6930320262908936,
            "answer": "explores",
            "hit": false
          },
          {
            "score": 0.6916442513465881,
            "answer": "explains",
            "hit": false
          },
          {
            "score": 0.6833965182304382,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.6798009872436523,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.6773374080657959,
            "answer": "knows",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7104374468326569
      }
    ],
    "result": {
      "cnt_questions_correct": 37,
      "cnt_questions_total": 47,
      "accuracy": 0.7872340425531915
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I08 [verb_Ving - 3pSg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "887782dc-2e74-4cc5-83c8-091f415c4afd",
      "timestamp": "2025-05-17T17:15:33.470352"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adding ",
        "b": "adding",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.7157078385353088,
            "answer": "add",
            "hit": false
          },
          {
            "score": 0.6850497722625732,
            "answer": "also",
            "hit": false
          },
          {
            "score": 0.6841480731964111,
            "answer": "putting",
            "hit": false
          },
          {
            "score": 0.6777759790420532,
            "answer": "while",
            "hit": false
          },
          {
            "score": 0.6762306690216064,
            "answer": "increased",
            "hit": false
          },
          {
            "score": 0.6725017428398132,
            "answer": "would",
            "hit": false
          }
        ],
        "set_exclude": [
          "adding"
        ],
        "rank": 15,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6642150282859802
      },
      {
        "question verbose": "What is to agreeing ",
        "b": "agreeing",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.8473837375640869,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.7610517740249634,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.7197842597961426,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.6940954327583313,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.6913039684295654,
            "answer": "signed",
            "hit": false
          },
          {
            "score": 0.6903074383735657,
            "answer": "insisted",
            "hit": false
          }
        ],
        "set_exclude": [
          "agreeing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8473837077617645
      },
      {
        "question verbose": "What is to allowing ",
        "b": "allowing",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.8066890835762024,
            "answer": "allowed",
            "hit": true
          },
          {
            "score": 0.7706454992294312,
            "answer": "letting",
            "hit": false
          },
          {
            "score": 0.7456745505332947,
            "answer": "enabling",
            "hit": false
          },
          {
            "score": 0.7342128753662109,
            "answer": "permitting",
            "hit": false
          },
          {
            "score": 0.7309964299201965,
            "answer": "permitted",
            "hit": false
          },
          {
            "score": 0.723778486251831,
            "answer": "granting",
            "hit": false
          }
        ],
        "set_exclude": [
          "allowing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.80668905377388
      },
      {
        "question verbose": "What is to announcing ",
        "b": "announcing",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8005051016807556,
            "answer": "announce",
            "hit": false
          },
          {
            "score": 0.783897876739502,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.7453978061676025,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.729572057723999,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.7221026420593262,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.6975224018096924,
            "answer": "launched",
            "hit": false
          }
        ],
        "set_exclude": [
          "announcing"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6792913377285004
      },
      {
        "question verbose": "What is to appearing ",
        "b": "appearing",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.8344947099685669,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.7853606939315796,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.709420919418335,
            "answer": "displayed",
            "hit": false
          },
          {
            "score": 0.6996890306472778,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.6994215250015259,
            "answer": "seemed",
            "hit": false
          },
          {
            "score": 0.6987258195877075,
            "answer": "produced",
            "hit": false
          }
        ],
        "set_exclude": [
          "appearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8344947695732117
      },
      {
        "question verbose": "What is to applying ",
        "b": "applying",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8801983594894409,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.7648308873176575,
            "answer": "applies",
            "hit": false
          },
          {
            "score": 0.707877516746521,
            "answer": "apply",
            "hit": false
          },
          {
            "score": 0.689643144607544,
            "answer": "subjected",
            "hit": false
          },
          {
            "score": 0.6878495216369629,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.6854385137557983,
            "answer": "evaluated",
            "hit": false
          }
        ],
        "set_exclude": [
          "applying"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8801983594894409
      },
      {
        "question verbose": "What is to asking ",
        "b": "asking",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.6480358839035034,
            "answer": "told",
            "hit": false
          },
          {
            "score": 0.6403154730796814,
            "answer": "involved",
            "hit": false
          },
          {
            "score": 0.6388840079307556,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.6352798938751221,
            "answer": "employed",
            "hit": false
          },
          {
            "score": 0.6341989040374756,
            "answer": "issued",
            "hit": false
          },
          {
            "score": 0.6330832242965698,
            "answer": "announced",
            "hit": false
          }
        ],
        "set_exclude": [
          "asking"
        ],
        "rank": 141,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5935497209429741
      },
      {
        "question verbose": "What is to attending ",
        "b": "attending",
        "expected answer": [
          "attended"
        ],
        "predictions": [
          {
            "score": 0.8299450874328613,
            "answer": "attended",
            "hit": true
          },
          {
            "score": 0.8104522228240967,
            "answer": "attend",
            "hit": false
          },
          {
            "score": 0.7304869890213013,
            "answer": "participated",
            "hit": false
          },
          {
            "score": 0.7282582521438599,
            "answer": "participating",
            "hit": false
          },
          {
            "score": 0.7070547342300415,
            "answer": "invited",
            "hit": false
          },
          {
            "score": 0.7021737098693848,
            "answer": "enrolled",
            "hit": false
          }
        ],
        "set_exclude": [
          "attending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8299451768398285
      },
      {
        "question verbose": "What is to becoming ",
        "b": "becoming",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8080150485038757,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.7422465682029724,
            "answer": "becomes",
            "hit": false
          },
          {
            "score": 0.7242522239685059,
            "answer": "being",
            "hit": false
          },
          {
            "score": 0.6995700597763062,
            "answer": "gaining",
            "hit": false
          },
          {
            "score": 0.6828268766403198,
            "answer": "attained",
            "hit": false
          },
          {
            "score": 0.6823639869689941,
            "answer": "made",
            "hit": false
          }
        ],
        "set_exclude": [
          "becoming"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8080150485038757
      },
      {
        "question verbose": "What is to considering ",
        "b": "considering",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.7926016449928284,
            "answer": "despite",
            "hit": false
          },
          {
            "score": 0.7820204496383667,
            "answer": "compared",
            "hit": false
          },
          {
            "score": 0.7706259489059448,
            "answer": "perhaps",
            "hit": false
          },
          {
            "score": 0.7623159885406494,
            "answer": "apparently",
            "hit": false
          },
          {
            "score": 0.7614004015922546,
            "answer": "according",
            "hit": false
          },
          {
            "score": 0.7477469444274902,
            "answer": "obviously",
            "hit": false
          }
        ],
        "set_exclude": [
          "considering"
        ],
        "rank": 822,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.588066965341568
      },
      {
        "question verbose": "What is to containing ",
        "b": "containing",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.7340477705001831,
            "answer": "contained",
            "hit": true
          },
          {
            "score": 0.6890052556991577,
            "answer": "opened",
            "hit": false
          },
          {
            "score": 0.6876720786094666,
            "answer": "derived",
            "hit": false
          },
          {
            "score": 0.6779537200927734,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.6726782321929932,
            "answer": "dominated",
            "hit": false
          },
          {
            "score": 0.6702790260314941,
            "answer": "assembled",
            "hit": false
          }
        ],
        "set_exclude": [
          "containing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7340478152036667
      },
      {
        "question verbose": "What is to continuing ",
        "b": "continuing",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.8489279747009277,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.7897645235061646,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.7660165429115295,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.7652838230133057,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.7174229621887207,
            "answer": "continuation",
            "hit": false
          },
          {
            "score": 0.7117209434509277,
            "answer": "remained",
            "hit": false
          }
        ],
        "set_exclude": [
          "continuing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8489280045032501
      },
      {
        "question verbose": "What is to creating ",
        "b": "creating",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.6946896910667419,
            "answer": "designed",
            "hit": false
          },
          {
            "score": 0.6918426752090454,
            "answer": "putting",
            "hit": false
          },
          {
            "score": 0.690845251083374,
            "answer": "adding",
            "hit": false
          },
          {
            "score": 0.6856482625007629,
            "answer": "making",
            "hit": false
          },
          {
            "score": 0.682452917098999,
            "answer": "started",
            "hit": false
          },
          {
            "score": 0.6794775128364563,
            "answer": "bringing",
            "hit": false
          }
        ],
        "set_exclude": [
          "creating"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6716389358043671
      },
      {
        "question verbose": "What is to deciding ",
        "b": "deciding",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8029454946517944,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.7748842835426331,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.7691973447799683,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.7585928440093994,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.7007442116737366,
            "answer": "choosing",
            "hit": false
          },
          {
            "score": 0.6990278959274292,
            "answer": "decision",
            "hit": false
          }
        ],
        "set_exclude": [
          "deciding"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8029454350471497
      },
      {
        "question verbose": "What is to describing ",
        "b": "describing",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8007208704948425,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.7996594309806824,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7951762676239014,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.7481993436813354,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.7334938049316406,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7068029046058655,
            "answer": "descriptions",
            "hit": false
          }
        ],
        "set_exclude": [
          "describing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7951762676239014
      },
      {
        "question verbose": "What is to developing ",
        "b": "developing",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8475934267044067,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.759550929069519,
            "answer": "develops",
            "hit": false
          },
          {
            "score": 0.7000091671943665,
            "answer": "emerging",
            "hit": false
          },
          {
            "score": 0.6777886152267456,
            "answer": "produced",
            "hit": false
          },
          {
            "score": 0.6729625463485718,
            "answer": "evolved",
            "hit": false
          },
          {
            "score": 0.672260582447052,
            "answer": "evolving",
            "hit": false
          }
        ],
        "set_exclude": [
          "developing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8475934267044067
      },
      {
        "question verbose": "What is to establishing ",
        "b": "establishing",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.7911132574081421,
            "answer": "establishes",
            "hit": false
          },
          {
            "score": 0.7172232866287231,
            "answer": "establish",
            "hit": false
          },
          {
            "score": 0.7006062865257263,
            "answer": "initiating",
            "hit": false
          },
          {
            "score": 0.693637490272522,
            "answer": "securing",
            "hit": false
          },
          {
            "score": 0.6887599229812622,
            "answer": "instituted",
            "hit": false
          },
          {
            "score": 0.686984658241272,
            "answer": "forming",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishing"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6741768419742584
      },
      {
        "question verbose": "What is to existing ",
        "b": "existing",
        "expected answer": [
          "existed"
        ],
        "predictions": [
          {
            "score": 0.6874479055404663,
            "answer": "proposed",
            "hit": false
          },
          {
            "score": 0.6855303645133972,
            "answer": "extant",
            "hit": false
          },
          {
            "score": 0.6695976853370667,
            "answer": "existed",
            "hit": true
          },
          {
            "score": 0.6664142608642578,
            "answer": "newly",
            "hit": false
          },
          {
            "score": 0.6597121953964233,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.655465841293335,
            "answer": "accumulated",
            "hit": false
          }
        ],
        "set_exclude": [
          "existing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6695976555347443
      },
      {
        "question verbose": "What is to expecting ",
        "b": "expecting",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.7527284026145935,
            "answer": "hoping",
            "hit": false
          },
          {
            "score": 0.7477459907531738,
            "answer": "expects",
            "hit": false
          },
          {
            "score": 0.7255204916000366,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.7109401226043701,
            "answer": "intending",
            "hit": false
          },
          {
            "score": 0.692786455154419,
            "answer": "waited",
            "hit": false
          },
          {
            "score": 0.6799396276473999,
            "answer": "hoped",
            "hit": false
          }
        ],
        "set_exclude": [
          "expecting"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.725520521402359
      },
      {
        "question verbose": "What is to failing ",
        "b": "failing",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.8313552737236023,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.7716445922851562,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.7610042095184326,
            "answer": "fails",
            "hit": false
          },
          {
            "score": 0.7341742515563965,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.7134976983070374,
            "answer": "refused",
            "hit": false
          },
          {
            "score": 0.6949250102043152,
            "answer": "faulty",
            "hit": false
          }
        ],
        "set_exclude": [
          "failing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8313552737236023
      },
      {
        "question verbose": "What is to following ",
        "b": "following",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.7914418578147888,
            "answer": "after",
            "hit": false
          },
          {
            "score": 0.7655752301216125,
            "answer": "during",
            "hit": false
          },
          {
            "score": 0.727148175239563,
            "answer": "while",
            "hit": false
          },
          {
            "score": 0.7255300283432007,
            "answer": "several",
            "hit": false
          },
          {
            "score": 0.705879807472229,
            "answer": "numerous",
            "hit": false
          },
          {
            "score": 0.7016606330871582,
            "answer": "along",
            "hit": false
          }
        ],
        "set_exclude": [
          "following"
        ],
        "rank": 45,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6463112831115723
      },
      {
        "question verbose": "What is to hearing ",
        "b": "hearing",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.6861338019371033,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.6662964224815369,
            "answer": "speech",
            "hit": false
          },
          {
            "score": 0.6419719457626343,
            "answer": "granted",
            "hit": false
          },
          {
            "score": 0.6368202567100525,
            "answer": "watching",
            "hit": false
          },
          {
            "score": 0.6366556286811829,
            "answer": "asked",
            "hit": false
          },
          {
            "score": 0.6363102197647095,
            "answer": "hearings",
            "hit": false
          }
        ],
        "set_exclude": [
          "hearing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6861337721347809
      },
      {
        "question verbose": "What is to improving ",
        "b": "improving",
        "expected answer": [
          "improved"
        ],
        "predictions": [
          {
            "score": 0.7822742462158203,
            "answer": "improves",
            "hit": false
          },
          {
            "score": 0.7650772333145142,
            "answer": "improvements",
            "hit": false
          },
          {
            "score": 0.7397511601448059,
            "answer": "enhancing",
            "hit": false
          },
          {
            "score": 0.7124208807945251,
            "answer": "expanding",
            "hit": false
          },
          {
            "score": 0.710127055644989,
            "answer": "strengthening",
            "hit": false
          },
          {
            "score": 0.7080844640731812,
            "answer": "enhanced",
            "hit": false
          }
        ],
        "set_exclude": [
          "improving"
        ],
        "rank": 30,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.667348712682724
      },
      {
        "question verbose": "What is to including ",
        "b": "including",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.752672553062439,
            "answer": "excluding",
            "hit": false
          },
          {
            "score": 0.7388200759887695,
            "answer": "especially",
            "hit": false
          },
          {
            "score": 0.729216456413269,
            "answer": "particularly",
            "hit": false
          },
          {
            "score": 0.7148853540420532,
            "answer": "both",
            "hit": false
          },
          {
            "score": 0.7108482122421265,
            "answer": "mostly",
            "hit": false
          },
          {
            "score": 0.6887218356132507,
            "answer": "formerly",
            "hit": false
          }
        ],
        "set_exclude": [
          "including"
        ],
        "rank": 60,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6299111396074295
      },
      {
        "question verbose": "What is to introducing ",
        "b": "introducing",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.86841881275177,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.8461849689483643,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.8124868273735046,
            "answer": "introduces",
            "hit": false
          },
          {
            "score": 0.6881808042526245,
            "answer": "brought",
            "hit": false
          },
          {
            "score": 0.6841896772384644,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.6837342381477356,
            "answer": "announcing",
            "hit": false
          }
        ],
        "set_exclude": [
          "introducing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8684188723564148
      },
      {
        "question verbose": "What is to involving ",
        "b": "involving",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.7534685134887695,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.738426923751831,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.709140419960022,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.7031162977218628,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7026883959770203,
            "answer": "conducted",
            "hit": false
          },
          {
            "score": 0.7017718553543091,
            "answer": "resulted",
            "hit": false
          }
        ],
        "set_exclude": [
          "involving"
        ],
        "rank": 216,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6179623901844025
      },
      {
        "question verbose": "What is to locating ",
        "b": "locating",
        "expected answer": [
          "located"
        ],
        "predictions": [
          {
            "score": 0.8184521198272705,
            "answer": "locate",
            "hit": false
          },
          {
            "score": 0.6998570561408997,
            "answer": "relocated",
            "hit": false
          },
          {
            "score": 0.688783586025238,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.6843197345733643,
            "answer": "discovered",
            "hit": false
          },
          {
            "score": 0.674892246723175,
            "answer": "encountered",
            "hit": false
          },
          {
            "score": 0.6743519902229309,
            "answer": "searched",
            "hit": false
          }
        ],
        "set_exclude": [
          "locating"
        ],
        "rank": 1468,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5721446350216866
      },
      {
        "question verbose": "What is to losing ",
        "b": "losing",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.7789852023124695,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.7197786569595337,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.6930948495864868,
            "answer": "regained",
            "hit": false
          },
          {
            "score": 0.691227912902832,
            "answer": "suffered",
            "hit": false
          },
          {
            "score": 0.6823527812957764,
            "answer": "defeated",
            "hit": false
          },
          {
            "score": 0.6786983013153076,
            "answer": "gained",
            "hit": false
          }
        ],
        "set_exclude": [
          "losing"
        ],
        "rank": 486,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5987911075353622
      },
      {
        "question verbose": "What is to managing ",
        "b": "managing",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.7898030281066895,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.7491864562034607,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.691466748714447,
            "answer": "handled",
            "hit": false
          },
          {
            "score": 0.6859534978866577,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.679185152053833,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.676618218421936,
            "answer": "maintained",
            "hit": false
          }
        ],
        "set_exclude": [
          "managing"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6791851818561554
      },
      {
        "question verbose": "What is to marrying ",
        "b": "marrying",
        "expected answer": [
          "married"
        ],
        "predictions": [
          {
            "score": 0.8396907448768616,
            "answer": "marry",
            "hit": false
          },
          {
            "score": 0.7136918306350708,
            "answer": "marriages",
            "hit": false
          },
          {
            "score": 0.7121396064758301,
            "answer": "married",
            "hit": true
          },
          {
            "score": 0.7023887634277344,
            "answer": "divorced",
            "hit": false
          },
          {
            "score": 0.6935028433799744,
            "answer": "kissed",
            "hit": false
          },
          {
            "score": 0.6667141914367676,
            "answer": "wedding",
            "hit": false
          }
        ],
        "set_exclude": [
          "marrying"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7121395617723465
      },
      {
        "question verbose": "What is to operating ",
        "b": "operating",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.6836285591125488,
            "answer": "operations",
            "hit": false
          },
          {
            "score": 0.6574007868766785,
            "answer": "supported",
            "hit": false
          },
          {
            "score": 0.6466901898384094,
            "answer": "applications",
            "hit": false
          },
          {
            "score": 0.6447418928146362,
            "answer": "operates",
            "hit": false
          },
          {
            "score": 0.6419596672058105,
            "answer": "application",
            "hit": false
          },
          {
            "score": 0.640596866607666,
            "answer": "management",
            "hit": false
          }
        ],
        "set_exclude": [
          "operating"
        ],
        "rank": 63,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6068784445524216
      },
      {
        "question verbose": "What is to performing ",
        "b": "performing",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.8497094511985779,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.8090611696243286,
            "answer": "performs",
            "hit": false
          },
          {
            "score": 0.7275622487068176,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.7253214716911316,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.6903175115585327,
            "answer": "conducted",
            "hit": false
          },
          {
            "score": 0.6795977354049683,
            "answer": "performances",
            "hit": false
          }
        ],
        "set_exclude": [
          "performing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8497094810009003
      },
      {
        "question verbose": "What is to proposing ",
        "b": "proposing",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8067833185195923,
            "answer": "proposes",
            "hit": false
          },
          {
            "score": 0.8047095537185669,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.7936484813690186,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.7346789240837097,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.7190691828727722,
            "answer": "proposals",
            "hit": false
          },
          {
            "score": 0.7180711627006531,
            "answer": "advocated",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposing"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7936484813690186
      },
      {
        "question verbose": "What is to providing ",
        "b": "providing",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.7753928303718567,
            "answer": "supplying",
            "hit": false
          },
          {
            "score": 0.7403515577316284,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.7389941811561584,
            "answer": "offering",
            "hit": false
          },
          {
            "score": 0.7379809617996216,
            "answer": "ensuring",
            "hit": false
          },
          {
            "score": 0.7365049123764038,
            "answer": "facilitating",
            "hit": false
          },
          {
            "score": 0.7362549304962158,
            "answer": "supplied",
            "hit": false
          }
        ],
        "set_exclude": [
          "providing"
        ],
        "rank": 268,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6319258213043213
      },
      {
        "question verbose": "What is to publishing ",
        "b": "publishing",
        "expected answer": [
          "published"
        ],
        "predictions": [
          {
            "score": 0.8221435546875,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.7677652835845947,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7585570812225342,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.6828290224075317,
            "answer": "printed",
            "hit": false
          },
          {
            "score": 0.6804143190383911,
            "answer": "editorial",
            "hit": false
          },
          {
            "score": 0.6783779859542847,
            "answer": "authored",
            "hit": false
          }
        ],
        "set_exclude": [
          "publishing"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6493711769580841
      },
      {
        "question verbose": "What is to receiving ",
        "b": "receiving",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.7987469434738159,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.7669442892074585,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.6915658712387085,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.6831605434417725,
            "answer": "recipient",
            "hit": false
          },
          {
            "score": 0.6830071806907654,
            "answer": "subjected",
            "hit": false
          },
          {
            "score": 0.6803845167160034,
            "answer": "treated",
            "hit": false
          }
        ],
        "set_exclude": [
          "receiving"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6682418882846832
      },
      {
        "question verbose": "What is to reducing ",
        "b": "reducing",
        "expected answer": [
          "reduced"
        ],
        "predictions": [
          {
            "score": 0.7929623126983643,
            "answer": "reduces",
            "hit": false
          },
          {
            "score": 0.7682666182518005,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.7676002979278564,
            "answer": "decreased",
            "hit": false
          },
          {
            "score": 0.763637125492096,
            "answer": "lowering",
            "hit": false
          },
          {
            "score": 0.7498461008071899,
            "answer": "reductions",
            "hit": false
          },
          {
            "score": 0.749840497970581,
            "answer": "eliminating",
            "hit": false
          }
        ],
        "set_exclude": [
          "reducing"
        ],
        "rank": 100,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6543305665254593
      },
      {
        "question verbose": "What is to relating ",
        "b": "relating",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8060914278030396,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.767971932888031,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.7570334076881409,
            "answer": "relates",
            "hit": false
          },
          {
            "score": 0.7416689991950989,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.739761233329773,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.7241523265838623,
            "answer": "involving",
            "hit": false
          }
        ],
        "set_exclude": [
          "relating"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.767971932888031
      },
      {
        "question verbose": "What is to remaining ",
        "b": "remaining",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.7659709453582764,
            "answer": "remainder",
            "hit": false
          },
          {
            "score": 0.7534995675086975,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.6912442445755005,
            "answer": "surviving",
            "hit": false
          },
          {
            "score": 0.6835128664970398,
            "answer": "retained",
            "hit": false
          },
          {
            "score": 0.6828247308731079,
            "answer": "remains",
            "hit": false
          },
          {
            "score": 0.6810792684555054,
            "answer": "stayed",
            "hit": false
          }
        ],
        "set_exclude": [
          "remaining"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7534995675086975
      },
      {
        "question verbose": "What is to replacing ",
        "b": "replacing",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8649899959564209,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.8019223213195801,
            "answer": "replaces",
            "hit": false
          },
          {
            "score": 0.736990213394165,
            "answer": "substituted",
            "hit": false
          },
          {
            "score": 0.730402410030365,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.6962864995002747,
            "answer": "removing",
            "hit": false
          },
          {
            "score": 0.6836937069892883,
            "answer": "installed",
            "hit": false
          }
        ],
        "set_exclude": [
          "replacing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8649900257587433
      },
      {
        "question verbose": "What is to representing ",
        "b": "representing",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.819051206111908,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.793871283531189,
            "answer": "represents",
            "hit": false
          },
          {
            "score": 0.704953670501709,
            "answer": "represent",
            "hit": false
          },
          {
            "score": 0.6856027841567993,
            "answer": "representation",
            "hit": false
          },
          {
            "score": 0.6854685544967651,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.6850795745849609,
            "answer": "comprising",
            "hit": false
          }
        ],
        "set_exclude": [
          "representing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.819051206111908
      },
      {
        "question verbose": "What is to requiring ",
        "b": "requiring",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.7255154848098755,
            "answer": "needing",
            "hit": false
          },
          {
            "score": 0.7177022695541382,
            "answer": "demanded",
            "hit": false
          },
          {
            "score": 0.715630054473877,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.6903015375137329,
            "answer": "prohibiting",
            "hit": false
          },
          {
            "score": 0.6849273443222046,
            "answer": "allowing",
            "hit": false
          },
          {
            "score": 0.6849112510681152,
            "answer": "requirement",
            "hit": false
          }
        ],
        "set_exclude": [
          "requiring"
        ],
        "rank": 105,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6362422108650208
      },
      {
        "question verbose": "What is to sending ",
        "b": "sending",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.6730194091796875,
            "answer": "started",
            "hit": false
          },
          {
            "score": 0.6613404750823975,
            "answer": "somehow",
            "hit": false
          },
          {
            "score": 0.6558367013931274,
            "answer": "sends",
            "hit": false
          },
          {
            "score": 0.651154100894928,
            "answer": "would",
            "hit": false
          },
          {
            "score": 0.6488744020462036,
            "answer": "creating",
            "hit": false
          },
          {
            "score": 0.6461645364761353,
            "answer": "reached",
            "hit": false
          }
        ],
        "set_exclude": [
          "sending"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.629559725522995
      },
      {
        "question verbose": "What is to spending ",
        "b": "spending",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.7692566514015198,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.7679718732833862,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.7481987476348877,
            "answer": "spends",
            "hit": false
          },
          {
            "score": 0.7417055368423462,
            "answer": "expenditure",
            "hit": false
          },
          {
            "score": 0.6929593682289124,
            "answer": "budgets",
            "hit": false
          },
          {
            "score": 0.6925583481788635,
            "answer": "expenses",
            "hit": false
          }
        ],
        "set_exclude": [
          "spending"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7692566514015198
      },
      {
        "question verbose": "What is to suffering ",
        "b": "suffering",
        "expected answer": [
          "suffered"
        ],
        "predictions": [
          {
            "score": 0.7917952537536621,
            "answer": "suffered",
            "hit": true
          },
          {
            "score": 0.775985598564148,
            "answer": "suffer",
            "hit": false
          },
          {
            "score": 0.7187516689300537,
            "answer": "misery",
            "hit": false
          },
          {
            "score": 0.714358925819397,
            "answer": "suffers",
            "hit": false
          },
          {
            "score": 0.709618091583252,
            "answer": "agony",
            "hit": false
          },
          {
            "score": 0.700933039188385,
            "answer": "inflicted",
            "hit": false
          }
        ],
        "set_exclude": [
          "suffering"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7917952537536621
      },
      {
        "question verbose": "What is to teaching ",
        "b": "teaching",
        "expected answer": [
          "taught"
        ],
        "predictions": [
          {
            "score": 0.8294004201889038,
            "answer": "teach",
            "hit": false
          },
          {
            "score": 0.824256420135498,
            "answer": "taught",
            "hit": true
          },
          {
            "score": 0.7758888006210327,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7373868227005005,
            "answer": "teachings",
            "hit": false
          },
          {
            "score": 0.7272495031356812,
            "answer": "classroom",
            "hit": false
          },
          {
            "score": 0.7186054587364197,
            "answer": "curriculum",
            "hit": false
          }
        ],
        "set_exclude": [
          "teaching"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.824256420135498
      },
      {
        "question verbose": "What is to telling ",
        "b": "telling",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.7496063709259033,
            "answer": "tells",
            "hit": false
          },
          {
            "score": 0.6942107677459717,
            "answer": "informing",
            "hit": false
          },
          {
            "score": 0.6785274147987366,
            "answer": "stating",
            "hit": false
          },
          {
            "score": 0.6753687262535095,
            "answer": "explaining",
            "hit": false
          },
          {
            "score": 0.6749824285507202,
            "answer": "talked",
            "hit": false
          },
          {
            "score": 0.6713659763336182,
            "answer": "told",
            "hit": true
          }
        ],
        "set_exclude": [
          "telling"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6713660210371017
      },
      {
        "question verbose": "What is to understanding ",
        "b": "understanding",
        "expected answer": [
          "understood"
        ],
        "predictions": [
          {
            "score": 0.6567471027374268,
            "answer": "analysis",
            "hit": false
          },
          {
            "score": 0.6509326100349426,
            "answer": "principles",
            "hit": false
          },
          {
            "score": 0.649263858795166,
            "answer": "perception",
            "hit": false
          },
          {
            "score": 0.6448837518692017,
            "answer": "studies",
            "hit": false
          },
          {
            "score": 0.6436876058578491,
            "answer": "essentially",
            "hit": false
          },
          {
            "score": 0.6425767540931702,
            "answer": "why",
            "hit": false
          }
        ],
        "set_exclude": [
          "understanding"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6369321793317795
      }
    ],
    "result": {
      "cnt_questions_correct": 18,
      "cnt_questions_total": 48,
      "accuracy": 0.375
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I09 [verb_Ving - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "fa67fd08-2c53-47cd-802f-d80f649d0a15",
      "timestamp": "2025-05-17T17:15:33.650202"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to adds ",
        "b": "adds",
        "expected answer": [
          "added"
        ],
        "predictions": [
          {
            "score": 0.6418365240097046,
            "answer": "increases",
            "hit": false
          },
          {
            "score": 0.6396362781524658,
            "answer": "changed",
            "hit": false
          },
          {
            "score": 0.6241827607154846,
            "answer": "video",
            "hit": false
          },
          {
            "score": 0.6214608550071716,
            "answer": "added",
            "hit": true
          },
          {
            "score": 0.6183547973632812,
            "answer": "created",
            "hit": false
          },
          {
            "score": 0.6152540445327759,
            "answer": "compared",
            "hit": false
          }
        ],
        "set_exclude": [
          "adds"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6214608550071716
      },
      {
        "question verbose": "What is to agrees ",
        "b": "agrees",
        "expected answer": [
          "agreed"
        ],
        "predictions": [
          {
            "score": 0.868746280670166,
            "answer": "agreed",
            "hit": true
          },
          {
            "score": 0.7555217146873474,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7518939971923828,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.7076677083969116,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.7006587982177734,
            "answer": "acknowledged",
            "hit": false
          },
          {
            "score": 0.6959572434425354,
            "answer": "admitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "agrees"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.868746280670166
      },
      {
        "question verbose": "What is to allows ",
        "b": "allows",
        "expected answer": [
          "allowed"
        ],
        "predictions": [
          {
            "score": 0.7072547078132629,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.6825839281082153,
            "answer": "designed",
            "hit": false
          },
          {
            "score": 0.66443932056427,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.6630111932754517,
            "answer": "started",
            "hit": false
          },
          {
            "score": 0.6590776443481445,
            "answer": "requires",
            "hit": false
          },
          {
            "score": 0.6531487703323364,
            "answer": "granted",
            "hit": false
          }
        ],
        "set_exclude": [
          "allows"
        ],
        "rank": 27,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6260063648223877
      },
      {
        "question verbose": "What is to announces ",
        "b": "announces",
        "expected answer": [
          "announced"
        ],
        "predictions": [
          {
            "score": 0.8074039220809937,
            "answer": "announce",
            "hit": false
          },
          {
            "score": 0.777969241142273,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.7254247069358826,
            "answer": "declared",
            "hit": false
          },
          {
            "score": 0.7178254127502441,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.7169759273529053,
            "answer": "announcement",
            "hit": false
          },
          {
            "score": 0.7052308320999146,
            "answer": "announcements",
            "hit": false
          }
        ],
        "set_exclude": [
          "announces"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7038740366697311
      },
      {
        "question verbose": "What is to appears ",
        "b": "appears",
        "expected answer": [
          "appeared"
        ],
        "predictions": [
          {
            "score": 0.6446874141693115,
            "answer": "appeared",
            "hit": true
          },
          {
            "score": 0.6347231864929199,
            "answer": "reached",
            "hit": false
          },
          {
            "score": 0.6273658275604248,
            "answer": "available",
            "hit": false
          },
          {
            "score": 0.6265972256660461,
            "answer": "numerous",
            "hit": false
          },
          {
            "score": 0.621091365814209,
            "answer": "supported",
            "hit": false
          },
          {
            "score": 0.6161963939666748,
            "answer": "learned",
            "hit": false
          }
        ],
        "set_exclude": [
          "appears"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6446873843669891
      },
      {
        "question verbose": "What is to applies ",
        "b": "applies",
        "expected answer": [
          "applied"
        ],
        "predictions": [
          {
            "score": 0.8343496322631836,
            "answer": "applied",
            "hit": true
          },
          {
            "score": 0.757149338722229,
            "answer": "applying",
            "hit": false
          },
          {
            "score": 0.7259305715560913,
            "answer": "applicable",
            "hit": false
          },
          {
            "score": 0.6818573474884033,
            "answer": "worked",
            "hit": false
          },
          {
            "score": 0.6795953512191772,
            "answer": "allowed",
            "hit": false
          },
          {
            "score": 0.6783989667892456,
            "answer": "implemented",
            "hit": false
          }
        ],
        "set_exclude": [
          "applies"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8343495726585388
      },
      {
        "question verbose": "What is to asks ",
        "b": "asks",
        "expected answer": [
          "asked"
        ],
        "predictions": [
          {
            "score": 0.7667254209518433,
            "answer": "inquired",
            "hit": false
          },
          {
            "score": 0.7506194710731506,
            "answer": "wondered",
            "hit": false
          },
          {
            "score": 0.7441955804824829,
            "answer": "questioned",
            "hit": false
          },
          {
            "score": 0.7426444292068481,
            "answer": "demanded",
            "hit": false
          },
          {
            "score": 0.7247409820556641,
            "answer": "requested",
            "hit": false
          },
          {
            "score": 0.720496654510498,
            "answer": "urged",
            "hit": false
          }
        ],
        "set_exclude": [
          "asks"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.707410454750061
      },
      {
        "question verbose": "What is to becomes ",
        "b": "becomes",
        "expected answer": [
          "became"
        ],
        "predictions": [
          {
            "score": 0.8757444620132446,
            "answer": "became",
            "hit": true
          },
          {
            "score": 0.7536938786506653,
            "answer": "becoming",
            "hit": false
          },
          {
            "score": 0.6998587250709534,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.6940107345581055,
            "answer": "disappears",
            "hit": false
          },
          {
            "score": 0.6938351392745972,
            "answer": "proved",
            "hit": false
          },
          {
            "score": 0.6927652955055237,
            "answer": "made",
            "hit": false
          }
        ],
        "set_exclude": [
          "becomes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8757444620132446
      },
      {
        "question verbose": "What is to believes ",
        "b": "believes",
        "expected answer": [
          "believed"
        ],
        "predictions": [
          {
            "score": 0.8447689414024353,
            "answer": "believed",
            "hit": true
          },
          {
            "score": 0.7606537938117981,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.7364506125450134,
            "answer": "insisted",
            "hit": false
          },
          {
            "score": 0.7321699261665344,
            "answer": "believing",
            "hit": false
          },
          {
            "score": 0.7216356992721558,
            "answer": "argued",
            "hit": false
          },
          {
            "score": 0.7139704823493958,
            "answer": "doubted",
            "hit": false
          }
        ],
        "set_exclude": [
          "believes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8447689414024353
      },
      {
        "question verbose": "What is to considers ",
        "b": "considers",
        "expected answer": [
          "considered"
        ],
        "predictions": [
          {
            "score": 0.8382701277732849,
            "answer": "considered",
            "hit": true
          },
          {
            "score": 0.7425519227981567,
            "answer": "regarded",
            "hit": false
          },
          {
            "score": 0.7364820837974548,
            "answer": "deemed",
            "hit": false
          },
          {
            "score": 0.710197925567627,
            "answer": "thinks",
            "hit": false
          },
          {
            "score": 0.6984018683433533,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.6939802765846252,
            "answer": "decided",
            "hit": false
          }
        ],
        "set_exclude": [
          "considers"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8382701277732849
      },
      {
        "question verbose": "What is to consists ",
        "b": "consists",
        "expected answer": [
          "consisted"
        ],
        "predictions": [
          {
            "score": 0.9131243228912354,
            "answer": "consisted",
            "hit": true
          },
          {
            "score": 0.8583675622940063,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.8159564733505249,
            "answer": "consisting",
            "hit": false
          },
          {
            "score": 0.801020622253418,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.7608492374420166,
            "answer": "comprises",
            "hit": false
          },
          {
            "score": 0.7211964130401611,
            "answer": "composed",
            "hit": false
          }
        ],
        "set_exclude": [
          "consists"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.913124293088913
      },
      {
        "question verbose": "What is to contains ",
        "b": "contains",
        "expected answer": [
          "contained"
        ],
        "predictions": [
          {
            "score": 0.8455882668495178,
            "answer": "contain",
            "hit": false
          },
          {
            "score": 0.7325010299682617,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.7220544219017029,
            "answer": "included",
            "hit": false
          },
          {
            "score": 0.7146251201629639,
            "answer": "consists",
            "hit": false
          },
          {
            "score": 0.7107870578765869,
            "answer": "comprised",
            "hit": false
          },
          {
            "score": 0.6936394572257996,
            "answer": "produced",
            "hit": false
          }
        ],
        "set_exclude": [
          "contains"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.688770592212677
      },
      {
        "question verbose": "What is to continues ",
        "b": "continues",
        "expected answer": [
          "continued"
        ],
        "predictions": [
          {
            "score": 0.8842951059341431,
            "answer": "continued",
            "hit": true
          },
          {
            "score": 0.8310604691505432,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.7769795656204224,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7592445015907288,
            "answer": "remained",
            "hit": false
          },
          {
            "score": 0.7270554304122925,
            "answer": "resumed",
            "hit": false
          },
          {
            "score": 0.7225799560546875,
            "answer": "persisted",
            "hit": false
          }
        ],
        "set_exclude": [
          "continues"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8842951059341431
      },
      {
        "question verbose": "What is to creates ",
        "b": "creates",
        "expected answer": [
          "created"
        ],
        "predictions": [
          {
            "score": 0.834763765335083,
            "answer": "create",
            "hit": false
          },
          {
            "score": 0.7555207014083862,
            "answer": "generates",
            "hit": false
          },
          {
            "score": 0.7515479326248169,
            "answer": "generated",
            "hit": false
          },
          {
            "score": 0.7380385398864746,
            "answer": "produced",
            "hit": false
          },
          {
            "score": 0.7376310229301453,
            "answer": "caused",
            "hit": false
          },
          {
            "score": 0.7345232367515564,
            "answer": "made",
            "hit": false
          }
        ],
        "set_exclude": [
          "creates"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.706550270318985
      },
      {
        "question verbose": "What is to decides ",
        "b": "decides",
        "expected answer": [
          "decided"
        ],
        "predictions": [
          {
            "score": 0.8959119915962219,
            "answer": "decided",
            "hit": true
          },
          {
            "score": 0.8430929183959961,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.7564480304718018,
            "answer": "deciding",
            "hit": false
          },
          {
            "score": 0.752857506275177,
            "answer": "chooses",
            "hit": false
          },
          {
            "score": 0.7441133260726929,
            "answer": "opted",
            "hit": false
          },
          {
            "score": 0.7433303594589233,
            "answer": "chose",
            "hit": false
          }
        ],
        "set_exclude": [
          "decides"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8959119617938995
      },
      {
        "question verbose": "What is to describes ",
        "b": "describes",
        "expected answer": [
          "described"
        ],
        "predictions": [
          {
            "score": 0.8520157337188721,
            "answer": "described",
            "hit": true
          },
          {
            "score": 0.826300859451294,
            "answer": "describe",
            "hit": false
          },
          {
            "score": 0.7750735282897949,
            "answer": "describing",
            "hit": false
          },
          {
            "score": 0.7500817775726318,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.7213883996009827,
            "answer": "refers",
            "hit": false
          },
          {
            "score": 0.7211069464683533,
            "answer": "characterized",
            "hit": false
          }
        ],
        "set_exclude": [
          "describes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8520157337188721
      },
      {
        "question verbose": "What is to develops ",
        "b": "develops",
        "expected answer": [
          "developed"
        ],
        "predictions": [
          {
            "score": 0.8347963094711304,
            "answer": "developed",
            "hit": true
          },
          {
            "score": 0.7723190188407898,
            "answer": "developing",
            "hit": false
          },
          {
            "score": 0.7133294343948364,
            "answer": "progressed",
            "hit": false
          },
          {
            "score": 0.6922090649604797,
            "answer": "emerged",
            "hit": false
          },
          {
            "score": 0.6912310123443604,
            "answer": "produced",
            "hit": false
          },
          {
            "score": 0.6879773736000061,
            "answer": "devised",
            "hit": false
          }
        ],
        "set_exclude": [
          "develops"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8347963094711304
      },
      {
        "question verbose": "What is to establishes ",
        "b": "establishes",
        "expected answer": [
          "established"
        ],
        "predictions": [
          {
            "score": 0.7861409187316895,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.7087415456771851,
            "answer": "ensured",
            "hit": false
          },
          {
            "score": 0.7070714235305786,
            "answer": "demonstrated",
            "hit": false
          },
          {
            "score": 0.7054942846298218,
            "answer": "instituted",
            "hit": false
          },
          {
            "score": 0.7028687000274658,
            "answer": "established",
            "hit": true
          },
          {
            "score": 0.6986219882965088,
            "answer": "establish",
            "hit": false
          }
        ],
        "set_exclude": [
          "establishes"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7028687000274658
      },
      {
        "question verbose": "What is to expects ",
        "b": "expects",
        "expected answer": [
          "expected"
        ],
        "predictions": [
          {
            "score": 0.8042477369308472,
            "answer": "expected",
            "hit": true
          },
          {
            "score": 0.7491283416748047,
            "answer": "expecting",
            "hit": false
          },
          {
            "score": 0.7289289832115173,
            "answer": "hoped",
            "hit": false
          },
          {
            "score": 0.7136658430099487,
            "answer": "intends",
            "hit": false
          },
          {
            "score": 0.6993062496185303,
            "answer": "believes",
            "hit": false
          },
          {
            "score": 0.6962676048278809,
            "answer": "predicted",
            "hit": false
          }
        ],
        "set_exclude": [
          "expects"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8042477965354919
      },
      {
        "question verbose": "What is to fails ",
        "b": "fails",
        "expected answer": [
          "failed"
        ],
        "predictions": [
          {
            "score": 0.8753715753555298,
            "answer": "failed",
            "hit": true
          },
          {
            "score": 0.7868674993515015,
            "answer": "failing",
            "hit": false
          },
          {
            "score": 0.7710747122764587,
            "answer": "failure",
            "hit": false
          },
          {
            "score": 0.7413630485534668,
            "answer": "failures",
            "hit": false
          },
          {
            "score": 0.7126812934875488,
            "answer": "refused",
            "hit": false
          },
          {
            "score": 0.7101304531097412,
            "answer": "missed",
            "hit": false
          }
        ],
        "set_exclude": [
          "fails"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8753715753555298
      },
      {
        "question verbose": "What is to follows ",
        "b": "follows",
        "expected answer": [
          "followed"
        ],
        "predictions": [
          {
            "score": 0.773932933807373,
            "answer": "followed",
            "hit": true
          },
          {
            "score": 0.7034367322921753,
            "answer": "follow",
            "hit": false
          },
          {
            "score": 0.6668953895568848,
            "answer": "preceded",
            "hit": false
          },
          {
            "score": 0.6624095439910889,
            "answer": "ensued",
            "hit": false
          },
          {
            "score": 0.6558905243873596,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.6527464389801025,
            "answer": "indicated",
            "hit": false
          }
        ],
        "set_exclude": [
          "follows"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7739329934120178
      },
      {
        "question verbose": "What is to happens ",
        "b": "happens",
        "expected answer": [
          "happened"
        ],
        "predictions": [
          {
            "score": 0.890466570854187,
            "answer": "happened",
            "hit": true
          },
          {
            "score": 0.8242315053939819,
            "answer": "happen",
            "hit": false
          },
          {
            "score": 0.7793226838111877,
            "answer": "happening",
            "hit": false
          },
          {
            "score": 0.7657872438430786,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.7570483684539795,
            "answer": "occurs",
            "hit": false
          },
          {
            "score": 0.7146420478820801,
            "answer": "occur",
            "hit": false
          }
        ],
        "set_exclude": [
          "happens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.890466570854187
      },
      {
        "question verbose": "What is to hears ",
        "b": "hears",
        "expected answer": [
          "heard"
        ],
        "predictions": [
          {
            "score": 0.7930462956428528,
            "answer": "heard",
            "hit": true
          },
          {
            "score": 0.7752060890197754,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.6653982996940613,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.6576071977615356,
            "answer": "whispered",
            "hit": false
          },
          {
            "score": 0.6539304256439209,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.6477794647216797,
            "answer": "witnessed",
            "hit": false
          }
        ],
        "set_exclude": [
          "hears"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7930462658405304
      },
      {
        "question verbose": "What is to includes ",
        "b": "includes",
        "expected answer": [
          "included"
        ],
        "predictions": [
          {
            "score": 0.6989103555679321,
            "answer": "included",
            "hit": true
          },
          {
            "score": 0.675838828086853,
            "answer": "designed",
            "hit": false
          },
          {
            "score": 0.6692330837249756,
            "answer": "available",
            "hit": false
          },
          {
            "score": 0.6609256267547607,
            "answer": "featuring",
            "hit": false
          },
          {
            "score": 0.6593079566955566,
            "answer": "including",
            "hit": false
          },
          {
            "score": 0.6556759476661682,
            "answer": "started",
            "hit": false
          }
        ],
        "set_exclude": [
          "includes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6989103257656097
      },
      {
        "question verbose": "What is to intends ",
        "b": "intends",
        "expected answer": [
          "intended"
        ],
        "predictions": [
          {
            "score": 0.8485248684883118,
            "answer": "intend",
            "hit": false
          },
          {
            "score": 0.7728740572929382,
            "answer": "intended",
            "hit": true
          },
          {
            "score": 0.7633296251296997,
            "answer": "intending",
            "hit": false
          },
          {
            "score": 0.7526865005493164,
            "answer": "planned",
            "hit": false
          },
          {
            "score": 0.7326834201812744,
            "answer": "hoped",
            "hit": false
          },
          {
            "score": 0.7326260805130005,
            "answer": "vowed",
            "hit": false
          }
        ],
        "set_exclude": [
          "intends"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7728740572929382
      },
      {
        "question verbose": "What is to introduces ",
        "b": "introduces",
        "expected answer": [
          "introduced"
        ],
        "predictions": [
          {
            "score": 0.8676245212554932,
            "answer": "introduced",
            "hit": true
          },
          {
            "score": 0.830337405204773,
            "answer": "introduce",
            "hit": false
          },
          {
            "score": 0.7903300523757935,
            "answer": "introducing",
            "hit": false
          },
          {
            "score": 0.7081810832023621,
            "answer": "brought",
            "hit": false
          },
          {
            "score": 0.6905809640884399,
            "answer": "unveiled",
            "hit": false
          },
          {
            "score": 0.6898318529129028,
            "answer": "presented",
            "hit": false
          }
        ],
        "set_exclude": [
          "introduces"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8676245212554932
      },
      {
        "question verbose": "What is to involves ",
        "b": "involves",
        "expected answer": [
          "involved"
        ],
        "predictions": [
          {
            "score": 0.8484185934066772,
            "answer": "involve",
            "hit": false
          },
          {
            "score": 0.7806292176246643,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7525149583816528,
            "answer": "consisted",
            "hit": false
          },
          {
            "score": 0.7505536079406738,
            "answer": "resulted",
            "hit": false
          },
          {
            "score": 0.7299563884735107,
            "answer": "occurred",
            "hit": false
          },
          {
            "score": 0.7174067497253418,
            "answer": "consists",
            "hit": false
          }
        ],
        "set_exclude": [
          "involves"
        ],
        "rank": 101,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6415763944387436
      },
      {
        "question verbose": "What is to loses ",
        "b": "loses",
        "expected answer": [
          "lost"
        ],
        "predictions": [
          {
            "score": 0.7949174642562866,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.7646242380142212,
            "answer": "losses",
            "hit": false
          },
          {
            "score": 0.7145450115203857,
            "answer": "suffered",
            "hit": false
          },
          {
            "score": 0.710464596748352,
            "answer": "regained",
            "hit": false
          },
          {
            "score": 0.7076845169067383,
            "answer": "gained",
            "hit": false
          },
          {
            "score": 0.7060582041740417,
            "answer": "wins",
            "hit": false
          }
        ],
        "set_exclude": [
          "loses"
        ],
        "rank": 330,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6142899245023727
      },
      {
        "question verbose": "What is to manages ",
        "b": "manages",
        "expected answer": [
          "managed"
        ],
        "predictions": [
          {
            "score": 0.8093124628067017,
            "answer": "manage",
            "hit": false
          },
          {
            "score": 0.7404346466064453,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7108182907104492,
            "answer": "managed",
            "hit": true
          },
          {
            "score": 0.7103681564331055,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.7091662883758545,
            "answer": "handled",
            "hit": false
          },
          {
            "score": 0.6919559836387634,
            "answer": "succeeded",
            "hit": false
          }
        ],
        "set_exclude": [
          "manages"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7108182460069656
      },
      {
        "question verbose": "What is to occurs ",
        "b": "occurs",
        "expected answer": [
          "occurred"
        ],
        "predictions": [
          {
            "score": 0.8883997201919556,
            "answer": "occurred",
            "hit": true
          },
          {
            "score": 0.8599324822425842,
            "answer": "occur",
            "hit": false
          },
          {
            "score": 0.8063190579414368,
            "answer": "occurring",
            "hit": false
          },
          {
            "score": 0.7859600782394409,
            "answer": "happened",
            "hit": false
          },
          {
            "score": 0.7663398385047913,
            "answer": "happens",
            "hit": false
          },
          {
            "score": 0.727389395236969,
            "answer": "resulted",
            "hit": false
          }
        ],
        "set_exclude": [
          "occurs"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8883996605873108
      },
      {
        "question verbose": "What is to operates ",
        "b": "operates",
        "expected answer": [
          "operated"
        ],
        "predictions": [
          {
            "score": 0.8463646173477173,
            "answer": "operate",
            "hit": false
          },
          {
            "score": 0.7216569781303406,
            "answer": "conducted",
            "hit": false
          },
          {
            "score": 0.7037762403488159,
            "answer": "worked",
            "hit": false
          },
          {
            "score": 0.7006523609161377,
            "answer": "maintained",
            "hit": false
          },
          {
            "score": 0.6979297399520874,
            "answer": "launched",
            "hit": false
          },
          {
            "score": 0.6971203088760376,
            "answer": "acted",
            "hit": false
          }
        ],
        "set_exclude": [
          "operates"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.675589919090271
      },
      {
        "question verbose": "What is to performs ",
        "b": "performs",
        "expected answer": [
          "performed"
        ],
        "predictions": [
          {
            "score": 0.8820137977600098,
            "answer": "performed",
            "hit": true
          },
          {
            "score": 0.8262903690338135,
            "answer": "performing",
            "hit": false
          },
          {
            "score": 0.7008591294288635,
            "answer": "conducted",
            "hit": false
          },
          {
            "score": 0.6899802088737488,
            "answer": "performer",
            "hit": false
          },
          {
            "score": 0.6861839890480042,
            "answer": "participated",
            "hit": false
          },
          {
            "score": 0.6790318489074707,
            "answer": "underwent",
            "hit": false
          }
        ],
        "set_exclude": [
          "performs"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.882013738155365
      },
      {
        "question verbose": "What is to proposes ",
        "b": "proposes",
        "expected answer": [
          "proposed"
        ],
        "predictions": [
          {
            "score": 0.8313003778457642,
            "answer": "proposed",
            "hit": true
          },
          {
            "score": 0.8257387280464172,
            "answer": "propose",
            "hit": false
          },
          {
            "score": 0.8012595176696777,
            "answer": "proposing",
            "hit": false
          },
          {
            "score": 0.737762987613678,
            "answer": "proposal",
            "hit": false
          },
          {
            "score": 0.7369154095649719,
            "answer": "suggested",
            "hit": false
          },
          {
            "score": 0.736133337020874,
            "answer": "proposals",
            "hit": false
          }
        ],
        "set_exclude": [
          "proposes"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8313003778457642
      },
      {
        "question verbose": "What is to provides ",
        "b": "provides",
        "expected answer": [
          "provided"
        ],
        "predictions": [
          {
            "score": 0.7587724924087524,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.7072741985321045,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.6940228939056396,
            "answer": "provided",
            "hit": true
          },
          {
            "score": 0.6818634271621704,
            "answer": "available",
            "hit": false
          },
          {
            "score": 0.6677557826042175,
            "answer": "designed",
            "hit": false
          },
          {
            "score": 0.6652970314025879,
            "answer": "requires",
            "hit": false
          }
        ],
        "set_exclude": [
          "provides"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6940229088068008
      },
      {
        "question verbose": "What is to receives ",
        "b": "receives",
        "expected answer": [
          "received"
        ],
        "predictions": [
          {
            "score": 0.8338608741760254,
            "answer": "receive",
            "hit": false
          },
          {
            "score": 0.7869728803634644,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.7085832953453064,
            "answer": "participated",
            "hit": false
          },
          {
            "score": 0.7080820798873901,
            "answer": "underwent",
            "hit": false
          },
          {
            "score": 0.7048546075820923,
            "answer": "suffered",
            "hit": false
          },
          {
            "score": 0.6972367763519287,
            "answer": "gets",
            "hit": false
          }
        ],
        "set_exclude": [
          "receives"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6961531043052673
      },
      {
        "question verbose": "What is to refers ",
        "b": "refers",
        "expected answer": [
          "referred"
        ],
        "predictions": [
          {
            "score": 0.8257321119308472,
            "answer": "referred",
            "hit": true
          },
          {
            "score": 0.7538082003593445,
            "answer": "referring",
            "hit": false
          },
          {
            "score": 0.7241251468658447,
            "answer": "referenced",
            "hit": false
          },
          {
            "score": 0.7168192267417908,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.7075309157371521,
            "answer": "describes",
            "hit": false
          },
          {
            "score": 0.7021718621253967,
            "answer": "mentioned",
            "hit": false
          }
        ],
        "set_exclude": [
          "refers"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8257321417331696
      },
      {
        "question verbose": "What is to relates ",
        "b": "relates",
        "expected answer": [
          "related"
        ],
        "predictions": [
          {
            "score": 0.8251640200614929,
            "answer": "relate",
            "hit": false
          },
          {
            "score": 0.7516981363296509,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7411288619041443,
            "answer": "related",
            "hit": true
          },
          {
            "score": 0.6952877640724182,
            "answer": "arose",
            "hit": false
          },
          {
            "score": 0.6925349235534668,
            "answer": "described",
            "hit": false
          },
          {
            "score": 0.6865869164466858,
            "answer": "explained",
            "hit": false
          }
        ],
        "set_exclude": [
          "relates"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7411288619041443
      },
      {
        "question verbose": "What is to remains ",
        "b": "remains",
        "expected answer": [
          "remained"
        ],
        "predictions": [
          {
            "score": 0.8120346665382385,
            "answer": "remained",
            "hit": true
          },
          {
            "score": 0.7166775465011597,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.7055903673171997,
            "answer": "remaining",
            "hit": false
          },
          {
            "score": 0.6803027391433716,
            "answer": "retained",
            "hit": false
          },
          {
            "score": 0.6759234666824341,
            "answer": "preserved",
            "hit": false
          },
          {
            "score": 0.6737131476402283,
            "answer": "stayed",
            "hit": false
          }
        ],
        "set_exclude": [
          "remains"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8120346665382385
      },
      {
        "question verbose": "What is to replaces ",
        "b": "replaces",
        "expected answer": [
          "replaced"
        ],
        "predictions": [
          {
            "score": 0.8551690578460693,
            "answer": "replaced",
            "hit": true
          },
          {
            "score": 0.7910335063934326,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.7334312200546265,
            "answer": "substituted",
            "hit": false
          },
          {
            "score": 0.684704065322876,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.6704788208007812,
            "answer": "inserted",
            "hit": false
          },
          {
            "score": 0.6653075814247131,
            "answer": "preceded",
            "hit": false
          }
        ],
        "set_exclude": [
          "replaces"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8551690876483917
      },
      {
        "question verbose": "What is to represents ",
        "b": "represents",
        "expected answer": [
          "represented"
        ],
        "predictions": [
          {
            "score": 0.8625211119651794,
            "answer": "represented",
            "hit": true
          },
          {
            "score": 0.7853021621704102,
            "answer": "representing",
            "hit": false
          },
          {
            "score": 0.6944456100463867,
            "answer": "corresponds",
            "hit": false
          },
          {
            "score": 0.6913665533065796,
            "answer": "stood",
            "hit": false
          },
          {
            "score": 0.6900770664215088,
            "answer": "presented",
            "hit": false
          },
          {
            "score": 0.6883513927459717,
            "answer": "indicated",
            "hit": false
          }
        ],
        "set_exclude": [
          "represents"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8625211417675018
      },
      {
        "question verbose": "What is to requires ",
        "b": "requires",
        "expected answer": [
          "required"
        ],
        "predictions": [
          {
            "score": 0.6640419960021973,
            "answer": "required",
            "hit": true
          },
          {
            "score": 0.653661847114563,
            "answer": "requirements",
            "hit": false
          },
          {
            "score": 0.6507477760314941,
            "answer": "supported",
            "hit": false
          },
          {
            "score": 0.6444519758224487,
            "answer": "optional",
            "hit": false
          },
          {
            "score": 0.6419296264648438,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.6383391618728638,
            "answer": "available",
            "hit": false
          }
        ],
        "set_exclude": [
          "requires"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6640419960021973
      },
      {
        "question verbose": "What is to seems ",
        "b": "seems",
        "expected answer": [
          "seemed"
        ],
        "predictions": [
          {
            "score": 0.9026345014572144,
            "answer": "seemed",
            "hit": true
          },
          {
            "score": 0.8579766750335693,
            "answer": "seem",
            "hit": false
          },
          {
            "score": 0.7634992003440857,
            "answer": "appeared",
            "hit": false
          },
          {
            "score": 0.7269910573959351,
            "answer": "appear",
            "hit": false
          },
          {
            "score": 0.7223686575889587,
            "answer": "was",
            "hit": false
          },
          {
            "score": 0.7209309935569763,
            "answer": "evidently",
            "hit": false
          }
        ],
        "set_exclude": [
          "seems"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9026345610618591
      },
      {
        "question verbose": "What is to sends ",
        "b": "sends",
        "expected answer": [
          "sent"
        ],
        "predictions": [
          {
            "score": 0.8359881639480591,
            "answer": "send",
            "hit": false
          },
          {
            "score": 0.6924418807029724,
            "answer": "gave",
            "hit": false
          },
          {
            "score": 0.689746618270874,
            "answer": "brought",
            "hit": false
          },
          {
            "score": 0.6887305974960327,
            "answer": "dispatched",
            "hit": false
          },
          {
            "score": 0.6820192337036133,
            "answer": "launched",
            "hit": false
          },
          {
            "score": 0.6817837953567505,
            "answer": "transmitted",
            "hit": false
          }
        ],
        "set_exclude": [
          "sends"
        ],
        "rank": 70,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6376973092556
      },
      {
        "question verbose": "What is to spends ",
        "b": "spends",
        "expected answer": [
          "spent"
        ],
        "predictions": [
          {
            "score": 0.8605460524559021,
            "answer": "spent",
            "hit": true
          },
          {
            "score": 0.766266405582428,
            "answer": "spending",
            "hit": false
          },
          {
            "score": 0.6928527355194092,
            "answer": "invested",
            "hit": false
          },
          {
            "score": 0.6913008093833923,
            "answer": "wasted",
            "hit": false
          },
          {
            "score": 0.6820575594902039,
            "answer": "expenditures",
            "hit": false
          },
          {
            "score": 0.6749873161315918,
            "answer": "spend",
            "hit": false
          }
        ],
        "set_exclude": [
          "spends"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8605460524559021
      },
      {
        "question verbose": "What is to suggests ",
        "b": "suggests",
        "expected answer": [
          "suggested"
        ],
        "predictions": [
          {
            "score": 0.8542186617851257,
            "answer": "suggested",
            "hit": true
          },
          {
            "score": 0.779900848865509,
            "answer": "suggesting",
            "hit": false
          },
          {
            "score": 0.7718886733055115,
            "answer": "indicates",
            "hit": false
          },
          {
            "score": 0.7688091397285461,
            "answer": "indicated",
            "hit": false
          },
          {
            "score": 0.7468336224555969,
            "answer": "implies",
            "hit": false
          },
          {
            "score": 0.7376291751861572,
            "answer": "indicate",
            "hit": false
          }
        ],
        "set_exclude": [
          "suggests"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8542186617851257
      },
      {
        "question verbose": "What is to tells ",
        "b": "tells",
        "expected answer": [
          "told"
        ],
        "predictions": [
          {
            "score": 0.7427109479904175,
            "answer": "telling",
            "hit": false
          },
          {
            "score": 0.7343956232070923,
            "answer": "explained",
            "hit": false
          },
          {
            "score": 0.7244548797607422,
            "answer": "says",
            "hit": false
          },
          {
            "score": 0.7154587507247925,
            "answer": "told",
            "hit": true
          },
          {
            "score": 0.7103943228721619,
            "answer": "gave",
            "hit": false
          },
          {
            "score": 0.7002668976783752,
            "answer": "informs",
            "hit": false
          }
        ],
        "set_exclude": [
          "tells"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7154587805271149
      }
    ],
    "result": {
      "cnt_questions_correct": 29,
      "cnt_questions_total": 46,
      "accuracy": 0.6304347826086957
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "1_Inflectional_morphology",
      "subcategory": "I10 [verb_3pSg - Ved].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "0bc04423-8aea-46e8-bc7f-24701414b7c6",
      "timestamp": "2025-05-17T17:15:33.835313"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to home ",
        "b": "home",
        "expected answer": [
          "homeless"
        ],
        "predictions": [
          {
            "score": 0.7706041932106018,
            "answer": "ruthless",
            "hit": false
          },
          {
            "score": 0.6672051548957825,
            "answer": "relentless",
            "hit": false
          },
          {
            "score": 0.6590234041213989,
            "answer": "brutal",
            "hit": false
          },
          {
            "score": 0.6311668157577515,
            "answer": "reckless",
            "hit": false
          },
          {
            "score": 0.6277310848236084,
            "answer": "terrifying",
            "hit": false
          },
          {
            "score": 0.6265383362770081,
            "answer": "cynical",
            "hit": false
          }
        ],
        "set_exclude": [
          "home"
        ],
        "rank": 10679,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.47969629243016243
      },
      {
        "question verbose": "What is to ruth ",
        "b": "ruth",
        "expected answer": [
          "ruthless"
        ],
        "predictions": [
          {
            "score": 0.7957174777984619,
            "answer": "homeless",
            "hit": false
          },
          {
            "score": 0.6610909104347229,
            "answer": "rebecca",
            "hit": false
          },
          {
            "score": 0.6585156917572021,
            "answer": "esther",
            "hit": false
          },
          {
            "score": 0.640245258808136,
            "answer": "donna",
            "hit": false
          },
          {
            "score": 0.6384087800979614,
            "answer": "stephanie",
            "hit": false
          },
          {
            "score": 0.6371410489082336,
            "answer": "judy",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruth"
        ],
        "rank": 4498,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5170352607965469
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 2,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D01 [noun+less_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "df8bf8ac-0dc4-4fa1-a339-f4d379b13e73",
      "timestamp": "2025-05-17T17:15:34.007173"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to able ",
        "b": "able",
        "expected answer": [
          "unable"
        ],
        "predictions": [
          {
            "score": 0.8296319842338562,
            "answer": "unable",
            "hit": true
          },
          {
            "score": 0.7522165775299072,
            "answer": "capable",
            "hit": false
          },
          {
            "score": 0.7506211996078491,
            "answer": "unwilling",
            "hit": false
          },
          {
            "score": 0.7505046725273132,
            "answer": "incapable",
            "hit": false
          },
          {
            "score": 0.7348900437355042,
            "answer": "willing",
            "hit": false
          },
          {
            "score": 0.7151786088943481,
            "answer": "unsuccessful",
            "hit": false
          }
        ],
        "set_exclude": [
          "able"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8296319842338562
      },
      {
        "question verbose": "What is to acceptable ",
        "b": "acceptable",
        "expected answer": [
          "unacceptable"
        ],
        "predictions": [
          {
            "score": 0.8413320779800415,
            "answer": "unacceptable",
            "hit": true
          },
          {
            "score": 0.7339659333229065,
            "answer": "adequate",
            "hit": false
          },
          {
            "score": 0.7334733009338379,
            "answer": "inappropriate",
            "hit": false
          },
          {
            "score": 0.731740415096283,
            "answer": "satisfactory",
            "hit": false
          },
          {
            "score": 0.7201281785964966,
            "answer": "inadequate",
            "hit": false
          },
          {
            "score": 0.7166060209274292,
            "answer": "appropriate",
            "hit": false
          }
        ],
        "set_exclude": [
          "acceptable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8413320481777191
      },
      {
        "question verbose": "What is to affected ",
        "b": "affected",
        "expected answer": [
          "unaffected"
        ],
        "predictions": [
          {
            "score": 0.8705909252166748,
            "answer": "impacted",
            "hit": false
          },
          {
            "score": 0.799762487411499,
            "answer": "unaffected",
            "hit": true
          },
          {
            "score": 0.7571316957473755,
            "answer": "damaged",
            "hit": false
          },
          {
            "score": 0.748740553855896,
            "answer": "affect",
            "hit": false
          },
          {
            "score": 0.7424459457397461,
            "answer": "susceptible",
            "hit": false
          },
          {
            "score": 0.741549015045166,
            "answer": "affects",
            "hit": false
          }
        ],
        "set_exclude": [
          "affected"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7997625470161438
      },
      {
        "question verbose": "What is to available ",
        "b": "available",
        "expected answer": [
          "unavailable"
        ],
        "predictions": [
          {
            "score": 0.7201225757598877,
            "answer": "unavailable",
            "hit": true
          },
          {
            "score": 0.6793111562728882,
            "answer": "unknown",
            "hit": false
          },
          {
            "score": 0.6563014388084412,
            "answer": "options",
            "hit": false
          },
          {
            "score": 0.6542433500289917,
            "answer": "featuring",
            "hit": false
          },
          {
            "score": 0.6523711681365967,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.652318000793457,
            "answer": "missing",
            "hit": false
          }
        ],
        "set_exclude": [
          "available"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7201225459575653
      },
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "unaware"
        ],
        "predictions": [
          {
            "score": 0.8189470767974854,
            "answer": "unaware",
            "hit": true
          },
          {
            "score": 0.7413077354431152,
            "answer": "wary",
            "hit": false
          },
          {
            "score": 0.733185887336731,
            "answer": "ignorant",
            "hit": false
          },
          {
            "score": 0.7308647632598877,
            "answer": "unable",
            "hit": false
          },
          {
            "score": 0.7264026403427124,
            "answer": "unwilling",
            "hit": false
          },
          {
            "score": 0.7147802114486694,
            "answer": "uneasy",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8189471662044525
      },
      {
        "question verbose": "What is to certain ",
        "b": "certain",
        "expected answer": [
          "uncertain"
        ],
        "predictions": [
          {
            "score": 0.7127456665039062,
            "answer": "particular",
            "hit": false
          },
          {
            "score": 0.688746988773346,
            "answer": "uncertain",
            "hit": true
          },
          {
            "score": 0.6796143054962158,
            "answer": "strange",
            "hit": false
          },
          {
            "score": 0.6769106984138489,
            "answer": "questionable",
            "hit": false
          },
          {
            "score": 0.6733710765838623,
            "answer": "definite",
            "hit": false
          },
          {
            "score": 0.6733397245407104,
            "answer": "incorrect",
            "hit": false
          }
        ],
        "set_exclude": [
          "certain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.688746988773346
      },
      {
        "question verbose": "What is to changed ",
        "b": "changed",
        "expected answer": [
          "unchanged"
        ],
        "predictions": [
          {
            "score": 0.7035578489303589,
            "answer": "changing",
            "hit": false
          },
          {
            "score": 0.6406261324882507,
            "answer": "exception",
            "hit": false
          },
          {
            "score": 0.6388709545135498,
            "answer": "destroy",
            "hit": false
          },
          {
            "score": 0.6381483674049377,
            "answer": "lost",
            "hit": false
          },
          {
            "score": 0.6343063712120056,
            "answer": "adjust",
            "hit": false
          },
          {
            "score": 0.6316529512405396,
            "answer": "removed",
            "hit": false
          }
        ],
        "set_exclude": [
          "changed"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6225488111376762
      },
      {
        "question verbose": "What is to comfortable ",
        "b": "comfortable",
        "expected answer": [
          "uncomfortable"
        ],
        "predictions": [
          {
            "score": 0.8382781744003296,
            "answer": "uncomfortable",
            "hit": true
          },
          {
            "score": 0.761550784111023,
            "answer": "uneasy",
            "hit": false
          },
          {
            "score": 0.7431643009185791,
            "answer": "comfortably",
            "hit": false
          },
          {
            "score": 0.7415980100631714,
            "answer": "confident",
            "hit": false
          },
          {
            "score": 0.7345202565193176,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.7197213172912598,
            "answer": "unfamiliar",
            "hit": false
          }
        ],
        "set_exclude": [
          "comfortable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.838278204202652
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "unconscious"
        ],
        "predictions": [
          {
            "score": 0.7103328108787537,
            "answer": "unconscious",
            "hit": true
          },
          {
            "score": 0.6968470811843872,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.666172206401825,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.6589277982711792,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.6355332732200623,
            "answer": "intention",
            "hit": false
          },
          {
            "score": 0.6355255246162415,
            "answer": "blind",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7103328108787537
      },
      {
        "question verbose": "What is to employed ",
        "b": "employed",
        "expected answer": [
          "unemployed"
        ],
        "predictions": [
          {
            "score": 0.7298184633255005,
            "answer": "unemployed",
            "hit": true
          },
          {
            "score": 0.6769471764564514,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.6422702074050903,
            "answer": "married",
            "hit": false
          },
          {
            "score": 0.6418806314468384,
            "answer": "unemployment",
            "hit": false
          },
          {
            "score": 0.6243930459022522,
            "answer": "appointed",
            "hit": false
          },
          {
            "score": 0.6237848997116089,
            "answer": "proclaimed",
            "hit": false
          }
        ],
        "set_exclude": [
          "employed"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7298184335231781
      },
      {
        "question verbose": "What is to expected ",
        "b": "expected",
        "expected answer": [
          "unexpected"
        ],
        "predictions": [
          {
            "score": 0.7503997683525085,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.7275906801223755,
            "answer": "unexpected",
            "hit": true
          },
          {
            "score": 0.7268860340118408,
            "answer": "assumed",
            "hit": false
          },
          {
            "score": 0.726805567741394,
            "answer": "hoped",
            "hit": false
          },
          {
            "score": 0.7254353165626526,
            "answer": "projected",
            "hit": false
          },
          {
            "score": 0.723395586013794,
            "answer": "estimated",
            "hit": false
          }
        ],
        "set_exclude": [
          "expected"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7275907099246979
      },
      {
        "question verbose": "What is to finished ",
        "b": "finished",
        "expected answer": [
          "unfinished"
        ],
        "predictions": [
          {
            "score": 0.738858699798584,
            "answer": "unfinished",
            "hit": true
          },
          {
            "score": 0.627787172794342,
            "answer": "assembled",
            "hit": false
          },
          {
            "score": 0.6246034502983093,
            "answer": "finishing",
            "hit": false
          },
          {
            "score": 0.6193822622299194,
            "answer": "incomplete",
            "hit": false
          },
          {
            "score": 0.6164596080780029,
            "answer": "still",
            "hit": false
          },
          {
            "score": 0.6157100200653076,
            "answer": "bare",
            "hit": false
          }
        ],
        "set_exclude": [
          "finished"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7388586699962616
      },
      {
        "question verbose": "What is to fortunate ",
        "b": "fortunate",
        "expected answer": [
          "unfortunate"
        ],
        "predictions": [
          {
            "score": 0.7988824844360352,
            "answer": "unfortunate",
            "hit": true
          },
          {
            "score": 0.7080819010734558,
            "answer": "privileged",
            "hit": false
          },
          {
            "score": 0.7048541307449341,
            "answer": "foolish",
            "hit": false
          },
          {
            "score": 0.6962878704071045,
            "answer": "unsuccessful",
            "hit": false
          },
          {
            "score": 0.6962074637413025,
            "answer": "thankful",
            "hit": false
          },
          {
            "score": 0.6891528367996216,
            "answer": "unhappy",
            "hit": false
          }
        ],
        "set_exclude": [
          "fortunate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7988824844360352
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "unhappy"
        ],
        "predictions": [
          {
            "score": 0.687595009803772,
            "answer": "hope",
            "hit": false
          },
          {
            "score": 0.6734273433685303,
            "answer": "amazing",
            "hit": false
          },
          {
            "score": 0.6729413270950317,
            "answer": "thank",
            "hit": false
          },
          {
            "score": 0.6707155704498291,
            "answer": "sad",
            "hit": false
          },
          {
            "score": 0.6697383522987366,
            "answer": "welcome",
            "hit": false
          },
          {
            "score": 0.6617306470870972,
            "answer": "sweet",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6589647233486176
      },
      {
        "question verbose": "What is to identified ",
        "b": "identified",
        "expected answer": [
          "unidentified"
        ],
        "predictions": [
          {
            "score": 0.7830461263656616,
            "answer": "identify",
            "hit": false
          },
          {
            "score": 0.779454231262207,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.7600017189979553,
            "answer": "identifiable",
            "hit": false
          },
          {
            "score": 0.754218578338623,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7366350889205933,
            "answer": "unidentified",
            "hit": true
          },
          {
            "score": 0.731404185295105,
            "answer": "described",
            "hit": false
          }
        ],
        "set_exclude": [
          "identified"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7366351038217545
      },
      {
        "question verbose": "What is to known ",
        "b": "known",
        "expected answer": [
          "unknown"
        ],
        "predictions": [
          {
            "score": 0.7274621725082397,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.6978731751441956,
            "answer": "commonly",
            "hit": false
          },
          {
            "score": 0.6937658190727234,
            "answer": "infamous",
            "hit": false
          },
          {
            "score": 0.6917020082473755,
            "answer": "dubbed",
            "hit": false
          },
          {
            "score": 0.6871426105499268,
            "answer": "renowned",
            "hit": false
          },
          {
            "score": 0.6845821142196655,
            "answer": "suspected",
            "hit": false
          }
        ],
        "set_exclude": [
          "known"
        ],
        "rank": 567,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5963189229369164
      },
      {
        "question verbose": "What is to lawful ",
        "b": "lawful",
        "expected answer": [
          "unlawful"
        ],
        "predictions": [
          {
            "score": 0.8396816849708557,
            "answer": "unlawful",
            "hit": true
          },
          {
            "score": 0.7634238004684448,
            "answer": "illegal",
            "hit": false
          },
          {
            "score": 0.727887749671936,
            "answer": "legitimate",
            "hit": false
          },
          {
            "score": 0.7196176052093506,
            "answer": "unauthorized",
            "hit": false
          },
          {
            "score": 0.7180837392807007,
            "answer": "improper",
            "hit": false
          },
          {
            "score": 0.7094259262084961,
            "answer": "unconstitutional",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8396817147731781
      },
      {
        "question verbose": "What is to paid ",
        "b": "paid",
        "expected answer": [
          "unpaid"
        ],
        "predictions": [
          {
            "score": 0.7191213965415955,
            "answer": "unpaid",
            "hit": true
          },
          {
            "score": 0.6683564186096191,
            "answer": "payments",
            "hit": false
          },
          {
            "score": 0.6460780501365662,
            "answer": "pays",
            "hit": false
          },
          {
            "score": 0.6368495225906372,
            "answer": "fees",
            "hit": false
          },
          {
            "score": 0.6366584300994873,
            "answer": "earn",
            "hit": false
          },
          {
            "score": 0.6352104544639587,
            "answer": "pricing",
            "hit": false
          }
        ],
        "set_exclude": [
          "paid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7191213816404343
      },
      {
        "question verbose": "What is to pleasant ",
        "b": "pleasant",
        "expected answer": [
          "unpleasant"
        ],
        "predictions": [
          {
            "score": 0.7259775400161743,
            "answer": "unpleasant",
            "hit": true
          },
          {
            "score": 0.6428340077400208,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.6394152641296387,
            "answer": "discomfort",
            "hit": false
          },
          {
            "score": 0.6384485363960266,
            "answer": "quiet",
            "hit": false
          },
          {
            "score": 0.6376442909240723,
            "answer": "uncomfortable",
            "hit": false
          },
          {
            "score": 0.6344298124313354,
            "answer": "negative",
            "hit": false
          }
        ],
        "set_exclude": [
          "pleasant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7259775847196579
      },
      {
        "question verbose": "What is to popular ",
        "b": "popular",
        "expected answer": [
          "unpopular"
        ],
        "predictions": [
          {
            "score": 0.7798241972923279,
            "answer": "unpopular",
            "hit": true
          },
          {
            "score": 0.7339553833007812,
            "answer": "controversial",
            "hit": false
          },
          {
            "score": 0.729488730430603,
            "answer": "widely",
            "hit": false
          },
          {
            "score": 0.7268843650817871,
            "answer": "popularity",
            "hit": false
          },
          {
            "score": 0.7181841135025024,
            "answer": "influential",
            "hit": false
          },
          {
            "score": 0.7154377698898315,
            "answer": "beloved",
            "hit": false
          }
        ],
        "set_exclude": [
          "popular"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7798241972923279
      },
      {
        "question verbose": "What is to predictable ",
        "b": "predictable",
        "expected answer": [
          "unpredictable"
        ],
        "predictions": [
          {
            "score": 0.7991169691085815,
            "answer": "unpredictable",
            "hit": true
          },
          {
            "score": 0.7434053421020508,
            "answer": "unexpected",
            "hit": false
          },
          {
            "score": 0.7137532234191895,
            "answer": "inevitable",
            "hit": false
          },
          {
            "score": 0.708953320980072,
            "answer": "unpleasant",
            "hit": false
          },
          {
            "score": 0.7058769464492798,
            "answer": "unreliable",
            "hit": false
          },
          {
            "score": 0.7013723850250244,
            "answer": "repetitive",
            "hit": false
          }
        ],
        "set_exclude": [
          "predictable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7991169691085815
      },
      {
        "question verbose": "What is to published ",
        "b": "published",
        "expected answer": [
          "unpublished"
        ],
        "predictions": [
          {
            "score": 0.658991813659668,
            "answer": "unpublished",
            "hit": true
          },
          {
            "score": 0.6461955904960632,
            "answer": "editor",
            "hit": false
          },
          {
            "score": 0.644905686378479,
            "answer": "publish",
            "hit": false
          },
          {
            "score": 0.6392479538917542,
            "answer": "publications",
            "hit": false
          },
          {
            "score": 0.6329025030136108,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.6293595433235168,
            "answer": "unknown",
            "hit": false
          }
        ],
        "set_exclude": [
          "published"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6589917838573456
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "unreasonable"
        ],
        "predictions": [
          {
            "score": 0.8112194538116455,
            "answer": "unreasonable",
            "hit": true
          },
          {
            "score": 0.7997102737426758,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.7828648090362549,
            "answer": "sensible",
            "hit": false
          },
          {
            "score": 0.766156017780304,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.7506103515625,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.7493108510971069,
            "answer": "decent",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8112194538116455
      },
      {
        "question verbose": "What is to related ",
        "b": "related",
        "expected answer": [
          "unrelated"
        ],
        "predictions": [
          {
            "score": 0.806043267250061,
            "answer": "unrelated",
            "hit": true
          },
          {
            "score": 0.7711707949638367,
            "answer": "relating",
            "hit": false
          },
          {
            "score": 0.7152122259140015,
            "answer": "pertaining",
            "hit": false
          },
          {
            "score": 0.7043525576591492,
            "answer": "relevant",
            "hit": false
          },
          {
            "score": 0.7005391716957092,
            "answer": "affiliated",
            "hit": false
          },
          {
            "score": 0.6888737678527832,
            "answer": "arising",
            "hit": false
          }
        ],
        "set_exclude": [
          "related"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.806043267250061
      },
      {
        "question verbose": "What is to reliable ",
        "b": "reliable",
        "expected answer": [
          "unreliable"
        ],
        "predictions": [
          {
            "score": 0.8549669981002808,
            "answer": "unreliable",
            "hit": true
          },
          {
            "score": 0.7581034898757935,
            "answer": "credible",
            "hit": false
          },
          {
            "score": 0.7561919689178467,
            "answer": "accurate",
            "hit": false
          },
          {
            "score": 0.750870943069458,
            "answer": "reliability",
            "hit": false
          },
          {
            "score": 0.7249928712844849,
            "answer": "unpredictable",
            "hit": false
          },
          {
            "score": 0.722893238067627,
            "answer": "inaccurate",
            "hit": false
          }
        ],
        "set_exclude": [
          "reliable"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8549669682979584
      },
      {
        "question verbose": "What is to specified ",
        "b": "specified",
        "expected answer": [
          "unspecified"
        ],
        "predictions": [
          {
            "score": 0.6802634596824646,
            "answer": "unspecified",
            "hit": true
          },
          {
            "score": 0.6316916942596436,
            "answer": "documented",
            "hit": false
          },
          {
            "score": 0.6263728141784668,
            "answer": "contained",
            "hit": false
          },
          {
            "score": 0.6247990727424622,
            "answer": "restricted",
            "hit": false
          },
          {
            "score": 0.6219824552536011,
            "answer": "specify",
            "hit": false
          },
          {
            "score": 0.6199188232421875,
            "answer": "usually",
            "hit": false
          }
        ],
        "set_exclude": [
          "specified"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6802634745836258
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "unsuccessful"
        ],
        "predictions": [
          {
            "score": 0.874482274055481,
            "answer": "unsuccessful",
            "hit": true
          },
          {
            "score": 0.7547854781150818,
            "answer": "successfully",
            "hit": false
          },
          {
            "score": 0.7396117448806763,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.738314151763916,
            "answer": "ineffective",
            "hit": false
          },
          {
            "score": 0.7226836085319519,
            "answer": "failed",
            "hit": false
          },
          {
            "score": 0.7092946767807007,
            "answer": "failure",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8744823336601257
      },
      {
        "question verbose": "What is to used ",
        "b": "used",
        "expected answer": [
          "unused"
        ],
        "predictions": [
          {
            "score": 0.6440833806991577,
            "answer": "unused",
            "hit": true
          },
          {
            "score": 0.6353943347930908,
            "answer": "played",
            "hit": false
          },
          {
            "score": 0.6258895397186279,
            "answer": "worn",
            "hit": false
          },
          {
            "score": 0.6210023760795593,
            "answer": "abused",
            "hit": false
          },
          {
            "score": 0.6172890663146973,
            "answer": "opened",
            "hit": false
          },
          {
            "score": 0.6167187690734863,
            "answer": "assembled",
            "hit": false
          }
        ],
        "set_exclude": [
          "used"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6440833508968353
      },
      {
        "question verbose": "What is to usual ",
        "b": "usual",
        "expected answer": [
          "unusual"
        ],
        "predictions": [
          {
            "score": 0.7673051953315735,
            "answer": "customary",
            "hit": false
          },
          {
            "score": 0.7379609942436218,
            "answer": "typical",
            "hit": false
          },
          {
            "score": 0.7015982270240784,
            "answer": "inevitable",
            "hit": false
          },
          {
            "score": 0.7006053328514099,
            "answer": "unusual",
            "hit": true
          },
          {
            "score": 0.697124719619751,
            "answer": "normally",
            "hit": false
          },
          {
            "score": 0.6927213668823242,
            "answer": "unexpected",
            "hit": false
          }
        ],
        "set_exclude": [
          "usual"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7006053328514099
      },
      {
        "question verbose": "What is to wanted ",
        "b": "wanted",
        "expected answer": [
          "unwanted"
        ],
        "predictions": [
          {
            "score": 0.7857497334480286,
            "answer": "wants",
            "hit": false
          },
          {
            "score": 0.7580265998840332,
            "answer": "wished",
            "hit": false
          },
          {
            "score": 0.7309442758560181,
            "answer": "needed",
            "hit": false
          },
          {
            "score": 0.7309339046478271,
            "answer": "hated",
            "hit": false
          },
          {
            "score": 0.7216635942459106,
            "answer": "wanting",
            "hit": false
          },
          {
            "score": 0.718747615814209,
            "answer": "sought",
            "hit": false
          }
        ],
        "set_exclude": [
          "wanted"
        ],
        "rank": 39,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6686154156923294
      }
    ],
    "result": {
      "cnt_questions_correct": 21,
      "cnt_questions_total": 30,
      "accuracy": 0.7
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D02 [un+adj_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "602626f1-2391-442c-91d5-30c77bf30bb6",
      "timestamp": "2025-05-17T17:15:34.020992"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to according ",
        "b": "according",
        "expected answer": [
          "accordingly"
        ],
        "predictions": [
          {
            "score": 0.7967250943183899,
            "answer": "apparently",
            "hit": false
          },
          {
            "score": 0.7834492921829224,
            "answer": "despite",
            "hit": false
          },
          {
            "score": 0.7620751857757568,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.7612184882164001,
            "answer": "the",
            "hit": false
          },
          {
            "score": 0.7611575722694397,
            "answer": "furthermore",
            "hit": false
          },
          {
            "score": 0.7388651371002197,
            "answer": "moreover",
            "hit": false
          }
        ],
        "set_exclude": [
          "according"
        ],
        "rank": 171,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6078832000494003
      },
      {
        "question verbose": "What is to actual ",
        "b": "actual",
        "expected answer": [
          "actually"
        ],
        "predictions": [
          {
            "score": 0.7108378410339355,
            "answer": "genuinely",
            "hit": false
          },
          {
            "score": 0.7080672383308411,
            "answer": "exact",
            "hit": false
          },
          {
            "score": 0.7007450461387634,
            "answer": "truly",
            "hit": false
          },
          {
            "score": 0.7003121376037598,
            "answer": "incredibly",
            "hit": false
          },
          {
            "score": 0.7000986337661743,
            "answer": "entire",
            "hit": false
          },
          {
            "score": 0.6989123821258545,
            "answer": "fully",
            "hit": false
          }
        ],
        "set_exclude": [
          "actual"
        ],
        "rank": 1019,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5937733501195908
      },
      {
        "question verbose": "What is to additional ",
        "b": "additional",
        "expected answer": [
          "additionally"
        ],
        "predictions": [
          {
            "score": 0.754392147064209,
            "answer": "additionally",
            "hit": true
          },
          {
            "score": 0.7072280049324036,
            "answer": "significantly",
            "hit": false
          },
          {
            "score": 0.7058852314949036,
            "answer": "potentially",
            "hit": false
          },
          {
            "score": 0.7053747177124023,
            "answer": "added",
            "hit": false
          },
          {
            "score": 0.7017027139663696,
            "answer": "other",
            "hit": false
          },
          {
            "score": 0.7016151547431946,
            "answer": "exceptionally",
            "hit": false
          }
        ],
        "set_exclude": [
          "additional"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.754392147064209
      },
      {
        "question verbose": "What is to apparent ",
        "b": "apparent",
        "expected answer": [
          "apparently"
        ],
        "predictions": [
          {
            "score": 0.799247682094574,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.7756879329681396,
            "answer": "obvious",
            "hit": false
          },
          {
            "score": 0.7355774641036987,
            "answer": "seemingly",
            "hit": false
          },
          {
            "score": 0.7248818874359131,
            "answer": "seeming",
            "hit": false
          },
          {
            "score": 0.7213327884674072,
            "answer": "noticeable",
            "hit": false
          },
          {
            "score": 0.7181546688079834,
            "answer": "evidently",
            "hit": false
          }
        ],
        "set_exclude": [
          "apparent"
        ],
        "rank": 7427,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5344549044966698
      },
      {
        "question verbose": "What is to beautiful ",
        "b": "beautiful",
        "expected answer": [
          "beautifully"
        ],
        "predictions": [
          {
            "score": 0.883525013923645,
            "answer": "gorgeous",
            "hit": false
          },
          {
            "score": 0.8459300398826599,
            "answer": "lovely",
            "hit": false
          },
          {
            "score": 0.8443418741226196,
            "answer": "beautifully",
            "hit": true
          },
          {
            "score": 0.8203675746917725,
            "answer": "wonderful",
            "hit": false
          },
          {
            "score": 0.8172464966773987,
            "answer": "magnificent",
            "hit": false
          },
          {
            "score": 0.7861437797546387,
            "answer": "delightful",
            "hit": false
          }
        ],
        "set_exclude": [
          "beautiful"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8443418741226196
      },
      {
        "question verbose": "What is to critical ",
        "b": "critical",
        "expected answer": [
          "critically"
        ],
        "predictions": [
          {
            "score": 0.7163835763931274,
            "answer": "critically",
            "hit": true
          },
          {
            "score": 0.6683741211891174,
            "answer": "crucial",
            "hit": false
          },
          {
            "score": 0.6508110761642456,
            "answer": "intensive",
            "hit": false
          },
          {
            "score": 0.6479396820068359,
            "answer": "highly",
            "hit": false
          },
          {
            "score": 0.6427739262580872,
            "answer": "sensitive",
            "hit": false
          },
          {
            "score": 0.6401655077934265,
            "answer": "important",
            "hit": false
          }
        ],
        "set_exclude": [
          "critical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7163836359977722
      },
      {
        "question verbose": "What is to cultural ",
        "b": "cultural",
        "expected answer": [
          "culturally"
        ],
        "predictions": [
          {
            "score": 0.8576066493988037,
            "answer": "culturally",
            "hit": true
          },
          {
            "score": 0.8002724647521973,
            "answer": "culture",
            "hit": false
          },
          {
            "score": 0.7639732956886292,
            "answer": "societal",
            "hit": false
          },
          {
            "score": 0.74753737449646,
            "answer": "socio",
            "hit": false
          },
          {
            "score": 0.7394348978996277,
            "answer": "socially",
            "hit": false
          },
          {
            "score": 0.731127142906189,
            "answer": "cultures",
            "hit": false
          }
        ],
        "set_exclude": [
          "cultural"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8576065897941589
      },
      {
        "question verbose": "What is to decided ",
        "b": "decided",
        "expected answer": [
          "decidedly"
        ],
        "predictions": [
          {
            "score": 0.8069586157798767,
            "answer": "decides",
            "hit": false
          },
          {
            "score": 0.7851890921592712,
            "answer": "opted",
            "hit": false
          },
          {
            "score": 0.7845199108123779,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.7774794101715088,
            "answer": "chose",
            "hit": false
          },
          {
            "score": 0.747550368309021,
            "answer": "determined",
            "hit": false
          },
          {
            "score": 0.7301701307296753,
            "answer": "concluded",
            "hit": false
          }
        ],
        "set_exclude": [
          "decided"
        ],
        "rank": 429,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6414247453212738
      },
      {
        "question verbose": "What is to different ",
        "b": "different",
        "expected answer": [
          "differently"
        ],
        "predictions": [
          {
            "score": 0.7268093824386597,
            "answer": "differently",
            "hit": true
          },
          {
            "score": 0.6686758995056152,
            "answer": "differentiated",
            "hit": false
          },
          {
            "score": 0.6583409905433655,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.6566582918167114,
            "answer": "differing",
            "hit": false
          },
          {
            "score": 0.6534751653671265,
            "answer": "radically",
            "hit": false
          },
          {
            "score": 0.6534360647201538,
            "answer": "uniquely",
            "hit": false
          }
        ],
        "set_exclude": [
          "different"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7268093675374985
      },
      {
        "question verbose": "What is to digital ",
        "b": "digital",
        "expected answer": [
          "digitally"
        ],
        "predictions": [
          {
            "score": 0.846435546875,
            "answer": "digitally",
            "hit": true
          },
          {
            "score": 0.736242413520813,
            "answer": "electronically",
            "hit": false
          },
          {
            "score": 0.7316281795501709,
            "answer": "computer",
            "hit": false
          },
          {
            "score": 0.6990361213684082,
            "answer": "technological",
            "hit": false
          },
          {
            "score": 0.6985664367675781,
            "answer": "broadband",
            "hit": false
          },
          {
            "score": 0.6959869265556335,
            "answer": "smartphone",
            "hit": false
          }
        ],
        "set_exclude": [
          "digital"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.846435546875
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectively"
        ],
        "predictions": [
          {
            "score": 0.6675670146942139,
            "answer": "effectively",
            "hit": true
          },
          {
            "score": 0.6597543358802795,
            "answer": "simply",
            "hit": false
          },
          {
            "score": 0.6365036964416504,
            "answer": "effect",
            "hit": false
          },
          {
            "score": 0.6362030506134033,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.6338961124420166,
            "answer": "using",
            "hit": false
          },
          {
            "score": 0.6309151649475098,
            "answer": "recently",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6675670444965363
      },
      {
        "question verbose": "What is to environmental ",
        "b": "environmental",
        "expected answer": [
          "environmentally"
        ],
        "predictions": [
          {
            "score": 0.7368712425231934,
            "answer": "epa",
            "hit": false
          },
          {
            "score": 0.7020479440689087,
            "answer": "environmentally",
            "hit": true
          },
          {
            "score": 0.6840176582336426,
            "answer": "agriculture",
            "hit": false
          },
          {
            "score": 0.6798653602600098,
            "answer": "energy",
            "hit": false
          },
          {
            "score": 0.6742034554481506,
            "answer": "transportation",
            "hit": false
          },
          {
            "score": 0.6691329479217529,
            "answer": "ecological",
            "hit": false
          }
        ],
        "set_exclude": [
          "environmental"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7020479738712311
      },
      {
        "question verbose": "What is to extensive ",
        "b": "extensive",
        "expected answer": [
          "extensively"
        ],
        "predictions": [
          {
            "score": 0.8039529323577881,
            "answer": "extensively",
            "hit": true
          },
          {
            "score": 0.7821394205093384,
            "answer": "lengthy",
            "hit": false
          },
          {
            "score": 0.7724561095237732,
            "answer": "considerable",
            "hit": false
          },
          {
            "score": 0.7720734477043152,
            "answer": "expansive",
            "hit": false
          },
          {
            "score": 0.7665743827819824,
            "answer": "substantial",
            "hit": false
          },
          {
            "score": 0.7476334571838379,
            "answer": "heavily",
            "hit": false
          }
        ],
        "set_exclude": [
          "extensive"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8039529919624329
      },
      {
        "question verbose": "What is to famous ",
        "b": "famous",
        "expected answer": [
          "famously"
        ],
        "predictions": [
          {
            "score": 0.6913107633590698,
            "answer": "famously",
            "hit": true
          },
          {
            "score": 0.6651607751846313,
            "answer": "famed",
            "hit": false
          },
          {
            "score": 0.66199791431427,
            "answer": "infamous",
            "hit": false
          },
          {
            "score": 0.6596083641052246,
            "answer": "renowned",
            "hit": false
          },
          {
            "score": 0.6567204594612122,
            "answer": "notorious",
            "hit": false
          },
          {
            "score": 0.6314417719841003,
            "answer": "proclaimed",
            "hit": false
          }
        ],
        "set_exclude": [
          "famous"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6913107931613922
      },
      {
        "question verbose": "What is to financial ",
        "b": "financial",
        "expected answer": [
          "financially"
        ],
        "predictions": [
          {
            "score": 0.7134149670600891,
            "answer": "financially",
            "hit": true
          },
          {
            "score": 0.696068525314331,
            "answer": "cash",
            "hit": false
          },
          {
            "score": 0.6796104311943054,
            "answer": "invest",
            "hit": false
          },
          {
            "score": 0.6721795201301575,
            "answer": "companies",
            "hit": false
          },
          {
            "score": 0.665025532245636,
            "answer": "drug",
            "hit": false
          },
          {
            "score": 0.6609659194946289,
            "answer": "pay",
            "hit": false
          }
        ],
        "set_exclude": [
          "financial"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7134149670600891
      },
      {
        "question verbose": "What is to global ",
        "b": "global",
        "expected answer": [
          "globally"
        ],
        "predictions": [
          {
            "score": 0.8678827285766602,
            "answer": "globally",
            "hit": true
          },
          {
            "score": 0.8057498931884766,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.7385685443878174,
            "answer": "internationally",
            "hit": false
          },
          {
            "score": 0.6962364315986633,
            "answer": "rapidly",
            "hit": false
          },
          {
            "score": 0.694728434085846,
            "answer": "hugely",
            "hit": false
          },
          {
            "score": 0.6922011375427246,
            "answer": "widely",
            "hit": false
          }
        ],
        "set_exclude": [
          "global"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8678827583789825
      },
      {
        "question verbose": "What is to historical ",
        "b": "historical",
        "expected answer": [
          "historically"
        ],
        "predictions": [
          {
            "score": 0.7218201160430908,
            "answer": "history",
            "hit": false
          },
          {
            "score": 0.7088196277618408,
            "answer": "historically",
            "hit": true
          },
          {
            "score": 0.6860066652297974,
            "answer": "historic",
            "hit": false
          },
          {
            "score": 0.6742794513702393,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.6632331609725952,
            "answer": "historians",
            "hit": false
          },
          {
            "score": 0.6551170349121094,
            "answer": "medieval",
            "hit": false
          }
        ],
        "set_exclude": [
          "historical"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7088195979595184
      },
      {
        "question verbose": "What is to huge ",
        "b": "huge",
        "expected answer": [
          "hugely"
        ],
        "predictions": [
          {
            "score": 0.8810421228408813,
            "answer": "massive",
            "hit": false
          },
          {
            "score": 0.8530657887458801,
            "answer": "enormous",
            "hit": false
          },
          {
            "score": 0.8454673886299133,
            "answer": "gigantic",
            "hit": false
          },
          {
            "score": 0.8242411613464355,
            "answer": "hugely",
            "hit": true
          },
          {
            "score": 0.8028587698936462,
            "answer": "tremendous",
            "hit": false
          },
          {
            "score": 0.7874950766563416,
            "answer": "immense",
            "hit": false
          }
        ],
        "set_exclude": [
          "huge"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8242412209510803
      },
      {
        "question verbose": "What is to immediate ",
        "b": "immediate",
        "expected answer": [
          "immediately"
        ],
        "predictions": [
          {
            "score": 0.796538233757019,
            "answer": "immediately",
            "hit": true
          },
          {
            "score": 0.7344774603843689,
            "answer": "instantly",
            "hit": false
          },
          {
            "score": 0.7106383442878723,
            "answer": "quickly",
            "hit": false
          },
          {
            "score": 0.7101514339447021,
            "answer": "imminent",
            "hit": false
          },
          {
            "score": 0.7027176022529602,
            "answer": "urgent",
            "hit": false
          },
          {
            "score": 0.6996064186096191,
            "answer": "rapidly",
            "hit": false
          }
        ],
        "set_exclude": [
          "immediate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7965382933616638
      },
      {
        "question verbose": "What is to important ",
        "b": "important",
        "expected answer": [
          "importantly"
        ],
        "predictions": [
          {
            "score": 0.6770615577697754,
            "answer": "crucial",
            "hit": false
          },
          {
            "score": 0.6482576727867126,
            "answer": "extremely",
            "hit": false
          },
          {
            "score": 0.6402521729469299,
            "answer": "irrelevant",
            "hit": false
          },
          {
            "score": 0.6390255689620972,
            "answer": "mattered",
            "hit": false
          },
          {
            "score": 0.6367374658584595,
            "answer": "necessary",
            "hit": false
          },
          {
            "score": 0.6363579630851746,
            "answer": "highly",
            "hit": false
          }
        ],
        "set_exclude": [
          "important"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6356752216815948
      },
      {
        "question verbose": "What is to increasing ",
        "b": "increasing",
        "expected answer": [
          "increasingly"
        ],
        "predictions": [
          {
            "score": 0.7217557430267334,
            "answer": "increasingly",
            "hit": true
          },
          {
            "score": 0.7068480253219604,
            "answer": "decreasing",
            "hit": false
          },
          {
            "score": 0.686090350151062,
            "answer": "progressively",
            "hit": false
          },
          {
            "score": 0.6843101978302002,
            "answer": "steadily",
            "hit": false
          },
          {
            "score": 0.6734880805015564,
            "answer": "extremely",
            "hit": false
          },
          {
            "score": 0.6700505018234253,
            "answer": "gradually",
            "hit": false
          }
        ],
        "set_exclude": [
          "increasing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7217557728290558
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "internally"
        ],
        "predictions": [
          {
            "score": 0.707434356212616,
            "answer": "internally",
            "hit": true
          },
          {
            "score": 0.6728269457817078,
            "answer": "externally",
            "hit": false
          },
          {
            "score": 0.645544707775116,
            "answer": "external",
            "hit": false
          },
          {
            "score": 0.6255571842193604,
            "answer": "intern",
            "hit": false
          },
          {
            "score": 0.611167311668396,
            "answer": "intra",
            "hit": false
          },
          {
            "score": 0.6111412048339844,
            "answer": "fundamentally",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.707434356212616
      },
      {
        "question verbose": "What is to international ",
        "b": "international",
        "expected answer": [
          "internationally"
        ],
        "predictions": [
          {
            "score": 0.7344549894332886,
            "answer": "internationally",
            "hit": true
          },
          {
            "score": 0.6779441237449646,
            "answer": "globally",
            "hit": false
          },
          {
            "score": 0.6695106029510498,
            "answer": "national",
            "hit": false
          },
          {
            "score": 0.6497208476066589,
            "answer": "intern",
            "hit": false
          },
          {
            "score": 0.647727906703949,
            "answer": "worldwide",
            "hit": false
          },
          {
            "score": 0.6432304382324219,
            "answer": "overseas",
            "hit": false
          }
        ],
        "set_exclude": [
          "international"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7344549596309662
      },
      {
        "question verbose": "What is to legal ",
        "b": "legal",
        "expected answer": [
          "legally"
        ],
        "predictions": [
          {
            "score": 0.7285808324813843,
            "answer": "legally",
            "hit": true
          },
          {
            "score": 0.6593297123908997,
            "answer": "criminal",
            "hit": false
          },
          {
            "score": 0.656832218170166,
            "answer": "illegally",
            "hit": false
          },
          {
            "score": 0.6499459743499756,
            "answer": "illegal",
            "hit": false
          },
          {
            "score": 0.6421133279800415,
            "answer": "lawyers",
            "hit": false
          },
          {
            "score": 0.6345359086990356,
            "answer": "technically",
            "hit": false
          }
        ],
        "set_exclude": [
          "legal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7285808622837067
      },
      {
        "question verbose": "What is to mental ",
        "b": "mental",
        "expected answer": [
          "mentally"
        ],
        "predictions": [
          {
            "score": 0.736748456954956,
            "answer": "psychiatric",
            "hit": false
          },
          {
            "score": 0.7227652668952942,
            "answer": "mentally",
            "hit": true
          },
          {
            "score": 0.70319002866745,
            "answer": "psychology",
            "hit": false
          },
          {
            "score": 0.6798632740974426,
            "answer": "cognitive",
            "hit": false
          },
          {
            "score": 0.6633354425430298,
            "answer": "psychiatrist",
            "hit": false
          },
          {
            "score": 0.6617419123649597,
            "answer": "disability",
            "hit": false
          }
        ],
        "set_exclude": [
          "mental"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7227652370929718
      },
      {
        "question verbose": "What is to nice ",
        "b": "nice",
        "expected answer": [
          "nicely"
        ],
        "predictions": [
          {
            "score": 0.6478211879730225,
            "answer": "nicely",
            "hit": true
          },
          {
            "score": 0.6265119314193726,
            "answer": "surprisingly",
            "hit": false
          },
          {
            "score": 0.6227626800537109,
            "answer": "mostly",
            "hit": false
          },
          {
            "score": 0.6138719916343689,
            "answer": "maybe",
            "hit": false
          },
          {
            "score": 0.6129525303840637,
            "answer": "quite",
            "hit": false
          },
          {
            "score": 0.6111722588539124,
            "answer": "especially",
            "hit": false
          }
        ],
        "set_exclude": [
          "nice"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6478211730718613
      },
      {
        "question verbose": "What is to obvious ",
        "b": "obvious",
        "expected answer": [
          "obviously"
        ],
        "predictions": [
          {
            "score": 0.772438645362854,
            "answer": "apparent",
            "hit": false
          },
          {
            "score": 0.7577482461929321,
            "answer": "evident",
            "hit": false
          },
          {
            "score": 0.7399357557296753,
            "answer": "glaring",
            "hit": false
          },
          {
            "score": 0.7324728965759277,
            "answer": "plainly",
            "hit": false
          },
          {
            "score": 0.7270710468292236,
            "answer": "straightforward",
            "hit": false
          },
          {
            "score": 0.7188078165054321,
            "answer": "readily",
            "hit": false
          }
        ],
        "set_exclude": [
          "obvious"
        ],
        "rank": 4426,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5584791265428066
      },
      {
        "question verbose": "What is to physical ",
        "b": "physical",
        "expected answer": [
          "physically"
        ],
        "predictions": [
          {
            "score": 0.7300005555152893,
            "answer": "physically",
            "hit": true
          },
          {
            "score": 0.6427515745162964,
            "answer": "cognitive",
            "hit": false
          },
          {
            "score": 0.6426597833633423,
            "answer": "mental",
            "hit": false
          },
          {
            "score": 0.6413648128509521,
            "answer": "magical",
            "hit": false
          },
          {
            "score": 0.6349594593048096,
            "answer": "normal",
            "hit": false
          },
          {
            "score": 0.6328262090682983,
            "answer": "psychiatric",
            "hit": false
          }
        ],
        "set_exclude": [
          "physical"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7300005853176117
      },
      {
        "question verbose": "What is to political ",
        "b": "political",
        "expected answer": [
          "politically"
        ],
        "predictions": [
          {
            "score": 0.7537404894828796,
            "answer": "politically",
            "hit": true
          },
          {
            "score": 0.7041000127792358,
            "answer": "politics",
            "hit": false
          },
          {
            "score": 0.67848801612854,
            "answer": "economic",
            "hit": false
          },
          {
            "score": 0.6556737422943115,
            "answer": "election",
            "hit": false
          },
          {
            "score": 0.6547402143478394,
            "answer": "politicians",
            "hit": false
          },
          {
            "score": 0.6454428434371948,
            "answer": "civil",
            "hit": false
          }
        ],
        "set_exclude": [
          "political"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.753740519285202
      },
      {
        "question verbose": "What is to practical ",
        "b": "practical",
        "expected answer": [
          "practically"
        ],
        "predictions": [
          {
            "score": 0.7466493844985962,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.731167733669281,
            "answer": "realistic",
            "hit": false
          },
          {
            "score": 0.72041916847229,
            "answer": "economical",
            "hit": false
          },
          {
            "score": 0.7187376022338867,
            "answer": "commercially",
            "hit": false
          },
          {
            "score": 0.714635968208313,
            "answer": "theoretical",
            "hit": false
          },
          {
            "score": 0.7143673896789551,
            "answer": "useful",
            "hit": false
          }
        ],
        "set_exclude": [
          "practical"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7082416713237762
      },
      {
        "question verbose": "What is to previous ",
        "b": "previous",
        "expected answer": [
          "previously"
        ],
        "predictions": [
          {
            "score": 0.7172250747680664,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.6736063957214355,
            "answer": "recently",
            "hit": false
          },
          {
            "score": 0.6703967452049255,
            "answer": "previously",
            "hit": true
          },
          {
            "score": 0.6663949489593506,
            "answer": "recent",
            "hit": false
          },
          {
            "score": 0.6504344344139099,
            "answer": "compared",
            "hit": false
          },
          {
            "score": 0.6495056748390198,
            "answer": "similar",
            "hit": false
          }
        ],
        "set_exclude": [
          "previous"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6703967154026031
      },
      {
        "question verbose": "What is to rare ",
        "b": "rare",
        "expected answer": [
          "rarely"
        ],
        "predictions": [
          {
            "score": 0.759066641330719,
            "answer": "uncommon",
            "hit": false
          },
          {
            "score": 0.6911126375198364,
            "answer": "rarely",
            "hit": true
          },
          {
            "score": 0.6832591891288757,
            "answer": "often",
            "hit": false
          },
          {
            "score": 0.6752747893333435,
            "answer": "common",
            "hit": false
          },
          {
            "score": 0.6738981008529663,
            "answer": "legendary",
            "hit": false
          },
          {
            "score": 0.6454734802246094,
            "answer": "myth",
            "hit": false
          }
        ],
        "set_exclude": [
          "rare"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6911126375198364
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriously"
        ],
        "predictions": [
          {
            "score": 0.6412933468818665,
            "answer": "dangerous",
            "hit": false
          },
          {
            "score": 0.6320332288742065,
            "answer": "totally",
            "hit": false
          },
          {
            "score": 0.6291665434837341,
            "answer": "badly",
            "hit": false
          },
          {
            "score": 0.6291000843048096,
            "answer": "genuinely",
            "hit": false
          },
          {
            "score": 0.6283406019210815,
            "answer": "profoundly",
            "hit": false
          },
          {
            "score": 0.6272497773170471,
            "answer": "severely",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 71,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5945104360580444
      },
      {
        "question verbose": "What is to sexual ",
        "b": "sexual",
        "expected answer": [
          "sexually"
        ],
        "predictions": [
          {
            "score": 0.8768293261528015,
            "answer": "sexually",
            "hit": true
          },
          {
            "score": 0.8111629486083984,
            "answer": "sexuality",
            "hit": false
          },
          {
            "score": 0.7650137543678284,
            "answer": "homosexual",
            "hit": false
          },
          {
            "score": 0.7542554140090942,
            "answer": "erotic",
            "hit": false
          },
          {
            "score": 0.7427201271057129,
            "answer": "homosexuality",
            "hit": false
          },
          {
            "score": 0.7296298742294312,
            "answer": "heterosexual",
            "hit": false
          }
        ],
        "set_exclude": [
          "sexual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8768293559551239
      },
      {
        "question verbose": "What is to significant ",
        "b": "significant",
        "expected answer": [
          "significantly"
        ],
        "predictions": [
          {
            "score": 0.6962932348251343,
            "answer": "significantly",
            "hit": true
          },
          {
            "score": 0.694983720779419,
            "answer": "historically",
            "hit": false
          },
          {
            "score": 0.6812246441841125,
            "answer": "numerous",
            "hit": false
          },
          {
            "score": 0.6776642799377441,
            "answer": "nearly",
            "hit": false
          },
          {
            "score": 0.6607869863510132,
            "answer": "clearly",
            "hit": false
          },
          {
            "score": 0.6587787866592407,
            "answer": "increased",
            "hit": false
          }
        ],
        "set_exclude": [
          "significant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6962932348251343
      },
      {
        "question verbose": "What is to similar ",
        "b": "similar",
        "expected answer": [
          "similarly"
        ],
        "predictions": [
          {
            "score": 0.7737371921539307,
            "answer": "similarly",
            "hit": true
          },
          {
            "score": 0.6993423700332642,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.6962633728981018,
            "answer": "perhaps",
            "hit": false
          },
          {
            "score": 0.6939730644226074,
            "answer": "earlier",
            "hit": false
          },
          {
            "score": 0.6891390085220337,
            "answer": "compared",
            "hit": false
          },
          {
            "score": 0.6888134479522705,
            "answer": "despite",
            "hit": false
          }
        ],
        "set_exclude": [
          "similar"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7737372517585754
      },
      {
        "question verbose": "What is to strong ",
        "b": "strong",
        "expected answer": [
          "strongly"
        ],
        "predictions": [
          {
            "score": 0.6855419278144836,
            "answer": "weak",
            "hit": false
          },
          {
            "score": 0.6754692196846008,
            "answer": "very",
            "hit": false
          },
          {
            "score": 0.6621814370155334,
            "answer": "stronger",
            "hit": false
          },
          {
            "score": 0.6603872179985046,
            "answer": "despite",
            "hit": false
          },
          {
            "score": 0.6536415815353394,
            "answer": "strongly",
            "hit": true
          },
          {
            "score": 0.6533632874488831,
            "answer": "strength",
            "hit": false
          }
        ],
        "set_exclude": [
          "strong"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6536415815353394
      },
      {
        "question verbose": "What is to subsequent ",
        "b": "subsequent",
        "expected answer": [
          "subsequently"
        ],
        "predictions": [
          {
            "score": 0.8394383788108826,
            "answer": "subsequently",
            "hit": true
          },
          {
            "score": 0.7887882590293884,
            "answer": "ensuing",
            "hit": false
          },
          {
            "score": 0.78456711769104,
            "answer": "later",
            "hit": false
          },
          {
            "score": 0.7434903383255005,
            "answer": "thereafter",
            "hit": false
          },
          {
            "score": 0.7396955490112305,
            "answer": "successive",
            "hit": false
          },
          {
            "score": 0.7302082777023315,
            "answer": "resultant",
            "hit": false
          }
        ],
        "set_exclude": [
          "subsequent"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8394384384155273
      },
      {
        "question verbose": "What is to successful ",
        "b": "successful",
        "expected answer": [
          "successfully"
        ],
        "predictions": [
          {
            "score": 0.8272119760513306,
            "answer": "successfully",
            "hit": true
          },
          {
            "score": 0.8195464015007019,
            "answer": "unsuccessful",
            "hit": false
          },
          {
            "score": 0.7280802130699158,
            "answer": "succeed",
            "hit": false
          },
          {
            "score": 0.7273242473602295,
            "answer": "profitable",
            "hit": false
          },
          {
            "score": 0.723161518573761,
            "answer": "successes",
            "hit": false
          },
          {
            "score": 0.7217249870300293,
            "answer": "prosperous",
            "hit": false
          }
        ],
        "set_exclude": [
          "successful"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8272119760513306
      },
      {
        "question verbose": "What is to traditional ",
        "b": "traditional",
        "expected answer": [
          "traditionally"
        ],
        "predictions": [
          {
            "score": 0.692172110080719,
            "answer": "modern",
            "hit": false
          },
          {
            "score": 0.6829558610916138,
            "answer": "simply",
            "hit": false
          },
          {
            "score": 0.6759007573127747,
            "answer": "traditionally",
            "hit": true
          },
          {
            "score": 0.6732540130615234,
            "answer": "classic",
            "hit": false
          },
          {
            "score": 0.667011559009552,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.6606851816177368,
            "answer": "historically",
            "hit": false
          }
        ],
        "set_exclude": [
          "traditional"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6759007573127747
      },
      {
        "question verbose": "What is to typical ",
        "b": "typical",
        "expected answer": [
          "typically"
        ],
        "predictions": [
          {
            "score": 0.7457120418548584,
            "answer": "commonly",
            "hit": false
          },
          {
            "score": 0.745206892490387,
            "answer": "usual",
            "hit": false
          },
          {
            "score": 0.7410075068473816,
            "answer": "normally",
            "hit": false
          },
          {
            "score": 0.7295984029769897,
            "answer": "characteristic",
            "hit": false
          },
          {
            "score": 0.7288033366203308,
            "answer": "generally",
            "hit": false
          },
          {
            "score": 0.7257245779037476,
            "answer": "relatively",
            "hit": false
          }
        ],
        "set_exclude": [
          "typical"
        ],
        "rank": 1152,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5951818078756332
      },
      {
        "question verbose": "What is to unique ",
        "b": "unique",
        "expected answer": [
          "uniquely"
        ],
        "predictions": [
          {
            "score": 0.8693817853927612,
            "answer": "uniquely",
            "hit": true
          },
          {
            "score": 0.7925558686256409,
            "answer": "distinctive",
            "hit": false
          },
          {
            "score": 0.7758578062057495,
            "answer": "distinct",
            "hit": false
          },
          {
            "score": 0.7581385970115662,
            "answer": "peculiar",
            "hit": false
          },
          {
            "score": 0.754045844078064,
            "answer": "unusual",
            "hit": false
          },
          {
            "score": 0.7355368733406067,
            "answer": "innovative",
            "hit": false
          }
        ],
        "set_exclude": [
          "unique"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8693817853927612
      },
      {
        "question verbose": "What is to virtual ",
        "b": "virtual",
        "expected answer": [
          "virtually"
        ],
        "predictions": [
          {
            "score": 0.6476047039031982,
            "answer": "digitally",
            "hit": false
          },
          {
            "score": 0.6281739473342896,
            "answer": "physically",
            "hit": false
          },
          {
            "score": 0.6212326288223267,
            "answer": "remote",
            "hit": false
          },
          {
            "score": 0.6183251142501831,
            "answer": "effectively",
            "hit": false
          },
          {
            "score": 0.6163182854652405,
            "answer": "activate",
            "hit": false
          },
          {
            "score": 0.6135640740394592,
            "answer": "mostly",
            "hit": false
          }
        ],
        "set_exclude": [
          "virtual"
        ],
        "rank": 184,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5722266435623169
      },
      {
        "question verbose": "What is to visual ",
        "b": "visual",
        "expected answer": [
          "visually"
        ],
        "predictions": [
          {
            "score": 0.732021152973175,
            "answer": "visually",
            "hit": true
          },
          {
            "score": 0.6483395099639893,
            "answer": "digitally",
            "hit": false
          },
          {
            "score": 0.6408499479293823,
            "answer": "creative",
            "hit": false
          },
          {
            "score": 0.6373396515846252,
            "answer": "vis",
            "hit": false
          },
          {
            "score": 0.635995090007782,
            "answer": "graphical",
            "hit": false
          },
          {
            "score": 0.6297121644020081,
            "answer": "cognitive",
            "hit": false
          }
        ],
        "set_exclude": [
          "visual"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.732021152973175
      }
    ],
    "result": {
      "cnt_questions_correct": 25,
      "cnt_questions_total": 44,
      "accuracy": 0.5681818181818182
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D03 [adj+ly_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "75da649a-56db-4d98-9cdf-f827b8b16fc1",
      "timestamp": "2025-05-17T17:15:34.125290"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aware ",
        "b": "aware",
        "expected answer": [
          "awareness"
        ],
        "predictions": [
          {
            "score": 0.7564479112625122,
            "answer": "unaware",
            "hit": false
          },
          {
            "score": 0.7110379934310913,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.7081307172775269,
            "answer": "wary",
            "hit": false
          },
          {
            "score": 0.7050349712371826,
            "answer": "confident",
            "hit": false
          },
          {
            "score": 0.7024115920066833,
            "answer": "noticing",
            "hit": false
          },
          {
            "score": 0.6961378455162048,
            "answer": "able",
            "hit": false
          }
        ],
        "set_exclude": [
          "aware"
        ],
        "rank": 1719,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6036394387483597
      },
      {
        "question verbose": "What is to conscious ",
        "b": "conscious",
        "expected answer": [
          "consciousness"
        ],
        "predictions": [
          {
            "score": 0.7492175102233887,
            "answer": "consciousness",
            "hit": true
          },
          {
            "score": 0.7311164140701294,
            "answer": "awareness",
            "hit": false
          },
          {
            "score": 0.6602992415428162,
            "answer": "unconscious",
            "hit": false
          },
          {
            "score": 0.656817615032196,
            "answer": "consciously",
            "hit": false
          },
          {
            "score": 0.6499297022819519,
            "answer": "significance",
            "hit": false
          },
          {
            "score": 0.6387844085693359,
            "answer": "importance",
            "hit": false
          }
        ],
        "set_exclude": [
          "conscious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7492174953222275
      },
      {
        "question verbose": "What is to effective ",
        "b": "effective",
        "expected answer": [
          "effectiveness"
        ],
        "predictions": [
          {
            "score": 0.6804684400558472,
            "answer": "effectiveness",
            "hit": true
          },
          {
            "score": 0.6374526619911194,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.6288405656814575,
            "answer": "efficacy",
            "hit": false
          },
          {
            "score": 0.6261393427848816,
            "answer": "efficiency",
            "hit": false
          },
          {
            "score": 0.6236277222633362,
            "answer": "clarity",
            "hit": false
          },
          {
            "score": 0.6203187108039856,
            "answer": "effect",
            "hit": false
          }
        ],
        "set_exclude": [
          "effective"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6804684400558472
      },
      {
        "question verbose": "What is to happy ",
        "b": "happy",
        "expected answer": [
          "happiness"
        ],
        "predictions": [
          {
            "score": 0.726569414138794,
            "answer": "happiness",
            "hit": true
          },
          {
            "score": 0.6729433536529541,
            "answer": "hope",
            "hit": false
          },
          {
            "score": 0.6665992736816406,
            "answer": "sadness",
            "hit": false
          },
          {
            "score": 0.6450768113136292,
            "answer": "gratitude",
            "hit": false
          },
          {
            "score": 0.6430667638778687,
            "answer": "thank",
            "hit": false
          },
          {
            "score": 0.639613151550293,
            "answer": "celebration",
            "hit": false
          }
        ],
        "set_exclude": [
          "happy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7265693992376328
      },
      {
        "question verbose": "What is to mad ",
        "b": "mad",
        "expected answer": [
          "madness"
        ],
        "predictions": [
          {
            "score": 0.6499446630477905,
            "answer": "insanity",
            "hit": false
          },
          {
            "score": 0.633041262626648,
            "answer": "agony",
            "hit": false
          },
          {
            "score": 0.6322346925735474,
            "answer": "seriousness",
            "hit": false
          },
          {
            "score": 0.6297442317008972,
            "answer": "sadness",
            "hit": false
          },
          {
            "score": 0.6247789859771729,
            "answer": "consciousness",
            "hit": false
          },
          {
            "score": 0.6235333681106567,
            "answer": "blindness",
            "hit": false
          }
        ],
        "set_exclude": [
          "mad"
        ],
        "rank": 127,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.580196313560009
      },
      {
        "question verbose": "What is to sad ",
        "b": "sad",
        "expected answer": [
          "sadness"
        ],
        "predictions": [
          {
            "score": 0.7365419864654541,
            "answer": "sadness",
            "hit": true
          },
          {
            "score": 0.6735820770263672,
            "answer": "happiness",
            "hit": false
          },
          {
            "score": 0.6549796462059021,
            "answer": "misery",
            "hit": false
          },
          {
            "score": 0.6518457531929016,
            "answer": "anguish",
            "hit": false
          },
          {
            "score": 0.6459760665893555,
            "answer": "sorrow",
            "hit": false
          },
          {
            "score": 0.6458636522293091,
            "answer": "insanity",
            "hit": false
          }
        ],
        "set_exclude": [
          "sad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7365419864654541
      },
      {
        "question verbose": "What is to serious ",
        "b": "serious",
        "expected answer": [
          "seriousness"
        ],
        "predictions": [
          {
            "score": 0.6881228089332581,
            "answer": "seriousness",
            "hit": true
          },
          {
            "score": 0.6322194933891296,
            "answer": "mental",
            "hit": false
          },
          {
            "score": 0.631549060344696,
            "answer": "effectiveness",
            "hit": false
          },
          {
            "score": 0.6303122043609619,
            "answer": "severity",
            "hit": false
          },
          {
            "score": 0.630300760269165,
            "answer": "real",
            "hit": false
          },
          {
            "score": 0.6299912929534912,
            "answer": "credibility",
            "hit": false
          }
        ],
        "set_exclude": [
          "serious"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6881228387355804
      },
      {
        "question verbose": "What is to weak ",
        "b": "weak",
        "expected answer": [
          "weakness"
        ],
        "predictions": [
          {
            "score": 0.7486797571182251,
            "answer": "weakness",
            "hit": true
          },
          {
            "score": 0.6993523240089417,
            "answer": "weaknesses",
            "hit": false
          },
          {
            "score": 0.6620044112205505,
            "answer": "weaker",
            "hit": false
          },
          {
            "score": 0.6598116159439087,
            "answer": "strength",
            "hit": false
          },
          {
            "score": 0.6515694856643677,
            "answer": "strong",
            "hit": false
          },
          {
            "score": 0.6460895538330078,
            "answer": "weakening",
            "hit": false
          }
        ],
        "set_exclude": [
          "weak"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7486797422170639
      }
    ],
    "result": {
      "cnt_questions_correct": 6,
      "cnt_questions_total": 8,
      "accuracy": 0.75
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D05 [adj+ness_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "b97be256-3920-426b-87dd-a18bbbece2ad",
      "timestamp": "2025-05-17T17:15:34.294707"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accept ",
        "b": "accept",
        "expected answer": [
          "acceptable"
        ],
        "predictions": [
          {
            "score": 0.8058910369873047,
            "answer": "accepted",
            "hit": false
          },
          {
            "score": 0.8034836053848267,
            "answer": "accepting",
            "hit": false
          },
          {
            "score": 0.7716410160064697,
            "answer": "accepts",
            "hit": false
          },
          {
            "score": 0.7554904222488403,
            "answer": "acceptable",
            "hit": true
          },
          {
            "score": 0.755290150642395,
            "answer": "acceptance",
            "hit": false
          },
          {
            "score": 0.7098314166069031,
            "answer": "reject",
            "hit": false
          }
        ],
        "set_exclude": [
          "accept"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7554904520511627
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustable"
        ],
        "predictions": [
          {
            "score": 0.7331951260566711,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.7015915513038635,
            "answer": "adjustable",
            "hit": true
          },
          {
            "score": 0.6859048008918762,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.6783260703086853,
            "answer": "adjustment",
            "hit": false
          },
          {
            "score": 0.6575332283973694,
            "answer": "setting",
            "hit": false
          },
          {
            "score": 0.6570676565170288,
            "answer": "offset",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7015915513038635
      },
      {
        "question verbose": "What is to afford ",
        "b": "afford",
        "expected answer": [
          "affordable"
        ],
        "predictions": [
          {
            "score": 0.7541011571884155,
            "answer": "affordable",
            "hit": true
          },
          {
            "score": 0.7228065133094788,
            "answer": "inexpensive",
            "hit": false
          },
          {
            "score": 0.7124738693237305,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.7121102809906006,
            "answer": "afforded",
            "hit": false
          },
          {
            "score": 0.7051220536231995,
            "answer": "reliable",
            "hit": false
          },
          {
            "score": 0.703892707824707,
            "answer": "adequate",
            "hit": false
          }
        ],
        "set_exclude": [
          "afford"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7541012167930603
      },
      {
        "question verbose": "What is to consider ",
        "b": "consider",
        "expected answer": [
          "considerable"
        ],
        "predictions": [
          {
            "score": 0.6495412588119507,
            "answer": "increasing",
            "hit": false
          },
          {
            "score": 0.6403934955596924,
            "answer": "thinking",
            "hit": false
          },
          {
            "score": 0.6391115188598633,
            "answer": "considering",
            "hit": false
          },
          {
            "score": 0.638974130153656,
            "answer": "sufficient",
            "hit": false
          },
          {
            "score": 0.6353222131729126,
            "answer": "particularly",
            "hit": false
          },
          {
            "score": 0.6326628923416138,
            "answer": "considerable",
            "hit": true
          }
        ],
        "set_exclude": [
          "consider"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6326629519462585
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyable"
        ],
        "predictions": [
          {
            "score": 0.6961584091186523,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.6944943070411682,
            "answer": "enjoyable",
            "hit": true
          },
          {
            "score": 0.6683846116065979,
            "answer": "enjoyed",
            "hit": false
          },
          {
            "score": 0.6502507328987122,
            "answer": "enjoyment",
            "hit": false
          },
          {
            "score": 0.6492799520492554,
            "answer": "enjoys",
            "hit": false
          },
          {
            "score": 0.6411683559417725,
            "answer": "delightful",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6944943219423294
      },
      {
        "question verbose": "What is to identify ",
        "b": "identify",
        "expected answer": [
          "identifiable"
        ],
        "predictions": [
          {
            "score": 0.8452314138412476,
            "answer": "identifying",
            "hit": false
          },
          {
            "score": 0.8075152039527893,
            "answer": "identified",
            "hit": false
          },
          {
            "score": 0.771165668964386,
            "answer": "identifiable",
            "hit": true
          },
          {
            "score": 0.762776255607605,
            "answer": "identification",
            "hit": false
          },
          {
            "score": 0.7618471384048462,
            "answer": "identifies",
            "hit": false
          },
          {
            "score": 0.7245751619338989,
            "answer": "distinctive",
            "hit": false
          }
        ],
        "set_exclude": [
          "identify"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7711656093597412
      },
      {
        "question verbose": "What is to predict ",
        "b": "predict",
        "expected answer": [
          "predictable"
        ],
        "predictions": [
          {
            "score": 0.7979528903961182,
            "answer": "predicting",
            "hit": false
          },
          {
            "score": 0.7810162901878357,
            "answer": "predicted",
            "hit": false
          },
          {
            "score": 0.7665021419525146,
            "answer": "prediction",
            "hit": false
          },
          {
            "score": 0.7471098899841309,
            "answer": "predictions",
            "hit": false
          },
          {
            "score": 0.7374920845031738,
            "answer": "predictable",
            "hit": true
          },
          {
            "score": 0.7268221974372864,
            "answer": "reliable",
            "hit": false
          }
        ],
        "set_exclude": [
          "predict"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7374921143054962
      },
      {
        "question verbose": "What is to rely ",
        "b": "rely",
        "expected answer": [
          "reliable"
        ],
        "predictions": [
          {
            "score": 0.6067594289779663,
            "answer": "enjoyable",
            "hit": false
          },
          {
            "score": 0.5990229845046997,
            "answer": "insignificant",
            "hit": false
          },
          {
            "score": 0.596091628074646,
            "answer": "ubiquitous",
            "hit": false
          },
          {
            "score": 0.5941619873046875,
            "answer": "mutually",
            "hit": false
          },
          {
            "score": 0.5934565663337708,
            "answer": "sustainable",
            "hit": false
          },
          {
            "score": 0.5904645919799805,
            "answer": "feasible",
            "hit": false
          }
        ],
        "set_exclude": [
          "rely"
        ],
        "rank": 93,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5701843053102493
      },
      {
        "question verbose": "What is to renew ",
        "b": "renew",
        "expected answer": [
          "renewable"
        ],
        "predictions": [
          {
            "score": 0.7467467188835144,
            "answer": "renewable",
            "hit": true
          },
          {
            "score": 0.7133098840713501,
            "answer": "renewal",
            "hit": false
          },
          {
            "score": 0.6873748302459717,
            "answer": "renewed",
            "hit": false
          },
          {
            "score": 0.6748365759849548,
            "answer": "sustainable",
            "hit": false
          },
          {
            "score": 0.6404751539230347,
            "answer": "environmental",
            "hit": false
          },
          {
            "score": 0.6309188604354858,
            "answer": "energy",
            "hit": false
          }
        ],
        "set_exclude": [
          "renew"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7467467486858368
      },
      {
        "question verbose": "What is to sustain ",
        "b": "sustain",
        "expected answer": [
          "sustainable"
        ],
        "predictions": [
          {
            "score": 0.8114057779312134,
            "answer": "sustaining",
            "hit": false
          },
          {
            "score": 0.775705099105835,
            "answer": "sustainable",
            "hit": true
          },
          {
            "score": 0.7598599791526794,
            "answer": "sustained",
            "hit": false
          },
          {
            "score": 0.728171706199646,
            "answer": "affordable",
            "hit": false
          },
          {
            "score": 0.7257950305938721,
            "answer": "reliable",
            "hit": false
          },
          {
            "score": 0.7126497626304626,
            "answer": "consistent",
            "hit": false
          }
        ],
        "set_exclude": [
          "sustain"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7757051587104797
      },
      {
        "question verbose": "What is to vary ",
        "b": "vary",
        "expected answer": [
          "variable"
        ],
        "predictions": [
          {
            "score": 0.8071127533912659,
            "answer": "varied",
            "hit": false
          },
          {
            "score": 0.8047399520874023,
            "answer": "varies",
            "hit": false
          },
          {
            "score": 0.7906630039215088,
            "answer": "differ",
            "hit": false
          },
          {
            "score": 0.758895993232727,
            "answer": "varying",
            "hit": false
          },
          {
            "score": 0.7138418555259705,
            "answer": "differed",
            "hit": false
          },
          {
            "score": 0.7095504999160767,
            "answer": "differing",
            "hit": false
          }
        ],
        "set_exclude": [
          "vary"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6758979856967926
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 11,
      "accuracy": 0.18181818181818182
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D07 [verb+able_reg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "fbaaac6a-7314-495e-a081-a165700949c5",
      "timestamp": "2025-05-17T17:15:34.320806"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to believe ",
        "b": "believe",
        "expected answer": [
          "believer"
        ],
        "predictions": [
          {
            "score": 0.6432548761367798,
            "answer": "belief",
            "hit": false
          },
          {
            "score": 0.6416616439819336,
            "answer": "absolutely",
            "hit": false
          },
          {
            "score": 0.639697790145874,
            "answer": "everybody",
            "hit": false
          },
          {
            "score": 0.6390565037727356,
            "answer": "almost",
            "hit": false
          },
          {
            "score": 0.6378929018974304,
            "answer": "every",
            "hit": false
          },
          {
            "score": 0.6335815191268921,
            "answer": "actually",
            "hit": false
          }
        ],
        "set_exclude": [
          "believe"
        ],
        "rank": 193,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.590091235935688
      },
      {
        "question verbose": "What is to compose ",
        "b": "compose",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.8098033666610718,
            "answer": "composing",
            "hit": false
          },
          {
            "score": 0.719074010848999,
            "answer": "composed",
            "hit": false
          },
          {
            "score": 0.7029865384101868,
            "answer": "composition",
            "hit": false
          },
          {
            "score": 0.6888540983200073,
            "answer": "composer",
            "hit": true
          },
          {
            "score": 0.6534662246704102,
            "answer": "compositions",
            "hit": false
          },
          {
            "score": 0.6516634821891785,
            "answer": "conductor",
            "hit": false
          }
        ],
        "set_exclude": [
          "compose"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6888540834188461
      },
      {
        "question verbose": "What is to consume ",
        "b": "consume",
        "expected answer": [
          "consumer"
        ],
        "predictions": [
          {
            "score": 0.8038268089294434,
            "answer": "consumed",
            "hit": false
          },
          {
            "score": 0.6863807439804077,
            "answer": "eats",
            "hit": false
          },
          {
            "score": 0.6731274724006653,
            "answer": "eating",
            "hit": false
          },
          {
            "score": 0.6727710962295532,
            "answer": "eaten",
            "hit": false
          },
          {
            "score": 0.6630411744117737,
            "answer": "consumers",
            "hit": false
          },
          {
            "score": 0.6513570547103882,
            "answer": "drank",
            "hit": false
          }
        ],
        "set_exclude": [
          "consume"
        ],
        "rank": 329,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5872808620333672
      },
      {
        "question verbose": "What is to contend ",
        "b": "contend",
        "expected answer": [
          "contender"
        ],
        "predictions": [
          {
            "score": 0.6952238082885742,
            "answer": "contention",
            "hit": false
          },
          {
            "score": 0.670263409614563,
            "answer": "contender",
            "hit": true
          },
          {
            "score": 0.6656419038772583,
            "answer": "argue",
            "hit": false
          },
          {
            "score": 0.6422243714332581,
            "answer": "reckon",
            "hit": false
          },
          {
            "score": 0.6361691951751709,
            "answer": "argued",
            "hit": false
          },
          {
            "score": 0.6354058980941772,
            "answer": "asserts",
            "hit": false
          }
        ],
        "set_exclude": [
          "contend"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6702633798122406
      },
      {
        "question verbose": "What is to defend ",
        "b": "defend",
        "expected answer": [
          "defender"
        ],
        "predictions": [
          {
            "score": 0.8024621605873108,
            "answer": "defending",
            "hit": false
          },
          {
            "score": 0.7823715209960938,
            "answer": "defended",
            "hit": false
          },
          {
            "score": 0.7313857078552246,
            "answer": "defence",
            "hit": false
          },
          {
            "score": 0.7093582153320312,
            "answer": "defensive",
            "hit": false
          },
          {
            "score": 0.6900986433029175,
            "answer": "defenses",
            "hit": false
          },
          {
            "score": 0.6756265759468079,
            "answer": "fight",
            "hit": false
          }
        ],
        "set_exclude": [
          "defend"
        ],
        "rank": 34,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.625185415148735
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "developer"
        ],
        "predictions": [
          {
            "score": 0.7384254336357117,
            "answer": "developer",
            "hit": true
          },
          {
            "score": 0.6849371194839478,
            "answer": "testing",
            "hit": false
          },
          {
            "score": 0.6819158792495728,
            "answer": "design",
            "hit": false
          },
          {
            "score": 0.6708052158355713,
            "answer": "development",
            "hit": false
          },
          {
            "score": 0.6663277745246887,
            "answer": "app",
            "hit": false
          },
          {
            "score": 0.6650173664093018,
            "answer": "invest",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7384254336357117
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examiner"
        ],
        "predictions": [
          {
            "score": 0.8022895455360413,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.7631784677505493,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.7383087873458862,
            "answer": "examines",
            "hit": false
          },
          {
            "score": 0.7160567045211792,
            "answer": "investigate",
            "hit": false
          },
          {
            "score": 0.7098082304000854,
            "answer": "assess",
            "hit": false
          },
          {
            "score": 0.7045339345932007,
            "answer": "analyze",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 181,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5977809652686119
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.6548765897750854,
            "answer": "visit",
            "hit": false
          },
          {
            "score": 0.6498794555664062,
            "answer": "discovery",
            "hit": false
          },
          {
            "score": 0.649416446685791,
            "answer": "explorer",
            "hit": true
          },
          {
            "score": 0.6452785134315491,
            "answer": "unlock",
            "hit": false
          },
          {
            "score": 0.6448839902877808,
            "answer": "highlights",
            "hit": false
          },
          {
            "score": 0.6436724662780762,
            "answer": "overview",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6494164615869522
      },
      {
        "question verbose": "What is to follow ",
        "b": "follow",
        "expected answer": [
          "follower"
        ],
        "predictions": [
          {
            "score": 0.6524372100830078,
            "answer": "follows",
            "hit": false
          },
          {
            "score": 0.6493382453918457,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.637694239616394,
            "answer": "followed",
            "hit": false
          },
          {
            "score": 0.6262034773826599,
            "answer": "follower",
            "hit": true
          },
          {
            "score": 0.6261091232299805,
            "answer": "respect",
            "hit": false
          },
          {
            "score": 0.6235830187797546,
            "answer": "creator",
            "hit": false
          }
        ],
        "set_exclude": [
          "follow"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6262034773826599
      },
      {
        "question verbose": "What is to interpret ",
        "b": "interpret",
        "expected answer": [
          "interpreter"
        ],
        "predictions": [
          {
            "score": 0.6581604480743408,
            "answer": "interpretation",
            "hit": false
          },
          {
            "score": 0.6472254991531372,
            "answer": "interpretations",
            "hit": false
          },
          {
            "score": 0.6209846138954163,
            "answer": "intention",
            "hit": false
          },
          {
            "score": 0.6208872199058533,
            "answer": "interpreting",
            "hit": false
          },
          {
            "score": 0.618756890296936,
            "answer": "orient",
            "hit": false
          },
          {
            "score": 0.6172091364860535,
            "answer": "interpreted",
            "hit": false
          }
        ],
        "set_exclude": [
          "interpret"
        ],
        "rank": 39,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5951684713363647
      },
      {
        "question verbose": "What is to listen ",
        "b": "listen",
        "expected answer": [
          "listener"
        ],
        "predictions": [
          {
            "score": 0.819392204284668,
            "answer": "listening",
            "hit": false
          },
          {
            "score": 0.7969397306442261,
            "answer": "listened",
            "hit": false
          },
          {
            "score": 0.7037562727928162,
            "answer": "hear",
            "hit": false
          },
          {
            "score": 0.6979097127914429,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.6819305419921875,
            "answer": "speaker",
            "hit": false
          },
          {
            "score": 0.6597802639007568,
            "answer": "musician",
            "hit": false
          }
        ],
        "set_exclude": [
          "listen"
        ],
        "rank": 37,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6152520403265953
      },
      {
        "question verbose": "What is to lose ",
        "b": "lose",
        "expected answer": [
          "loser"
        ],
        "predictions": [
          {
            "score": 0.6535596251487732,
            "answer": "winning",
            "hit": false
          },
          {
            "score": 0.6494160890579224,
            "answer": "loses",
            "hit": false
          },
          {
            "score": 0.6446903944015503,
            "answer": "losing",
            "hit": false
          },
          {
            "score": 0.6439799070358276,
            "answer": "gain",
            "hit": false
          },
          {
            "score": 0.6412322521209717,
            "answer": "loser",
            "hit": true
          },
          {
            "score": 0.6397881507873535,
            "answer": "lucky",
            "hit": false
          }
        ],
        "set_exclude": [
          "lose"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6412322819232941
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "manager"
        ],
        "predictions": [
          {
            "score": 0.785997748374939,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7819226980209351,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.6745140552520752,
            "answer": "administrator",
            "hit": false
          },
          {
            "score": 0.6630574464797974,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.6591571569442749,
            "answer": "organizer",
            "hit": false
          },
          {
            "score": 0.6499601602554321,
            "answer": "maintain",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 49,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6161172986030579
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observer"
        ],
        "predictions": [
          {
            "score": 0.8129227161407471,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.7680118680000305,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.751380443572998,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.7199195623397827,
            "answer": "observation",
            "hit": false
          },
          {
            "score": 0.6921430230140686,
            "answer": "observers",
            "hit": false
          },
          {
            "score": 0.6897199153900146,
            "answer": "observations",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 23,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6179514974355698
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organizer"
        ],
        "predictions": [
          {
            "score": 0.8149734139442444,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.794568657875061,
            "answer": "organizer",
            "hit": true
          },
          {
            "score": 0.7776856422424316,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.737783670425415,
            "answer": "organizers",
            "hit": false
          },
          {
            "score": 0.7143236398696899,
            "answer": "organization",
            "hit": false
          },
          {
            "score": 0.7025469541549683,
            "answer": "organizational",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7945687174797058
      },
      {
        "question verbose": "What is to perform ",
        "b": "perform",
        "expected answer": [
          "performer"
        ],
        "predictions": [
          {
            "score": 0.7008851170539856,
            "answer": "performer",
            "hit": true
          },
          {
            "score": 0.679374098777771,
            "answer": "performers",
            "hit": false
          },
          {
            "score": 0.655747652053833,
            "answer": "performance",
            "hit": false
          },
          {
            "score": 0.6425900459289551,
            "answer": "artist",
            "hit": false
          },
          {
            "score": 0.641751766204834,
            "answer": "musical",
            "hit": false
          },
          {
            "score": 0.6389179825782776,
            "answer": "actress",
            "hit": false
          }
        ],
        "set_exclude": [
          "perform"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.700885146856308
      },
      {
        "question verbose": "What is to preach ",
        "b": "preach",
        "expected answer": [
          "preacher"
        ],
        "predictions": [
          {
            "score": 0.8220663070678711,
            "answer": "preaching",
            "hit": false
          },
          {
            "score": 0.762032151222229,
            "answer": "preacher",
            "hit": true
          },
          {
            "score": 0.7341440320014954,
            "answer": "sermon",
            "hit": false
          },
          {
            "score": 0.6895999908447266,
            "answer": "pastor",
            "hit": false
          },
          {
            "score": 0.6796748042106628,
            "answer": "missionary",
            "hit": false
          },
          {
            "score": 0.6777682304382324,
            "answer": "theological",
            "hit": false
          }
        ],
        "set_exclude": [
          "preach"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.762032151222229
      },
      {
        "question verbose": "What is to promote ",
        "b": "promote",
        "expected answer": [
          "promoter"
        ],
        "predictions": [
          {
            "score": 0.8032022714614868,
            "answer": "promoting",
            "hit": false
          },
          {
            "score": 0.7989588379859924,
            "answer": "promotes",
            "hit": false
          },
          {
            "score": 0.7484820485115051,
            "answer": "promoted",
            "hit": false
          },
          {
            "score": 0.7212585806846619,
            "answer": "encourage",
            "hit": false
          },
          {
            "score": 0.7172101736068726,
            "answer": "promoter",
            "hit": true
          },
          {
            "score": 0.6965969204902649,
            "answer": "facilitate",
            "hit": false
          }
        ],
        "set_exclude": [
          "promote"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.717210203409195
      },
      {
        "question verbose": "What is to provide ",
        "b": "provide",
        "expected answer": [
          "provider"
        ],
        "predictions": [
          {
            "score": 0.7692065834999084,
            "answer": "provides",
            "hit": false
          },
          {
            "score": 0.6829050779342651,
            "answer": "provided",
            "hit": false
          },
          {
            "score": 0.6819376945495605,
            "answer": "provider",
            "hit": true
          },
          {
            "score": 0.6743885278701782,
            "answer": "improve",
            "hit": false
          },
          {
            "score": 0.6736514568328857,
            "answer": "allows",
            "hit": false
          },
          {
            "score": 0.6647663116455078,
            "answer": "offer",
            "hit": false
          }
        ],
        "set_exclude": [
          "provide"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6819376647472382
      },
      {
        "question verbose": "What is to publish ",
        "b": "publish",
        "expected answer": [
          "publisher"
        ],
        "predictions": [
          {
            "score": 0.8271704912185669,
            "answer": "publishing",
            "hit": false
          },
          {
            "score": 0.7936437726020813,
            "answer": "publication",
            "hit": false
          },
          {
            "score": 0.7353453636169434,
            "answer": "publishers",
            "hit": false
          },
          {
            "score": 0.6904094219207764,
            "answer": "journalist",
            "hit": false
          },
          {
            "score": 0.6778810620307922,
            "answer": "author",
            "hit": false
          },
          {
            "score": 0.6683139801025391,
            "answer": "manuscript",
            "hit": false
          }
        ],
        "set_exclude": [
          "publish"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6514604985713959
      },
      {
        "question verbose": "What is to receive ",
        "b": "receive",
        "expected answer": [
          "receiver"
        ],
        "predictions": [
          {
            "score": 0.8074742555618286,
            "answer": "receives",
            "hit": false
          },
          {
            "score": 0.793925404548645,
            "answer": "receiving",
            "hit": false
          },
          {
            "score": 0.7218231558799744,
            "answer": "recipient",
            "hit": false
          },
          {
            "score": 0.6796762347221375,
            "answer": "receiver",
            "hit": true
          },
          {
            "score": 0.6780738830566406,
            "answer": "receipt",
            "hit": false
          },
          {
            "score": 0.6596997380256653,
            "answer": "obtain",
            "hit": false
          }
        ],
        "set_exclude": [
          "receive"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6796762645244598
      },
      {
        "question verbose": "What is to speak ",
        "b": "speak",
        "expected answer": [
          "speaker"
        ],
        "predictions": [
          {
            "score": 0.7658296823501587,
            "answer": "speaks",
            "hit": false
          },
          {
            "score": 0.7658161520957947,
            "answer": "spoke",
            "hit": false
          },
          {
            "score": 0.7035529613494873,
            "answer": "speaker",
            "hit": true
          },
          {
            "score": 0.6780924797058105,
            "answer": "speakers",
            "hit": false
          },
          {
            "score": 0.6705924272537231,
            "answer": "talking",
            "hit": false
          },
          {
            "score": 0.6567720174789429,
            "answer": "voice",
            "hit": false
          }
        ],
        "set_exclude": [
          "speak"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7035529762506485
      },
      {
        "question verbose": "What is to teach ",
        "b": "teach",
        "expected answer": [
          "teacher"
        ],
        "predictions": [
          {
            "score": 0.8330515623092651,
            "answer": "teaching",
            "hit": false
          },
          {
            "score": 0.8008260130882263,
            "answer": "taught",
            "hit": false
          },
          {
            "score": 0.7951213121414185,
            "answer": "teaches",
            "hit": false
          },
          {
            "score": 0.7148388028144836,
            "answer": "tutor",
            "hit": false
          },
          {
            "score": 0.7123941779136658,
            "answer": "curriculum",
            "hit": false
          },
          {
            "score": 0.7112324237823486,
            "answer": "classroom",
            "hit": false
          }
        ],
        "set_exclude": [
          "teach"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6924246847629547
      },
      {
        "question verbose": "What is to write ",
        "b": "write",
        "expected answer": [
          "writer"
        ],
        "predictions": [
          {
            "score": 0.6619070768356323,
            "answer": "print",
            "hit": false
          },
          {
            "score": 0.6600596308708191,
            "answer": "editor",
            "hit": false
          },
          {
            "score": 0.6571719646453857,
            "answer": "writer",
            "hit": true
          },
          {
            "score": 0.6505850553512573,
            "answer": "reporter",
            "hit": false
          },
          {
            "score": 0.6466918587684631,
            "answer": "copy",
            "hit": false
          },
          {
            "score": 0.6459102630615234,
            "answer": "readers",
            "hit": false
          }
        ],
        "set_exclude": [
          "write"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6571719497442245
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 24,
      "accuracy": 0.08333333333333333
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D08 [verb+er_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "3b7d0f48-8cb9-4e58-bb51-b9cd2939d2f1",
      "timestamp": "2025-05-17T17:15:34.357753"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accuse ",
        "b": "accuse",
        "expected answer": [
          "accusation"
        ],
        "predictions": [
          {
            "score": 0.810745120048523,
            "answer": "accusing",
            "hit": false
          },
          {
            "score": 0.800035834312439,
            "answer": "accusation",
            "hit": true
          },
          {
            "score": 0.767013430595398,
            "answer": "accused",
            "hit": false
          },
          {
            "score": 0.760773777961731,
            "answer": "accusations",
            "hit": false
          },
          {
            "score": 0.693289041519165,
            "answer": "blaming",
            "hit": false
          },
          {
            "score": 0.6856697797775269,
            "answer": "alleging",
            "hit": false
          }
        ],
        "set_exclude": [
          "accuse"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8000358939170837
      },
      {
        "question verbose": "What is to admire ",
        "b": "admire",
        "expected answer": [
          "admiration"
        ],
        "predictions": [
          {
            "score": 0.7955648899078369,
            "answer": "admiration",
            "hit": true
          },
          {
            "score": 0.7338417172431946,
            "answer": "admired",
            "hit": false
          },
          {
            "score": 0.6987075805664062,
            "answer": "appreciation",
            "hit": false
          },
          {
            "score": 0.6786168217658997,
            "answer": "inspiration",
            "hit": false
          },
          {
            "score": 0.6744710206985474,
            "answer": "praise",
            "hit": false
          },
          {
            "score": 0.6702573895454407,
            "answer": "sympathy",
            "hit": false
          }
        ],
        "set_exclude": [
          "admire"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7955649495124817
      },
      {
        "question verbose": "What is to compute ",
        "b": "compute",
        "expected answer": [
          "computation"
        ],
        "predictions": [
          {
            "score": 0.8044595718383789,
            "answer": "computation",
            "hit": true
          },
          {
            "score": 0.7931292057037354,
            "answer": "computing",
            "hit": false
          },
          {
            "score": 0.7458282709121704,
            "answer": "computational",
            "hit": false
          },
          {
            "score": 0.7147340774536133,
            "answer": "calculation",
            "hit": false
          },
          {
            "score": 0.7117710113525391,
            "answer": "computed",
            "hit": false
          },
          {
            "score": 0.6874703168869019,
            "answer": "processing",
            "hit": false
          }
        ],
        "set_exclude": [
          "compute"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8044595718383789
      },
      {
        "question verbose": "What is to continue ",
        "b": "continue",
        "expected answer": [
          "continuation"
        ],
        "predictions": [
          {
            "score": 0.8259836435317993,
            "answer": "continued",
            "hit": false
          },
          {
            "score": 0.8236119747161865,
            "answer": "continues",
            "hit": false
          },
          {
            "score": 0.8189021348953247,
            "answer": "continuing",
            "hit": false
          },
          {
            "score": 0.7520523071289062,
            "answer": "continuation",
            "hit": true
          },
          {
            "score": 0.7022914886474609,
            "answer": "ongoing",
            "hit": false
          },
          {
            "score": 0.6908794641494751,
            "answer": "persist",
            "hit": false
          }
        ],
        "set_exclude": [
          "continue"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7520523071289062
      },
      {
        "question verbose": "What is to declare ",
        "b": "declare",
        "expected answer": [
          "declaration"
        ],
        "predictions": [
          {
            "score": 0.8354084491729736,
            "answer": "declaration",
            "hit": true
          },
          {
            "score": 0.8109408020973206,
            "answer": "declaring",
            "hit": false
          },
          {
            "score": 0.7979227900505066,
            "answer": "declared",
            "hit": false
          },
          {
            "score": 0.7755325436592102,
            "answer": "declares",
            "hit": false
          },
          {
            "score": 0.6875056624412537,
            "answer": "assertion",
            "hit": false
          },
          {
            "score": 0.6732686161994934,
            "answer": "designation",
            "hit": false
          }
        ],
        "set_exclude": [
          "declare"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8354085087776184
      },
      {
        "question verbose": "What is to determine ",
        "b": "determine",
        "expected answer": [
          "determination"
        ],
        "predictions": [
          {
            "score": 0.819994330406189,
            "answer": "determining",
            "hit": false
          },
          {
            "score": 0.7822990417480469,
            "answer": "determines",
            "hit": false
          },
          {
            "score": 0.7772107124328613,
            "answer": "determination",
            "hit": true
          },
          {
            "score": 0.7604246139526367,
            "answer": "determined",
            "hit": false
          },
          {
            "score": 0.7463489770889282,
            "answer": "decide",
            "hit": false
          },
          {
            "score": 0.7205492854118347,
            "answer": "evaluation",
            "hit": false
          }
        ],
        "set_exclude": [
          "determine"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7772106528282166
      },
      {
        "question verbose": "What is to examine ",
        "b": "examine",
        "expected answer": [
          "examination"
        ],
        "predictions": [
          {
            "score": 0.8146045804023743,
            "answer": "examining",
            "hit": false
          },
          {
            "score": 0.7666720747947693,
            "answer": "examined",
            "hit": false
          },
          {
            "score": 0.7509456872940063,
            "answer": "evaluation",
            "hit": false
          },
          {
            "score": 0.7424365282058716,
            "answer": "investigation",
            "hit": false
          },
          {
            "score": 0.7373639345169067,
            "answer": "examinations",
            "hit": false
          },
          {
            "score": 0.735851526260376,
            "answer": "inspection",
            "hit": false
          }
        ],
        "set_exclude": [
          "examine"
        ],
        "rank": 44,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.658570721745491
      },
      {
        "question verbose": "What is to explore ",
        "b": "explore",
        "expected answer": [
          "exploration"
        ],
        "predictions": [
          {
            "score": 0.675528883934021,
            "answer": "exploration",
            "hit": true
          },
          {
            "score": 0.6664209961891174,
            "answer": "visit",
            "hit": false
          },
          {
            "score": 0.6593977212905884,
            "answer": "discovery",
            "hit": false
          },
          {
            "score": 0.656947910785675,
            "answer": "overview",
            "hit": false
          },
          {
            "score": 0.6528096199035645,
            "answer": "experience",
            "hit": false
          },
          {
            "score": 0.6443605422973633,
            "answer": "exploring",
            "hit": false
          }
        ],
        "set_exclude": [
          "explore"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6755289137363434
      },
      {
        "question verbose": "What is to imagine ",
        "b": "imagine",
        "expected answer": [
          "imagination"
        ],
        "predictions": [
          {
            "score": 0.7251772880554199,
            "answer": "think",
            "hit": false
          },
          {
            "score": 0.6964691877365112,
            "answer": "nobody",
            "hit": false
          },
          {
            "score": 0.6823927760124207,
            "answer": "someone",
            "hit": false
          },
          {
            "score": 0.6796408891677856,
            "answer": "perhaps",
            "hit": false
          },
          {
            "score": 0.6752678155899048,
            "answer": "obviously",
            "hit": false
          },
          {
            "score": 0.6695234775543213,
            "answer": "now",
            "hit": false
          }
        ],
        "set_exclude": [
          "imagine"
        ],
        "rank": 610,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5694638937711716
      },
      {
        "question verbose": "What is to inspire ",
        "b": "inspire",
        "expected answer": [
          "inspiration"
        ],
        "predictions": [
          {
            "score": 0.7828392386436462,
            "answer": "inspiring",
            "hit": false
          },
          {
            "score": 0.7664346694946289,
            "answer": "inspiration",
            "hit": true
          },
          {
            "score": 0.7453147172927856,
            "answer": "inspired",
            "hit": false
          },
          {
            "score": 0.6935851573944092,
            "answer": "admiration",
            "hit": false
          },
          {
            "score": 0.6878665089607239,
            "answer": "encouragement",
            "hit": false
          },
          {
            "score": 0.6868953704833984,
            "answer": "motivation",
            "hit": false
          }
        ],
        "set_exclude": [
          "inspire"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7664346694946289
      },
      {
        "question verbose": "What is to observe ",
        "b": "observe",
        "expected answer": [
          "observation"
        ],
        "predictions": [
          {
            "score": 0.8300868272781372,
            "answer": "observing",
            "hit": false
          },
          {
            "score": 0.7859039306640625,
            "answer": "observation",
            "hit": true
          },
          {
            "score": 0.764228343963623,
            "answer": "observed",
            "hit": false
          },
          {
            "score": 0.754983127117157,
            "answer": "observes",
            "hit": false
          },
          {
            "score": 0.7421151399612427,
            "answer": "observations",
            "hit": false
          },
          {
            "score": 0.6880956292152405,
            "answer": "inspection",
            "hit": false
          }
        ],
        "set_exclude": [
          "observe"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7859039306640625
      },
      {
        "question verbose": "What is to occupy ",
        "b": "occupy",
        "expected answer": [
          "occupation"
        ],
        "predictions": [
          {
            "score": 0.6621878147125244,
            "answer": "activist",
            "hit": false
          },
          {
            "score": 0.6532614231109619,
            "answer": "activism",
            "hit": false
          },
          {
            "score": 0.6477181911468506,
            "answer": "bernie",
            "hit": false
          },
          {
            "score": 0.6472921967506409,
            "answer": "communist",
            "hit": false
          },
          {
            "score": 0.6456702351570129,
            "answer": "protests",
            "hit": false
          },
          {
            "score": 0.6428872346878052,
            "answer": "ngo",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupy"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6238378435373306
      },
      {
        "question verbose": "What is to organize ",
        "b": "organize",
        "expected answer": [
          "organization"
        ],
        "predictions": [
          {
            "score": 0.8402029275894165,
            "answer": "organizing",
            "hit": false
          },
          {
            "score": 0.7806176543235779,
            "answer": "organized",
            "hit": false
          },
          {
            "score": 0.7388274669647217,
            "answer": "organization",
            "hit": true
          },
          {
            "score": 0.7343073487281799,
            "answer": "organizational",
            "hit": false
          },
          {
            "score": 0.7343007922172546,
            "answer": "organizer",
            "hit": false
          },
          {
            "score": 0.7086987495422363,
            "answer": "organizers",
            "hit": false
          }
        ],
        "set_exclude": [
          "organize"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7388274818658829
      },
      {
        "question verbose": "What is to prepare ",
        "b": "prepare",
        "expected answer": [
          "preparation"
        ],
        "predictions": [
          {
            "score": 0.8352360129356384,
            "answer": "preparation",
            "hit": true
          },
          {
            "score": 0.7938167452812195,
            "answer": "preparing",
            "hit": false
          },
          {
            "score": 0.7850838899612427,
            "answer": "prepared",
            "hit": false
          },
          {
            "score": 0.7816038727760315,
            "answer": "prepares",
            "hit": false
          },
          {
            "score": 0.7538192272186279,
            "answer": "preparations",
            "hit": false
          },
          {
            "score": 0.6983996629714966,
            "answer": "readiness",
            "hit": false
          }
        ],
        "set_exclude": [
          "prepare"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8352360129356384
      },
      {
        "question verbose": "What is to restore ",
        "b": "restore",
        "expected answer": [
          "restoration"
        ],
        "predictions": [
          {
            "score": 0.6835140585899353,
            "answer": "restoration",
            "hit": true
          },
          {
            "score": 0.6760497093200684,
            "answer": "restoring",
            "hit": false
          },
          {
            "score": 0.6430384516716003,
            "answer": "administration",
            "hit": false
          },
          {
            "score": 0.6416559219360352,
            "answer": "maintenance",
            "hit": false
          },
          {
            "score": 0.640170693397522,
            "answer": "restored",
            "hit": false
          },
          {
            "score": 0.6362000107765198,
            "answer": "healing",
            "hit": false
          }
        ],
        "set_exclude": [
          "restore"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6835140585899353
      },
      {
        "question verbose": "What is to stabilize ",
        "b": "stabilize",
        "expected answer": [
          "stabilization"
        ],
        "predictions": [
          {
            "score": 0.8301419019699097,
            "answer": "stabilization",
            "hit": true
          },
          {
            "score": 0.8288100361824036,
            "answer": "stabilized",
            "hit": false
          },
          {
            "score": 0.7714918851852417,
            "answer": "stability",
            "hit": false
          },
          {
            "score": 0.733922004699707,
            "answer": "stable",
            "hit": false
          },
          {
            "score": 0.7085475325584412,
            "answer": "instability",
            "hit": false
          },
          {
            "score": 0.6919413805007935,
            "answer": "equilibrium",
            "hit": false
          }
        ],
        "set_exclude": [
          "stabilize"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8301418721675873
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 16,
      "accuracy": 0.4375
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D09 [verb+tion_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "910d9060-de2d-415d-85f9-de72ca114a5c",
      "timestamp": "2025-05-17T17:15:34.437942"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to accomplish ",
        "b": "accomplish",
        "expected answer": [
          "accomplishment"
        ],
        "predictions": [
          {
            "score": 0.7889304161071777,
            "answer": "achieve",
            "hit": false
          },
          {
            "score": 0.7675514817237854,
            "answer": "accomplished",
            "hit": false
          },
          {
            "score": 0.7602649331092834,
            "answer": "accomplishment",
            "hit": true
          },
          {
            "score": 0.702910304069519,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7025512456893921,
            "answer": "accomplishments",
            "hit": false
          },
          {
            "score": 0.686381459236145,
            "answer": "achieved",
            "hit": false
          }
        ],
        "set_exclude": [
          "accomplish"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7602649331092834
      },
      {
        "question verbose": "What is to achieve ",
        "b": "achieve",
        "expected answer": [
          "achievement"
        ],
        "predictions": [
          {
            "score": 0.8201414346694946,
            "answer": "achieving",
            "hit": false
          },
          {
            "score": 0.7958425283432007,
            "answer": "accomplish",
            "hit": false
          },
          {
            "score": 0.7956657409667969,
            "answer": "achieved",
            "hit": false
          },
          {
            "score": 0.747535765171051,
            "answer": "attain",
            "hit": false
          },
          {
            "score": 0.7092484831809998,
            "answer": "accomplishment",
            "hit": false
          },
          {
            "score": 0.704623818397522,
            "answer": "obtain",
            "hit": false
          }
        ],
        "set_exclude": [
          "achieve"
        ],
        "rank": 1203,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5846728533506393
      },
      {
        "question verbose": "What is to adjust ",
        "b": "adjust",
        "expected answer": [
          "adjustment"
        ],
        "predictions": [
          {
            "score": 0.7123528122901917,
            "answer": "adjustment",
            "hit": true
          },
          {
            "score": 0.6999793648719788,
            "answer": "adjustments",
            "hit": false
          },
          {
            "score": 0.6985949277877808,
            "answer": "adjusted",
            "hit": false
          },
          {
            "score": 0.6781112551689148,
            "answer": "setting",
            "hit": false
          },
          {
            "score": 0.672429621219635,
            "answer": "changing",
            "hit": false
          },
          {
            "score": 0.6680691838264465,
            "answer": "offset",
            "hit": false
          }
        ],
        "set_exclude": [
          "adjust"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7123527824878693
      },
      {
        "question verbose": "What is to agree ",
        "b": "agree",
        "expected answer": [
          "agreement"
        ],
        "predictions": [
          {
            "score": 0.6624944806098938,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.6304874420166016,
            "answer": "disagreement",
            "hit": false
          },
          {
            "score": 0.6228091716766357,
            "answer": "disagree",
            "hit": false
          },
          {
            "score": 0.621202826499939,
            "answer": "agreement",
            "hit": true
          },
          {
            "score": 0.6198853850364685,
            "answer": "agrees",
            "hit": false
          },
          {
            "score": 0.6160956025123596,
            "answer": "suggest",
            "hit": false
          }
        ],
        "set_exclude": [
          "agree"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6212027966976166
      },
      {
        "question verbose": "What is to align ",
        "b": "align",
        "expected answer": [
          "alignment"
        ],
        "predictions": [
          {
            "score": 0.85097336769104,
            "answer": "alignment",
            "hit": true
          },
          {
            "score": 0.6963040828704834,
            "answer": "positioning",
            "hit": false
          },
          {
            "score": 0.6825412511825562,
            "answer": "orientation",
            "hit": false
          },
          {
            "score": 0.6641182899475098,
            "answer": "affiliation",
            "hit": false
          },
          {
            "score": 0.6588237881660461,
            "answer": "shifting",
            "hit": false
          },
          {
            "score": 0.6585038304328918,
            "answer": "convergence",
            "hit": false
          }
        ],
        "set_exclude": [
          "align"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8509734272956848
      },
      {
        "question verbose": "What is to amend ",
        "b": "amend",
        "expected answer": [
          "amendment"
        ],
        "predictions": [
          {
            "score": 0.7757449150085449,
            "answer": "amendment",
            "hit": true
          },
          {
            "score": 0.7346231341362,
            "answer": "amended",
            "hit": false
          },
          {
            "score": 0.6805278658866882,
            "answer": "amendments",
            "hit": false
          },
          {
            "score": 0.6650477051734924,
            "answer": "alteration",
            "hit": false
          },
          {
            "score": 0.6578395962715149,
            "answer": "revision",
            "hit": false
          },
          {
            "score": 0.6577311158180237,
            "answer": "modification",
            "hit": false
          }
        ],
        "set_exclude": [
          "amend"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7757449150085449
      },
      {
        "question verbose": "What is to announce ",
        "b": "announce",
        "expected answer": [
          "announcement"
        ],
        "predictions": [
          {
            "score": 0.8499383926391602,
            "answer": "announcement",
            "hit": true
          },
          {
            "score": 0.7971385717391968,
            "answer": "announcing",
            "hit": false
          },
          {
            "score": 0.7859287261962891,
            "answer": "announcements",
            "hit": false
          },
          {
            "score": 0.7801105380058289,
            "answer": "announces",
            "hit": false
          },
          {
            "score": 0.6802787184715271,
            "answer": "notification",
            "hit": false
          },
          {
            "score": 0.6769277453422546,
            "answer": "reveal",
            "hit": false
          }
        ],
        "set_exclude": [
          "announce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8499383330345154
      },
      {
        "question verbose": "What is to appoint ",
        "b": "appoint",
        "expected answer": [
          "appointment"
        ],
        "predictions": [
          {
            "score": 0.7795473337173462,
            "answer": "appointment",
            "hit": true
          },
          {
            "score": 0.736341655254364,
            "answer": "appointments",
            "hit": false
          },
          {
            "score": 0.6909089088439941,
            "answer": "nomination",
            "hit": false
          },
          {
            "score": 0.6833847761154175,
            "answer": "adviser",
            "hit": false
          },
          {
            "score": 0.6791119575500488,
            "answer": "hiring",
            "hit": false
          },
          {
            "score": 0.6781586408615112,
            "answer": "nominations",
            "hit": false
          }
        ],
        "set_exclude": [
          "appoint"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7795473635196686
      },
      {
        "question verbose": "What is to arrange ",
        "b": "arrange",
        "expected answer": [
          "arrangement"
        ],
        "predictions": [
          {
            "score": 0.8198900818824768,
            "answer": "arranging",
            "hit": false
          },
          {
            "score": 0.794243335723877,
            "answer": "arranged",
            "hit": false
          },
          {
            "score": 0.7890499830245972,
            "answer": "arrangement",
            "hit": true
          },
          {
            "score": 0.7507559061050415,
            "answer": "arrangements",
            "hit": false
          },
          {
            "score": 0.7090033888816833,
            "answer": "organize",
            "hit": false
          },
          {
            "score": 0.6749207973480225,
            "answer": "placement",
            "hit": false
          }
        ],
        "set_exclude": [
          "arrange"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7890499830245972
      },
      {
        "question verbose": "What is to assess ",
        "b": "assess",
        "expected answer": [
          "assessment"
        ],
        "predictions": [
          {
            "score": 0.8493943214416504,
            "answer": "assessment",
            "hit": true
          },
          {
            "score": 0.7986293435096741,
            "answer": "assessing",
            "hit": false
          },
          {
            "score": 0.7931131720542908,
            "answer": "assessments",
            "hit": false
          },
          {
            "score": 0.7848329544067383,
            "answer": "assessed",
            "hit": false
          },
          {
            "score": 0.7691430449485779,
            "answer": "evaluation",
            "hit": false
          },
          {
            "score": 0.7397392392158508,
            "answer": "evaluate",
            "hit": false
          }
        ],
        "set_exclude": [
          "assess"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8493943214416504
      },
      {
        "question verbose": "What is to assign ",
        "b": "assign",
        "expected answer": [
          "assignment"
        ],
        "predictions": [
          {
            "score": 0.8017815351486206,
            "answer": "assignment",
            "hit": true
          },
          {
            "score": 0.788021981716156,
            "answer": "assigns",
            "hit": false
          },
          {
            "score": 0.7801810503005981,
            "answer": "assigned",
            "hit": false
          },
          {
            "score": 0.7313183546066284,
            "answer": "assignments",
            "hit": false
          },
          {
            "score": 0.696316123008728,
            "answer": "allocation",
            "hit": false
          },
          {
            "score": 0.6797076463699341,
            "answer": "evaluation",
            "hit": false
          }
        ],
        "set_exclude": [
          "assign"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.801781564950943
      },
      {
        "question verbose": "What is to commit ",
        "b": "commit",
        "expected answer": [
          "commitment"
        ],
        "predictions": [
          {
            "score": 0.7160548567771912,
            "answer": "commitment",
            "hit": true
          },
          {
            "score": 0.6480219960212708,
            "answer": "commitments",
            "hit": false
          },
          {
            "score": 0.6366080045700073,
            "answer": "committing",
            "hit": false
          },
          {
            "score": 0.6324251890182495,
            "answer": "dedication",
            "hit": false
          },
          {
            "score": 0.6286640763282776,
            "answer": "commits",
            "hit": false
          },
          {
            "score": 0.6224879026412964,
            "answer": "committed",
            "hit": false
          }
        ],
        "set_exclude": [
          "commit"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7160548865795135
      },
      {
        "question verbose": "What is to develop ",
        "b": "develop",
        "expected answer": [
          "development"
        ],
        "predictions": [
          {
            "score": 0.70823073387146,
            "answer": "developer",
            "hit": false
          },
          {
            "score": 0.6894251108169556,
            "answer": "development",
            "hit": true
          },
          {
            "score": 0.6884793043136597,
            "answer": "testing",
            "hit": false
          },
          {
            "score": 0.6732262372970581,
            "answer": "design",
            "hit": false
          },
          {
            "score": 0.6662583947181702,
            "answer": "production",
            "hit": false
          },
          {
            "score": 0.6529233455657959,
            "answer": "construction",
            "hit": false
          }
        ],
        "set_exclude": [
          "develop"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.689425140619278
      },
      {
        "question verbose": "What is to disagree ",
        "b": "disagree",
        "expected answer": [
          "disagreement"
        ],
        "predictions": [
          {
            "score": 0.7829188108444214,
            "answer": "disagreed",
            "hit": false
          },
          {
            "score": 0.7741897702217102,
            "answer": "disagreement",
            "hit": true
          },
          {
            "score": 0.693212628364563,
            "answer": "agreeing",
            "hit": false
          },
          {
            "score": 0.6930522918701172,
            "answer": "dispute",
            "hit": false
          },
          {
            "score": 0.6854046583175659,
            "answer": "differing",
            "hit": false
          },
          {
            "score": 0.6817032694816589,
            "answer": "differ",
            "hit": false
          }
        ],
        "set_exclude": [
          "disagree"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7741897702217102
      },
      {
        "question verbose": "What is to encourage ",
        "b": "encourage",
        "expected answer": [
          "encouragement"
        ],
        "predictions": [
          {
            "score": 0.8123824596405029,
            "answer": "discourage",
            "hit": false
          },
          {
            "score": 0.7937708497047424,
            "answer": "encourages",
            "hit": false
          },
          {
            "score": 0.7737736701965332,
            "answer": "encouraged",
            "hit": false
          },
          {
            "score": 0.7461910247802734,
            "answer": "encouragement",
            "hit": true
          },
          {
            "score": 0.7448750734329224,
            "answer": "encouraging",
            "hit": false
          },
          {
            "score": 0.7348989844322205,
            "answer": "promote",
            "hit": false
          }
        ],
        "set_exclude": [
          "encourage"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.746190994977951
      },
      {
        "question verbose": "What is to enforce ",
        "b": "enforce",
        "expected answer": [
          "enforcement"
        ],
        "predictions": [
          {
            "score": 0.808771014213562,
            "answer": "enforcing",
            "hit": false
          },
          {
            "score": 0.7960508465766907,
            "answer": "enforced",
            "hit": false
          },
          {
            "score": 0.710807740688324,
            "answer": "implementation",
            "hit": false
          },
          {
            "score": 0.6941213607788086,
            "answer": "policing",
            "hit": false
          },
          {
            "score": 0.6907409429550171,
            "answer": "compliance",
            "hit": false
          },
          {
            "score": 0.6887447237968445,
            "answer": "obligation",
            "hit": false
          }
        ],
        "set_exclude": [
          "enforce"
        ],
        "rank": 39,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.65312759578228
      },
      {
        "question verbose": "What is to engage ",
        "b": "engage",
        "expected answer": [
          "engagement"
        ],
        "predictions": [
          {
            "score": 0.830642580986023,
            "answer": "engages",
            "hit": false
          },
          {
            "score": 0.8178582191467285,
            "answer": "engaging",
            "hit": false
          },
          {
            "score": 0.8041278123855591,
            "answer": "engagement",
            "hit": true
          },
          {
            "score": 0.7950918674468994,
            "answer": "engaged",
            "hit": false
          },
          {
            "score": 0.7061808109283447,
            "answer": "involvement",
            "hit": false
          },
          {
            "score": 0.6986066699028015,
            "answer": "participate",
            "hit": false
          }
        ],
        "set_exclude": [
          "engage"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8041278719902039
      },
      {
        "question verbose": "What is to enhance ",
        "b": "enhance",
        "expected answer": [
          "enhancement"
        ],
        "predictions": [
          {
            "score": 0.7053364515304565,
            "answer": "enhancement",
            "hit": true
          },
          {
            "score": 0.7021745443344116,
            "answer": "improvement",
            "hit": false
          },
          {
            "score": 0.6735383868217468,
            "answer": "transformation",
            "hit": false
          },
          {
            "score": 0.6638762950897217,
            "answer": "upgrade",
            "hit": false
          },
          {
            "score": 0.6609182357788086,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.660361647605896,
            "answer": "techniques",
            "hit": false
          }
        ],
        "set_exclude": [
          "enhance"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7053364813327789
      },
      {
        "question verbose": "What is to enjoy ",
        "b": "enjoy",
        "expected answer": [
          "enjoyment"
        ],
        "predictions": [
          {
            "score": 0.6671283841133118,
            "answer": "enjoyment",
            "hit": true
          },
          {
            "score": 0.6628893613815308,
            "answer": "enjoying",
            "hit": false
          },
          {
            "score": 0.6604176759719849,
            "answer": "thanks",
            "hit": false
          },
          {
            "score": 0.6559585332870483,
            "answer": "experience",
            "hit": false
          },
          {
            "score": 0.6485203504562378,
            "answer": "entertainment",
            "hit": false
          },
          {
            "score": 0.6441285610198975,
            "answer": "check",
            "hit": false
          }
        ],
        "set_exclude": [
          "enjoy"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.667128399014473
      },
      {
        "question verbose": "What is to entertain ",
        "b": "entertain",
        "expected answer": [
          "entertainment"
        ],
        "predictions": [
          {
            "score": 0.7332804203033447,
            "answer": "entertaining",
            "hit": false
          },
          {
            "score": 0.7187882661819458,
            "answer": "entertained",
            "hit": false
          },
          {
            "score": 0.6847344636917114,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.6794154047966003,
            "answer": "amusement",
            "hit": false
          },
          {
            "score": 0.6734659671783447,
            "answer": "musician",
            "hit": false
          },
          {
            "score": 0.6644243001937866,
            "answer": "performer",
            "hit": false
          }
        ],
        "set_exclude": [
          "entertain"
        ],
        "rank": 37,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6270625293254852
      },
      {
        "question verbose": "What is to establish ",
        "b": "establish",
        "expected answer": [
          "establishment"
        ],
        "predictions": [
          {
            "score": 0.7449219226837158,
            "answer": "establishment",
            "hit": true
          },
          {
            "score": 0.7370579242706299,
            "answer": "established",
            "hit": false
          },
          {
            "score": 0.7198339700698853,
            "answer": "establishing",
            "hit": false
          },
          {
            "score": 0.6395132541656494,
            "answer": "producing",
            "hit": false
          },
          {
            "score": 0.6345283389091492,
            "answer": "education",
            "hit": false
          },
          {
            "score": 0.6325319409370422,
            "answer": "activation",
            "hit": false
          }
        ],
        "set_exclude": [
          "establish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.744921937584877
      },
      {
        "question verbose": "What is to fulfill ",
        "b": "fulfill",
        "expected answer": [
          "fulfillment"
        ],
        "predictions": [
          {
            "score": 0.8004878759384155,
            "answer": "fulfillment",
            "hit": true
          },
          {
            "score": 0.7711897492408752,
            "answer": "fulfilling",
            "hit": false
          },
          {
            "score": 0.7678078413009644,
            "answer": "fulfilled",
            "hit": false
          },
          {
            "score": 0.7356240749359131,
            "answer": "satisfy",
            "hit": false
          },
          {
            "score": 0.6972404718399048,
            "answer": "accomplishment",
            "hit": false
          },
          {
            "score": 0.6877975463867188,
            "answer": "obligation",
            "hit": false
          }
        ],
        "set_exclude": [
          "fulfill"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8004879355430603
      },
      {
        "question verbose": "What is to improve ",
        "b": "improve",
        "expected answer": [
          "improvement"
        ],
        "predictions": [
          {
            "score": 0.741618812084198,
            "answer": "improvement",
            "hit": true
          },
          {
            "score": 0.740656852722168,
            "answer": "improved",
            "hit": false
          },
          {
            "score": 0.7215458154678345,
            "answer": "reduce",
            "hit": false
          },
          {
            "score": 0.6918687224388123,
            "answer": "provide",
            "hit": false
          },
          {
            "score": 0.6834686398506165,
            "answer": "increased",
            "hit": false
          },
          {
            "score": 0.680914044380188,
            "answer": "enhance",
            "hit": false
          }
        ],
        "set_exclude": [
          "improve"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7416188418865204
      },
      {
        "question verbose": "What is to invest ",
        "b": "invest",
        "expected answer": [
          "investment"
        ],
        "predictions": [
          {
            "score": 0.7515490651130676,
            "answer": "investment",
            "hit": true
          },
          {
            "score": 0.719507098197937,
            "answer": "investor",
            "hit": false
          },
          {
            "score": 0.6888970136642456,
            "answer": "financial",
            "hit": false
          },
          {
            "score": 0.6676763296127319,
            "answer": "interest",
            "hit": false
          },
          {
            "score": 0.6676096320152283,
            "answer": "investigations",
            "hit": false
          },
          {
            "score": 0.6623255014419556,
            "answer": "government",
            "hit": false
          }
        ],
        "set_exclude": [
          "invest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7515490055084229
      },
      {
        "question verbose": "What is to involve ",
        "b": "involve",
        "expected answer": [
          "involvement"
        ],
        "predictions": [
          {
            "score": 0.8166684508323669,
            "answer": "involves",
            "hit": false
          },
          {
            "score": 0.7476584315299988,
            "answer": "involving",
            "hit": false
          },
          {
            "score": 0.7335352301597595,
            "answer": "involvement",
            "hit": true
          },
          {
            "score": 0.7019446492195129,
            "answer": "include",
            "hit": false
          },
          {
            "score": 0.6989732980728149,
            "answer": "consist",
            "hit": false
          },
          {
            "score": 0.6841676235198975,
            "answer": "occur",
            "hit": false
          }
        ],
        "set_exclude": [
          "involve"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7335352301597595
      },
      {
        "question verbose": "What is to manage ",
        "b": "manage",
        "expected answer": [
          "management"
        ],
        "predictions": [
          {
            "score": 0.7896886467933655,
            "answer": "managing",
            "hit": false
          },
          {
            "score": 0.7836300730705261,
            "answer": "manages",
            "hit": false
          },
          {
            "score": 0.6688531637191772,
            "answer": "oversee",
            "hit": false
          },
          {
            "score": 0.6640239953994751,
            "answer": "decision",
            "hit": false
          },
          {
            "score": 0.6633763313293457,
            "answer": "managers",
            "hit": false
          },
          {
            "score": 0.6628580689430237,
            "answer": "cope",
            "hit": false
          }
        ],
        "set_exclude": [
          "manage"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6610433459281921
      },
      {
        "question verbose": "What is to punish ",
        "b": "punish",
        "expected answer": [
          "punishment"
        ],
        "predictions": [
          {
            "score": 0.8391544818878174,
            "answer": "punishment",
            "hit": true
          },
          {
            "score": 0.7938419580459595,
            "answer": "punished",
            "hit": false
          },
          {
            "score": 0.7181397676467896,
            "answer": "penalty",
            "hit": false
          },
          {
            "score": 0.7158516645431519,
            "answer": "penal",
            "hit": false
          },
          {
            "score": 0.7087088823318481,
            "answer": "retaliation",
            "hit": false
          },
          {
            "score": 0.7044300436973572,
            "answer": "penalties",
            "hit": false
          }
        ],
        "set_exclude": [
          "punish"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8391544222831726
      },
      {
        "question verbose": "What is to reinforce ",
        "b": "reinforce",
        "expected answer": [
          "reinforcement"
        ],
        "predictions": [
          {
            "score": 0.801310658454895,
            "answer": "reinforcement",
            "hit": true
          },
          {
            "score": 0.7901581525802612,
            "answer": "reinforced",
            "hit": false
          },
          {
            "score": 0.7311866283416748,
            "answer": "strengthen",
            "hit": false
          },
          {
            "score": 0.7076044678688049,
            "answer": "strengthening",
            "hit": false
          },
          {
            "score": 0.6880010366439819,
            "answer": "undermine",
            "hit": false
          },
          {
            "score": 0.680722713470459,
            "answer": "strengthened",
            "hit": false
          }
        ],
        "set_exclude": [
          "reinforce"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8013105690479279
      },
      {
        "question verbose": "What is to replace ",
        "b": "replace",
        "expected answer": [
          "replacement"
        ],
        "predictions": [
          {
            "score": 0.6685466766357422,
            "answer": "replacement",
            "hit": true
          },
          {
            "score": 0.6277713775634766,
            "answer": "replacing",
            "hit": false
          },
          {
            "score": 0.6245153546333313,
            "answer": "repair",
            "hit": false
          },
          {
            "score": 0.621483325958252,
            "answer": "replacements",
            "hit": false
          },
          {
            "score": 0.6102933287620544,
            "answer": "replaced",
            "hit": false
          },
          {
            "score": 0.6080721020698547,
            "answer": "switch",
            "hit": false
          }
        ],
        "set_exclude": [
          "replace"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6685466766357422
      },
      {
        "question verbose": "What is to require ",
        "b": "require",
        "expected answer": [
          "requirement"
        ],
        "predictions": [
          {
            "score": 0.6599576473236084,
            "answer": "required",
            "hit": false
          },
          {
            "score": 0.6377923488616943,
            "answer": "requirement",
            "hit": true
          },
          {
            "score": 0.6194425225257874,
            "answer": "requiring",
            "hit": false
          },
          {
            "score": 0.6181601285934448,
            "answer": "installation",
            "hit": false
          },
          {
            "score": 0.6149335503578186,
            "answer": "necessary",
            "hit": false
          },
          {
            "score": 0.6141349673271179,
            "answer": "requirements",
            "hit": false
          }
        ],
        "set_exclude": [
          "require"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.637792319059372
      }
    ],
    "result": {
      "cnt_questions_correct": 17,
      "cnt_questions_total": 30,
      "accuracy": 0.5666666666666667
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "2_Derivational_morphology",
      "subcategory": "D10 [verb+ment_irreg].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "d636765f-f300-4c4a-a9cc-b35807d25da9",
      "timestamp": "2025-05-17T17:15:34.493227"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to athens ",
        "b": "athens",
        "expected answer": [
          "greece"
        ],
        "predictions": [
          {
            "score": 0.8858876824378967,
            "answer": "greece",
            "hit": true
          },
          {
            "score": 0.7702971696853638,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7436360120773315,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7408437728881836,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.7384512424468994,
            "answer": "bulgaria",
            "hit": false
          },
          {
            "score": 0.7343800067901611,
            "answer": "portugal",
            "hit": false
          }
        ],
        "set_exclude": [
          "athens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8858877420425415
      },
      {
        "question verbose": "What is to baghdad ",
        "b": "baghdad",
        "expected answer": [
          "iraq"
        ],
        "predictions": [
          {
            "score": 0.8149065971374512,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.7753974199295044,
            "answer": "iraq",
            "hit": true
          },
          {
            "score": 0.7693799734115601,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.7634130716323853,
            "answer": "afghanistan",
            "hit": false
          },
          {
            "score": 0.7615728378295898,
            "answer": "iran",
            "hit": false
          },
          {
            "score": 0.7522472143173218,
            "answer": "kuwait",
            "hit": false
          }
        ],
        "set_exclude": [
          "baghdad"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7753974497318268
      },
      {
        "question verbose": "What is to bangkok ",
        "b": "bangkok",
        "expected answer": [
          "thailand"
        ],
        "predictions": [
          {
            "score": 0.9051879644393921,
            "answer": "thailand",
            "hit": true
          },
          {
            "score": 0.8017148971557617,
            "answer": "thai",
            "hit": false
          },
          {
            "score": 0.7880990505218506,
            "answer": "cambodia",
            "hit": false
          },
          {
            "score": 0.7680679559707642,
            "answer": "myanmar",
            "hit": false
          },
          {
            "score": 0.7656971216201782,
            "answer": "indonesia",
            "hit": false
          },
          {
            "score": 0.754998505115509,
            "answer": "singapore",
            "hit": false
          }
        ],
        "set_exclude": [
          "bangkok"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9051879644393921
      },
      {
        "question verbose": "What is to beijing ",
        "b": "beijing",
        "expected answer": [
          "china"
        ],
        "predictions": [
          {
            "score": 0.8207096457481384,
            "answer": "china",
            "hit": true
          },
          {
            "score": 0.8060333728790283,
            "answer": "chinese",
            "hit": false
          },
          {
            "score": 0.7833766341209412,
            "answer": "japan",
            "hit": false
          },
          {
            "score": 0.770187497138977,
            "answer": "taiwan",
            "hit": false
          },
          {
            "score": 0.7571728229522705,
            "answer": "hong",
            "hit": false
          },
          {
            "score": 0.7561653852462769,
            "answer": "thailand",
            "hit": false
          }
        ],
        "set_exclude": [
          "beijing"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8207096755504608
      },
      {
        "question verbose": "What is to berlin ",
        "b": "berlin",
        "expected answer": [
          "germany"
        ],
        "predictions": [
          {
            "score": 0.799078106880188,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7985773086547852,
            "answer": "germany",
            "hit": true
          },
          {
            "score": 0.7742685079574585,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7741908431053162,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.7731958627700806,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.7665691375732422,
            "answer": "belgium",
            "hit": false
          }
        ],
        "set_exclude": [
          "berlin"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7985773384571075
      },
      {
        "question verbose": "What is to bern ",
        "b": "bern",
        "expected answer": [
          "switzerland"
        ],
        "predictions": [
          {
            "score": 0.686265766620636,
            "answer": "switzerland",
            "hit": true
          },
          {
            "score": 0.6722450852394104,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.6664832234382629,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.6650912165641785,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.657829999923706,
            "answer": "bernard",
            "hit": false
          },
          {
            "score": 0.6523762941360474,
            "answer": "argentina",
            "hit": false
          }
        ],
        "set_exclude": [
          "bern"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.686265766620636
      },
      {
        "question verbose": "What is to brussels ",
        "b": "brussels",
        "expected answer": [
          "belgium"
        ],
        "predictions": [
          {
            "score": 0.8430719375610352,
            "answer": "belgium",
            "hit": true
          },
          {
            "score": 0.7917903065681458,
            "answer": "europe",
            "hit": false
          },
          {
            "score": 0.775610089302063,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7715325951576233,
            "answer": "belgian",
            "hit": false
          },
          {
            "score": 0.7526983022689819,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.749641478061676,
            "answer": "greece",
            "hit": false
          }
        ],
        "set_exclude": [
          "brussels"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8430719077587128
      },
      {
        "question verbose": "What is to budapest ",
        "b": "budapest",
        "expected answer": [
          "hungary"
        ],
        "predictions": [
          {
            "score": 0.8991694450378418,
            "answer": "hungary",
            "hit": true
          },
          {
            "score": 0.8221340775489807,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.785076916217804,
            "answer": "austria",
            "hit": false
          },
          {
            "score": 0.7661325931549072,
            "answer": "bulgaria",
            "hit": false
          },
          {
            "score": 0.7625288963317871,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.760312557220459,
            "answer": "romania",
            "hit": false
          }
        ],
        "set_exclude": [
          "budapest"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8991695046424866
      },
      {
        "question verbose": "What is to cairo ",
        "b": "cairo",
        "expected answer": [
          "egypt"
        ],
        "predictions": [
          {
            "score": 0.8752356171607971,
            "answer": "egypt",
            "hit": true
          },
          {
            "score": 0.7918347120285034,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.7612285017967224,
            "answer": "libya",
            "hit": false
          },
          {
            "score": 0.7450360655784607,
            "answer": "morocco",
            "hit": false
          },
          {
            "score": 0.7308406829833984,
            "answer": "ethiopia",
            "hit": false
          },
          {
            "score": 0.7268166542053223,
            "answer": "france",
            "hit": false
          }
        ],
        "set_exclude": [
          "cairo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8752356171607971
      },
      {
        "question verbose": "What is to copenhagen ",
        "b": "copenhagen",
        "expected answer": [
          "denmark"
        ],
        "predictions": [
          {
            "score": 0.8700481653213501,
            "answer": "denmark",
            "hit": true
          },
          {
            "score": 0.8058221340179443,
            "answer": "danish",
            "hit": false
          },
          {
            "score": 0.7906351089477539,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.7886284589767456,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.7636690139770508,
            "answer": "iceland",
            "hit": false
          },
          {
            "score": 0.7519557476043701,
            "answer": "finland",
            "hit": false
          }
        ],
        "set_exclude": [
          "copenhagen"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8700482249259949
      },
      {
        "question verbose": "What is to damascus ",
        "b": "damascus",
        "expected answer": [
          "syria"
        ],
        "predictions": [
          {
            "score": 0.8291096687316895,
            "answer": "syria",
            "hit": true
          },
          {
            "score": 0.7693175077438354,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.7452516555786133,
            "answer": "lebanon",
            "hit": false
          },
          {
            "score": 0.7427001595497131,
            "answer": "egypt",
            "hit": false
          },
          {
            "score": 0.7170403003692627,
            "answer": "libya",
            "hit": false
          },
          {
            "score": 0.7141389846801758,
            "answer": "iran",
            "hit": false
          }
        ],
        "set_exclude": [
          "damascus"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8291096687316895
      },
      {
        "question verbose": "What is to dublin ",
        "b": "dublin",
        "expected answer": [
          "ireland"
        ],
        "predictions": [
          {
            "score": 0.7988880276679993,
            "answer": "ireland",
            "hit": true
          },
          {
            "score": 0.7466453313827515,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.7370052337646484,
            "answer": "cork",
            "hit": false
          },
          {
            "score": 0.7367963790893555,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.735355794429779,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.7351558804512024,
            "answer": "denmark",
            "hit": false
          }
        ],
        "set_exclude": [
          "dublin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7988879978656769
      },
      {
        "question verbose": "What is to helsinki ",
        "b": "helsinki",
        "expected answer": [
          "finland"
        ],
        "predictions": [
          {
            "score": 0.8461846113204956,
            "answer": "finland",
            "hit": true
          },
          {
            "score": 0.788148820400238,
            "answer": "finnish",
            "hit": false
          },
          {
            "score": 0.762307345867157,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.7361240386962891,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.7311967015266418,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.7284287214279175,
            "answer": "hungary",
            "hit": false
          }
        ],
        "set_exclude": [
          "helsinki"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8461846113204956
      },
      {
        "question verbose": "What is to kingston ",
        "b": "kingston",
        "expected answer": [
          "jamaica"
        ],
        "predictions": [
          {
            "score": 0.7364596128463745,
            "answer": "jamaica",
            "hit": true
          },
          {
            "score": 0.6806284189224243,
            "answer": "ontario",
            "hit": false
          },
          {
            "score": 0.6727362871170044,
            "answer": "ghana",
            "hit": false
          },
          {
            "score": 0.6691145896911621,
            "answer": "johnston",
            "hit": false
          },
          {
            "score": 0.6690340638160706,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.6669056415557861,
            "answer": "portugal",
            "hit": false
          }
        ],
        "set_exclude": [
          "kingston"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7364596426486969
      },
      {
        "question verbose": "What is to lisbon ",
        "b": "lisbon",
        "expected answer": [
          "portugal"
        ],
        "predictions": [
          {
            "score": 0.8568354249000549,
            "answer": "portugal",
            "hit": true
          },
          {
            "score": 0.7656179666519165,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7430123686790466,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.7396520376205444,
            "answer": "belgium",
            "hit": false
          },
          {
            "score": 0.7350137829780579,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.7318345308303833,
            "answer": "norway",
            "hit": false
          }
        ],
        "set_exclude": [
          "lisbon"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8568353652954102
      },
      {
        "question verbose": "What is to madrid ",
        "b": "madrid",
        "expected answer": [
          "spain"
        ],
        "predictions": [
          {
            "score": 0.8071736097335815,
            "answer": "spain",
            "hit": true
          },
          {
            "score": 0.7934993505477905,
            "answer": "portugal",
            "hit": false
          },
          {
            "score": 0.7787689566612244,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.771816611289978,
            "answer": "barcelona",
            "hit": false
          },
          {
            "score": 0.7595499753952026,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.7439806461334229,
            "answer": "morocco",
            "hit": false
          }
        ],
        "set_exclude": [
          "madrid"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8071736693382263
      },
      {
        "question verbose": "What is to manila ",
        "b": "manila",
        "expected answer": [
          "philippines"
        ],
        "predictions": [
          {
            "score": 0.8214530944824219,
            "answer": "philippines",
            "hit": true
          },
          {
            "score": 0.8200188875198364,
            "answer": "philippine",
            "hit": false
          },
          {
            "score": 0.7483975887298584,
            "answer": "indonesia",
            "hit": false
          },
          {
            "score": 0.7420753836631775,
            "answer": "malaysia",
            "hit": false
          },
          {
            "score": 0.7417278289794922,
            "answer": "japan",
            "hit": false
          },
          {
            "score": 0.7401536703109741,
            "answer": "thailand",
            "hit": false
          }
        ],
        "set_exclude": [
          "manila"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8214530646800995
      },
      {
        "question verbose": "What is to moscow ",
        "b": "moscow",
        "expected answer": [
          "russia"
        ],
        "predictions": [
          {
            "score": 0.8480809926986694,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.7885783910751343,
            "answer": "putin",
            "hit": false
          },
          {
            "score": 0.7806444764137268,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7772249579429626,
            "answer": "russia",
            "hit": true
          },
          {
            "score": 0.7619431018829346,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7608749270439148,
            "answer": "china",
            "hit": false
          }
        ],
        "set_exclude": [
          "moscow"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7772249579429626
      },
      {
        "question verbose": "What is to oslo ",
        "b": "oslo",
        "expected answer": [
          "norway"
        ],
        "predictions": [
          {
            "score": 0.8558530807495117,
            "answer": "norway",
            "hit": true
          },
          {
            "score": 0.7838900685310364,
            "answer": "norwegian",
            "hit": false
          },
          {
            "score": 0.7661676406860352,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.7533352375030518,
            "answer": "sweden",
            "hit": false
          },
          {
            "score": 0.7399672269821167,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.7336980700492859,
            "answer": "iceland",
            "hit": false
          }
        ],
        "set_exclude": [
          "oslo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8558530509471893
      },
      {
        "question verbose": "What is to ottawa ",
        "b": "ottawa",
        "expected answer": [
          "canada"
        ],
        "predictions": [
          {
            "score": 0.8077378869056702,
            "answer": "ontario",
            "hit": false
          },
          {
            "score": 0.7853422164916992,
            "answer": "quebec",
            "hit": false
          },
          {
            "score": 0.7848331928253174,
            "answer": "saskatchewan",
            "hit": false
          },
          {
            "score": 0.7794570922851562,
            "answer": "canada",
            "hit": true
          },
          {
            "score": 0.7790358662605286,
            "answer": "alberta",
            "hit": false
          },
          {
            "score": 0.7781778573989868,
            "answer": "canadians",
            "hit": false
          }
        ],
        "set_exclude": [
          "ottawa"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7794570922851562
      },
      {
        "question verbose": "What is to paris ",
        "b": "paris",
        "expected answer": [
          "france"
        ],
        "predictions": [
          {
            "score": 0.7894324064254761,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7741881608963013,
            "answer": "italy",
            "hit": false
          },
          {
            "score": 0.7698999643325806,
            "answer": "spain",
            "hit": false
          },
          {
            "score": 0.7571618556976318,
            "answer": "france",
            "hit": true
          },
          {
            "score": 0.738825798034668,
            "answer": "canada",
            "hit": false
          },
          {
            "score": 0.7374072074890137,
            "answer": "china",
            "hit": false
          }
        ],
        "set_exclude": [
          "paris"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7571618854999542
      },
      {
        "question verbose": "What is to rome ",
        "b": "rome",
        "expected answer": [
          "italy"
        ],
        "predictions": [
          {
            "score": 0.7721964120864868,
            "answer": "france",
            "hit": false
          },
          {
            "score": 0.769671618938446,
            "answer": "greece",
            "hit": false
          },
          {
            "score": 0.7519612908363342,
            "answer": "romania",
            "hit": false
          },
          {
            "score": 0.7475423812866211,
            "answer": "europe",
            "hit": false
          },
          {
            "score": 0.7460839748382568,
            "answer": "italy",
            "hit": true
          },
          {
            "score": 0.7308502197265625,
            "answer": "portugal",
            "hit": false
          }
        ],
        "set_exclude": [
          "rome"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7460839301347733
      },
      {
        "question verbose": "What is to santiago ",
        "b": "santiago",
        "expected answer": [
          "chile"
        ],
        "predictions": [
          {
            "score": 0.78825443983078,
            "answer": "chile",
            "hit": true
          },
          {
            "score": 0.7376855611801147,
            "answer": "argentina",
            "hit": false
          },
          {
            "score": 0.714881181716919,
            "answer": "venezuela",
            "hit": false
          },
          {
            "score": 0.7134689688682556,
            "answer": "peru",
            "hit": false
          },
          {
            "score": 0.7083053588867188,
            "answer": "cuba",
            "hit": false
          },
          {
            "score": 0.7016783952713013,
            "answer": "spain",
            "hit": false
          }
        ],
        "set_exclude": [
          "santiago"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.78825443983078
      },
      {
        "question verbose": "What is to stockholm ",
        "b": "stockholm",
        "expected answer": [
          "sweden"
        ],
        "predictions": [
          {
            "score": 0.8674161434173584,
            "answer": "sweden",
            "hit": true
          },
          {
            "score": 0.7935090065002441,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.7906848192214966,
            "answer": "norway",
            "hit": false
          },
          {
            "score": 0.7798764705657959,
            "answer": "denmark",
            "hit": false
          },
          {
            "score": 0.7784501910209656,
            "answer": "finland",
            "hit": false
          },
          {
            "score": 0.7339461445808411,
            "answer": "austria",
            "hit": false
          }
        ],
        "set_exclude": [
          "stockholm"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8674161732196808
      },
      {
        "question verbose": "What is to tehran ",
        "b": "tehran",
        "expected answer": [
          "iran"
        ],
        "predictions": [
          {
            "score": 0.9153459668159485,
            "answer": "iran",
            "hit": true
          },
          {
            "score": 0.8435841202735901,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.749182939529419,
            "answer": "syria",
            "hit": false
          },
          {
            "score": 0.7474779486656189,
            "answer": "india",
            "hit": false
          },
          {
            "score": 0.7465722560882568,
            "answer": "russia",
            "hit": false
          },
          {
            "score": 0.736242413520813,
            "answer": "venezuela",
            "hit": false
          }
        ],
        "set_exclude": [
          "tehran"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.9153459668159485
      },
      {
        "question verbose": "What is to tokyo ",
        "b": "tokyo",
        "expected answer": [
          "japan"
        ],
        "predictions": [
          {
            "score": 0.896737277507782,
            "answer": "japan",
            "hit": true
          },
          {
            "score": 0.7504965662956238,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.7362955212593079,
            "answer": "seoul",
            "hit": false
          },
          {
            "score": 0.7355373501777649,
            "answer": "taiwan",
            "hit": false
          },
          {
            "score": 0.7317606210708618,
            "answer": "korea",
            "hit": false
          },
          {
            "score": 0.7291029691696167,
            "answer": "finland",
            "hit": false
          }
        ],
        "set_exclude": [
          "tokyo"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.896737277507782
      },
      {
        "question verbose": "What is to vienna ",
        "b": "vienna",
        "expected answer": [
          "austria"
        ],
        "predictions": [
          {
            "score": 0.8548235893249512,
            "answer": "austria",
            "hit": true
          },
          {
            "score": 0.7668517231941223,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.7654728889465332,
            "answer": "switzerland",
            "hit": false
          },
          {
            "score": 0.7612088918685913,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.7465081214904785,
            "answer": "poland",
            "hit": false
          },
          {
            "score": 0.745434045791626,
            "answer": "sweden",
            "hit": false
          }
        ],
        "set_exclude": [
          "vienna"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8548235297203064
      },
      {
        "question verbose": "What is to warsaw ",
        "b": "warsaw",
        "expected answer": [
          "poland"
        ],
        "predictions": [
          {
            "score": 0.8661298155784607,
            "answer": "poland",
            "hit": true
          },
          {
            "score": 0.785056471824646,
            "answer": "polish",
            "hit": false
          },
          {
            "score": 0.7536669373512268,
            "answer": "hungary",
            "hit": false
          },
          {
            "score": 0.744856595993042,
            "answer": "romania",
            "hit": false
          },
          {
            "score": 0.7369015216827393,
            "answer": "ukraine",
            "hit": false
          },
          {
            "score": 0.7344290018081665,
            "answer": "austria",
            "hit": false
          }
        ],
        "set_exclude": [
          "warsaw"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8661298751831055
      }
    ],
    "result": {
      "cnt_questions_correct": 22,
      "cnt_questions_total": 28,
      "accuracy": 0.7857142857142857
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E01 [country - capital].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "e8be1b8b-2aef-474b-9fa2-f7ab71b30e4c",
      "timestamp": "2025-05-17T17:15:34.598810"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to argentina ",
        "b": "argentina",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8458994626998901,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.7747737169265747,
            "answer": "buenos",
            "hit": false
          },
          {
            "score": 0.76020348072052,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7554033994674683,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7424943447113037,
            "answer": "argent",
            "hit": false
          },
          {
            "score": 0.7374975681304932,
            "answer": "arabic",
            "hit": false
          }
        ],
        "set_exclude": [
          "argentina"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.76020348072052
      },
      {
        "question verbose": "What is to australia ",
        "b": "australia",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.8752180337905884,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.7968558669090271,
            "answer": "australians",
            "hit": false
          },
          {
            "score": 0.7514150738716125,
            "answer": "sydney",
            "hit": false
          },
          {
            "score": 0.7430185079574585,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7419701814651489,
            "answer": "melbourne",
            "hit": false
          },
          {
            "score": 0.7315182685852051,
            "answer": "queensland",
            "hit": false
          }
        ],
        "set_exclude": [
          "australia"
        ],
        "rank": 29,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6747939139604568
      },
      {
        "question verbose": "What is to austria ",
        "b": "austria",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.8367413282394409,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.7794367671012878,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7611081600189209,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.7341414093971252,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7337425351142883,
            "answer": "vienna",
            "hit": false
          },
          {
            "score": 0.7290552854537964,
            "answer": "hungary",
            "hit": false
          }
        ],
        "set_exclude": [
          "austria"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7794367671012878
      },
      {
        "question verbose": "What is to brazil ",
        "b": "brazil",
        "expected answer": [
          "portuguese"
        ],
        "predictions": [
          {
            "score": 0.8277977705001831,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7859958410263062,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.7665963768959045,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.7482103705406189,
            "answer": "portuguese",
            "hit": true
          },
          {
            "score": 0.7394442558288574,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.7182947993278503,
            "answer": "dutch",
            "hit": false
          }
        ],
        "set_exclude": [
          "brazil"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7482104003429413
      },
      {
        "question verbose": "What is to canada ",
        "b": "canada",
        "expected answer": [
          "english",
          "french"
        ],
        "predictions": [
          {
            "score": 0.8320440053939819,
            "answer": "canadian",
            "hit": false
          },
          {
            "score": 0.7679643630981445,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7098743915557861,
            "answer": "japanese",
            "hit": false
          },
          {
            "score": 0.7094085216522217,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.7089860439300537,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.700425386428833,
            "answer": "spain",
            "hit": false
          }
        ],
        "set_exclude": [
          "canada"
        ],
        "rank": 44,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6370017528533936
      },
      {
        "question verbose": "What is to chile ",
        "b": "chile",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7601039409637451,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7330818772315979,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7295690178871155,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7279284000396729,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.7270511388778687,
            "answer": "argentine",
            "hit": false
          },
          {
            "score": 0.7259016036987305,
            "answer": "german",
            "hit": false
          }
        ],
        "set_exclude": [
          "chile"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7601040005683899
      },
      {
        "question verbose": "What is to colombia ",
        "b": "colombia",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7609125375747681,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7515285611152649,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7453746795654297,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7293041944503784,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.726527214050293,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7071455717086792,
            "answer": "german",
            "hit": false
          }
        ],
        "set_exclude": [
          "colombia"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7515285909175873
      },
      {
        "question verbose": "What is to cuba ",
        "b": "cuba",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.8384436964988708,
            "answer": "cuban",
            "hit": false
          },
          {
            "score": 0.7500964403152466,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7412174940109253,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7281564474105835,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7158092856407166,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.712010383605957,
            "answer": "mexican",
            "hit": false
          }
        ],
        "set_exclude": [
          "cuba"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7412175238132477
      },
      {
        "question verbose": "What is to cyprus ",
        "b": "cyprus",
        "expected answer": [
          "greek",
          "turkish"
        ],
        "predictions": [
          {
            "score": 0.7607017755508423,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.7461999654769897,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.71620774269104,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7145666480064392,
            "answer": "byzantine",
            "hit": false
          },
          {
            "score": 0.7103367447853088,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7066044807434082,
            "answer": "german",
            "hit": false
          }
        ],
        "set_exclude": [
          "cyprus"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7607018053531647
      },
      {
        "question verbose": "What is to egypt ",
        "b": "egypt",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8956512808799744,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.8154752254486084,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7773318290710449,
            "answer": "cairo",
            "hit": false
          },
          {
            "score": 0.75021892786026,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.743342399597168,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7134242057800293,
            "answer": "german",
            "hit": false
          }
        ],
        "set_exclude": [
          "egypt"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8154752254486084
      },
      {
        "question verbose": "What is to guatemala ",
        "b": "guatemala",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7426479458808899,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7391650080680847,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7331083416938782,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7311387062072754,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7042792439460754,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.6988894939422607,
            "answer": "hebrew",
            "hit": false
          }
        ],
        "set_exclude": [
          "guatemala"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7311387360095978
      },
      {
        "question verbose": "What is to iran ",
        "b": "iran",
        "expected answer": [
          "persian"
        ],
        "predictions": [
          {
            "score": 0.8813246488571167,
            "answer": "iranian",
            "hit": false
          },
          {
            "score": 0.8085774183273315,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.8060360550880432,
            "answer": "tehran",
            "hit": false
          },
          {
            "score": 0.7937291264533997,
            "answer": "persian",
            "hit": true
          },
          {
            "score": 0.7325069308280945,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.729471743106842,
            "answer": "hebrew",
            "hit": false
          }
        ],
        "set_exclude": [
          "iran"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.793729156255722
      },
      {
        "question verbose": "What is to iraq ",
        "b": "iraq",
        "expected answer": [
          "arabic",
          "kurdish"
        ],
        "predictions": [
          {
            "score": 0.7763466835021973,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.7549588680267334,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.7488043904304504,
            "answer": "turkish",
            "hit": false
          },
          {
            "score": 0.7455311417579651,
            "answer": "arab",
            "hit": false
          },
          {
            "score": 0.7246296405792236,
            "answer": "islamic",
            "hit": false
          },
          {
            "score": 0.7243922352790833,
            "answer": "arabic",
            "hit": true
          }
        ],
        "set_exclude": [
          "iraq"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7243922352790833
      },
      {
        "question verbose": "What is to israel ",
        "b": "israel",
        "expected answer": [
          "hebrew",
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.7858332395553589,
            "answer": "palestinian",
            "hit": false
          },
          {
            "score": 0.767728865146637,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.765887975692749,
            "answer": "hebrew",
            "hit": true
          },
          {
            "score": 0.7606806755065918,
            "answer": "israeli",
            "hit": false
          },
          {
            "score": 0.7461470365524292,
            "answer": "arab",
            "hit": false
          },
          {
            "score": 0.7344865798950195,
            "answer": "turkish",
            "hit": false
          }
        ],
        "set_exclude": [
          "israel"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.765887975692749
      },
      {
        "question verbose": "What is to jordan ",
        "b": "jordan",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.7470670938491821,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.6813069581985474,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.6752843856811523,
            "answer": "christian",
            "hit": false
          },
          {
            "score": 0.6634951233863831,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6529651880264282,
            "answer": "isaiah",
            "hit": false
          },
          {
            "score": 0.6507189869880676,
            "answer": "jackson",
            "hit": false
          }
        ],
        "set_exclude": [
          "jordan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7470670938491821
      },
      {
        "question verbose": "What is to kuwait ",
        "b": "kuwait",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.787961483001709,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7491344809532166,
            "answer": "persian",
            "hit": false
          },
          {
            "score": 0.7276818752288818,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.7199380993843079,
            "answer": "lebanese",
            "hit": false
          },
          {
            "score": 0.7159424424171448,
            "answer": "kurdish",
            "hit": false
          },
          {
            "score": 0.6996767520904541,
            "answer": "portuguese",
            "hit": false
          }
        ],
        "set_exclude": [
          "kuwait"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7879614233970642
      },
      {
        "question verbose": "What is to palestine ",
        "b": "palestine",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.803431510925293,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7820576429367065,
            "answer": "hebrew",
            "hit": false
          },
          {
            "score": 0.7607158422470093,
            "answer": "jewish",
            "hit": false
          },
          {
            "score": 0.754959225654602,
            "answer": "palestinians",
            "hit": false
          },
          {
            "score": 0.7332746982574463,
            "answer": "palestinian",
            "hit": false
          },
          {
            "score": 0.7313053011894226,
            "answer": "israeli",
            "hit": false
          }
        ],
        "set_exclude": [
          "palestine"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8034315407276154
      },
      {
        "question verbose": "What is to peru ",
        "b": "peru",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7625770568847656,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7465793490409851,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.719751238822937,
            "answer": "brazilian",
            "hit": false
          },
          {
            "score": 0.7149119973182678,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7099563479423523,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.6950733065605164,
            "answer": "greek",
            "hit": false
          }
        ],
        "set_exclude": [
          "peru"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7465793639421463
      },
      {
        "question verbose": "What is to switzerland ",
        "b": "switzerland",
        "expected answer": [
          "german",
          "french",
          "italian"
        ],
        "predictions": [
          {
            "score": 0.8431224226951599,
            "answer": "swiss",
            "hit": false
          },
          {
            "score": 0.7617860436439514,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7477725148200989,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.7443681955337524,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.715221643447876,
            "answer": "austrian",
            "hit": false
          },
          {
            "score": 0.7130987644195557,
            "answer": "portuguese",
            "hit": false
          }
        ],
        "set_exclude": [
          "switzerland"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7617860436439514
      },
      {
        "question verbose": "What is to syria ",
        "b": "syria",
        "expected answer": [
          "arabic"
        ],
        "predictions": [
          {
            "score": 0.8586631417274475,
            "answer": "syrian",
            "hit": false
          },
          {
            "score": 0.8227986693382263,
            "answer": "arabic",
            "hit": true
          },
          {
            "score": 0.7408415675163269,
            "answer": "damascus",
            "hit": false
          },
          {
            "score": 0.7194265723228455,
            "answer": "iraqi",
            "hit": false
          },
          {
            "score": 0.7191380262374878,
            "answer": "kurdish",
            "hit": false
          },
          {
            "score": 0.7136917114257812,
            "answer": "libya",
            "hit": false
          }
        ],
        "set_exclude": [
          "syria"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8227986395359039
      },
      {
        "question verbose": "What is to taiwan ",
        "b": "taiwan",
        "expected answer": [
          "chinese"
        ],
        "predictions": [
          {
            "score": 0.7710766792297363,
            "answer": "chinese",
            "hit": true
          },
          {
            "score": 0.756050169467926,
            "answer": "tai",
            "hit": false
          },
          {
            "score": 0.755020022392273,
            "answer": "korean",
            "hit": false
          },
          {
            "score": 0.7252322435379028,
            "answer": "vietnamese",
            "hit": false
          },
          {
            "score": 0.7224559783935547,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7066130042076111,
            "answer": "thai",
            "hit": false
          }
        ],
        "set_exclude": [
          "taiwan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7710766792297363
      },
      {
        "question verbose": "What is to usa ",
        "b": "usa",
        "expected answer": [
          "english"
        ],
        "predictions": [
          {
            "score": 0.6781144738197327,
            "answer": "spanish",
            "hit": false
          },
          {
            "score": 0.6503250598907471,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.630780041217804,
            "answer": "uno",
            "hit": false
          },
          {
            "score": 0.6186546087265015,
            "answer": "une",
            "hit": false
          },
          {
            "score": 0.6158223748207092,
            "answer": "iso",
            "hit": false
          },
          {
            "score": 0.6153839826583862,
            "answer": "english",
            "hit": true
          }
        ],
        "set_exclude": [
          "usa"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6153839528560638
      },
      {
        "question verbose": "What is to venezuela ",
        "b": "venezuela",
        "expected answer": [
          "spanish"
        ],
        "predictions": [
          {
            "score": 0.7550822496414185,
            "answer": "spanish",
            "hit": true
          },
          {
            "score": 0.7502726316452026,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7317314743995667,
            "answer": "portuguese",
            "hit": false
          },
          {
            "score": 0.7294939160346985,
            "answer": "mexican",
            "hit": false
          },
          {
            "score": 0.7208576798439026,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7189821600914001,
            "answer": "brazilian",
            "hit": false
          }
        ],
        "set_exclude": [
          "venezuela"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7550822496414185
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 23,
      "accuracy": 0.30434782608695654
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E02 [country - language].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "756ae566-4de0-4c5e-accb-621042fc3466",
      "timestamp": "2025-05-17T17:15:34.695700"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bath ",
        "b": "bath",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.695279598236084,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.6501013040542603,
            "answer": "baths",
            "hit": false
          },
          {
            "score": 0.6371062994003296,
            "answer": "bathroom",
            "hit": false
          },
          {
            "score": 0.6244593858718872,
            "answer": "bed",
            "hit": false
          },
          {
            "score": 0.6169835329055786,
            "answer": "bathrooms",
            "hit": false
          },
          {
            "score": 0.6111786365509033,
            "answer": "washed",
            "hit": false
          }
        ],
        "set_exclude": [
          "bath"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5925965756177902
      },
      {
        "question verbose": "What is to bradford ",
        "b": "bradford",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8197451233863831,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7362067699432373,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7076663374900818,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7030635476112366,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.7025181651115417,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.6925580501556396,
            "answer": "essex",
            "hit": false
          }
        ],
        "set_exclude": [
          "bradford"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8197451233863831
      },
      {
        "question verbose": "What is to brighton ",
        "b": "brighton",
        "expected answer": [
          "sussex"
        ],
        "predictions": [
          {
            "score": 0.8255062103271484,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.7666963934898376,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7636191844940186,
            "answer": "sussex",
            "hit": true
          },
          {
            "score": 0.7245522737503052,
            "answer": "devon",
            "hit": false
          },
          {
            "score": 0.7159203290939331,
            "answer": "essex",
            "hit": false
          },
          {
            "score": 0.7154310345649719,
            "answer": "bristol",
            "hit": false
          }
        ],
        "set_exclude": [
          "brighton"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7636191844940186
      },
      {
        "question verbose": "What is to hull ",
        "b": "hull",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8016237020492554,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7203269600868225,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.6971360445022583,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.6948652863502502,
            "answer": "wales",
            "hit": false
          },
          {
            "score": 0.6909698247909546,
            "answer": "cornwall",
            "hit": false
          },
          {
            "score": 0.6902536749839783,
            "answer": "leicester",
            "hit": false
          }
        ],
        "set_exclude": [
          "hull"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8016237020492554
      },
      {
        "question verbose": "What is to leeds ",
        "b": "leeds",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8719565868377686,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7569108009338379,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7472817897796631,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.7380267381668091,
            "answer": "newcastle",
            "hit": false
          },
          {
            "score": 0.7326532602310181,
            "answer": "sheffield",
            "hit": false
          },
          {
            "score": 0.7308338284492493,
            "answer": "sussex",
            "hit": false
          }
        ],
        "set_exclude": [
          "leeds"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8719565868377686
      },
      {
        "question verbose": "What is to plymouth ",
        "b": "plymouth",
        "expected answer": [
          "devon"
        ],
        "predictions": [
          {
            "score": 0.8117666244506836,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.7732775211334229,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7223466634750366,
            "answer": "devon",
            "hit": true
          },
          {
            "score": 0.7167975306510925,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7068840265274048,
            "answer": "cornwall",
            "hit": false
          },
          {
            "score": 0.7001479864120483,
            "answer": "worcester",
            "hit": false
          }
        ],
        "set_exclude": [
          "plymouth"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7223466783761978
      },
      {
        "question verbose": "What is to sheffield ",
        "b": "sheffield",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8494960069656372,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7741783261299133,
            "answer": "nottingham",
            "hit": false
          },
          {
            "score": 0.7584770917892456,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7416449189186096,
            "answer": "leeds",
            "hit": false
          },
          {
            "score": 0.7335790991783142,
            "answer": "sussex",
            "hit": false
          },
          {
            "score": 0.7274780869483948,
            "answer": "manchester",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheffield"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.849496066570282
      },
      {
        "question verbose": "What is to wells ",
        "b": "wells",
        "expected answer": [
          "somerset"
        ],
        "predictions": [
          {
            "score": 0.6876242160797119,
            "answer": "reservoirs",
            "hit": false
          },
          {
            "score": 0.6657689809799194,
            "answer": "groundwater",
            "hit": false
          },
          {
            "score": 0.6632384061813354,
            "answer": "drilling",
            "hit": false
          },
          {
            "score": 0.6618244051933289,
            "answer": "yorkshire",
            "hit": false
          },
          {
            "score": 0.6596698760986328,
            "answer": "lakes",
            "hit": false
          },
          {
            "score": 0.6564102172851562,
            "answer": "barrels",
            "hit": false
          }
        ],
        "set_exclude": [
          "wells"
        ],
        "rank": 145,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6052180677652359
      },
      {
        "question verbose": "What is to york ",
        "b": "york",
        "expected answer": [
          "yorkshire"
        ],
        "predictions": [
          {
            "score": 0.8131812214851379,
            "answer": "yorkshire",
            "hit": true
          },
          {
            "score": 0.7888575792312622,
            "answer": "jersey",
            "hit": false
          },
          {
            "score": 0.7714307904243469,
            "answer": "hampshire",
            "hit": false
          },
          {
            "score": 0.7564679384231567,
            "answer": "yorker",
            "hit": false
          },
          {
            "score": 0.7385991811752319,
            "answer": "somerset",
            "hit": false
          },
          {
            "score": 0.7331525683403015,
            "answer": "orleans",
            "hit": false
          }
        ],
        "set_exclude": [
          "york"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8131812214851379
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 9,
      "accuracy": 0.5555555555555556
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E03 [UK_city - county].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "e30c869f-2e6d-498f-9de2-3f319e5876a3",
      "timestamp": "2025-05-17T17:15:34.774118"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.7996453642845154,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.7488635778427124,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.7360267639160156,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7138399481773376,
            "answer": "arabic",
            "hit": false
          },
          {
            "score": 0.7134338021278381,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.7114298939704895,
            "answer": "european",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7996454238891602
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "roman"
        ],
        "predictions": [
          {
            "score": 0.7549084424972534,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.754841148853302,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7312736511230469,
            "answer": "roman",
            "hit": true
          },
          {
            "score": 0.7169097065925598,
            "answer": "egyptian",
            "hit": false
          },
          {
            "score": 0.7135741710662842,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.7085384130477905,
            "answer": "romanian",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7312735915184021
      },
      {
        "question verbose": "What is to darwin ",
        "b": "darwin",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7523725032806396,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.7493796348571777,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7220273613929749,
            "answer": "european",
            "hit": false
          },
          {
            "score": 0.7206246852874756,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.7085342407226562,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7035121917724609,
            "answer": "american",
            "hit": false
          }
        ],
        "set_exclude": [
          "darwin"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6083752810955048
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7330102920532227,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6928725838661194,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.682269275188446,
            "answer": "european",
            "hit": false
          },
          {
            "score": 0.6772727370262146,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6768415570259094,
            "answer": "british",
            "hit": false
          },
          {
            "score": 0.6699023246765137,
            "answer": "danish",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6928725838661194
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "jewish",
          "german",
          "american"
        ],
        "predictions": [
          {
            "score": 0.7868168354034424,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7231244444847107,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.7146986722946167,
            "answer": "european",
            "hit": false
          },
          {
            "score": 0.7130786776542664,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7123939990997314,
            "answer": "israeli",
            "hit": false
          },
          {
            "score": 0.7014023661613464,
            "answer": "austrian",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.698049008846283
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "german",
          "austrian"
        ],
        "predictions": [
          {
            "score": 0.8420838117599487,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.774622917175293,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.7445979118347168,
            "answer": "polish",
            "hit": false
          },
          {
            "score": 0.7394900321960449,
            "answer": "jewish",
            "hit": false
          },
          {
            "score": 0.7266285419464111,
            "answer": "european",
            "hit": false
          },
          {
            "score": 0.7256252765655518,
            "answer": "ukrainian",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8420838117599487
      },
      {
        "question verbose": "What is to homer ",
        "b": "homer",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.7899360656738281,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7657813429832458,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.7000951170921326,
            "answer": "germans",
            "hit": false
          },
          {
            "score": 0.692200243473053,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6914363503456116,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6900339126586914,
            "answer": "egyptian",
            "hit": false
          }
        ],
        "set_exclude": [
          "homer"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7657813429832458
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7289533615112305,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6988617181777954,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.6981807351112366,
            "answer": "scottish",
            "hit": true
          },
          {
            "score": 0.691094160079956,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6830214858055115,
            "answer": "australian",
            "hit": false
          },
          {
            "score": 0.6810969114303589,
            "answer": "american",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6981807351112366
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7731238603591919,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7108930349349976,
            "answer": "european",
            "hit": false
          },
          {
            "score": 0.7031689882278442,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.7030161023139954,
            "answer": "belgian",
            "hit": false
          },
          {
            "score": 0.6972112655639648,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6959118247032166,
            "answer": "danish",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7731239199638367
      },
      {
        "question verbose": "What is to kepler ",
        "b": "kepler",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7123129367828369,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7080421447753906,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6886802911758423,
            "answer": "european",
            "hit": false
          },
          {
            "score": 0.6740509271621704,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6700013279914856,
            "answer": "korean",
            "hit": false
          },
          {
            "score": 0.6680588722229004,
            "answer": "egyptian",
            "hit": false
          }
        ],
        "set_exclude": [
          "kepler"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.708042174577713
      },
      {
        "question verbose": "What is to lenin ",
        "b": "lenin",
        "expected answer": [
          "soviet",
          "russian"
        ],
        "predictions": [
          {
            "score": 0.754979133605957,
            "answer": "russian",
            "hit": true
          },
          {
            "score": 0.7162288427352905,
            "answer": "soviet",
            "hit": true
          },
          {
            "score": 0.7093697786331177,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7039171457290649,
            "answer": "ukrainian",
            "hit": false
          },
          {
            "score": 0.7013788223266602,
            "answer": "italian",
            "hit": false
          },
          {
            "score": 0.6944907903671265,
            "answer": "spanish",
            "hit": false
          }
        ],
        "set_exclude": [
          "lenin"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7162288725376129
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7588710784912109,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7439872622489929,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.721446692943573,
            "answer": "british",
            "hit": false
          },
          {
            "score": 0.7157857418060303,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.7062052488327026,
            "answer": "european",
            "hit": false
          },
          {
            "score": 0.7058929204940796,
            "answer": "nebraska",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7439872771501541
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.7219511270523071,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7095736861228943,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.7090964913368225,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.7085356116294861,
            "answer": "european",
            "hit": false
          },
          {
            "score": 0.707730233669281,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.7007123231887817,
            "answer": "american",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.644996702671051
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7705332040786743,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.6965330243110657,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.6963794827461243,
            "answer": "russian",
            "hit": false
          },
          {
            "score": 0.6906919479370117,
            "answer": "soviet",
            "hit": false
          },
          {
            "score": 0.6864844560623169,
            "answer": "germany",
            "hit": false
          },
          {
            "score": 0.675201952457428,
            "answer": "italian",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6965330243110657
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "scottish",
          "british"
        ],
        "predictions": [
          {
            "score": 0.6426512002944946,
            "answer": "english",
            "hit": false
          },
          {
            "score": 0.6222033500671387,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.6216943860054016,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.6126819849014282,
            "answer": "french",
            "hit": false
          },
          {
            "score": 0.6079424023628235,
            "answer": "canadian",
            "hit": false
          },
          {
            "score": 0.6012107133865356,
            "answer": "russian",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5950454920530319
      },
      {
        "question verbose": "What is to newton ",
        "b": "newton",
        "expected answer": [
          "english",
          "british"
        ],
        "predictions": [
          {
            "score": 0.75841224193573,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7133210301399231,
            "answer": "british",
            "hit": true
          },
          {
            "score": 0.6974145770072937,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6917286515235901,
            "answer": "scottish",
            "hit": false
          },
          {
            "score": 0.6906958818435669,
            "answer": "american",
            "hit": false
          },
          {
            "score": 0.6898583769798279,
            "answer": "norwegian",
            "hit": false
          }
        ],
        "set_exclude": [
          "newton"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6487726718187332
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "greek"
        ],
        "predictions": [
          {
            "score": 0.801461935043335,
            "answer": "greek",
            "hit": true
          },
          {
            "score": 0.7741210460662842,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7377662062644958,
            "answer": "greeks",
            "hit": false
          },
          {
            "score": 0.7235608696937561,
            "answer": "european",
            "hit": false
          },
          {
            "score": 0.7211570739746094,
            "answer": "polish",
            "hit": false
          },
          {
            "score": 0.7209532260894775,
            "answer": "greece",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.801461935043335
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "american"
        ],
        "predictions": [
          {
            "score": 0.7269384264945984,
            "answer": "german",
            "hit": false
          },
          {
            "score": 0.7167196273803711,
            "answer": "american",
            "hit": true
          },
          {
            "score": 0.697765588760376,
            "answer": "korean",
            "hit": false
          },
          {
            "score": 0.6909757256507874,
            "answer": "british",
            "hit": false
          },
          {
            "score": 0.688971996307373,
            "answer": "polish",
            "hit": false
          },
          {
            "score": 0.6805402636528015,
            "answer": "jewish",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7167196273803711
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "german"
        ],
        "predictions": [
          {
            "score": 0.7855002880096436,
            "answer": "german",
            "hit": true
          },
          {
            "score": 0.7127871513366699,
            "answer": "polish",
            "hit": false
          },
          {
            "score": 0.7126408219337463,
            "answer": "hungarian",
            "hit": false
          },
          {
            "score": 0.7053239345550537,
            "answer": "swedish",
            "hit": false
          },
          {
            "score": 0.7035387754440308,
            "answer": "greek",
            "hit": false
          },
          {
            "score": 0.6963653564453125,
            "answer": "norwegian",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7855002880096436
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 19,
      "accuracy": 0.3684210526315789
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E04 [name - nationality].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "30359f46-9b10-4784-930a-7d51857a3755",
      "timestamp": "2025-05-17T17:15:34.803749"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to aristotle ",
        "b": "aristotle",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8111889958381653,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7478281259536743,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7278251647949219,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.7191709280014038,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7063831090927124,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7060880064964294,
            "answer": "plato",
            "hit": false
          }
        ],
        "set_exclude": [
          "aristotle"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8111889958381653
      },
      {
        "question verbose": "What is to caesar ",
        "b": "caesar",
        "expected answer": [
          "emperor",
          "commander",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.7417962551116943,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7046725749969482,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.6831225156784058,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6726502776145935,
            "answer": "ruler",
            "hit": false
          },
          {
            "score": 0.6632758378982544,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.6603553891181946,
            "answer": "philosophers",
            "hit": false
          }
        ],
        "set_exclude": [
          "caesar"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6535203456878662
      },
      {
        "question verbose": "What is to columbus ",
        "b": "columbus",
        "expected answer": [
          "explorer"
        ],
        "predictions": [
          {
            "score": 0.7150251865386963,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6795214414596558,
            "answer": "ohio",
            "hit": false
          },
          {
            "score": 0.6734201312065125,
            "answer": "cleveland",
            "hit": false
          },
          {
            "score": 0.6715430617332458,
            "answer": "cincinnati",
            "hit": false
          },
          {
            "score": 0.6712226867675781,
            "answer": "indianapolis",
            "hit": false
          },
          {
            "score": 0.6599110960960388,
            "answer": "chicago",
            "hit": false
          }
        ],
        "set_exclude": [
          "columbus"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6348506808280945
      },
      {
        "question verbose": "What is to dante ",
        "b": "dante",
        "expected answer": [
          "poet"
        ],
        "predictions": [
          {
            "score": 0.7279437780380249,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7111835479736328,
            "answer": "poet",
            "hit": true
          },
          {
            "score": 0.6734737157821655,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.6687355637550354,
            "answer": "composer",
            "hit": false
          },
          {
            "score": 0.6616562604904175,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6560139060020447,
            "answer": "rapper",
            "hit": false
          }
        ],
        "set_exclude": [
          "dante"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7111835777759552
      },
      {
        "question verbose": "What is to edison ",
        "b": "edison",
        "expected answer": [
          "inventor",
          "businessman"
        ],
        "predictions": [
          {
            "score": 0.706204354763031,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.7048677206039429,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6827018857002258,
            "answer": "inventor",
            "hit": true
          },
          {
            "score": 0.6628925800323486,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6559732556343079,
            "answer": "entrepreneur",
            "hit": false
          },
          {
            "score": 0.6559629440307617,
            "answer": "scientist",
            "hit": false
          }
        ],
        "set_exclude": [
          "edison"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6827019155025482
      },
      {
        "question verbose": "What is to einstein ",
        "b": "einstein",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.7911419868469238,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.7690410017967224,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.733006477355957,
            "answer": "scientist",
            "hit": true
          },
          {
            "score": 0.7006403207778931,
            "answer": "inventor",
            "hit": false
          },
          {
            "score": 0.692689061164856,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6764397621154785,
            "answer": "poet",
            "hit": false
          }
        ],
        "set_exclude": [
          "einstein"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7911420166492462
      },
      {
        "question verbose": "What is to hitler ",
        "b": "hitler",
        "expected answer": [
          "dictator",
          "politician",
          "nazi"
        ],
        "predictions": [
          {
            "score": 0.7369706630706787,
            "answer": "dictator",
            "hit": true
          },
          {
            "score": 0.7247817516326904,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7037889957427979,
            "answer": "stalin",
            "hit": false
          },
          {
            "score": 0.6994147300720215,
            "answer": "holocaust",
            "hit": false
          },
          {
            "score": 0.6938296556472778,
            "answer": "emperor",
            "hit": false
          },
          {
            "score": 0.6913825273513794,
            "answer": "historian",
            "hit": false
          }
        ],
        "set_exclude": [
          "hitler"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7369706630706787
      },
      {
        "question verbose": "What is to hume ",
        "b": "hume",
        "expected answer": [
          "philosopher",
          "politician"
        ],
        "predictions": [
          {
            "score": 0.7562546730041504,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6921045780181885,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6883658766746521,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.669537365436554,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.6688039302825928,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.667951226234436,
            "answer": "historian",
            "hit": false
          }
        ],
        "set_exclude": [
          "hume"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7562546730041504
      },
      {
        "question verbose": "What is to kant ",
        "b": "kant",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7542913556098938,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6988433003425598,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6847473382949829,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6806948184967041,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6667709946632385,
            "answer": "psychologist",
            "hit": false
          },
          {
            "score": 0.6665656566619873,
            "answer": "scholar",
            "hit": false
          }
        ],
        "set_exclude": [
          "kant"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7542913556098938
      },
      {
        "question verbose": "What is to lincoln ",
        "b": "lincoln",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.7318645119667053,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6948135495185852,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6864535808563232,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.6642888188362122,
            "answer": "scholar",
            "hit": false
          },
          {
            "score": 0.6624433398246765,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.6607942581176758,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "lincoln"
        ],
        "rank": 303,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5758279636502266
      },
      {
        "question verbose": "What is to locke ",
        "b": "locke",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.7280157804489136,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6753264665603638,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.664376437664032,
            "answer": "scientist",
            "hit": false
          },
          {
            "score": 0.6561089158058167,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6554048657417297,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6454313397407532,
            "answer": "novelist",
            "hit": false
          }
        ],
        "set_exclude": [
          "locke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7280157804489136
      },
      {
        "question verbose": "What is to marx ",
        "b": "marx",
        "expected answer": [
          "philosopher",
          "communist"
        ],
        "predictions": [
          {
            "score": 0.751277506351471,
            "answer": "marxist",
            "hit": false
          },
          {
            "score": 0.7060515880584717,
            "answer": "lenin",
            "hit": false
          },
          {
            "score": 0.6944633722305298,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.6583976745605469,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6556379199028015,
            "answer": "capitalist",
            "hit": false
          },
          {
            "score": 0.6544884443283081,
            "answer": "socialist",
            "hit": false
          }
        ],
        "set_exclude": [
          "marx"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6944633424282074
      },
      {
        "question verbose": "What is to maxwell ",
        "b": "maxwell",
        "expected answer": [
          "physicist",
          "scientist"
        ],
        "predictions": [
          {
            "score": 0.6810097694396973,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6493515968322754,
            "answer": "physicist",
            "hit": true
          },
          {
            "score": 0.6207396388053894,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.6190629005432129,
            "answer": "scholar",
            "hit": false
          },
          {
            "score": 0.6164898872375488,
            "answer": "scientist",
            "hit": true
          },
          {
            "score": 0.6076318025588989,
            "answer": "inventor",
            "hit": false
          }
        ],
        "set_exclude": [
          "maxwell"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6493515819311142
      },
      {
        "question verbose": "What is to moses ",
        "b": "moses",
        "expected answer": [
          "prophet",
          "leader"
        ],
        "predictions": [
          {
            "score": 0.7300294637680054,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.7024590373039246,
            "answer": "prophet",
            "hit": true
          },
          {
            "score": 0.6956132054328918,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.691715657711029,
            "answer": "rabbi",
            "hit": false
          },
          {
            "score": 0.6776093244552612,
            "answer": "prophets",
            "hit": false
          },
          {
            "score": 0.6708443760871887,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "moses"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7024590522050858
      },
      {
        "question verbose": "What is to napoleon ",
        "b": "napoleon",
        "expected answer": [
          "emperor",
          "leader",
          "politician",
          "commander"
        ],
        "predictions": [
          {
            "score": 0.7531484365463257,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6999959945678711,
            "answer": "emperor",
            "hit": true
          },
          {
            "score": 0.6968350410461426,
            "answer": "dictator",
            "hit": false
          },
          {
            "score": 0.6889676451683044,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6863142251968384,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.6784826517105103,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "napoleon"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6999960541725159
      },
      {
        "question verbose": "What is to plato ",
        "b": "plato",
        "expected answer": [
          "philosopher"
        ],
        "predictions": [
          {
            "score": 0.8255229592323303,
            "answer": "philosopher",
            "hit": true
          },
          {
            "score": 0.7570012807846069,
            "answer": "philosophers",
            "hit": false
          },
          {
            "score": 0.7440271973609924,
            "answer": "socrates",
            "hit": false
          },
          {
            "score": 0.7147772312164307,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.7051844596862793,
            "answer": "aristotle",
            "hit": false
          },
          {
            "score": 0.7014509439468384,
            "answer": "physicist",
            "hit": false
          }
        ],
        "set_exclude": [
          "plato"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8255228996276855
      },
      {
        "question verbose": "What is to truman ",
        "b": "truman",
        "expected answer": [
          "president"
        ],
        "predictions": [
          {
            "score": 0.731214165687561,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6969579458236694,
            "answer": "historian",
            "hit": false
          },
          {
            "score": 0.6786853075027466,
            "answer": "physicist",
            "hit": false
          },
          {
            "score": 0.6763997673988342,
            "answer": "novelist",
            "hit": false
          },
          {
            "score": 0.6561106443405151,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.654287576675415,
            "answer": "psychologist",
            "hit": false
          }
        ],
        "set_exclude": [
          "truman"
        ],
        "rank": 43,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6065086126327515
      },
      {
        "question verbose": "What is to wagner ",
        "b": "wagner",
        "expected answer": [
          "composer"
        ],
        "predictions": [
          {
            "score": 0.7161622643470764,
            "answer": "philosopher",
            "hit": false
          },
          {
            "score": 0.6824591159820557,
            "answer": "poet",
            "hit": false
          },
          {
            "score": 0.6812317371368408,
            "answer": "composer",
            "hit": true
          },
          {
            "score": 0.6638895273208618,
            "answer": "musician",
            "hit": false
          },
          {
            "score": 0.6590930223464966,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.6530899405479431,
            "answer": "historian",
            "hit": false
          }
        ],
        "set_exclude": [
          "wagner"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6812317669391632
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 18,
      "accuracy": 0.3888888888888889
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E05 [name - occupation].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "f605e23c-0e5a-49e0-825d-3fa24a5f3f30",
      "timestamp": "2025-05-17T17:15:34.866660"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "baby",
          "infant"
        ],
        "predictions": [
          {
            "score": 0.7014586329460144,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.6557662487030029,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6297692656517029,
            "answer": "elf",
            "hit": false
          },
          {
            "score": 0.6192327737808228,
            "answer": "all",
            "hit": false
          },
          {
            "score": 0.6152024865150452,
            "answer": "own",
            "hit": false
          },
          {
            "score": 0.6126188039779663,
            "answer": "esa",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 283,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5620028860867023
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.7256782650947571,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.6675182580947876,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.6520916223526001,
            "answer": "cubs",
            "hit": false
          },
          {
            "score": 0.6481791734695435,
            "answer": "eagle",
            "hit": false
          },
          {
            "score": 0.6377838850021362,
            "answer": "buck",
            "hit": false
          },
          {
            "score": 0.637115478515625,
            "answer": "beast",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7256782650947571
      },
      {
        "question verbose": "What is to buffalo ",
        "b": "buffalo",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.6791137456893921,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6780714392662048,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.6468878984451294,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.6436557769775391,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.6400946378707886,
            "answer": "chicken",
            "hit": false
          },
          {
            "score": 0.6393520832061768,
            "answer": "cattle",
            "hit": false
          }
        ],
        "set_exclude": [
          "buffalo"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6780714988708496
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.7119137048721313,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6748980283737183,
            "answer": "kid",
            "hit": false
          },
          {
            "score": 0.6698318719863892,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.6635403633117676,
            "answer": "circus",
            "hit": false
          },
          {
            "score": 0.6572371125221252,
            "answer": "eagle",
            "hit": false
          },
          {
            "score": 0.6463634967803955,
            "answer": "animal",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6325491964817047
      },
      {
        "question verbose": "What is to goat ",
        "b": "goat",
        "expected answer": [
          "kid"
        ],
        "predictions": [
          {
            "score": 0.7106209397315979,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6877890825271606,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.6448112726211548,
            "answer": "pig",
            "hit": false
          },
          {
            "score": 0.6395285129547119,
            "answer": "goose",
            "hit": false
          },
          {
            "score": 0.6377977728843689,
            "answer": "dwarf",
            "hit": false
          },
          {
            "score": 0.635402262210846,
            "answer": "calf",
            "hit": false
          }
        ],
        "set_exclude": [
          "goat"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6068745478987694
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.6999818086624146,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6569768786430359,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.6380807161331177,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.6375608444213867,
            "answer": "lump",
            "hit": false
          },
          {
            "score": 0.6342563629150391,
            "answer": "puppy",
            "hit": false
          },
          {
            "score": 0.6333396434783936,
            "answer": "kidney",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6276366710662842
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "infant"
        ],
        "predictions": [
          {
            "score": 0.7978762984275818,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.6755104064941406,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6600290536880493,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6581950783729553,
            "answer": "puppy",
            "hit": false
          },
          {
            "score": 0.645011305809021,
            "answer": "babies",
            "hit": false
          },
          {
            "score": 0.6421092748641968,
            "answer": "mouse",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 39,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6042740941047668
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "pup"
        ],
        "predictions": [
          {
            "score": 0.7999969124794006,
            "answer": "seals",
            "hit": false
          },
          {
            "score": 0.7852526903152466,
            "answer": "sealing",
            "hit": false
          },
          {
            "score": 0.7390826940536499,
            "answer": "sealed",
            "hit": false
          },
          {
            "score": 0.6670054197311401,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6627078652381897,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6609874963760376,
            "answer": "lid",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 105,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5973388999700546
      },
      {
        "question verbose": "What is to shark ",
        "b": "shark",
        "expected answer": [
          "cub",
          "pup"
        ],
        "predictions": [
          {
            "score": 0.6693355441093445,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.6661327481269836,
            "answer": "cub",
            "hit": true
          },
          {
            "score": 0.6635534763336182,
            "answer": "kid",
            "hit": false
          },
          {
            "score": 0.6351916790008545,
            "answer": "clown",
            "hit": false
          },
          {
            "score": 0.625423014163971,
            "answer": "skull",
            "hit": false
          },
          {
            "score": 0.6252894401550293,
            "answer": "sting",
            "hit": false
          }
        ],
        "set_exclude": [
          "shark"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6661327183246613
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "cub"
        ],
        "predictions": [
          {
            "score": 0.7147241830825806,
            "answer": "calf",
            "hit": false
          },
          {
            "score": 0.6732405424118042,
            "answer": "puppy",
            "hit": false
          },
          {
            "score": 0.6715704202651978,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.6631122827529907,
            "answer": "pup",
            "hit": false
          },
          {
            "score": 0.6590045690536499,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.6516015529632568,
            "answer": "infant",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6445757448673248
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "calf"
        ],
        "predictions": [
          {
            "score": 0.8292397260665894,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7108713388442993,
            "answer": "calf",
            "hit": true
          },
          {
            "score": 0.655221700668335,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.6548429727554321,
            "answer": "cub",
            "hit": false
          },
          {
            "score": 0.6535723209381104,
            "answer": "infant",
            "hit": false
          },
          {
            "score": 0.646923303604126,
            "answer": "sperm",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7108713388442993
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 11,
      "accuracy": 0.09090909090909091
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E06 [animal - young].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "9771961e-a14d-47f4-a3cc-d9fe061d0381",
      "timestamp": "2025-05-17T17:15:34.927649"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bee ",
        "b": "bee",
        "expected answer": [
          "buzz",
          "hum"
        ],
        "predictions": [
          {
            "score": 0.6617875099182129,
            "answer": "buzz",
            "hit": true
          },
          {
            "score": 0.6519172787666321,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.6377118229866028,
            "answer": "bees",
            "hit": false
          },
          {
            "score": 0.6368483901023865,
            "answer": "berry",
            "hit": false
          },
          {
            "score": 0.6345611214637756,
            "answer": "bloom",
            "hit": false
          },
          {
            "score": 0.6276448965072632,
            "answer": "berkeley",
            "hit": false
          }
        ],
        "set_exclude": [
          "bee"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6617875397205353
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "buzz"
        ],
        "predictions": [
          {
            "score": 0.7112576365470886,
            "answer": "buzz",
            "hit": true
          },
          {
            "score": 0.6872010231018066,
            "answer": "flight",
            "hit": false
          },
          {
            "score": 0.6627252101898193,
            "answer": "travel",
            "hit": false
          },
          {
            "score": 0.6577772498130798,
            "answer": "speed",
            "hit": false
          },
          {
            "score": 0.6572126150131226,
            "answer": "radio",
            "hit": false
          },
          {
            "score": 0.6485471725463867,
            "answer": "stay",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7112576216459274
      },
      {
        "question verbose": "What is to seal ",
        "b": "seal",
        "expected answer": [
          "bark"
        ],
        "predictions": [
          {
            "score": 0.7614670991897583,
            "answer": "seals",
            "hit": false
          },
          {
            "score": 0.7433030009269714,
            "answer": "sealing",
            "hit": false
          },
          {
            "score": 0.7032358646392822,
            "answer": "sealed",
            "hit": false
          },
          {
            "score": 0.6704967617988586,
            "answer": "buzz",
            "hit": false
          },
          {
            "score": 0.6656138896942139,
            "answer": "sing",
            "hit": false
          },
          {
            "score": 0.6303172707557678,
            "answer": "crush",
            "hit": false
          }
        ],
        "set_exclude": [
          "seal"
        ],
        "rank": 1864,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5502368956804276
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sing"
        ],
        "predictions": [
          {
            "score": 0.7970552444458008,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.7134093046188354,
            "answer": "buzz",
            "hit": false
          },
          {
            "score": 0.66432785987854,
            "answer": "bark",
            "hit": false
          },
          {
            "score": 0.6595430374145508,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.6222928166389465,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.6211918592453003,
            "answer": "pirate",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 3625,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5234565995633602
      }
    ],
    "result": {
      "cnt_questions_correct": 2,
      "cnt_questions_total": 4,
      "accuracy": 0.5
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E07 [animal - sound].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "86de73c9-2385-4ff1-8199-074c36c8602f",
      "timestamp": "2025-05-17T17:15:34.962835"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ape ",
        "b": "ape",
        "expected answer": [
          "grove",
          "tree",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.686139702796936,
            "answer": "apes",
            "hit": false
          },
          {
            "score": 0.6842722296714783,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6218101382255554,
            "answer": "own",
            "hit": false
          },
          {
            "score": 0.6212617754936218,
            "answer": "esa",
            "hit": false
          },
          {
            "score": 0.6068462133407593,
            "answer": "ore",
            "hit": false
          },
          {
            "score": 0.6062648296356201,
            "answer": "all",
            "hit": false
          }
        ],
        "set_exclude": [
          "ape"
        ],
        "rank": 814,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5186666958034039
      },
      {
        "question verbose": "What is to bat ",
        "b": "bat",
        "expected answer": [
          "cave",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7157975435256958,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6301600933074951,
            "answer": "fat",
            "hit": false
          },
          {
            "score": 0.6277207136154175,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6275999546051025,
            "answer": "cap",
            "hit": false
          },
          {
            "score": 0.6252435445785522,
            "answer": "ter",
            "hit": false
          },
          {
            "score": 0.6250170469284058,
            "answer": "nor",
            "hit": false
          }
        ],
        "set_exclude": [
          "bat"
        ],
        "rank": 2517,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5081260483711958
      },
      {
        "question verbose": "What is to bear ",
        "b": "bear",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7315229773521423,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6713125705718994,
            "answer": "mountain",
            "hit": false
          },
          {
            "score": 0.6696974635124207,
            "answer": "bears",
            "hit": false
          },
          {
            "score": 0.657014012336731,
            "answer": "grove",
            "hit": false
          },
          {
            "score": 0.6542536020278931,
            "answer": "tree",
            "hit": false
          },
          {
            "score": 0.6540831327438354,
            "answer": "sea",
            "hit": false
          }
        ],
        "set_exclude": [
          "bear"
        ],
        "rank": 76,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6222602501511574
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "barn",
          "coral"
        ],
        "predictions": [
          {
            "score": 0.8120152354240417,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.7520803213119507,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.719694972038269,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7128851413726807,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6938167810440063,
            "answer": "pasture",
            "hit": false
          },
          {
            "score": 0.6934410333633423,
            "answer": "sheep",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 309,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5810472518205643
      },
      {
        "question verbose": "What is to cricket ",
        "b": "cricket",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.7278289794921875,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.7001286745071411,
            "answer": "baseball",
            "hit": false
          },
          {
            "score": 0.6938543915748596,
            "answer": "rugby",
            "hit": false
          },
          {
            "score": 0.6897874474525452,
            "answer": "tennis",
            "hit": false
          },
          {
            "score": 0.6585210561752319,
            "answer": "golf",
            "hit": false
          },
          {
            "score": 0.6507115960121155,
            "answer": "pond",
            "hit": false
          }
        ],
        "set_exclude": [
          "cricket"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7278289645910263
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7360128164291382,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6566912531852722,
            "answer": "kirk",
            "hit": false
          },
          {
            "score": 0.6547855138778687,
            "answer": "creek",
            "hit": false
          },
          {
            "score": 0.6547584533691406,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.6540167331695557,
            "answer": "dew",
            "hit": false
          },
          {
            "score": 0.6513118147850037,
            "answer": "grove",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7360128164291382
      },
      {
        "question verbose": "What is to duck ",
        "b": "duck",
        "expected answer": [
          "pond",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.759680449962616,
            "answer": "ducks",
            "hit": false
          },
          {
            "score": 0.704781174659729,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.655958354473114,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6457957029342651,
            "answer": "egg",
            "hit": false
          },
          {
            "score": 0.6358535289764404,
            "answer": "bird",
            "hit": false
          },
          {
            "score": 0.6342105865478516,
            "answer": "nests",
            "hit": false
          }
        ],
        "set_exclude": [
          "duck"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5748066008090973
      },
      {
        "question verbose": "What is to fly ",
        "b": "fly",
        "expected answer": [
          "nest"
        ],
        "predictions": [
          {
            "score": 0.6751577258110046,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6684418320655823,
            "answer": "flight",
            "hit": false
          },
          {
            "score": 0.6520907282829285,
            "answer": "travel",
            "hit": false
          },
          {
            "score": 0.6472134590148926,
            "answer": "stay",
            "hit": false
          },
          {
            "score": 0.6355470418930054,
            "answer": "ice",
            "hit": false
          },
          {
            "score": 0.6341849565505981,
            "answer": "life",
            "hit": false
          }
        ],
        "set_exclude": [
          "fly"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6751577258110046
      },
      {
        "question verbose": "What is to fox ",
        "b": "fox",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.698275089263916,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6756709814071655,
            "answer": "house",
            "hit": false
          },
          {
            "score": 0.6663668155670166,
            "answer": "cbs",
            "hit": false
          },
          {
            "score": 0.6656072735786438,
            "answer": "cnn",
            "hit": false
          },
          {
            "score": 0.6521506309509277,
            "answer": "espn",
            "hit": false
          },
          {
            "score": 0.6482194066047668,
            "answer": "abc",
            "hit": false
          }
        ],
        "set_exclude": [
          "fox"
        ],
        "rank": 427,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5867289006710052
      },
      {
        "question verbose": "What is to insect ",
        "b": "insect",
        "expected answer": [
          "nest",
          "cage",
          "box"
        ],
        "predictions": [
          {
            "score": 0.7467436790466309,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6817443370819092,
            "answer": "insects",
            "hit": false
          },
          {
            "score": 0.6636060476303101,
            "answer": "birds",
            "hit": false
          },
          {
            "score": 0.6578073501586914,
            "answer": "animal",
            "hit": false
          },
          {
            "score": 0.6521890759468079,
            "answer": "seed",
            "hit": false
          },
          {
            "score": 0.6502959728240967,
            "answer": "seeds",
            "hit": false
          }
        ],
        "set_exclude": [
          "insect"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7467436641454697
      },
      {
        "question verbose": "What is to mole ",
        "b": "mole",
        "expected answer": [
          "hole",
          "nest"
        ],
        "predictions": [
          {
            "score": 0.6954759359359741,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6664388179779053,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.5951358079910278,
            "answer": "hole",
            "hit": true
          },
          {
            "score": 0.5932185649871826,
            "answer": "cave",
            "hit": false
          },
          {
            "score": 0.5924088954925537,
            "answer": "secret",
            "hit": false
          },
          {
            "score": 0.5919594764709473,
            "answer": "nests",
            "hit": false
          }
        ],
        "set_exclude": [
          "mole"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5951357930898666
      },
      {
        "question verbose": "What is to monkey ",
        "b": "monkey",
        "expected answer": [
          "tree",
          "grove",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7925715446472168,
            "answer": "monkeys",
            "hit": false
          },
          {
            "score": 0.7064543962478638,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6606799960136414,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6386995315551758,
            "answer": "monk",
            "hit": false
          },
          {
            "score": 0.6257731914520264,
            "answer": "puppy",
            "hit": false
          },
          {
            "score": 0.6252797245979309,
            "answer": "mon",
            "hit": false
          }
        ],
        "set_exclude": [
          "monkey"
        ],
        "rank": 81,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5855742022395134
      },
      {
        "question verbose": "What is to mouse ",
        "b": "mouse",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7544000744819641,
            "answer": "mice",
            "hit": false
          },
          {
            "score": 0.6802944540977478,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6538151502609253,
            "answer": "click",
            "hit": false
          },
          {
            "score": 0.6460156440734863,
            "answer": "rodents",
            "hit": false
          },
          {
            "score": 0.6343262195587158,
            "answer": "clicking",
            "hit": false
          },
          {
            "score": 0.6342507600784302,
            "answer": "den",
            "hit": false
          }
        ],
        "set_exclude": [
          "mouse"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6802944540977478
      },
      {
        "question verbose": "What is to rat ",
        "b": "rat",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.722196638584137,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6676000952720642,
            "answer": "sal",
            "hit": false
          },
          {
            "score": 0.6605527400970459,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6589958667755127,
            "answer": "pond",
            "hit": false
          },
          {
            "score": 0.6585364937782288,
            "answer": "mat",
            "hit": false
          },
          {
            "score": 0.6537917852401733,
            "answer": "berg",
            "hit": false
          }
        ],
        "set_exclude": [
          "rat"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7221966236829758
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "nest",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7055239677429199,
            "answer": "nest",
            "hit": true
          },
          {
            "score": 0.6489624977111816,
            "answer": "den",
            "hit": false
          },
          {
            "score": 0.6450780034065247,
            "answer": "cavern",
            "hit": false
          },
          {
            "score": 0.637312650680542,
            "answer": "thirst",
            "hit": false
          },
          {
            "score": 0.6336644291877747,
            "answer": "starving",
            "hit": false
          },
          {
            "score": 0.629449725151062,
            "answer": "legion",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7055239379405975
      },
      {
        "question verbose": "What is to tiger ",
        "b": "tiger",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.7194870710372925,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6885176301002502,
            "answer": "lion",
            "hit": false
          },
          {
            "score": 0.6672868132591248,
            "answer": "tigers",
            "hit": false
          },
          {
            "score": 0.6467517614364624,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.6422557234764099,
            "answer": "cave",
            "hit": false
          },
          {
            "score": 0.6381669640541077,
            "answer": "turtle",
            "hit": false
          }
        ],
        "set_exclude": [
          "tiger"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6038847863674164
      },
      {
        "question verbose": "What is to whale ",
        "b": "whale",
        "expected answer": [
          "sea",
          "sanctuary"
        ],
        "predictions": [
          {
            "score": 0.8263088464736938,
            "answer": "whales",
            "hit": false
          },
          {
            "score": 0.6965949535369873,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6561623811721802,
            "answer": "sharks",
            "hit": false
          },
          {
            "score": 0.6465573310852051,
            "answer": "submarine",
            "hit": false
          },
          {
            "score": 0.6448728442192078,
            "answer": "salmon",
            "hit": false
          },
          {
            "score": 0.6444659233093262,
            "answer": "canoe",
            "hit": false
          }
        ],
        "set_exclude": [
          "whale"
        ],
        "rank": 21,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6215883493423462
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "den",
          "cage"
        ],
        "predictions": [
          {
            "score": 0.6964033842086792,
            "answer": "nest",
            "hit": false
          },
          {
            "score": 0.6151425242424011,
            "answer": "walker",
            "hit": false
          },
          {
            "score": 0.6085118651390076,
            "answer": "den",
            "hit": true
          },
          {
            "score": 0.605298638343811,
            "answer": "cloud",
            "hit": false
          },
          {
            "score": 0.6025946736335754,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.6019310355186462,
            "answer": "mark",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6085118651390076
      }
    ],
    "result": {
      "cnt_questions_correct": 7,
      "cnt_questions_total": 18,
      "accuracy": 0.3888888888888889
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E08 [animal - shelter].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "db4e994f-c7c2-4d34-8ea2-72784bc5aa54",
      "timestamp": "2025-05-17T17:15:34.978634"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to ant ",
        "b": "ant",
        "expected answer": [
          "black",
          "brown",
          "red"
        ],
        "predictions": [
          {
            "score": 0.7850127220153809,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.722760796546936,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6962261199951172,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6812340021133423,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6745979189872742,
            "answer": "blacks",
            "hit": false
          },
          {
            "score": 0.6631616353988647,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "ant"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6210465729236603
      },
      {
        "question verbose": "What is to apple ",
        "b": "apple",
        "expected answer": [
          "red",
          "orange",
          "yellow",
          "golden"
        ],
        "predictions": [
          {
            "score": 0.7381505966186523,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7109863758087158,
            "answer": "samsung",
            "hit": false
          },
          {
            "score": 0.6943768262863159,
            "answer": "ipad",
            "hit": false
          },
          {
            "score": 0.6854594945907593,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6796829700469971,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.679226815700531,
            "answer": "black",
            "hit": false
          }
        ],
        "set_exclude": [
          "apple"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6796829700469971
      },
      {
        "question verbose": "What is to blood ",
        "b": "blood",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7172985076904297,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7051758766174316,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.668467104434967,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.6651561260223389,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6591919660568237,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6380980014801025,
            "answer": "color",
            "hit": false
          }
        ],
        "set_exclude": [
          "blood"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6651561260223389
      },
      {
        "question verbose": "What is to cabbage ",
        "b": "cabbage",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.7418394684791565,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7339070439338684,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7323654294013977,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.727892279624939,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.727663516998291,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6945253610610962,
            "answer": "grey",
            "hit": false
          }
        ],
        "set_exclude": [
          "cabbage"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7323654294013977
      },
      {
        "question verbose": "What is to carrot ",
        "b": "carrot",
        "expected answer": [
          "orange",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7508379220962524,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7478008270263672,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7412086129188538,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7401187419891357,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7362948656082153,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.6840987205505371,
            "answer": "grey",
            "hit": false
          }
        ],
        "set_exclude": [
          "carrot"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5529408603906631
      },
      {
        "question verbose": "What is to cherry ",
        "b": "cherry",
        "expected answer": [
          "red",
          "yellow",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7099912762641907,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7003917694091797,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6957242488861084,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6864776611328125,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6846277117729187,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6747239828109741,
            "answer": "pink",
            "hit": false
          }
        ],
        "set_exclude": [
          "cherry"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6846277117729187
      },
      {
        "question verbose": "What is to chocolate ",
        "b": "chocolate",
        "expected answer": [
          "white",
          "brown",
          "black"
        ],
        "predictions": [
          {
            "score": 0.7868314981460571,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7762060165405273,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7516832947731018,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7487078905105591,
            "answer": "cocoa",
            "hit": false
          },
          {
            "score": 0.7367954254150391,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.7342695593833923,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "chocolate"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7868314981460571
      },
      {
        "question verbose": "What is to cloud ",
        "b": "cloud",
        "expected answer": [
          "white",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.6995177268981934,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6714640855789185,
            "answer": "clouds",
            "hit": false
          },
          {
            "score": 0.6679297089576721,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.6653578281402588,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6609470844268799,
            "answer": "gray",
            "hit": true
          },
          {
            "score": 0.6518146395683289,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloud"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6653578579425812
      },
      {
        "question verbose": "What is to coal ",
        "b": "coal",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7817997336387634,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7434345483779907,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7413994073867798,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7392251491546631,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7101640701293945,
            "answer": "fossil",
            "hit": false
          },
          {
            "score": 0.6918410062789917,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "coal"
        ],
        "rank": 139,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6041207611560822
      },
      {
        "question verbose": "What is to coffee ",
        "b": "coffee",
        "expected answer": [
          "black",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7798666954040527,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7527776956558228,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7511746883392334,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7359474897384644,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.724528431892395,
            "answer": "tea",
            "hit": false
          },
          {
            "score": 0.7115365266799927,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "coffee"
        ],
        "rank": 98,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.615827739238739
      },
      {
        "question verbose": "What is to cream ",
        "b": "cream",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7823517322540283,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7649549245834351,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7499648332595825,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7378920912742615,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7302525639533997,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.7121155858039856,
            "answer": "creamy",
            "hit": false
          }
        ],
        "set_exclude": [
          "cream"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7823517322540283
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7259594202041626,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7049835324287415,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6771106719970703,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6670408844947815,
            "answer": "whites",
            "hit": false
          },
          {
            "score": 0.6650292873382568,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6632511615753174,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7049835622310638
      },
      {
        "question verbose": "What is to fridge ",
        "b": "fridge",
        "expected answer": [
          "white",
          "silver",
          "black"
        ],
        "predictions": [
          {
            "score": 0.8429645299911499,
            "answer": "refrigerator",
            "hit": false
          },
          {
            "score": 0.7187230587005615,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7000390887260437,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6941018104553223,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.6879760026931763,
            "answer": "closet",
            "hit": false
          },
          {
            "score": 0.6834055185317993,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "fridge"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7187230587005615
      },
      {
        "question verbose": "What is to frog ",
        "b": "frog",
        "expected answer": [
          "green",
          "brown",
          "grey",
          "gray"
        ],
        "predictions": [
          {
            "score": 0.6959908604621887,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6842889785766602,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6808853149414062,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6610236763954163,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.6524200439453125,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6471995115280151,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "frog"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6610236763954163
      },
      {
        "question verbose": "What is to grapes ",
        "b": "grapes",
        "expected answer": [
          "black",
          "red",
          "green",
          "purple"
        ],
        "predictions": [
          {
            "score": 0.7518683671951294,
            "answer": "grape",
            "hit": false
          },
          {
            "score": 0.7307450771331787,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7297978401184082,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7156893014907837,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7146883606910706,
            "answer": "purple",
            "hit": true
          },
          {
            "score": 0.7084929347038269,
            "answer": "green",
            "hit": true
          }
        ],
        "set_exclude": [
          "grapes"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6104713976383209
      },
      {
        "question verbose": "What is to grass ",
        "b": "grass",
        "expected answer": [
          "green"
        ],
        "predictions": [
          {
            "score": 0.7052707672119141,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6940313577651978,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6650381684303284,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6634660363197327,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6580374836921692,
            "answer": "gray",
            "hit": false
          },
          {
            "score": 0.6551072597503662,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "grass"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6538679301738739
      },
      {
        "question verbose": "What is to leaves ",
        "b": "leaves",
        "expected answer": [
          "green",
          "red",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7449033856391907,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7097067832946777,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7054613828659058,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6969907283782959,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.6920537948608398,
            "answer": "leaving",
            "hit": false
          },
          {
            "score": 0.6771685481071472,
            "answer": "leaf",
            "hit": false
          }
        ],
        "set_exclude": [
          "leaves"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6969907432794571
      },
      {
        "question verbose": "What is to milk ",
        "b": "milk",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7755248546600342,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7462089657783508,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7445893883705139,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7207134962081909,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7026855945587158,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.6849114298820496,
            "answer": "grey",
            "hit": false
          }
        ],
        "set_exclude": [
          "milk"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.775524914264679
      },
      {
        "question verbose": "What is to paper ",
        "b": "paper",
        "expected answer": [
          "white",
          "color"
        ],
        "predictions": [
          {
            "score": 0.6964011192321777,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6752158999443054,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6539925336837769,
            "answer": "gray",
            "hit": false
          },
          {
            "score": 0.6484268307685852,
            "answer": "color",
            "hit": true
          },
          {
            "score": 0.6457011699676514,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.6407603025436401,
            "answer": "colored",
            "hit": false
          }
        ],
        "set_exclude": [
          "paper"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6752159148454666
      },
      {
        "question verbose": "What is to pepper ",
        "b": "pepper",
        "expected answer": [
          "black",
          "red",
          "green",
          "yellow",
          "orange"
        ],
        "predictions": [
          {
            "score": 0.774177610874176,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7558491230010986,
            "answer": "peppers",
            "hit": false
          },
          {
            "score": 0.7457162141799927,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.713560938835144,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.7126410603523254,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.6998965740203857,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "pepper"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6469919234514236
      },
      {
        "question verbose": "What is to potato ",
        "b": "potato",
        "expected answer": [
          "brown"
        ],
        "predictions": [
          {
            "score": 0.788305401802063,
            "answer": "potatoes",
            "hit": false
          },
          {
            "score": 0.772138237953186,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7393209934234619,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7203024625778198,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7175556421279907,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7084041833877563,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "potato"
        ],
        "rank": 65,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6134258359670639
      },
      {
        "question verbose": "What is to raven ",
        "b": "raven",
        "expected answer": [
          "black"
        ],
        "predictions": [
          {
            "score": 0.7595077753067017,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7454947233200073,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7223125696182251,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7199870347976685,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.7049708366394043,
            "answer": "grey",
            "hit": false
          },
          {
            "score": 0.6896899938583374,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "raven"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6477334201335907
      },
      {
        "question verbose": "What is to rose ",
        "b": "rose",
        "expected answer": [
          "red",
          "yellow",
          "pink",
          "white",
          "blue"
        ],
        "predictions": [
          {
            "score": 0.7333155870437622,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.699555516242981,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6974637508392334,
            "answer": "pink",
            "hit": true
          },
          {
            "score": 0.6972609758377075,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6832075119018555,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6756761074066162,
            "answer": "blue",
            "hit": true
          }
        ],
        "set_exclude": [
          "rose"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.699555516242981
      },
      {
        "question verbose": "What is to ruby ",
        "b": "ruby",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.7854894399642944,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.7319199442863464,
            "answer": "weiss",
            "hit": false
          },
          {
            "score": 0.700474739074707,
            "answer": "blake",
            "hit": false
          },
          {
            "score": 0.678143322467804,
            "answer": "gold",
            "hit": false
          },
          {
            "score": 0.6729222536087036,
            "answer": "crystal",
            "hit": false
          },
          {
            "score": 0.6598037481307983,
            "answer": "clinton",
            "hit": false
          }
        ],
        "set_exclude": [
          "ruby"
        ],
        "rank": 51,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6268648207187653
      },
      {
        "question verbose": "What is to salt ",
        "b": "salt",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7691821455955505,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6663895845413208,
            "answer": "gold",
            "hit": false
          },
          {
            "score": 0.6652249097824097,
            "answer": "philadelphia",
            "hit": false
          },
          {
            "score": 0.661041796207428,
            "answer": "baltimore",
            "hit": false
          },
          {
            "score": 0.6586928367614746,
            "answer": "dallas",
            "hit": false
          },
          {
            "score": 0.6573396921157837,
            "answer": "portland",
            "hit": false
          }
        ],
        "set_exclude": [
          "salt"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6514494866132736
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "blue",
          "green",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7132472991943359,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.705548107624054,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6926035284996033,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.692463755607605,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6815440654754639,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.6540818810462952,
            "answer": "red",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6815440356731415
      },
      {
        "question verbose": "What is to sky ",
        "b": "sky",
        "expected answer": [
          "blue",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7101286053657532,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6937294006347656,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6931970715522766,
            "answer": "blue",
            "hit": true
          },
          {
            "score": 0.6854801177978516,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6822051405906677,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.670378565788269,
            "answer": "green",
            "hit": false
          }
        ],
        "set_exclude": [
          "sky"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6931970566511154
      },
      {
        "question verbose": "What is to snow ",
        "b": "snow",
        "expected answer": [
          "white"
        ],
        "predictions": [
          {
            "score": 0.7227641344070435,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7105517387390137,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6987378597259521,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6894734501838684,
            "answer": "winter",
            "hit": false
          },
          {
            "score": 0.6851276159286499,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6766171455383301,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "snow"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7227641642093658
      },
      {
        "question verbose": "What is to soil ",
        "b": "soil",
        "expected answer": [
          "black",
          "brown",
          "dark"
        ],
        "predictions": [
          {
            "score": 0.7721148133277893,
            "answer": "soils",
            "hit": false
          },
          {
            "score": 0.7665366530418396,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.7349733710289001,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.714958667755127,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.7145663499832153,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7129238843917847,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "soil"
        ],
        "rank": 495,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5856674760580063
      },
      {
        "question verbose": "What is to sugar ",
        "b": "sugar",
        "expected answer": [
          "white",
          "brown"
        ],
        "predictions": [
          {
            "score": 0.7915223240852356,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7647059559822083,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.7359621524810791,
            "answer": "green",
            "hit": false
          },
          {
            "score": 0.7348430156707764,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6973424553871155,
            "answer": "glucose",
            "hit": false
          },
          {
            "score": 0.696836531162262,
            "answer": "purple",
            "hit": false
          }
        ],
        "set_exclude": [
          "sugar"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7915223240852356
      },
      {
        "question verbose": "What is to sun ",
        "b": "sun",
        "expected answer": [
          "yellow",
          "gold"
        ],
        "predictions": [
          {
            "score": 0.7374179363250732,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6985586285591125,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.6883601546287537,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6874613761901855,
            "answer": "yellow",
            "hit": true
          },
          {
            "score": 0.6848831176757812,
            "answer": "sat",
            "hit": false
          },
          {
            "score": 0.6758307218551636,
            "answer": "black",
            "hit": false
          }
        ],
        "set_exclude": [
          "sun"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6874613761901855
      },
      {
        "question verbose": "What is to swan ",
        "b": "swan",
        "expected answer": [
          "white",
          "black",
          "gray",
          "grey"
        ],
        "predictions": [
          {
            "score": 0.7139493823051453,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.6906644105911255,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.6785116195678711,
            "answer": "red",
            "hit": false
          },
          {
            "score": 0.674960732460022,
            "answer": "black",
            "hit": true
          },
          {
            "score": 0.6502622365951538,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.6466666460037231,
            "answer": "whites",
            "hit": false
          }
        ],
        "set_exclude": [
          "swan"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7139493972063065
      },
      {
        "question verbose": "What is to tea ",
        "b": "tea",
        "expected answer": [
          "black",
          "green",
          "white",
          "red",
          "brown",
          "yellow"
        ],
        "predictions": [
          {
            "score": 0.7920166850090027,
            "answer": "white",
            "hit": true
          },
          {
            "score": 0.7447329759597778,
            "answer": "blue",
            "hit": false
          },
          {
            "score": 0.7336158752441406,
            "answer": "green",
            "hit": true
          },
          {
            "score": 0.7256741523742676,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.7211801409721375,
            "answer": "purple",
            "hit": false
          },
          {
            "score": 0.7176952362060547,
            "answer": "coffee",
            "hit": false
          }
        ],
        "set_exclude": [
          "tea"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6083831265568733
      },
      {
        "question verbose": "What is to tomato ",
        "b": "tomato",
        "expected answer": [
          "red"
        ],
        "predictions": [
          {
            "score": 0.6911978721618652,
            "answer": "white",
            "hit": false
          },
          {
            "score": 0.6894350051879883,
            "answer": "yellow",
            "hit": false
          },
          {
            "score": 0.683442234992981,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.674646258354187,
            "answer": "tomatoes",
            "hit": false
          },
          {
            "score": 0.6704145073890686,
            "answer": "red",
            "hit": true
          },
          {
            "score": 0.6683923602104187,
            "answer": "blue",
            "hit": false
          }
        ],
        "set_exclude": [
          "tomato"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6704144924879074
      }
    ],
    "result": {
      "cnt_questions_correct": 9,
      "cnt_questions_total": 34,
      "accuracy": 0.2647058823529412
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E09 [things - color].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "af367906-ea14-4ec7-91d3-0a81f24eac15",
      "timestamp": "2025-05-17T17:15:35.040045"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to actor ",
        "b": "actor",
        "expected answer": [
          "actress"
        ],
        "predictions": [
          {
            "score": 0.8396719694137573,
            "answer": "actors",
            "hit": false
          },
          {
            "score": 0.7481659650802612,
            "answer": "actresses",
            "hit": false
          },
          {
            "score": 0.7473478317260742,
            "answer": "comedian",
            "hit": false
          },
          {
            "score": 0.7424017786979675,
            "answer": "singer",
            "hit": false
          },
          {
            "score": 0.7422442436218262,
            "answer": "filmmaker",
            "hit": false
          },
          {
            "score": 0.7336833477020264,
            "answer": "actress",
            "hit": true
          }
        ],
        "set_exclude": [
          "actor"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7336833775043488
      },
      {
        "question verbose": "What is to boy ",
        "b": "boy",
        "expected answer": [
          "girl"
        ],
        "predictions": [
          {
            "score": 0.8167171478271484,
            "answer": "boys",
            "hit": false
          },
          {
            "score": 0.8000826239585876,
            "answer": "girl",
            "hit": true
          },
          {
            "score": 0.662722647190094,
            "answer": "woman",
            "hit": false
          },
          {
            "score": 0.652595579624176,
            "answer": "baby",
            "hit": false
          },
          {
            "score": 0.6452343463897705,
            "answer": "guy",
            "hit": false
          },
          {
            "score": 0.6430270075798035,
            "answer": "wife",
            "hit": false
          }
        ],
        "set_exclude": [
          "boy"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8000826239585876
      },
      {
        "question verbose": "What is to brother ",
        "b": "brother",
        "expected answer": [
          "sister"
        ],
        "predictions": [
          {
            "score": 0.7873881459236145,
            "answer": "brothers",
            "hit": false
          },
          {
            "score": 0.783160924911499,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.7816420197486877,
            "answer": "sibling",
            "hit": false
          },
          {
            "score": 0.7615789771080017,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.7537310123443604,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.743659257888794,
            "answer": "siblings",
            "hit": false
          }
        ],
        "set_exclude": [
          "brother"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7196384370326996
      },
      {
        "question verbose": "What is to buck ",
        "b": "buck",
        "expected answer": [
          "doe"
        ],
        "predictions": [
          {
            "score": 0.6615157127380371,
            "answer": "betty",
            "hit": false
          },
          {
            "score": 0.6563659310340881,
            "answer": "cow",
            "hit": false
          },
          {
            "score": 0.6544855833053589,
            "answer": "ruth",
            "hit": false
          },
          {
            "score": 0.6535937786102295,
            "answer": "bree",
            "hit": false
          },
          {
            "score": 0.6524913907051086,
            "answer": "chuck",
            "hit": false
          },
          {
            "score": 0.6486320495605469,
            "answer": "kate",
            "hit": false
          }
        ],
        "set_exclude": [
          "buck"
        ],
        "rank": 3463,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5263697169721127
      },
      {
        "question verbose": "What is to bull ",
        "b": "bull",
        "expected answer": [
          "cow"
        ],
        "predictions": [
          {
            "score": 0.6249885559082031,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.6223486661911011,
            "answer": "woman",
            "hit": false
          },
          {
            "score": 0.6184266805648804,
            "answer": "bullying",
            "hit": false
          },
          {
            "score": 0.6119861602783203,
            "answer": "abortion",
            "hit": false
          },
          {
            "score": 0.6089221835136414,
            "answer": "lgbt",
            "hit": false
          },
          {
            "score": 0.6068626642227173,
            "answer": "lady",
            "hit": false
          }
        ],
        "set_exclude": [
          "bull"
        ],
        "rank": 218,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5687696114182472
      },
      {
        "question verbose": "What is to dad ",
        "b": "dad",
        "expected answer": [
          "mom",
          "mum"
        ],
        "predictions": [
          {
            "score": 0.6608182191848755,
            "answer": "mom",
            "hit": true
          },
          {
            "score": 0.6468033790588379,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.6402638554573059,
            "answer": "kids",
            "hit": false
          },
          {
            "score": 0.6390186548233032,
            "answer": "father",
            "hit": false
          },
          {
            "score": 0.6363216638565063,
            "answer": "bride",
            "hit": false
          },
          {
            "score": 0.6340161561965942,
            "answer": "wife",
            "hit": false
          }
        ],
        "set_exclude": [
          "dad"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6608182191848755
      },
      {
        "question verbose": "What is to duke ",
        "b": "duke",
        "expected answer": [
          "duchess"
        ],
        "predictions": [
          {
            "score": 0.740792989730835,
            "answer": "duchess",
            "hit": true
          },
          {
            "score": 0.6869857311248779,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.6864839792251587,
            "answer": "durham",
            "hit": false
          },
          {
            "score": 0.6834288239479065,
            "answer": "earl",
            "hit": false
          },
          {
            "score": 0.6721141934394836,
            "answer": "yale",
            "hit": false
          },
          {
            "score": 0.6717091798782349,
            "answer": "diana",
            "hit": false
          }
        ],
        "set_exclude": [
          "duke"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.740792989730835
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "mother"
        ],
        "predictions": [
          {
            "score": 0.6991155743598938,
            "answer": "wife",
            "hit": false
          },
          {
            "score": 0.6630412340164185,
            "answer": "wives",
            "hit": false
          },
          {
            "score": 0.6619808673858643,
            "answer": "dad",
            "hit": false
          },
          {
            "score": 0.6542904376983643,
            "answer": "lady",
            "hit": false
          },
          {
            "score": 0.6529510021209717,
            "answer": "woman",
            "hit": false
          },
          {
            "score": 0.6522001028060913,
            "answer": "fathers",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6328206956386566
      },
      {
        "question verbose": "What is to god ",
        "b": "god",
        "expected answer": [
          "goddess"
        ],
        "predictions": [
          {
            "score": 0.6638338565826416,
            "answer": "lord",
            "hit": false
          },
          {
            "score": 0.657012939453125,
            "answer": "allah",
            "hit": false
          },
          {
            "score": 0.6504865884780884,
            "answer": "one",
            "hit": false
          },
          {
            "score": 0.6487777233123779,
            "answer": "dark",
            "hit": false
          },
          {
            "score": 0.6465684175491333,
            "answer": "goddess",
            "hit": true
          },
          {
            "score": 0.6446609497070312,
            "answer": "world",
            "hit": false
          }
        ],
        "set_exclude": [
          "god"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6465684175491333
      },
      {
        "question verbose": "What is to grandfather ",
        "b": "grandfather",
        "expected answer": [
          "grandmother"
        ],
        "predictions": [
          {
            "score": 0.8711833953857422,
            "answer": "grandmother",
            "hit": true
          },
          {
            "score": 0.8169507384300232,
            "answer": "grandparents",
            "hit": false
          },
          {
            "score": 0.7808114290237427,
            "answer": "mother",
            "hit": false
          },
          {
            "score": 0.7418743371963501,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.7072232961654663,
            "answer": "grandchildren",
            "hit": false
          },
          {
            "score": 0.7053483724594116,
            "answer": "parents",
            "hit": false
          }
        ],
        "set_exclude": [
          "grandfather"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8711834251880646
      },
      {
        "question verbose": "What is to groom ",
        "b": "groom",
        "expected answer": [
          "bride"
        ],
        "predictions": [
          {
            "score": 0.6622608304023743,
            "answer": "wedding",
            "hit": false
          },
          {
            "score": 0.6469911932945251,
            "answer": "niece",
            "hit": false
          },
          {
            "score": 0.6423636674880981,
            "answer": "queen",
            "hit": false
          },
          {
            "score": 0.6415110230445862,
            "answer": "marry",
            "hit": false
          },
          {
            "score": 0.640765368938446,
            "answer": "nurse",
            "hit": false
          },
          {
            "score": 0.636520266532898,
            "answer": "dancer",
            "hit": false
          }
        ],
        "set_exclude": [
          "groom"
        ],
        "rank": 208,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5870055854320526
      },
      {
        "question verbose": "What is to husband ",
        "b": "husband",
        "expected answer": [
          "wife"
        ],
        "predictions": [
          {
            "score": 0.7740404605865479,
            "answer": "wife",
            "hit": true
          },
          {
            "score": 0.7001819610595703,
            "answer": "wives",
            "hit": false
          },
          {
            "score": 0.689956784248352,
            "answer": "married",
            "hit": false
          },
          {
            "score": 0.6837344169616699,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.6720048189163208,
            "answer": "woman",
            "hit": false
          },
          {
            "score": 0.6563975811004639,
            "answer": "bride",
            "hit": false
          }
        ],
        "set_exclude": [
          "husband"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7740404307842255
      },
      {
        "question verbose": "What is to king ",
        "b": "king",
        "expected answer": [
          "queen"
        ],
        "predictions": [
          {
            "score": 0.7346159219741821,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.6959311962127686,
            "answer": "emperor",
            "hit": false
          },
          {
            "score": 0.6881641149520874,
            "answer": "queen",
            "hit": true
          },
          {
            "score": 0.6708356142044067,
            "answer": "crown",
            "hit": false
          },
          {
            "score": 0.6701460480690002,
            "answer": "bishop",
            "hit": false
          },
          {
            "score": 0.6657000184059143,
            "answer": "duke",
            "hit": false
          }
        ],
        "set_exclude": [
          "king"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.688164159655571
      },
      {
        "question verbose": "What is to man ",
        "b": "man",
        "expected answer": [
          "woman"
        ],
        "predictions": [
          {
            "score": 0.7981036901473999,
            "answer": "men",
            "hit": false
          },
          {
            "score": 0.7192862033843994,
            "answer": "person",
            "hit": false
          },
          {
            "score": 0.6997215747833252,
            "answer": "girl",
            "hit": false
          },
          {
            "score": 0.6931963562965393,
            "answer": "woman",
            "hit": true
          },
          {
            "score": 0.6534892320632935,
            "answer": "wife",
            "hit": false
          },
          {
            "score": 0.6362913250923157,
            "answer": "guy",
            "hit": false
          }
        ],
        "set_exclude": [
          "man"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6931963562965393
      },
      {
        "question verbose": "What is to nephew ",
        "b": "nephew",
        "expected answer": [
          "niece"
        ],
        "predictions": [
          {
            "score": 0.8685723543167114,
            "answer": "niece",
            "hit": true
          },
          {
            "score": 0.7948576807975769,
            "answer": "grandson",
            "hit": false
          },
          {
            "score": 0.7529392242431641,
            "answer": "cousin",
            "hit": false
          },
          {
            "score": 0.7500617504119873,
            "answer": "daughters",
            "hit": false
          },
          {
            "score": 0.7157202959060669,
            "answer": "brother",
            "hit": false
          },
          {
            "score": 0.7130501866340637,
            "answer": "cousins",
            "hit": false
          }
        ],
        "set_exclude": [
          "nephew"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8685723841190338
      },
      {
        "question verbose": "What is to prince ",
        "b": "prince",
        "expected answer": [
          "princess"
        ],
        "predictions": [
          {
            "score": 0.8091980814933777,
            "answer": "princes",
            "hit": false
          },
          {
            "score": 0.7291444540023804,
            "answer": "royal",
            "hit": false
          },
          {
            "score": 0.7272969484329224,
            "answer": "queen",
            "hit": false
          },
          {
            "score": 0.7052353024482727,
            "answer": "princess",
            "hit": true
          },
          {
            "score": 0.6989217400550842,
            "answer": "kingdom",
            "hit": false
          },
          {
            "score": 0.6916975378990173,
            "answer": "goddess",
            "hit": false
          }
        ],
        "set_exclude": [
          "prince"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7052353322505951
      },
      {
        "question verbose": "What is to son ",
        "b": "son",
        "expected answer": [
          "daughter"
        ],
        "predictions": [
          {
            "score": 0.6991678476333618,
            "answer": "mom",
            "hit": false
          },
          {
            "score": 0.6894044876098633,
            "answer": "daughter",
            "hit": true
          },
          {
            "score": 0.6857117414474487,
            "answer": "woman",
            "hit": false
          },
          {
            "score": 0.671198308467865,
            "answer": "lady",
            "hit": false
          },
          {
            "score": 0.6702703237533569,
            "answer": "susan",
            "hit": false
          },
          {
            "score": 0.6654643416404724,
            "answer": "two",
            "hit": false
          }
        ],
        "set_exclude": [
          "son"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6894044578075409
      },
      {
        "question verbose": "What is to uncle ",
        "b": "uncle",
        "expected answer": [
          "aunt"
        ],
        "predictions": [
          {
            "score": 0.7089545726776123,
            "answer": "mama",
            "hit": false
          },
          {
            "score": 0.70733642578125,
            "answer": "sister",
            "hit": false
          },
          {
            "score": 0.7003238797187805,
            "answer": "mrs",
            "hit": false
          },
          {
            "score": 0.6731989979743958,
            "answer": "daddy",
            "hit": false
          },
          {
            "score": 0.6639988422393799,
            "answer": "daughter",
            "hit": false
          },
          {
            "score": 0.6625368595123291,
            "answer": "mum",
            "hit": false
          }
        ],
        "set_exclude": [
          "uncle"
        ],
        "rank": 3052,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5330687426030636
      }
    ],
    "result": {
      "cnt_questions_correct": 5,
      "cnt_questions_total": 18,
      "accuracy": 0.2777777777777778
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "3_Encyclopedic_semantics",
      "subcategory": "E10 [male - female].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "c7fd2a74-4672-4d96-8025-b5a6f72e1e2c",
      "timestamp": "2025-05-17T17:15:35.161069"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to atmosphere ",
        "b": "atmosphere",
        "expected answer": [
          "gas",
          "oxygen",
          "hydrogen",
          "nitrogen",
          "ozone"
        ],
        "predictions": [
          {
            "score": 0.7452988028526306,
            "answer": "atmospheric",
            "hit": false
          },
          {
            "score": 0.6896967887878418,
            "answer": "attitude",
            "hit": false
          },
          {
            "score": 0.6834251880645752,
            "answer": "vibe",
            "hit": false
          },
          {
            "score": 0.6824035048484802,
            "answer": "ambient",
            "hit": false
          },
          {
            "score": 0.6744954586029053,
            "answer": "environments",
            "hit": false
          },
          {
            "score": 0.674136757850647,
            "answer": "vegetation",
            "hit": false
          }
        ],
        "set_exclude": [
          "atmosphere"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.48561642691493034
      },
      {
        "question verbose": "What is to bag ",
        "b": "bag",
        "expected answer": [
          "leather",
          "fabric",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.7107678651809692,
            "answer": "bags",
            "hit": false
          },
          {
            "score": 0.6382290124893188,
            "answer": "boy",
            "hit": false
          },
          {
            "score": 0.6380874514579773,
            "answer": "belt",
            "hit": false
          },
          {
            "score": 0.6327040195465088,
            "answer": "balls",
            "hit": false
          },
          {
            "score": 0.6292832493782043,
            "answer": "bike",
            "hit": false
          },
          {
            "score": 0.6184484362602234,
            "answer": "card",
            "hit": false
          }
        ],
        "set_exclude": [
          "bag"
        ],
        "rank": 281,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.563449814915657
      },
      {
        "question verbose": "What is to beard ",
        "b": "beard",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.6068440079689026,
            "answer": "hard",
            "hit": false
          },
          {
            "score": 0.604674756526947,
            "answer": "grass",
            "hit": false
          },
          {
            "score": 0.6029547452926636,
            "answer": "hairs",
            "hit": false
          },
          {
            "score": 0.6006581783294678,
            "answer": "boys",
            "hit": false
          },
          {
            "score": 0.5992467999458313,
            "answer": "horn",
            "hit": false
          },
          {
            "score": 0.5991515517234802,
            "answer": "hand",
            "hit": false
          }
        ],
        "set_exclude": [
          "beard"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5986224636435509
      },
      {
        "question verbose": "What is to body ",
        "b": "body",
        "expected answer": [
          "flesh",
          "bones"
        ],
        "predictions": [
          {
            "score": 0.6673157215118408,
            "answer": "bodies",
            "hit": false
          },
          {
            "score": 0.6659590005874634,
            "answer": "black",
            "hit": false
          },
          {
            "score": 0.6618515253067017,
            "answer": "cell",
            "hit": false
          },
          {
            "score": 0.6592956781387329,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6561927199363708,
            "answer": "female",
            "hit": false
          },
          {
            "score": 0.6541740298271179,
            "answer": "material",
            "hit": false
          }
        ],
        "set_exclude": [
          "body"
        ],
        "rank": 602,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5443177744746208
      },
      {
        "question verbose": "What is to boots ",
        "b": "boots",
        "expected answer": [
          "leather",
          "canvas"
        ],
        "predictions": [
          {
            "score": 0.7383281588554382,
            "answer": "shoes",
            "hit": false
          },
          {
            "score": 0.7051900625228882,
            "answer": "gloves",
            "hit": false
          },
          {
            "score": 0.6856051683425903,
            "answer": "boot",
            "hit": false
          },
          {
            "score": 0.6806529760360718,
            "answer": "legs",
            "hit": false
          },
          {
            "score": 0.6722553968429565,
            "answer": "leather",
            "hit": true
          },
          {
            "score": 0.6524696946144104,
            "answer": "helmet",
            "hit": false
          }
        ],
        "set_exclude": [
          "boots"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6722554266452789
      },
      {
        "question verbose": "What is to bottle ",
        "b": "bottle",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.858147382736206,
            "answer": "bottles",
            "hit": false
          },
          {
            "score": 0.7333662509918213,
            "answer": "beer",
            "hit": false
          },
          {
            "score": 0.732832133769989,
            "answer": "drink",
            "hit": false
          },
          {
            "score": 0.7150485515594482,
            "answer": "water",
            "hit": false
          },
          {
            "score": 0.6999610662460327,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.6973276734352112,
            "answer": "beverage",
            "hit": false
          }
        ],
        "set_exclude": [
          "bottle"
        ],
        "rank": 1708,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5661238878965378
      },
      {
        "question verbose": "What is to bowl ",
        "b": "bowl",
        "expected answer": [
          "glass",
          "china",
          "aluminium",
          "wood",
          "steel",
          "plastic",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.701628565788269,
            "answer": "bowls",
            "hit": false
          },
          {
            "score": 0.6212814450263977,
            "answer": "basketball",
            "hit": false
          },
          {
            "score": 0.6197662353515625,
            "answer": "fruit",
            "hit": false
          },
          {
            "score": 0.6138226389884949,
            "answer": "brown",
            "hit": false
          },
          {
            "score": 0.6110227108001709,
            "answer": "balls",
            "hit": false
          },
          {
            "score": 0.6104641556739807,
            "answer": "belt",
            "hit": false
          }
        ],
        "set_exclude": [
          "bowl"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5967437103390694
      },
      {
        "question verbose": "What is to cocktail ",
        "b": "cocktail",
        "expected answer": [
          "alcohol",
          "juice",
          "water"
        ],
        "predictions": [
          {
            "score": 0.7100872993469238,
            "answer": "drink",
            "hit": false
          },
          {
            "score": 0.693936824798584,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.6937142014503479,
            "answer": "drinks",
            "hit": false
          },
          {
            "score": 0.6925133466720581,
            "answer": "whiskey",
            "hit": false
          },
          {
            "score": 0.6893251538276672,
            "answer": "beer",
            "hit": false
          },
          {
            "score": 0.6848981380462646,
            "answer": "vodka",
            "hit": false
          }
        ],
        "set_exclude": [
          "cocktail"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5996014922857285
      },
      {
        "question verbose": "What is to desk ",
        "b": "desk",
        "expected answer": [
          "wood",
          "metal",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.6661901473999023,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6300435066223145,
            "answer": "monitor",
            "hit": false
          },
          {
            "score": 0.6232813000679016,
            "answer": "pocket",
            "hit": false
          },
          {
            "score": 0.6194647550582886,
            "answer": "battery",
            "hit": false
          },
          {
            "score": 0.6184079647064209,
            "answer": "website",
            "hit": false
          },
          {
            "score": 0.6138456463813782,
            "answer": "view",
            "hit": false
          }
        ],
        "set_exclude": [
          "desk"
        ],
        "rank": 659,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5238460469990969
      },
      {
        "question verbose": "What is to diamond ",
        "b": "diamond",
        "expected answer": [
          "carbon"
        ],
        "predictions": [
          {
            "score": 0.8378562927246094,
            "answer": "diamonds",
            "hit": false
          },
          {
            "score": 0.7238693237304688,
            "answer": "platinum",
            "hit": false
          },
          {
            "score": 0.7064406275749207,
            "answer": "copper",
            "hit": false
          },
          {
            "score": 0.7026214599609375,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.6959214210510254,
            "answer": "granite",
            "hit": false
          },
          {
            "score": 0.6908098459243774,
            "answer": "silver",
            "hit": false
          }
        ],
        "set_exclude": [
          "diamond"
        ],
        "rank": 7240,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5192443486303091
      },
      {
        "question verbose": "What is to flag ",
        "b": "flag",
        "expected answer": [
          "fabric",
          "paper"
        ],
        "predictions": [
          {
            "score": 0.7287998199462891,
            "answer": "flags",
            "hit": false
          },
          {
            "score": 0.632030725479126,
            "answer": "color",
            "hit": false
          },
          {
            "score": 0.6176724433898926,
            "answer": "property",
            "hit": false
          },
          {
            "score": 0.6139702796936035,
            "answer": "font",
            "hit": false
          },
          {
            "score": 0.6134234070777893,
            "answer": "stat",
            "hit": false
          },
          {
            "score": 0.6122305989265442,
            "answer": "armor",
            "hit": false
          }
        ],
        "set_exclude": [
          "flag"
        ],
        "rank": 91,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5357182174921036
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "bricks",
          "cement",
          "wood",
          "clay"
        ],
        "predictions": [
          {
            "score": 0.7159435153007507,
            "answer": "rep",
            "hit": false
          },
          {
            "score": 0.6932660341262817,
            "answer": "houses",
            "hit": false
          },
          {
            "score": 0.6832841038703918,
            "answer": "congress",
            "hit": false
          },
          {
            "score": 0.6713675260543823,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.670002281665802,
            "answer": "the",
            "hit": false
          },
          {
            "score": 0.6641877889633179,
            "answer": "hall",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 426,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5182754751294851
      },
      {
        "question verbose": "What is to jam ",
        "b": "jam",
        "expected answer": [
          "fruit",
          "sugar",
          "berries"
        ],
        "predictions": [
          {
            "score": 0.6851857900619507,
            "answer": "ham",
            "hit": false
          },
          {
            "score": 0.6577193737030029,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6393582820892334,
            "answer": "johnson",
            "hit": false
          },
          {
            "score": 0.6388673782348633,
            "answer": "brad",
            "hit": false
          },
          {
            "score": 0.6367924809455872,
            "answer": "mix",
            "hit": false
          },
          {
            "score": 0.6364951133728027,
            "answer": "jones",
            "hit": false
          }
        ],
        "set_exclude": [
          "jam"
        ],
        "rank": 1972,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5254381485283375
      },
      {
        "question verbose": "What is to lawn ",
        "b": "lawn",
        "expected answer": [
          "grass"
        ],
        "predictions": [
          {
            "score": 0.6584859490394592,
            "answer": "leather",
            "hit": false
          },
          {
            "score": 0.6538337469100952,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.6528712511062622,
            "answer": "hair",
            "hit": false
          },
          {
            "score": 0.6430374979972839,
            "answer": "garden",
            "hit": false
          },
          {
            "score": 0.638584315776825,
            "answer": "golf",
            "hit": false
          },
          {
            "score": 0.6383006572723389,
            "answer": "flower",
            "hit": false
          }
        ],
        "set_exclude": [
          "lawn"
        ],
        "rank": 1108,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5544069148600101
      },
      {
        "question verbose": "What is to lens ",
        "b": "lens",
        "expected answer": [
          "glass",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.6817868947982788,
            "answer": "glass",
            "hit": true
          },
          {
            "score": 0.665632426738739,
            "answer": "lenses",
            "hit": false
          },
          {
            "score": 0.6214120984077454,
            "answer": "blade",
            "hit": false
          },
          {
            "score": 0.621115505695343,
            "answer": "gas",
            "hit": false
          },
          {
            "score": 0.6210901737213135,
            "answer": "gear",
            "hit": false
          },
          {
            "score": 0.620786190032959,
            "answer": "storage",
            "hit": false
          }
        ],
        "set_exclude": [
          "lens"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6817869544029236
      },
      {
        "question verbose": "What is to mirror ",
        "b": "mirror",
        "expected answer": [
          "glass",
          "bronze"
        ],
        "predictions": [
          {
            "score": 0.832673192024231,
            "answer": "mirrors",
            "hit": false
          },
          {
            "score": 0.6913533210754395,
            "answer": "reflect",
            "hit": false
          },
          {
            "score": 0.6709637641906738,
            "answer": "reflective",
            "hit": false
          },
          {
            "score": 0.6679478883743286,
            "answer": "reflecting",
            "hit": false
          },
          {
            "score": 0.6581864953041077,
            "answer": "paint",
            "hit": false
          },
          {
            "score": 0.6579010486602783,
            "answer": "metal",
            "hit": false
          }
        ],
        "set_exclude": [
          "mirror"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5464124232530594
      },
      {
        "question verbose": "What is to money ",
        "b": "money",
        "expected answer": [
          "paper",
          "metal",
          "silver",
          "gold",
          "iron",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.776566743850708,
            "answer": "funds",
            "hit": false
          },
          {
            "score": 0.7426469326019287,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.7092411518096924,
            "answer": "finances",
            "hit": false
          },
          {
            "score": 0.6945493221282959,
            "answer": "currency",
            "hit": false
          },
          {
            "score": 0.6893509030342102,
            "answer": "payment",
            "hit": false
          },
          {
            "score": 0.6876837611198425,
            "answer": "financing",
            "hit": false
          }
        ],
        "set_exclude": [
          "money"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5155957713723183
      },
      {
        "question verbose": "What is to ocean ",
        "b": "ocean",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.6762617230415344,
            "answer": "fish",
            "hit": false
          },
          {
            "score": 0.6686819195747375,
            "answer": "glass",
            "hit": false
          },
          {
            "score": 0.6621497273445129,
            "answer": "ice",
            "hit": false
          },
          {
            "score": 0.6551194787025452,
            "answer": "salt",
            "hit": false
          },
          {
            "score": 0.6482334733009338,
            "answer": "oceans",
            "hit": false
          },
          {
            "score": 0.644180178642273,
            "answer": "seas",
            "hit": false
          }
        ],
        "set_exclude": [
          "ocean"
        ],
        "rank": 714,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5629943087697029
      },
      {
        "question verbose": "What is to pastry ",
        "b": "pastry",
        "expected answer": [
          "flour",
          "egg",
          "butter",
          "filling"
        ],
        "predictions": [
          {
            "score": 0.7232805490493774,
            "answer": "culinary",
            "hit": false
          },
          {
            "score": 0.7052515149116516,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.6972207427024841,
            "answer": "chocolate",
            "hit": false
          },
          {
            "score": 0.6948220729827881,
            "answer": "pasta",
            "hit": false
          },
          {
            "score": 0.6870409250259399,
            "answer": "baking",
            "hit": false
          },
          {
            "score": 0.6862671375274658,
            "answer": "butter",
            "hit": true
          }
        ],
        "set_exclude": [
          "pastry"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6653015911579132
      },
      {
        "question verbose": "What is to penny ",
        "b": "penny",
        "expected answer": [
          "metal",
          "alloy",
          "bronze",
          "nickel",
          "zinc",
          "copper",
          "tin"
        ],
        "predictions": [
          {
            "score": 0.6871879696846008,
            "answer": "jenny",
            "hit": false
          },
          {
            "score": 0.6598305702209473,
            "answer": "shirley",
            "hit": false
          },
          {
            "score": 0.6584306359291077,
            "answer": "erin",
            "hit": false
          },
          {
            "score": 0.6565016508102417,
            "answer": "greg",
            "hit": false
          },
          {
            "score": 0.6550205945968628,
            "answer": "rebecca",
            "hit": false
          },
          {
            "score": 0.653342068195343,
            "answer": "bruce",
            "hit": false
          }
        ],
        "set_exclude": [
          "penny"
        ],
        "rank": 256,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5752323567867279
      },
      {
        "question verbose": "What is to pill ",
        "b": "pill",
        "expected answer": [
          "medicine",
          "drug"
        ],
        "predictions": [
          {
            "score": 0.7513704299926758,
            "answer": "pillar",
            "hit": false
          },
          {
            "score": 0.6803445816040039,
            "answer": "pills",
            "hit": false
          },
          {
            "score": 0.6305420994758606,
            "answer": "pillars",
            "hit": false
          },
          {
            "score": 0.6086642146110535,
            "answer": "hook",
            "hit": false
          },
          {
            "score": 0.6051347255706787,
            "answer": "cigarette",
            "hit": false
          },
          {
            "score": 0.6045832633972168,
            "answer": "plant",
            "hit": false
          }
        ],
        "set_exclude": [
          "pill"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5213823895901442
      },
      {
        "question verbose": "What is to plastic ",
        "b": "plastic",
        "expected answer": [
          "polymer",
          "oil",
          "gas",
          "coal"
        ],
        "predictions": [
          {
            "score": 0.7131916284561157,
            "answer": "plastics",
            "hit": false
          },
          {
            "score": 0.6836097836494446,
            "answer": "leather",
            "hit": false
          },
          {
            "score": 0.6659444570541382,
            "answer": "steel",
            "hit": false
          },
          {
            "score": 0.6644093990325928,
            "answer": "metal",
            "hit": false
          },
          {
            "score": 0.6634123921394348,
            "answer": "vinyl",
            "hit": false
          },
          {
            "score": 0.6599269509315491,
            "answer": "hair",
            "hit": false
          }
        ],
        "set_exclude": [
          "plastic"
        ],
        "rank": 65,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6123851984739304
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "water"
        ],
        "predictions": [
          {
            "score": 0.7436681389808655,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.6758685111999512,
            "answer": "arctic",
            "hit": false
          },
          {
            "score": 0.6698235273361206,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.6676381826400757,
            "answer": "marine",
            "hit": false
          },
          {
            "score": 0.6633690595626831,
            "answer": "leather",
            "hit": false
          },
          {
            "score": 0.6572803854942322,
            "answer": "air",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 8,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6522881388664246
      },
      {
        "question verbose": "What is to spoon ",
        "b": "spoon",
        "expected answer": [
          "aluminium",
          "wood",
          "steel"
        ],
        "predictions": [
          {
            "score": 0.693294107913971,
            "answer": "shovel",
            "hit": false
          },
          {
            "score": 0.6627987623214722,
            "answer": "spit",
            "hit": false
          },
          {
            "score": 0.6597832441329956,
            "answer": "butter",
            "hit": false
          },
          {
            "score": 0.6591328382492065,
            "answer": "knife",
            "hit": false
          },
          {
            "score": 0.6559303998947144,
            "answer": "milk",
            "hit": false
          },
          {
            "score": 0.6546492576599121,
            "answer": "plaster",
            "hit": false
          }
        ],
        "set_exclude": [
          "spoon"
        ],
        "rank": 404,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5904184728860855
      },
      {
        "question verbose": "What is to table ",
        "b": "table",
        "expected answer": [
          "wood",
          "metal",
          "plastic"
        ],
        "predictions": [
          {
            "score": 0.7535452842712402,
            "answer": "figure",
            "hit": false
          },
          {
            "score": 0.7206047773361206,
            "answer": "tables",
            "hit": false
          },
          {
            "score": 0.6858919858932495,
            "answer": "appendix",
            "hit": false
          },
          {
            "score": 0.678380012512207,
            "answer": "figures",
            "hit": false
          },
          {
            "score": 0.6307388544082642,
            "answer": "book",
            "hit": false
          },
          {
            "score": 0.6257362365722656,
            "answer": "round",
            "hit": false
          }
        ],
        "set_exclude": [
          "table"
        ],
        "rank": 13,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.618971474468708
      },
      {
        "question verbose": "What is to wig ",
        "b": "wig",
        "expected answer": [
          "hair"
        ],
        "predictions": [
          {
            "score": 0.6140839457511902,
            "answer": "grass",
            "hit": false
          },
          {
            "score": 0.6111468076705933,
            "answer": "haired",
            "hit": false
          },
          {
            "score": 0.6032966375350952,
            "answer": "gel",
            "hit": false
          },
          {
            "score": 0.6015178561210632,
            "answer": "ludwig",
            "hit": false
          },
          {
            "score": 0.6006325483322144,
            "answer": "jew",
            "hit": false
          },
          {
            "score": 0.5972123146057129,
            "answer": "brown",
            "hit": false
          }
        ],
        "set_exclude": [
          "wig"
        ],
        "rank": 622,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5387681499123573
      },
      {
        "question verbose": "What is to wine ",
        "b": "wine",
        "expected answer": [
          "grapes",
          "grape"
        ],
        "predictions": [
          {
            "score": 0.723737359046936,
            "answer": "wines",
            "hit": false
          },
          {
            "score": 0.7058130502700806,
            "answer": "alcohol",
            "hit": false
          },
          {
            "score": 0.6725357174873352,
            "answer": "drinking",
            "hit": false
          },
          {
            "score": 0.6639032363891602,
            "answer": "cooking",
            "hit": false
          },
          {
            "score": 0.6632862687110901,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.6595854759216309,
            "answer": "whiskey",
            "hit": false
          }
        ],
        "set_exclude": [
          "wine"
        ],
        "rank": 14,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6418182253837585
      },
      {
        "question verbose": "What is to wire ",
        "b": "wire",
        "expected answer": [
          "metal"
        ],
        "predictions": [
          {
            "score": 0.693790078163147,
            "answer": "wires",
            "hit": false
          },
          {
            "score": 0.6616460084915161,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.6426863670349121,
            "answer": "steel",
            "hit": false
          },
          {
            "score": 0.633527934551239,
            "answer": "electrical",
            "hit": false
          },
          {
            "score": 0.6317756175994873,
            "answer": "leather",
            "hit": false
          },
          {
            "score": 0.6277197599411011,
            "answer": "networks",
            "hit": false
          }
        ],
        "set_exclude": [
          "wire"
        ],
        "rank": 204,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5828154683113098
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 28,
      "accuracy": 0.03571428571428571
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L04 [meronyms - substance].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "957a370a-0ced-46ef-8b8c-12d34170bb33",
      "timestamp": "2025-05-17T17:15:35.222717"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bird ",
        "b": "bird",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.7180811166763306,
            "answer": "wildlife",
            "hit": false
          },
          {
            "score": 0.7125493884086609,
            "answer": "chicken",
            "hit": false
          },
          {
            "score": 0.7035199403762817,
            "answer": "flock",
            "hit": true
          },
          {
            "score": 0.6968197226524353,
            "answer": "poultry",
            "hit": false
          },
          {
            "score": 0.6935511827468872,
            "answer": "birds",
            "hit": false
          },
          {
            "score": 0.6897004842758179,
            "answer": "feathers",
            "hit": false
          }
        ],
        "set_exclude": [
          "bird"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7035199850797653
      },
      {
        "question verbose": "What is to calf ",
        "b": "calf",
        "expected answer": [
          "cattle",
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8305904269218445,
            "answer": "calves",
            "hit": false
          },
          {
            "score": 0.7499065399169922,
            "answer": "thigh",
            "hit": false
          },
          {
            "score": 0.7053645849227905,
            "answer": "ankle",
            "hit": false
          },
          {
            "score": 0.6914967894554138,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.6757779121398926,
            "answer": "knee",
            "hit": false
          },
          {
            "score": 0.6749813556671143,
            "answer": "leg",
            "hit": false
          }
        ],
        "set_exclude": [
          "calf"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6553924679756165
      },
      {
        "question verbose": "What is to car ",
        "b": "car",
        "expected answer": [
          "train",
          "procession"
        ],
        "predictions": [
          {
            "score": 0.785354495048523,
            "answer": "automobile",
            "hit": false
          },
          {
            "score": 0.7509164214134216,
            "answer": "truck",
            "hit": false
          },
          {
            "score": 0.7389326691627502,
            "answer": "vehicles",
            "hit": false
          },
          {
            "score": 0.7348189949989319,
            "answer": "sedan",
            "hit": false
          },
          {
            "score": 0.7316035032272339,
            "answer": "motor",
            "hit": false
          },
          {
            "score": 0.7193882465362549,
            "answer": "automotive",
            "hit": false
          }
        ],
        "set_exclude": [
          "car"
        ],
        "rank": 22,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.667492687702179
      },
      {
        "question verbose": "What is to cattle ",
        "b": "cattle",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.8486785292625427,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.7890302538871765,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.7414349317550659,
            "answer": "herds",
            "hit": false
          },
          {
            "score": 0.7247123718261719,
            "answer": "sheep",
            "hit": false
          },
          {
            "score": 0.7239765524864197,
            "answer": "herd",
            "hit": true
          },
          {
            "score": 0.7226364612579346,
            "answer": "goats",
            "hit": false
          }
        ],
        "set_exclude": [
          "cattle"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7239765673875809
      },
      {
        "question verbose": "What is to christian ",
        "b": "christian",
        "expected answer": [
          "congregation",
          "church",
          "parish"
        ],
        "predictions": [
          {
            "score": 0.8281657695770264,
            "answer": "christians",
            "hit": false
          },
          {
            "score": 0.8067516088485718,
            "answer": "christianity",
            "hit": false
          },
          {
            "score": 0.7910262942314148,
            "answer": "catholic",
            "hit": false
          },
          {
            "score": 0.7575377225875854,
            "answer": "evangelical",
            "hit": false
          },
          {
            "score": 0.7455165982246399,
            "answer": "protestant",
            "hit": false
          },
          {
            "score": 0.735733151435852,
            "answer": "baptist",
            "hit": false
          }
        ],
        "set_exclude": [
          "christian"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.62840436398983
      },
      {
        "question verbose": "What is to college ",
        "b": "college",
        "expected answer": [
          "university"
        ],
        "predictions": [
          {
            "score": 0.7362087965011597,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.717265248298645,
            "answer": "colleges",
            "hit": false
          },
          {
            "score": 0.6683416962623596,
            "answer": "high",
            "hit": false
          },
          {
            "score": 0.6619144678115845,
            "answer": "young",
            "hit": false
          },
          {
            "score": 0.6610791683197021,
            "answer": "faculty",
            "hit": false
          },
          {
            "score": 0.6599501371383667,
            "answer": "schools",
            "hit": false
          }
        ],
        "set_exclude": [
          "college"
        ],
        "rank": 18,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6441071331501007
      },
      {
        "question verbose": "What is to county ",
        "b": "county",
        "expected answer": [
          "state",
          "country"
        ],
        "predictions": [
          {
            "score": 0.742485761642456,
            "answer": "counties",
            "hit": false
          },
          {
            "score": 0.7301965355873108,
            "answer": "township",
            "hit": false
          },
          {
            "score": 0.6909335851669312,
            "answer": "country",
            "hit": true
          },
          {
            "score": 0.6791793704032898,
            "answer": "parish",
            "hit": false
          },
          {
            "score": 0.6693968772888184,
            "answer": "regional",
            "hit": false
          },
          {
            "score": 0.6605896949768066,
            "answer": "valley",
            "hit": false
          }
        ],
        "set_exclude": [
          "county"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5927422344684601
      },
      {
        "question verbose": "What is to cow ",
        "b": "cow",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.6564189791679382,
            "answer": "cows",
            "hit": false
          },
          {
            "score": 0.6531221866607666,
            "answer": "smith",
            "hit": false
          },
          {
            "score": 0.6494898796081543,
            "answer": "lab",
            "hit": false
          },
          {
            "score": 0.6453748941421509,
            "answer": "dairy",
            "hit": false
          },
          {
            "score": 0.6403019428253174,
            "answer": "hog",
            "hit": false
          },
          {
            "score": 0.6397885084152222,
            "answer": "dave",
            "hit": false
          }
        ],
        "set_exclude": [
          "cow"
        ],
        "rank": 245,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5885001718997955
      },
      {
        "question verbose": "What is to crow ",
        "b": "crow",
        "expected answer": [
          "murder"
        ],
        "predictions": [
          {
            "score": 0.6447921395301819,
            "answer": "shaw",
            "hit": false
          },
          {
            "score": 0.6390977501869202,
            "answer": "cobb",
            "hit": false
          },
          {
            "score": 0.638073205947876,
            "answer": "hawks",
            "hit": false
          },
          {
            "score": 0.6371630430221558,
            "answer": "crab",
            "hit": false
          },
          {
            "score": 0.633161723613739,
            "answer": "butler",
            "hit": false
          },
          {
            "score": 0.6319186687469482,
            "answer": "cox",
            "hit": false
          }
        ],
        "set_exclude": [
          "crow"
        ],
        "rank": 6396,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.4997957741143182
      },
      {
        "question verbose": "What is to elephant ",
        "b": "elephant",
        "expected answer": [
          "herd"
        ],
        "predictions": [
          {
            "score": 0.7376502752304077,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.6842818260192871,
            "answer": "circus",
            "hit": false
          },
          {
            "score": 0.6614482402801514,
            "answer": "zoo",
            "hit": false
          },
          {
            "score": 0.6551992893218994,
            "answer": "eagles",
            "hit": false
          },
          {
            "score": 0.6497766375541687,
            "answer": "eagle",
            "hit": false
          },
          {
            "score": 0.6491791009902954,
            "answer": "animal",
            "hit": false
          }
        ],
        "set_exclude": [
          "elephant"
        ],
        "rank": 101,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5980678796768188
      },
      {
        "question verbose": "What is to employee ",
        "b": "employee",
        "expected answer": [
          "staff",
          "company"
        ],
        "predictions": [
          {
            "score": 0.8674247860908508,
            "answer": "employees",
            "hit": false
          },
          {
            "score": 0.7848712205886841,
            "answer": "employer",
            "hit": false
          },
          {
            "score": 0.7577930688858032,
            "answer": "workforce",
            "hit": false
          },
          {
            "score": 0.7509671449661255,
            "answer": "workers",
            "hit": false
          },
          {
            "score": 0.749164342880249,
            "answer": "workplace",
            "hit": false
          },
          {
            "score": 0.7076557278633118,
            "answer": "employ",
            "hit": false
          }
        ],
        "set_exclude": [
          "employee"
        ],
        "rank": 19,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5567511431872845
      },
      {
        "question verbose": "What is to fish ",
        "b": "fish",
        "expected answer": [
          "school"
        ],
        "predictions": [
          {
            "score": 0.6797840595245361,
            "answer": "food",
            "hit": false
          },
          {
            "score": 0.6754629611968994,
            "answer": "ocean",
            "hit": false
          },
          {
            "score": 0.6704890727996826,
            "answer": "wild",
            "hit": false
          },
          {
            "score": 0.6703102588653564,
            "answer": "snake",
            "hit": false
          },
          {
            "score": 0.663754940032959,
            "answer": "dog",
            "hit": false
          },
          {
            "score": 0.6509842872619629,
            "answer": "fox",
            "hit": false
          }
        ],
        "set_exclude": [
          "fish"
        ],
        "rank": 10177,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.45928955078125
      },
      {
        "question verbose": "What is to galaxy ",
        "b": "galaxy",
        "expected answer": [
          "universe"
        ],
        "predictions": [
          {
            "score": 0.7074007987976074,
            "answer": "samsung",
            "hit": false
          },
          {
            "score": 0.6920324563980103,
            "answer": "nexus",
            "hit": false
          },
          {
            "score": 0.6895084381103516,
            "answer": "milky",
            "hit": false
          },
          {
            "score": 0.667641282081604,
            "answer": "galaxies",
            "hit": false
          },
          {
            "score": 0.6578558683395386,
            "answer": "universe",
            "hit": true
          },
          {
            "score": 0.6547455787658691,
            "answer": "galactic",
            "hit": false
          }
        ],
        "set_exclude": [
          "galaxy"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6578558385372162
      },
      {
        "question verbose": "What is to letter ",
        "b": "letter",
        "expected answer": [
          "alphabet"
        ],
        "predictions": [
          {
            "score": 0.8497629165649414,
            "answer": "letters",
            "hit": false
          },
          {
            "score": 0.7245559692382812,
            "answer": "memo",
            "hit": false
          },
          {
            "score": 0.7104941010475159,
            "answer": "email",
            "hit": false
          },
          {
            "score": 0.7005789279937744,
            "answer": "correspondence",
            "hit": false
          },
          {
            "score": 0.6981072425842285,
            "answer": "memorandum",
            "hit": false
          },
          {
            "score": 0.6892238855361938,
            "answer": "text",
            "hit": false
          }
        ],
        "set_exclude": [
          "letter"
        ],
        "rank": 4866,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5394330136477947
      },
      {
        "question verbose": "What is to lion ",
        "b": "lion",
        "expected answer": [
          "pride"
        ],
        "predictions": [
          {
            "score": 0.7275065183639526,
            "answer": "tiger",
            "hit": false
          },
          {
            "score": 0.6604976654052734,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.6518799066543579,
            "answer": "elephants",
            "hit": false
          },
          {
            "score": 0.6509362459182739,
            "answer": "spear",
            "hit": false
          },
          {
            "score": 0.6481246948242188,
            "answer": "flock",
            "hit": false
          },
          {
            "score": 0.6457623243331909,
            "answer": "vast",
            "hit": false
          }
        ],
        "set_exclude": [
          "lion"
        ],
        "rank": 20,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6286687552928925
      },
      {
        "question verbose": "What is to listener ",
        "b": "listener",
        "expected answer": [
          "audience"
        ],
        "predictions": [
          {
            "score": 0.6705379486083984,
            "answer": "handler",
            "hit": false
          },
          {
            "score": 0.642388105392456,
            "answer": "listeners",
            "hit": false
          },
          {
            "score": 0.6392888426780701,
            "answer": "theme",
            "hit": false
          },
          {
            "score": 0.6290238499641418,
            "answer": "setting",
            "hit": false
          },
          {
            "score": 0.6251690983772278,
            "answer": "repeat",
            "hit": false
          },
          {
            "score": 0.6247150301933289,
            "answer": "members",
            "hit": false
          }
        ],
        "set_exclude": [
          "listener"
        ],
        "rank": 352,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5734529942274094
      },
      {
        "question verbose": "What is to member ",
        "b": "member",
        "expected answer": [
          "club",
          "team",
          "group",
          "band",
          "community"
        ],
        "predictions": [
          {
            "score": 0.6959275007247925,
            "answer": "membership",
            "hit": false
          },
          {
            "score": 0.6633259654045105,
            "answer": "members",
            "hit": false
          },
          {
            "score": 0.6632658243179321,
            "answer": "chairman",
            "hit": false
          },
          {
            "score": 0.6500958204269409,
            "answer": "leader",
            "hit": false
          },
          {
            "score": 0.6410990357398987,
            "answer": "chair",
            "hit": false
          },
          {
            "score": 0.6340450048446655,
            "answer": "user",
            "hit": false
          }
        ],
        "set_exclude": [
          "member"
        ],
        "rank": 16,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6095250844955444
      },
      {
        "question verbose": "What is to musician ",
        "b": "musician",
        "expected answer": [
          "orchestra",
          "band"
        ],
        "predictions": [
          {
            "score": 0.8504593372344971,
            "answer": "musicians",
            "hit": false
          },
          {
            "score": 0.8160508275032043,
            "answer": "singer",
            "hit": false
          },
          {
            "score": 0.7786130905151367,
            "answer": "guitarist",
            "hit": false
          },
          {
            "score": 0.7736860513687134,
            "answer": "rapper",
            "hit": false
          },
          {
            "score": 0.7698501348495483,
            "answer": "drummer",
            "hit": false
          },
          {
            "score": 0.7502634525299072,
            "answer": "composer",
            "hit": false
          }
        ],
        "set_exclude": [
          "musician"
        ],
        "rank": 134,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6202648803591728
      },
      {
        "question verbose": "What is to person ",
        "b": "person",
        "expected answer": [
          "society",
          "company",
          "party",
          "world"
        ],
        "predictions": [
          {
            "score": 0.7031630277633667,
            "answer": "man",
            "hit": false
          },
          {
            "score": 0.675068736076355,
            "answer": "men",
            "hit": false
          },
          {
            "score": 0.6414914727210999,
            "answer": "party",
            "hit": true
          },
          {
            "score": 0.6340867877006531,
            "answer": "gender",
            "hit": false
          },
          {
            "score": 0.6334320306777954,
            "answer": "office",
            "hit": false
          },
          {
            "score": 0.6323964595794678,
            "answer": "quarter",
            "hit": false
          }
        ],
        "set_exclude": [
          "person"
        ],
        "rank": 2,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5167696662247181
      },
      {
        "question verbose": "What is to photo ",
        "b": "photo",
        "expected answer": [
          "album",
          "collection",
          "library"
        ],
        "predictions": [
          {
            "score": 0.7777475118637085,
            "answer": "photographs",
            "hit": false
          },
          {
            "score": 0.7770751714706421,
            "answer": "image",
            "hit": false
          },
          {
            "score": 0.7630605101585388,
            "answer": "pictures",
            "hit": false
          },
          {
            "score": 0.7597070932388306,
            "answer": "photography",
            "hit": false
          },
          {
            "score": 0.7483431696891785,
            "answer": "photographic",
            "hit": false
          },
          {
            "score": 0.7381033897399902,
            "answer": "photographer",
            "hit": false
          }
        ],
        "set_exclude": [
          "photo"
        ],
        "rank": 29,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5112189808860421
      },
      {
        "question verbose": "What is to player ",
        "b": "player",
        "expected answer": [
          "team",
          "group",
          "orchestra"
        ],
        "predictions": [
          {
            "score": 0.6845308542251587,
            "answer": "players",
            "hit": false
          },
          {
            "score": 0.670275092124939,
            "answer": "manager",
            "hit": false
          },
          {
            "score": 0.6550998687744141,
            "answer": "button",
            "hit": false
          },
          {
            "score": 0.6545776128768921,
            "answer": "games",
            "hit": false
          },
          {
            "score": 0.6532671451568604,
            "answer": "season",
            "hit": false
          },
          {
            "score": 0.6512832641601562,
            "answer": "record",
            "hit": false
          }
        ],
        "set_exclude": [
          "player"
        ],
        "rank": 296,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5993764400482178
      },
      {
        "question verbose": "What is to policeman ",
        "b": "policeman",
        "expected answer": [
          "police"
        ],
        "predictions": [
          {
            "score": 0.7312930822372437,
            "answer": "cops",
            "hit": false
          },
          {
            "score": 0.7029448747634888,
            "answer": "officer",
            "hit": false
          },
          {
            "score": 0.6986665725708008,
            "answer": "policing",
            "hit": false
          },
          {
            "score": 0.6870203018188477,
            "answer": "patrol",
            "hit": false
          },
          {
            "score": 0.6837440133094788,
            "answer": "police",
            "hit": true
          },
          {
            "score": 0.6712656021118164,
            "answer": "magistrate",
            "hit": false
          }
        ],
        "set_exclude": [
          "policeman"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6837440431118011
      },
      {
        "question verbose": "What is to secretary ",
        "b": "secretary",
        "expected answer": [
          "staff"
        ],
        "predictions": [
          {
            "score": 0.7298635244369507,
            "answer": "attorney",
            "hit": false
          },
          {
            "score": 0.721606969833374,
            "answer": "chairman",
            "hit": false
          },
          {
            "score": 0.7128556966781616,
            "answer": "deputy",
            "hit": false
          },
          {
            "score": 0.7128245830535889,
            "answer": "commissioner",
            "hit": false
          },
          {
            "score": 0.705425500869751,
            "answer": "ambassador",
            "hit": false
          },
          {
            "score": 0.6975820064544678,
            "answer": "senator",
            "hit": false
          }
        ],
        "set_exclude": [
          "secretary"
        ],
        "rank": 3110,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5311525128781796
      },
      {
        "question verbose": "What is to senator ",
        "b": "senator",
        "expected answer": [
          "senate",
          "house"
        ],
        "predictions": [
          {
            "score": 0.8064975142478943,
            "answer": "senators",
            "hit": false
          },
          {
            "score": 0.8037737607955933,
            "answer": "congressman",
            "hit": false
          },
          {
            "score": 0.7721264362335205,
            "answer": "representative",
            "hit": false
          },
          {
            "score": 0.7075527906417847,
            "answer": "attorney",
            "hit": false
          },
          {
            "score": 0.6981892585754395,
            "answer": "senate",
            "hit": true
          },
          {
            "score": 0.6967098712921143,
            "answer": "secretary",
            "hit": false
          }
        ],
        "set_exclude": [
          "senator"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6981892883777618
      },
      {
        "question verbose": "What is to sheep ",
        "b": "sheep",
        "expected answer": [
          "flock"
        ],
        "predictions": [
          {
            "score": 0.7493057250976562,
            "answer": "goats",
            "hit": false
          },
          {
            "score": 0.7396414279937744,
            "answer": "cattle",
            "hit": false
          },
          {
            "score": 0.7265745997428894,
            "answer": "livestock",
            "hit": false
          },
          {
            "score": 0.7186083197593689,
            "answer": "flock",
            "hit": true
          },
          {
            "score": 0.7162148952484131,
            "answer": "herd",
            "hit": false
          },
          {
            "score": 0.7132797241210938,
            "answer": "chickens",
            "hit": false
          }
        ],
        "set_exclude": [
          "sheep"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7186083346605301
      },
      {
        "question verbose": "What is to soldier ",
        "b": "soldier",
        "expected answer": [
          "army",
          "unit",
          "division",
          "troop"
        ],
        "predictions": [
          {
            "score": 0.7650178670883179,
            "answer": "soldiers",
            "hit": false
          },
          {
            "score": 0.6884312629699707,
            "answer": "army",
            "hit": true
          },
          {
            "score": 0.669465184211731,
            "answer": "sold",
            "hit": false
          },
          {
            "score": 0.6692380905151367,
            "answer": "warrior",
            "hit": false
          },
          {
            "score": 0.6572021245956421,
            "answer": "regiment",
            "hit": false
          },
          {
            "score": 0.6433566212654114,
            "answer": "scout",
            "hit": false
          }
        ],
        "set_exclude": [
          "soldier"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6884313076734543
      },
      {
        "question verbose": "What is to spouse ",
        "b": "spouse",
        "expected answer": [
          "couple",
          "relationship",
          "family"
        ],
        "predictions": [
          {
            "score": 0.7177006006240845,
            "answer": "marital",
            "hit": false
          },
          {
            "score": 0.7090935707092285,
            "answer": "husbands",
            "hit": false
          },
          {
            "score": 0.7043724060058594,
            "answer": "partner",
            "hit": false
          },
          {
            "score": 0.6973417401313782,
            "answer": "girlfriend",
            "hit": false
          },
          {
            "score": 0.694915771484375,
            "answer": "family",
            "hit": true
          },
          {
            "score": 0.6908950805664062,
            "answer": "boyfriend",
            "hit": false
          }
        ],
        "set_exclude": [
          "spouse"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6275918483734131
      },
      {
        "question verbose": "What is to state ",
        "b": "state",
        "expected answer": [
          "country",
          "province"
        ],
        "predictions": [
          {
            "score": 0.6661213040351868,
            "answer": "world",
            "hit": false
          },
          {
            "score": 0.646138072013855,
            "answer": "service",
            "hit": false
          },
          {
            "score": 0.6450656652450562,
            "answer": "public",
            "hit": false
          },
          {
            "score": 0.642744779586792,
            "answer": "services",
            "hit": false
          },
          {
            "score": 0.6307469606399536,
            "answer": "district",
            "hit": false
          },
          {
            "score": 0.6301925778388977,
            "answer": "group",
            "hit": false
          }
        ],
        "set_exclude": [
          "state"
        ],
        "rank": 84,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5766590610146523
      },
      {
        "question verbose": "What is to student ",
        "b": "student",
        "expected answer": [
          "class",
          "school"
        ],
        "predictions": [
          {
            "score": 0.7514132857322693,
            "answer": "students",
            "hit": false
          },
          {
            "score": 0.7308484315872192,
            "answer": "campus",
            "hit": false
          },
          {
            "score": 0.7077857851982117,
            "answer": "education",
            "hit": false
          },
          {
            "score": 0.6709660291671753,
            "answer": "graduate",
            "hit": false
          },
          {
            "score": 0.6663625240325928,
            "answer": "employ",
            "hit": false
          },
          {
            "score": 0.6638993620872498,
            "answer": "learning",
            "hit": false
          }
        ],
        "set_exclude": [
          "student"
        ],
        "rank": 6,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5919362902641296
      },
      {
        "question verbose": "What is to tree ",
        "b": "tree",
        "expected answer": [
          "forest",
          "wood",
          "grove"
        ],
        "predictions": [
          {
            "score": 0.7920328378677368,
            "answer": "trees",
            "hit": false
          },
          {
            "score": 0.6723220348358154,
            "answer": "garden",
            "hit": false
          },
          {
            "score": 0.6594696044921875,
            "answer": "seed",
            "hit": false
          },
          {
            "score": 0.6465111374855042,
            "answer": "tower",
            "hit": false
          },
          {
            "score": 0.6391520500183105,
            "answer": "mountain",
            "hit": false
          },
          {
            "score": 0.6379676461219788,
            "answer": "flower",
            "hit": false
          }
        ],
        "set_exclude": [
          "tree"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5965511128306389
      },
      {
        "question verbose": "What is to wolf ",
        "b": "wolf",
        "expected answer": [
          "pack"
        ],
        "predictions": [
          {
            "score": 0.6231675744056702,
            "answer": "breeding",
            "hit": false
          },
          {
            "score": 0.6176165342330933,
            "answer": "wolves",
            "hit": false
          },
          {
            "score": 0.614817202091217,
            "answer": "master",
            "hit": false
          },
          {
            "score": 0.6139848828315735,
            "answer": "bull",
            "hit": false
          },
          {
            "score": 0.6114295721054077,
            "answer": "cloud",
            "hit": false
          },
          {
            "score": 0.6098048686981201,
            "answer": "walker",
            "hit": false
          }
        ],
        "set_exclude": [
          "wolf"
        ],
        "rank": 944,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5358383432030678
      },
      {
        "question verbose": "What is to word ",
        "b": "word",
        "expected answer": [
          "paragraph",
          "sentence",
          "text"
        ],
        "predictions": [
          {
            "score": 0.6877545118331909,
            "answer": "words",
            "hit": false
          },
          {
            "score": 0.6475380659103394,
            "answer": "term",
            "hit": false
          },
          {
            "score": 0.6395460367202759,
            "answer": "theme",
            "hit": false
          },
          {
            "score": 0.6367843151092529,
            "answer": "some",
            "hit": false
          },
          {
            "score": 0.6367290019989014,
            "answer": "strong",
            "hit": false
          },
          {
            "score": 0.6364147663116455,
            "answer": "through",
            "hit": false
          }
        ],
        "set_exclude": [
          "word"
        ],
        "rank": 405,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5791026651859283
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 32,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L05 [meronyms - member].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "0db6e80b-81a8-414a-b0a1-dd4fa400dd68",
      "timestamp": "2025-05-17T17:15:35.327288"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bus ",
        "b": "bus",
        "expected answer": [
          "seats",
          "conductor",
          "window",
          "driver",
          "roof"
        ],
        "predictions": [
          {
            "score": 0.6555319428443909,
            "answer": "cent",
            "hit": false
          },
          {
            "score": 0.6387801170349121,
            "answer": "shuttle",
            "hit": false
          },
          {
            "score": 0.6386970281600952,
            "answer": "boat",
            "hit": false
          },
          {
            "score": 0.6356793642044067,
            "answer": "bit",
            "hit": false
          },
          {
            "score": 0.6323014497756958,
            "answer": "cars",
            "hit": false
          },
          {
            "score": 0.6246469616889954,
            "answer": "traffic",
            "hit": false
          }
        ],
        "set_exclude": [
          "bus"
        ],
        "rank": 25,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5252358224242926
      },
      {
        "question verbose": "What is to byte ",
        "b": "byte",
        "expected answer": [
          "bit"
        ],
        "predictions": [
          {
            "score": 0.6873594522476196,
            "answer": "teeth",
            "hit": false
          },
          {
            "score": 0.6395007371902466,
            "answer": "pixels",
            "hit": false
          },
          {
            "score": 0.6385027170181274,
            "answer": "seats",
            "hit": false
          },
          {
            "score": 0.624212384223938,
            "answer": "decimal",
            "hit": false
          },
          {
            "score": 0.6231167316436768,
            "answer": "bytes",
            "hit": false
          },
          {
            "score": 0.6101025342941284,
            "answer": "pointer",
            "hit": false
          }
        ],
        "set_exclude": [
          "byte"
        ],
        "rank": 1128,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5433245450258255
      },
      {
        "question verbose": "What is to comb ",
        "b": "comb",
        "expected answer": [
          "teeth",
          "shaft",
          "grip",
          "tooth",
          "handle"
        ],
        "predictions": [
          {
            "score": 0.6146610379219055,
            "answer": "seats",
            "hit": false
          },
          {
            "score": 0.6136723160743713,
            "answer": "battling",
            "hit": false
          },
          {
            "score": 0.608320951461792,
            "answer": "brushes",
            "hit": false
          },
          {
            "score": 0.6082150936126709,
            "answer": "confront",
            "hit": false
          },
          {
            "score": 0.6074219942092896,
            "answer": "contests",
            "hit": false
          },
          {
            "score": 0.6061215400695801,
            "answer": "gathered",
            "hit": false
          }
        ],
        "set_exclude": [
          "comb"
        ],
        "rank": 320,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5474750697612762
      },
      {
        "question verbose": "What is to dollar ",
        "b": "dollar",
        "expected answer": [
          "cent"
        ],
        "predictions": [
          {
            "score": 0.6928702592849731,
            "answer": "dollars",
            "hit": false
          },
          {
            "score": 0.6421680450439453,
            "answer": "pound",
            "hit": false
          },
          {
            "score": 0.6409177780151367,
            "answer": "income",
            "hit": false
          },
          {
            "score": 0.6295254230499268,
            "answer": "paying",
            "hit": false
          },
          {
            "score": 0.6293494701385498,
            "answer": "bit",
            "hit": false
          },
          {
            "score": 0.6279781460762024,
            "answer": "seats",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollar"
        ],
        "rank": 514,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5612489953637123
      }
    ],
    "result": {
      "cnt_questions_correct": 0,
      "cnt_questions_total": 4,
      "accuracy": 0.0
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L06 [meronyms - part].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "4222ed6c-af8f-4a1f-8a8e-4b8829ac0093",
      "timestamp": "2025-05-17T17:15:35.450169"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to excited ",
        "b": "excited",
        "expected answer": [
          "agitated",
          "nervous"
        ],
        "predictions": [
          {
            "score": 0.7930517196655273,
            "answer": "thrilled",
            "hit": false
          },
          {
            "score": 0.7818902730941772,
            "answer": "delighted",
            "hit": false
          },
          {
            "score": 0.763145923614502,
            "answer": "intrigued",
            "hit": false
          },
          {
            "score": 0.7431448698043823,
            "answer": "enthusiastic",
            "hit": false
          },
          {
            "score": 0.7378655672073364,
            "answer": "fascinated",
            "hit": false
          },
          {
            "score": 0.7360920906066895,
            "answer": "excitement",
            "hit": false
          }
        ],
        "set_exclude": [
          "excited"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7263792157173157
      },
      {
        "question verbose": "What is to house ",
        "b": "house",
        "expected answer": [
          "palace",
          "castle"
        ],
        "predictions": [
          {
            "score": 0.7168883085250854,
            "answer": "rep",
            "hit": false
          },
          {
            "score": 0.685798168182373,
            "answer": "congress",
            "hit": false
          },
          {
            "score": 0.6807879209518433,
            "answer": "the",
            "hit": false
          },
          {
            "score": 0.6771575212478638,
            "answer": "hall",
            "hit": false
          },
          {
            "score": 0.6702080368995667,
            "answer": "five",
            "hit": false
          },
          {
            "score": 0.6678523421287537,
            "answer": "houses",
            "hit": false
          }
        ],
        "set_exclude": [
          "house"
        ],
        "rank": 900,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5443819835782051
      },
      {
        "question verbose": "What is to lake ",
        "b": "lake",
        "expected answer": [
          "sea",
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.642244815826416,
            "answer": "ocean",
            "hit": true
          },
          {
            "score": 0.6303592920303345,
            "answer": "horse",
            "hit": false
          },
          {
            "score": 0.6293764114379883,
            "answer": "east",
            "hit": false
          },
          {
            "score": 0.620681881904602,
            "answer": "kernel",
            "hit": false
          },
          {
            "score": 0.6191856265068054,
            "answer": "vale",
            "hit": false
          },
          {
            "score": 0.6177978515625,
            "answer": "waters",
            "hit": false
          }
        ],
        "set_exclude": [
          "lake"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.49809282971546054
      },
      {
        "question verbose": "What is to pain ",
        "b": "pain",
        "expected answer": [
          "torment",
          "torture",
          "agony"
        ],
        "predictions": [
          {
            "score": 0.651881217956543,
            "answer": "violence",
            "hit": false
          },
          {
            "score": 0.6507952809333801,
            "answer": "painting",
            "hit": false
          },
          {
            "score": 0.646807074546814,
            "answer": "hurt",
            "hit": false
          },
          {
            "score": 0.6466719508171082,
            "answer": "surgery",
            "hit": false
          },
          {
            "score": 0.6444398760795593,
            "answer": "chronic",
            "hit": false
          },
          {
            "score": 0.6423888802528381,
            "answer": "muscle",
            "hit": false
          }
        ],
        "set_exclude": [
          "pain"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5747486799955368
      },
      {
        "question verbose": "What is to pony ",
        "b": "pony",
        "expected answer": [
          "horse"
        ],
        "predictions": [
          {
            "score": 0.6301892399787903,
            "answer": "princess",
            "hit": false
          },
          {
            "score": 0.626726508140564,
            "answer": "pokemon",
            "hit": false
          },
          {
            "score": 0.6245478391647339,
            "answer": "donkey",
            "hit": false
          },
          {
            "score": 0.6243442296981812,
            "answer": "friendship",
            "hit": false
          },
          {
            "score": 0.6226497888565063,
            "answer": "fairy",
            "hit": false
          },
          {
            "score": 0.622185230255127,
            "answer": "wizard",
            "hit": false
          }
        ],
        "set_exclude": [
          "pony"
        ],
        "rank": 1607,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5371740385890007
      },
      {
        "question verbose": "What is to sea ",
        "b": "sea",
        "expected answer": [
          "ocean"
        ],
        "predictions": [
          {
            "score": 0.7356357574462891,
            "answer": "seas",
            "hit": false
          },
          {
            "score": 0.6567686796188354,
            "answer": "marine",
            "hit": false
          },
          {
            "score": 0.6566197276115417,
            "answer": "arctic",
            "hit": false
          },
          {
            "score": 0.6517139077186584,
            "answer": "mediterranean",
            "hit": false
          },
          {
            "score": 0.6423898935317993,
            "answer": "naval",
            "hit": false
          },
          {
            "score": 0.6410460472106934,
            "answer": "antarctic",
            "hit": false
          }
        ],
        "set_exclude": [
          "sea"
        ],
        "rank": 56,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6059375330805779
      },
      {
        "question verbose": "What is to snack ",
        "b": "snack",
        "expected answer": [
          "meal",
          "eat"
        ],
        "predictions": [
          {
            "score": 0.8325140476226807,
            "answer": "snacks",
            "hit": false
          },
          {
            "score": 0.7328678369522095,
            "answer": "dessert",
            "hit": false
          },
          {
            "score": 0.724319338798523,
            "answer": "drink",
            "hit": false
          },
          {
            "score": 0.7239433526992798,
            "answer": "beverage",
            "hit": false
          },
          {
            "score": 0.7102850675582886,
            "answer": "breakfast",
            "hit": false
          },
          {
            "score": 0.7079849243164062,
            "answer": "lunch",
            "hit": false
          }
        ],
        "set_exclude": [
          "snack"
        ],
        "rank": 565,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5925672724843025
      },
      {
        "question verbose": "What is to tired ",
        "b": "tired",
        "expected answer": [
          "exhausted",
          "drained"
        ],
        "predictions": [
          {
            "score": 0.7912237644195557,
            "answer": "weary",
            "hit": false
          },
          {
            "score": 0.7661236524581909,
            "answer": "exhausted",
            "hit": true
          },
          {
            "score": 0.7659370303153992,
            "answer": "bored",
            "hit": false
          },
          {
            "score": 0.7419531941413879,
            "answer": "frustrated",
            "hit": false
          },
          {
            "score": 0.7254027128219604,
            "answer": "restless",
            "hit": false
          },
          {
            "score": 0.7215960025787354,
            "answer": "annoyed",
            "hit": false
          }
        ],
        "set_exclude": [
          "tired"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7661237418651581
      }
    ],
    "result": {
      "cnt_questions_correct": 1,
      "cnt_questions_total": 8,
      "accuracy": 0.125
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L07 [synonyms - intensity].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "17a6a82d-d01b-40ac-924d-a9a7758c4d9a",
      "timestamp": "2025-05-17T17:15:35.464384"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to bicycle ",
        "b": "bicycle",
        "expected answer": [
          "bike",
          "wheel",
          "cycle"
        ],
        "predictions": [
          {
            "score": 0.7012900710105896,
            "answer": "cycling",
            "hit": false
          },
          {
            "score": 0.6922284960746765,
            "answer": "cyclists",
            "hit": false
          },
          {
            "score": 0.6816533803939819,
            "answer": "bikes",
            "hit": false
          },
          {
            "score": 0.6804797649383545,
            "answer": "motorcycle",
            "hit": false
          },
          {
            "score": 0.6539093852043152,
            "answer": "transportation",
            "hit": false
          },
          {
            "score": 0.645043134689331,
            "answer": "automobile",
            "hit": false
          }
        ],
        "set_exclude": [
          "bicycle"
        ],
        "rank": 7,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6361175775527954
      },
      {
        "question verbose": "What is to cloth ",
        "b": "cloth",
        "expected answer": [
          "fabric",
          "material",
          "textile"
        ],
        "predictions": [
          {
            "score": 0.7123056054115295,
            "answer": "linen",
            "hit": false
          },
          {
            "score": 0.7023921012878418,
            "answer": "clothes",
            "hit": false
          },
          {
            "score": 0.6965194940567017,
            "answer": "towel",
            "hit": false
          },
          {
            "score": 0.6964493989944458,
            "answer": "fabric",
            "hit": true
          },
          {
            "score": 0.6891558170318604,
            "answer": "garments",
            "hit": false
          },
          {
            "score": 0.6839697957038879,
            "answer": "fabrics",
            "hit": false
          }
        ],
        "set_exclude": [
          "cloth"
        ],
        "rank": 3,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6964493989944458
      },
      {
        "question verbose": "What is to dollars ",
        "b": "dollars",
        "expected answer": [
          "bucks"
        ],
        "predictions": [
          {
            "score": 0.7641975283622742,
            "answer": "bucks",
            "hit": true
          },
          {
            "score": 0.7584294080734253,
            "answer": "money",
            "hit": false
          },
          {
            "score": 0.7131290435791016,
            "answer": "dollar",
            "hit": false
          },
          {
            "score": 0.7103134989738464,
            "answer": "funds",
            "hit": false
          },
          {
            "score": 0.7053713798522949,
            "answer": "cents",
            "hit": false
          },
          {
            "score": 0.6826848983764648,
            "answer": "pounds",
            "hit": false
          }
        ],
        "set_exclude": [
          "dollars"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7641975283622742
      },
      {
        "question verbose": "What is to father ",
        "b": "father",
        "expected answer": [
          "dad",
          "daddy"
        ],
        "predictions": [
          {
            "score": 0.6833895444869995,
            "answer": "dad",
            "hit": true
          },
          {
            "score": 0.6516083478927612,
            "answer": "husband",
            "hit": false
          },
          {
            "score": 0.6487746238708496,
            "answer": "grandfather",
            "hit": false
          },
          {
            "score": 0.6458165049552917,
            "answer": "wife",
            "hit": false
          },
          {
            "score": 0.6374301910400391,
            "answer": "master",
            "hit": false
          },
          {
            "score": 0.6366225481033325,
            "answer": "mother",
            "hit": false
          }
        ],
        "set_exclude": [
          "father"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6833895444869995
      },
      {
        "question verbose": "What is to help ",
        "b": "help",
        "expected answer": [
          "aid",
          "assist"
        ],
        "predictions": [
          {
            "score": 0.6916311979293823,
            "answer": "please",
            "hit": false
          },
          {
            "score": 0.687792181968689,
            "answer": "give",
            "hit": false
          },
          {
            "score": 0.6779400110244751,
            "answer": "support",
            "hit": false
          },
          {
            "score": 0.6771010160446167,
            "answer": "find",
            "hit": false
          },
          {
            "score": 0.6711591482162476,
            "answer": "save",
            "hit": false
          },
          {
            "score": 0.6667426824569702,
            "answer": "thank",
            "hit": false
          }
        ],
        "set_exclude": [
          "help"
        ],
        "rank": 560,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5761934518814087
      },
      {
        "question verbose": "What is to intelligent ",
        "b": "intelligent",
        "expected answer": [
          "clever",
          "smart"
        ],
        "predictions": [
          {
            "score": 0.6398752331733704,
            "answer": "automatic",
            "hit": false
          },
          {
            "score": 0.6308348178863525,
            "answer": "adaptive",
            "hit": false
          },
          {
            "score": 0.6287781000137329,
            "answer": "smarter",
            "hit": false
          },
          {
            "score": 0.626443088054657,
            "answer": "cognitive",
            "hit": false
          },
          {
            "score": 0.6233142614364624,
            "answer": "functional",
            "hit": false
          },
          {
            "score": 0.6204093098640442,
            "answer": "artificial",
            "hit": false
          }
        ],
        "set_exclude": [
          "intelligent"
        ],
        "rank": 39,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5950075760483742
      },
      {
        "question verbose": "What is to jewel ",
        "b": "jewel",
        "expected answer": [
          "gem",
          "stone"
        ],
        "predictions": [
          {
            "score": 0.7278748750686646,
            "answer": "jewelry",
            "hit": false
          },
          {
            "score": 0.6727005243301392,
            "answer": "jewels",
            "hit": false
          },
          {
            "score": 0.6482741832733154,
            "answer": "jew",
            "hit": false
          },
          {
            "score": 0.6286354064941406,
            "answer": "mason",
            "hit": false
          },
          {
            "score": 0.6254984140396118,
            "answer": "gem",
            "hit": true
          },
          {
            "score": 0.6226124167442322,
            "answer": "gift",
            "hit": false
          }
        ],
        "set_exclude": [
          "jewel"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.625498428940773
      },
      {
        "question verbose": "What is to monument ",
        "b": "monument",
        "expected answer": [
          "memorial"
        ],
        "predictions": [
          {
            "score": 0.8209512829780579,
            "answer": "monuments",
            "hit": false
          },
          {
            "score": 0.7528899908065796,
            "answer": "memorial",
            "hit": true
          },
          {
            "score": 0.7094945311546326,
            "answer": "cemetery",
            "hit": false
          },
          {
            "score": 0.7033967971801758,
            "answer": "statues",
            "hit": false
          },
          {
            "score": 0.6955282092094421,
            "answer": "sculpture",
            "hit": false
          },
          {
            "score": 0.6852729320526123,
            "answer": "museum",
            "hit": false
          }
        ],
        "set_exclude": [
          "monument"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7528899908065796
      },
      {
        "question verbose": "What is to new ",
        "b": "new",
        "expected answer": [
          "modern",
          "recent"
        ],
        "predictions": [
          {
            "score": 0.8250872492790222,
            "answer": "newly",
            "hit": false
          },
          {
            "score": 0.7484014630317688,
            "answer": "newer",
            "hit": false
          },
          {
            "score": 0.7464932799339294,
            "answer": "newest",
            "hit": false
          },
          {
            "score": 0.7420703768730164,
            "answer": "fresh",
            "hit": false
          },
          {
            "score": 0.7044582366943359,
            "answer": "unique",
            "hit": false
          },
          {
            "score": 0.6987857222557068,
            "answer": "additional",
            "hit": false
          }
        ],
        "set_exclude": [
          "new"
        ],
        "rank": 10767,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.4598658159375191
      },
      {
        "question verbose": "What is to package ",
        "b": "package",
        "expected answer": [
          "parcel",
          "pack",
          "packet",
          "bundle"
        ],
        "predictions": [
          {
            "score": 0.6801313161849976,
            "answer": "packages",
            "hit": false
          },
          {
            "score": 0.6557272672653198,
            "answer": "installation",
            "hit": false
          },
          {
            "score": 0.6543872952461243,
            "answer": "item",
            "hit": false
          },
          {
            "score": 0.648072361946106,
            "answer": "output",
            "hit": false
          },
          {
            "score": 0.6475679874420166,
            "answer": "spec",
            "hit": false
          },
          {
            "score": 0.6461677551269531,
            "answer": "device",
            "hit": false
          }
        ],
        "set_exclude": [
          "package"
        ],
        "rank": 24,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5507334843277931
      },
      {
        "question verbose": "What is to railway ",
        "b": "railway",
        "expected answer": [
          "railroad"
        ],
        "predictions": [
          {
            "score": 0.7248879671096802,
            "answer": "railroad",
            "hit": true
          },
          {
            "score": 0.6616326570510864,
            "answer": "rail",
            "hit": false
          },
          {
            "score": 0.6551742553710938,
            "answer": "transport",
            "hit": false
          },
          {
            "score": 0.6444460153579712,
            "answer": "transportation",
            "hit": false
          },
          {
            "score": 0.6326276063919067,
            "answer": "rural",
            "hit": false
          },
          {
            "score": 0.6314143538475037,
            "answer": "maritime",
            "hit": false
          }
        ],
        "set_exclude": [
          "railway"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7248879671096802
      },
      {
        "question verbose": "What is to rational ",
        "b": "rational",
        "expected answer": [
          "logical",
          "coherent",
          "reasonable",
          "sane"
        ],
        "predictions": [
          {
            "score": 0.6746823787689209,
            "answer": "irrational",
            "hit": false
          },
          {
            "score": 0.6452170610427856,
            "answer": "cognitive",
            "hit": false
          },
          {
            "score": 0.6339215040206909,
            "answer": "moral",
            "hit": false
          },
          {
            "score": 0.6240052580833435,
            "answer": "stupid",
            "hit": false
          },
          {
            "score": 0.6229797601699829,
            "answer": "sane",
            "hit": true
          },
          {
            "score": 0.6177810430526733,
            "answer": "belief",
            "hit": false
          }
        ],
        "set_exclude": [
          "rational"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6151686236262321
      },
      {
        "question verbose": "What is to reasonable ",
        "b": "reasonable",
        "expected answer": [
          "sensible"
        ],
        "predictions": [
          {
            "score": 0.8360873460769653,
            "answer": "reasonably",
            "hit": false
          },
          {
            "score": 0.798262894153595,
            "answer": "sensible",
            "hit": true
          },
          {
            "score": 0.7798066735267639,
            "answer": "plausible",
            "hit": false
          },
          {
            "score": 0.7667458653450012,
            "answer": "decent",
            "hit": false
          },
          {
            "score": 0.7661712765693665,
            "answer": "feasible",
            "hit": false
          },
          {
            "score": 0.7473922967910767,
            "answer": "unreasonable",
            "hit": false
          }
        ],
        "set_exclude": [
          "reasonable"
        ],
        "rank": 1,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7982629239559174
      },
      {
        "question verbose": "What is to rock ",
        "b": "rock",
        "expected answer": [
          "stone"
        ],
        "predictions": [
          {
            "score": 0.6580026149749756,
            "answer": "pop",
            "hit": false
          },
          {
            "score": 0.6475369930267334,
            "answer": "brock",
            "hit": false
          },
          {
            "score": 0.6473240852355957,
            "answer": "mountain",
            "hit": false
          },
          {
            "score": 0.6460705399513245,
            "answer": "wood",
            "hit": false
          },
          {
            "score": 0.6418930292129517,
            "answer": "beach",
            "hit": false
          },
          {
            "score": 0.6392319202423096,
            "answer": "rocks",
            "hit": false
          }
        ],
        "set_exclude": [
          "rock"
        ],
        "rank": 1103,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5548895597457886
      },
      {
        "question verbose": "What is to sofa ",
        "b": "sofa",
        "expected answer": [
          "couch",
          "lounge"
        ],
        "predictions": [
          {
            "score": 0.7272986769676208,
            "answer": "mattress",
            "hit": false
          },
          {
            "score": 0.7044858336448669,
            "answer": "furniture",
            "hit": false
          },
          {
            "score": 0.7008352279663086,
            "answer": "carpet",
            "hit": false
          },
          {
            "score": 0.6962012648582458,
            "answer": "fridge",
            "hit": false
          },
          {
            "score": 0.6959596276283264,
            "answer": "bedroom",
            "hit": false
          },
          {
            "score": 0.6933633089065552,
            "answer": "pillow",
            "hit": false
          }
        ],
        "set_exclude": [
          "sofa"
        ],
        "rank": 11,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5534166283905506
      },
      {
        "question verbose": "What is to style ",
        "b": "style",
        "expected answer": [
          "manner",
          "mode",
          "fashion",
          "way"
        ],
        "predictions": [
          {
            "score": 0.6632148027420044,
            "answer": "theme",
            "hit": false
          },
          {
            "score": 0.6503753662109375,
            "answer": "styles",
            "hit": false
          },
          {
            "score": 0.6482090950012207,
            "answer": "design",
            "hit": false
          },
          {
            "score": 0.6476407051086426,
            "answer": "classic",
            "hit": false
          },
          {
            "score": 0.6455032825469971,
            "answer": "form",
            "hit": false
          },
          {
            "score": 0.6383616328239441,
            "answer": "custom",
            "hit": false
          }
        ],
        "set_exclude": [
          "style"
        ],
        "rank": 26,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5214330945163965
      }
    ],
    "result": {
      "cnt_questions_correct": 3,
      "cnt_questions_total": 16,
      "accuracy": 0.1875
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L08 [synonyms - exact].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "309125f2-fcb7-4067-bf28-f4281140b463",
      "timestamp": "2025-05-17T17:15:35.491874"
    }
  },
  {
    "details": [
      {
        "question verbose": "What is to after ",
        "b": "after",
        "expected answer": [
          "before",
          "earlier",
          "previously"
        ],
        "predictions": [
          {
            "score": 0.814337968826294,
            "answer": "during",
            "hit": false
          },
          {
            "score": 0.8060364723205566,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.7776185274124146,
            "answer": "while",
            "hit": false
          },
          {
            "score": 0.7522277235984802,
            "answer": "then",
            "hit": false
          },
          {
            "score": 0.7215768098831177,
            "answer": "several",
            "hit": false
          },
          {
            "score": 0.7191897630691528,
            "answer": "almost",
            "hit": false
          }
        ],
        "set_exclude": [
          "after"
        ],
        "rank": 56,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5879052877426147
      },
      {
        "question verbose": "What is to ahead ",
        "b": "ahead",
        "expected answer": [
          "behind",
          "rear",
          "after",
          "tail",
          "beforehand"
        ],
        "predictions": [
          {
            "score": 0.6752432584762573,
            "answer": "away",
            "hit": false
          },
          {
            "score": 0.6629902720451355,
            "answer": "along",
            "hit": false
          },
          {
            "score": 0.6585994958877563,
            "answer": "beyond",
            "hit": false
          },
          {
            "score": 0.6585978269577026,
            "answer": "already",
            "hit": false
          },
          {
            "score": 0.6579102873802185,
            "answer": "below",
            "hit": false
          },
          {
            "score": 0.6483226418495178,
            "answer": "following",
            "hit": false
          }
        ],
        "set_exclude": [
          "ahead"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.608841598033905
      },
      {
        "question verbose": "What is to anterior ",
        "b": "anterior",
        "expected answer": [
          "posterior"
        ],
        "predictions": [
          {
            "score": 0.8211698532104492,
            "answer": "posterior",
            "hit": true
          },
          {
            "score": 0.7695885896682739,
            "answer": "medial",
            "hit": false
          },
          {
            "score": 0.7311570644378662,
            "answer": "dorsal",
            "hit": false
          },
          {
            "score": 0.7261311411857605,
            "answer": "lateral",
            "hit": false
          },
          {
            "score": 0.6922810077667236,
            "answer": "abdominal",
            "hit": false
          },
          {
            "score": 0.6806568503379822,
            "answer": "abdomen",
            "hit": false
          }
        ],
        "set_exclude": [
          "anterior"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.8211698532104492
      },
      {
        "question verbose": "What is to before ",
        "b": "before",
        "expected answer": [
          "after",
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "ahead"
        ],
        "predictions": [
          {
            "score": 0.7714279294013977,
            "answer": "prior",
            "hit": false
          },
          {
            "score": 0.7557010054588318,
            "answer": "beforehand",
            "hit": false
          },
          {
            "score": 0.731500506401062,
            "answer": "when",
            "hit": false
          },
          {
            "score": 0.6972242593765259,
            "answer": "shortly",
            "hit": false
          },
          {
            "score": 0.6945254802703857,
            "answer": "afterwards",
            "hit": true
          },
          {
            "score": 0.6798664331436157,
            "answer": "afterward",
            "hit": true
          }
        ],
        "set_exclude": [
          "before"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6123397499322891
      },
      {
        "question verbose": "What is to beginning ",
        "b": "beginning",
        "expected answer": [
          "end",
          "terminal",
          "ending",
          "last",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.6966179609298706,
            "answer": "following",
            "hit": false
          },
          {
            "score": 0.6856988668441772,
            "answer": "after",
            "hit": false
          },
          {
            "score": 0.679866373538971,
            "answer": "during",
            "hit": false
          },
          {
            "score": 0.6764674782752991,
            "answer": "begins",
            "hit": false
          },
          {
            "score": 0.6742791533470154,
            "answer": "ending",
            "hit": true
          },
          {
            "score": 0.6700394749641418,
            "answer": "coming",
            "hit": false
          }
        ],
        "set_exclude": [
          "beginning"
        ],
        "rank": 4,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6118340864777565
      },
      {
        "question verbose": "What is to dead ",
        "b": "dead",
        "expected answer": [
          "alive",
          "living",
          "live"
        ],
        "predictions": [
          {
            "score": 0.7737138867378235,
            "answer": "deceased",
            "hit": false
          },
          {
            "score": 0.7204866409301758,
            "answer": "lifeless",
            "hit": false
          },
          {
            "score": 0.7107874751091003,
            "answer": "killed",
            "hit": false
          },
          {
            "score": 0.7073540091514587,
            "answer": "corpse",
            "hit": false
          },
          {
            "score": 0.6842379570007324,
            "answer": "slain",
            "hit": false
          },
          {
            "score": 0.683809757232666,
            "answer": "murdered",
            "hit": false
          }
        ],
        "set_exclude": [
          "dead"
        ],
        "rank": 42,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5630016773939133
      },
      {
        "question verbose": "What is to dive ",
        "b": "dive",
        "expected answer": [
          "emerge"
        ],
        "predictions": [
          {
            "score": 0.6738863587379456,
            "answer": "diving",
            "hit": false
          },
          {
            "score": 0.6517500281333923,
            "answer": "drop",
            "hit": false
          },
          {
            "score": 0.6391608715057373,
            "answer": "beach",
            "hit": false
          },
          {
            "score": 0.6349627375602722,
            "answer": "bounce",
            "hit": false
          },
          {
            "score": 0.6319301128387451,
            "answer": "depth",
            "hit": false
          },
          {
            "score": 0.6319020986557007,
            "answer": "surf",
            "hit": false
          }
        ],
        "set_exclude": [
          "dive"
        ],
        "rank": 10851,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.46988473646342754
      },
      {
        "question verbose": "What is to fall ",
        "b": "fall",
        "expected answer": [
          "rise",
          "upward",
          "climb"
        ],
        "predictions": [
          {
            "score": 0.7559589147567749,
            "answer": "spring",
            "hit": false
          },
          {
            "score": 0.7227672338485718,
            "answer": "summer",
            "hit": false
          },
          {
            "score": 0.7175852060317993,
            "answer": "winter",
            "hit": false
          },
          {
            "score": 0.6620069146156311,
            "answer": "falls",
            "hit": false
          },
          {
            "score": 0.6613954305648804,
            "answer": "autumn",
            "hit": false
          },
          {
            "score": 0.6532151103019714,
            "answer": "september",
            "hit": false
          }
        ],
        "set_exclude": [
          "fall"
        ],
        "rank": 1098,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5583623647689819
      },
      {
        "question verbose": "What is to first ",
        "b": "first",
        "expected answer": [
          "last",
          "end",
          "terminal",
          "ending",
          "final",
          "finish",
          "finale",
          "conclusion"
        ],
        "predictions": [
          {
            "score": 0.6883894801139832,
            "answer": "next",
            "hit": false
          },
          {
            "score": 0.672331690788269,
            "answer": "only",
            "hit": false
          },
          {
            "score": 0.669050931930542,
            "answer": "best",
            "hit": false
          },
          {
            "score": 0.6635240316390991,
            "answer": "not",
            "hit": false
          },
          {
            "score": 0.6592873334884644,
            "answer": "and",
            "hit": false
          },
          {
            "score": 0.6555831432342529,
            "answer": "one",
            "hit": false
          }
        ],
        "set_exclude": [
          "first"
        ],
        "rank": 45,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6094079464673996
      },
      {
        "question verbose": "What is to input ",
        "b": "input",
        "expected answer": [
          "output"
        ],
        "predictions": [
          {
            "score": 0.7938677668571472,
            "answer": "output",
            "hit": true
          },
          {
            "score": 0.7055056691169739,
            "answer": "inputs",
            "hit": false
          },
          {
            "score": 0.6935125589370728,
            "answer": "feed",
            "hit": false
          },
          {
            "score": 0.680280327796936,
            "answer": "download",
            "hit": false
          },
          {
            "score": 0.6736280918121338,
            "answer": "device",
            "hit": false
          },
          {
            "score": 0.6665809154510498,
            "answer": "field",
            "hit": false
          }
        ],
        "set_exclude": [
          "input"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7938677668571472
      },
      {
        "question verbose": "What is to inside ",
        "b": "inside",
        "expected answer": [
          "outside",
          "exterior",
          "out"
        ],
        "predictions": [
          {
            "score": 0.7647891044616699,
            "answer": "underneath",
            "hit": false
          },
          {
            "score": 0.7073833346366882,
            "answer": "upstairs",
            "hit": false
          },
          {
            "score": 0.7025507688522339,
            "answer": "beneath",
            "hit": false
          },
          {
            "score": 0.6984009742736816,
            "answer": "indoors",
            "hit": false
          },
          {
            "score": 0.6766945123672485,
            "answer": "downstairs",
            "hit": false
          },
          {
            "score": 0.6720325946807861,
            "answer": "exterior",
            "hit": true
          }
        ],
        "set_exclude": [
          "inside"
        ],
        "rank": 5,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6275656670331955
      },
      {
        "question verbose": "What is to internal ",
        "b": "internal",
        "expected answer": [
          "external",
          "outer",
          "outside"
        ],
        "predictions": [
          {
            "score": 0.6346174478530884,
            "answer": "external",
            "hit": true
          },
          {
            "score": 0.6334547996520996,
            "answer": "micro",
            "hit": false
          },
          {
            "score": 0.628129243850708,
            "answer": "internally",
            "hit": false
          },
          {
            "score": 0.6251049041748047,
            "answer": "false",
            "hit": false
          },
          {
            "score": 0.6212838888168335,
            "answer": "generic",
            "hit": false
          },
          {
            "score": 0.620485782623291,
            "answer": "intern",
            "hit": false
          }
        ],
        "set_exclude": [
          "internal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6346174627542496
      },
      {
        "question verbose": "What is to mortal ",
        "b": "mortal",
        "expected answer": [
          "immortal"
        ],
        "predictions": [
          {
            "score": 0.6801166534423828,
            "answer": "immortal",
            "hit": true
          },
          {
            "score": 0.6730437278747559,
            "answer": "mortality",
            "hit": false
          },
          {
            "score": 0.6568461656570435,
            "answer": "lethal",
            "hit": false
          },
          {
            "score": 0.6546658873558044,
            "answer": "heavenly",
            "hit": false
          },
          {
            "score": 0.6466493606567383,
            "answer": "terrestrial",
            "hit": false
          },
          {
            "score": 0.6410934925079346,
            "answer": "tragic",
            "hit": false
          }
        ],
        "set_exclude": [
          "mortal"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.680116668343544
      },
      {
        "question verbose": "What is to occupied ",
        "b": "occupied",
        "expected answer": [
          "vacant",
          "free"
        ],
        "predictions": [
          {
            "score": 0.776401162147522,
            "answer": "occupying",
            "hit": false
          },
          {
            "score": 0.7574912309646606,
            "answer": "inhabited",
            "hit": false
          },
          {
            "score": 0.7293128967285156,
            "answer": "occupies",
            "hit": false
          },
          {
            "score": 0.7258229851722717,
            "answer": "occupation",
            "hit": false
          },
          {
            "score": 0.6994253993034363,
            "answer": "populated",
            "hit": false
          },
          {
            "score": 0.6945998668670654,
            "answer": "invaded",
            "hit": false
          }
        ],
        "set_exclude": [
          "occupied"
        ],
        "rank": 10,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6726313829421997
      },
      {
        "question verbose": "What is to over ",
        "b": "over",
        "expected answer": [
          "under",
          "below",
          "beneath"
        ],
        "predictions": [
          {
            "score": 0.6489723324775696,
            "answer": "back",
            "hit": false
          },
          {
            "score": 0.6367493271827698,
            "answer": "overs",
            "hit": false
          },
          {
            "score": 0.6318393349647522,
            "answer": "offs",
            "hit": false
          },
          {
            "score": 0.6290004849433899,
            "answer": "more",
            "hit": false
          },
          {
            "score": 0.6274906396865845,
            "answer": "for",
            "hit": false
          },
          {
            "score": 0.619246780872345,
            "answer": "including",
            "hit": false
          }
        ],
        "set_exclude": [
          "over"
        ],
        "rank": 1248,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5378028862178326
      },
      {
        "question verbose": "What is to previously ",
        "b": "previously",
        "expected answer": [
          "subsequently",
          "later",
          "afterwards",
          "afterward",
          "after",
          "subsequent"
        ],
        "predictions": [
          {
            "score": 0.7068126797676086,
            "answer": "typically",
            "hit": false
          },
          {
            "score": 0.7010093331336975,
            "answer": "during",
            "hit": false
          },
          {
            "score": 0.698101282119751,
            "answer": "already",
            "hit": false
          },
          {
            "score": 0.6956087350845337,
            "answer": "several",
            "hit": false
          },
          {
            "score": 0.6938217282295227,
            "answer": "essentially",
            "hit": false
          },
          {
            "score": 0.6920226812362671,
            "answer": "unlike",
            "hit": false
          }
        ],
        "set_exclude": [
          "previously"
        ],
        "rank": 12,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5473464131355286
      },
      {
        "question verbose": "What is to proceed ",
        "b": "proceed",
        "expected answer": [
          "retreat",
          "return"
        ],
        "predictions": [
          {
            "score": 0.7797430157661438,
            "answer": "proceeded",
            "hit": false
          },
          {
            "score": 0.7356414794921875,
            "answer": "continue",
            "hit": false
          },
          {
            "score": 0.7351353168487549,
            "answer": "commence",
            "hit": false
          },
          {
            "score": 0.7258355617523193,
            "answer": "proceeding",
            "hit": false
          },
          {
            "score": 0.7109932899475098,
            "answer": "proceeds",
            "hit": false
          },
          {
            "score": 0.699952244758606,
            "answer": "pursue",
            "hit": false
          }
        ],
        "set_exclude": [
          "proceed"
        ],
        "rank": 695,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5748308449983597
      },
      {
        "question verbose": "What is to rise ",
        "b": "rise",
        "expected answer": [
          "sink",
          "drop",
          "fall"
        ],
        "predictions": [
          {
            "score": 0.7548982501029968,
            "answer": "risen",
            "hit": false
          },
          {
            "score": 0.7535970211029053,
            "answer": "increase",
            "hit": false
          },
          {
            "score": 0.7423715591430664,
            "answer": "decline",
            "hit": false
          },
          {
            "score": 0.7293286323547363,
            "answer": "surge",
            "hit": false
          },
          {
            "score": 0.7289859056472778,
            "answer": "emergence",
            "hit": false
          },
          {
            "score": 0.7136997580528259,
            "answer": "ascent",
            "hit": false
          }
        ],
        "set_exclude": [
          "rise"
        ],
        "rank": 120,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6221054568886757
      },
      {
        "question verbose": "What is to south ",
        "b": "south",
        "expected answer": [
          "north"
        ],
        "predictions": [
          {
            "score": 0.7234753370285034,
            "answer": "east",
            "hit": false
          },
          {
            "score": 0.6688000559806824,
            "answer": "southern",
            "hit": false
          },
          {
            "score": 0.6313629150390625,
            "answer": "northeast",
            "hit": false
          },
          {
            "score": 0.6277518272399902,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.6240788698196411,
            "answer": "super",
            "hit": false
          },
          {
            "score": 0.6233283281326294,
            "answer": "west",
            "hit": false
          }
        ],
        "set_exclude": [
          "south"
        ],
        "rank": 147,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5866988375782967
      },
      {
        "question verbose": "What is to southeast ",
        "b": "southeast",
        "expected answer": [
          "southwest",
          "northeast"
        ],
        "predictions": [
          {
            "score": 0.7810859084129333,
            "answer": "southwest",
            "hit": true
          },
          {
            "score": 0.7218081951141357,
            "answer": "north",
            "hit": false
          },
          {
            "score": 0.7193259000778198,
            "answer": "thailand",
            "hit": false
          },
          {
            "score": 0.7057188749313354,
            "answer": "northeast",
            "hit": true
          },
          {
            "score": 0.6938060522079468,
            "answer": "indonesia",
            "hit": false
          },
          {
            "score": 0.6927700638771057,
            "answer": "midwest",
            "hit": false
          }
        ],
        "set_exclude": [
          "southeast"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7810859680175781
      },
      {
        "question verbose": "What is to toward ",
        "b": "toward",
        "expected answer": [
          "away",
          "off",
          "forth",
          "aside"
        ],
        "predictions": [
          {
            "score": 0.9138488173484802,
            "answer": "towards",
            "hit": false
          },
          {
            "score": 0.6774014234542847,
            "answer": "against",
            "hit": false
          },
          {
            "score": 0.652536153793335,
            "answer": "upward",
            "hit": false
          },
          {
            "score": 0.6482023000717163,
            "answer": "aimed",
            "hit": false
          },
          {
            "score": 0.6471737623214722,
            "answer": "regarding",
            "hit": false
          },
          {
            "score": 0.6460506319999695,
            "answer": "downward",
            "hit": false
          }
        ],
        "set_exclude": [
          "toward"
        ],
        "rank": 130,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.5613564997911453
      },
      {
        "question verbose": "What is to true ",
        "b": "true",
        "expected answer": [
          "false",
          "incorrect",
          "wrong",
          "mistaken"
        ],
        "predictions": [
          {
            "score": 0.7048802375793457,
            "answer": "false",
            "hit": true
          },
          {
            "score": 0.6986775398254395,
            "answer": "indeed",
            "hit": false
          },
          {
            "score": 0.6915318965911865,
            "answer": "pure",
            "hit": false
          },
          {
            "score": 0.6892000436782837,
            "answer": "the",
            "hit": false
          },
          {
            "score": 0.686077356338501,
            "answer": "very",
            "hit": false
          },
          {
            "score": 0.6799418330192566,
            "answer": "two",
            "hit": false
          }
        ],
        "set_exclude": [
          "true"
        ],
        "rank": 0,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.7048802226781845
      },
      {
        "question verbose": "What is to west ",
        "b": "west",
        "expected answer": [
          "east"
        ],
        "predictions": [
          {
            "score": 0.8340924382209778,
            "answer": "northwest",
            "hit": false
          },
          {
            "score": 0.8209320306777954,
            "answer": "northeast",
            "hit": false
          },
          {
            "score": 0.7692774534225464,
            "answer": "eastern",
            "hit": false
          },
          {
            "score": 0.7344571352005005,
            "answer": "northern",
            "hit": false
          },
          {
            "score": 0.7011089324951172,
            "answer": "north",
            "hit": false
          },
          {
            "score": 0.6882138252258301,
            "answer": "inland",
            "hit": false
          }
        ],
        "set_exclude": [
          "west"
        ],
        "rank": 9,
        "landing_b": true,
        "landing_b_prime": false,
        "landing_a": false,
        "landing_a_prime": false,
        "distances to correct cosine": 0.6507752239704132
      }
    ],
    "result": {
      "cnt_questions_correct": 6,
      "cnt_questions_total": 23,
      "accuracy": 0.2608695652173913
    },
    "experiment_setup": {
      "dataset": {
        "_base_path": "BATS_shared",
        "_class": "vecto.data.base.Dataset",
        "name": "BATS_shared"
      },
      "embeddings": {
        "_class": "vecto.embeddings.legacy_w2v.ModelW2V",
        "normalized": true
      },
      "category": "4_Lexicographic_semantics",
      "subcategory": "L10 [antonyms - binary].txt",
      "task": "word_analogy",
      "default_measurement": "accuracy",
      "method": "3CosAvg",
      "uuid": "67630ca6-f294-40d9-ac79-bb71869ee19f",
      "timestamp": "2025-05-17T17:15:35.550178"
    }
  }
]